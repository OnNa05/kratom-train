{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "Adam = tf.keras.optimizers.Adam\n",
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "ModelCheckpoint = tf.keras.callbacks.ModelCheckpoint\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten , Conv2D, MaxPool2D\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly import subplots\n",
    "import plotly\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 28 # ปรับขนาดรูป\n",
    "num_classes = 8\n",
    "trainpath = '/Users/onna/Documents/krotom-train/img-eng/train'\n",
    "testpath = '/Users/onna/Documents/krotom-train/img-eng/test'\n",
    "trainImg = [trainpath + \"/\"+ f for f in listdir(trainpath)]\n",
    "testImg = [testpath + \"/\"+ f for f in listdir(testpath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2data(path):\n",
    "    rawImgs = []\n",
    "    labels = []\n",
    "\n",
    "    for imagePath in (path):\n",
    "        for item in tqdm(listdir(imagePath)):\n",
    "            file = join(imagePath, item)\n",
    "            \n",
    "            if file[-1] =='g':\n",
    "                img = cv2.imread(file , cv2.COLOR_BGR2RGB) # ปรับสีรูป\n",
    "                img = cv2.resize(img ,(width,width))\n",
    "                rawImgs.append(img)\n",
    "\n",
    "                name =  imagePath.split('/')\n",
    "                l = name[len(name) - 1]\n",
    "            #['Boiled_leaves', 'Green_stalk_GradeA', 'Green_stalk_GradeB', 'Green_stalk_GradeC', 'JUMBO', 'Red_stalk_GradeA', 'Red_stalk_GradeB', 'Red_stalk_GradeC']\n",
    "            if l == 'Boiled_leaves':\n",
    "                labels.append([1,0,0,0,0,0,0,0])         \n",
    "            elif l == 'Green_stalk_GradeA':\n",
    "                labels.append([0,1,0,0,0,0,0,0])  \n",
    "            elif l == 'Green_stalk_GradeB':\n",
    "                labels.append([0,0,1,0,0,0,0,0])\n",
    "            elif l == 'Green_stalk_GradeC':\n",
    "                labels.append([0,0,0,1,0,0,0,0])\n",
    "            elif l == 'JUMBO':\n",
    "                labels.append([0,0,0,0,1,0,0,0])\n",
    "            elif l == 'Red_stalk_GradeA':\n",
    "                labels.append([0,0,0,0,0,1,0,0])\n",
    "            elif l == 'Red_stalk_GradeB':\n",
    "                labels.append([0,0,0,0,0,0,1,0])\n",
    "            elif l == 'Red_stalk_GradeC':\n",
    "                labels.append([0,0,0,0,0,0,0,1])\n",
    "    return rawImgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 105.12it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 100.70it/s]\n",
      "100%|██████████| 394/394 [00:03<00:00, 110.83it/s]\n",
      "100%|██████████| 429/429 [00:03<00:00, 108.17it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 119.40it/s]\n",
      "100%|██████████| 176/176 [00:01<00:00, 98.50it/s] \n",
      "100%|██████████| 146/146 [00:01<00:00, 118.79it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 119.57it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = img2data(trainImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 97.72it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 124.94it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.00it/s]\n",
      "100%|██████████| 104/104 [00:00<00:00, 136.57it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 129.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 97.63it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 123.94it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 94.72it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = img2data(testImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1381, 28, 28, 3), (1381, 8), (352, 28, 28, 3), (352, 8))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "# test_data = x_test.reshape((x_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8\n",
    "VAL_SIZE = 0.2\n",
    "RANDOM_STATE = 99\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1104, 28, 28, 3), (277, 28, 28, 3), (1104, 8), (277, 8))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=VAL_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trace(x,y,ylabel,color):\n",
    "        trace = go.Scatter(\n",
    "            x = x,y = y,\n",
    "            name=ylabel,\n",
    "            marker=dict(color=color),\n",
    "            mode = \"markers+lines\",\n",
    "            text=x\n",
    "        )\n",
    "        return trace\n",
    "    \n",
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['accuracy']\n",
    "    val_acc = hist['val_accuracy']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = list(range(1,len(acc)+1))\n",
    "    \n",
    "    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n",
    "    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n",
    "    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n",
    "    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n",
    "   \n",
    "    fig = subplots.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n",
    "                                                             'Training and validation loss'))\n",
    "    fig.append_trace(trace_ta,1,1)\n",
    "    fig.append_trace(trace_va,1,1)\n",
    "    fig.append_trace(trace_tl,1,2)\n",
    "    fig.append_trace(trace_vl,1,2)\n",
    "    fig['layout']['xaxis'].update(title = 'Epoch')\n",
    "    fig['layout']['xaxis2'].update(title = 'Epoch')\n",
    "    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n",
    "    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n",
    "\n",
    "    plotly.offline.iplot(fig, filename='accuracy-loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=0.05,    #Randomly rotate images in the range\n",
    "        zoom_range=0.2,         #Randomly zoom image\n",
    "        width_shift_range=0.1,  #Randomly shift images horizontally\n",
    "        height_shift_range=0.1, #Randomly shift images vertically\n",
    "        shear_range=0.05        #Randomly shear images\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#1. CNN LAYER\n",
    "model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', input_shape=(width, width, 3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#2. CNN LAYER\n",
    "model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#3. CNN LAYER\n",
    "model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#4. CNN LAYER\n",
    "model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "#FULLY CONNECTED LAYER\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.30))\n",
    "\n",
    "#OUTPUT LAYER\n",
    "model.add(tf.keras.layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               803072    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 872,488\n",
      "Trainable params: 871,592\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ถ้า val_loss ไม่น้อยลง {patience} epoch ติด จะทำการ lr = lr * {factor} แต่ lr ต่ำสุดไม่เกิน {min_lr}\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.0001)\n",
    "\n",
    "# ตั้งชื่อไฟล์ที่จะเซฟ\n",
    "filepath=\"weights_best.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, rlrp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.4687 - accuracy: 0.1851\n",
      "Epoch 1: val_loss improved from inf to 2.06203, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 2s 266ms/step - loss: 2.4687 - accuracy: 0.1851 - val_loss: 2.0620 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8682 - accuracy: 0.3915\n",
      "Epoch 2: val_loss improved from 2.06203 to 1.94376, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.8682 - accuracy: 0.3915 - val_loss: 1.9438 - val_accuracy: 0.3141 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6659 - accuracy: 0.4528\n",
      "Epoch 3: val_loss improved from 1.94376 to 1.88900, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 1.6659 - accuracy: 0.4528 - val_loss: 1.8890 - val_accuracy: 0.3141 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5647 - accuracy: 0.4870\n",
      "Epoch 4: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 1.5647 - accuracy: 0.4870 - val_loss: 1.9846 - val_accuracy: 0.3141 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4801 - accuracy: 0.5322\n",
      "Epoch 5: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.4801 - accuracy: 0.5322 - val_loss: 2.3035 - val_accuracy: 0.3141 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4175 - accuracy: 0.5318\n",
      "Epoch 6: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 1.4175 - accuracy: 0.5318 - val_loss: 2.7125 - val_accuracy: 0.3141 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4174 - accuracy: 0.5307\n",
      "Epoch 7: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.4174 - accuracy: 0.5307 - val_loss: 3.0682 - val_accuracy: 0.3141 - lr: 1.0000e-04\n",
      "Epoch 8/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4424 - accuracy: 0.5318\n",
      "Epoch 8: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 1.4424 - accuracy: 0.5318 - val_loss: 3.3845 - val_accuracy: 0.3141 - lr: 1.0000e-04\n",
      "Epoch 9/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4012 - accuracy: 0.5307\n",
      "Epoch 9: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 1.4012 - accuracy: 0.5307 - val_loss: 3.6709 - val_accuracy: 0.3141 - lr: 1.0000e-04\n",
      "Epoch 10/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3541 - accuracy: 0.5330\n",
      "Epoch 10: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 1.3541 - accuracy: 0.5330 - val_loss: 3.9325 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 11/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3764 - accuracy: 0.5248\n",
      "Epoch 11: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 1.3764 - accuracy: 0.5248 - val_loss: 4.1690 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 12/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3968 - accuracy: 0.5177\n",
      "Epoch 12: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.3968 - accuracy: 0.5177 - val_loss: 4.3881 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 13/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3681 - accuracy: 0.5578\n",
      "Epoch 13: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.3681 - accuracy: 0.5578 - val_loss: 4.5819 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 14/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4231 - accuracy: 0.5361\n",
      "Epoch 14: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.4231 - accuracy: 0.5361 - val_loss: 4.7634 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 15/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4099 - accuracy: 0.5295\n",
      "Epoch 15: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.4099 - accuracy: 0.5295 - val_loss: 4.9306 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 16/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4072 - accuracy: 0.5293\n",
      "Epoch 16: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.4072 - accuracy: 0.5293 - val_loss: 5.0856 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 17/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3934 - accuracy: 0.5259\n",
      "Epoch 17: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.3934 - accuracy: 0.5259 - val_loss: 5.2195 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 18/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3748 - accuracy: 0.5236\n",
      "Epoch 18: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.3748 - accuracy: 0.5236 - val_loss: 5.3498 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 19/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3860 - accuracy: 0.5401\n",
      "Epoch 19: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.3860 - accuracy: 0.5401 - val_loss: 5.4671 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 20/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3976 - accuracy: 0.5448\n",
      "Epoch 20: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.3976 - accuracy: 0.5448 - val_loss: 5.5842 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 21/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3641 - accuracy: 0.5531\n",
      "Epoch 21: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.3641 - accuracy: 0.5531 - val_loss: 5.6929 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 22/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4116 - accuracy: 0.5307\n",
      "Epoch 22: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4116 - accuracy: 0.5307 - val_loss: 5.7931 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 23/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4238 - accuracy: 0.5200\n",
      "Epoch 23: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.4238 - accuracy: 0.5200 - val_loss: 5.8851 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 24/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3752 - accuracy: 0.5495\n",
      "Epoch 24: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.3752 - accuracy: 0.5495 - val_loss: 5.9674 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 25/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3630 - accuracy: 0.5554\n",
      "Epoch 25: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.3630 - accuracy: 0.5554 - val_loss: 6.0523 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 26/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4610 - accuracy: 0.4953\n",
      "Epoch 26: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 1.4610 - accuracy: 0.4953 - val_loss: 6.1319 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 27/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3543 - accuracy: 0.5330\n",
      "Epoch 27: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.3543 - accuracy: 0.5330 - val_loss: 6.2076 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 28/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3995 - accuracy: 0.5330\n",
      "Epoch 28: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3995 - accuracy: 0.5330 - val_loss: 6.2761 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 29/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3993 - accuracy: 0.5212\n",
      "Epoch 29: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3993 - accuracy: 0.5212 - val_loss: 6.3379 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 30/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3677 - accuracy: 0.5366\n",
      "Epoch 30: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.3677 - accuracy: 0.5366 - val_loss: 6.3943 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 31/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4079 - accuracy: 0.5318\n",
      "Epoch 31: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.4079 - accuracy: 0.5318 - val_loss: 6.4450 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 32/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4101 - accuracy: 0.5271\n",
      "Epoch 32: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4101 - accuracy: 0.5271 - val_loss: 6.4926 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 33/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4774 - accuracy: 0.5236\n",
      "Epoch 33: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.4774 - accuracy: 0.5236 - val_loss: 6.5426 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 34/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3656 - accuracy: 0.5483\n",
      "Epoch 34: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.3656 - accuracy: 0.5483 - val_loss: 6.5651 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 35/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4190 - accuracy: 0.5254\n",
      "Epoch 35: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.4190 - accuracy: 0.5254 - val_loss: 6.6060 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 36/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3476 - accuracy: 0.5531\n",
      "Epoch 36: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.3476 - accuracy: 0.5531 - val_loss: 6.6396 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 37/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3874 - accuracy: 0.5195\n",
      "Epoch 37: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.3874 - accuracy: 0.5195 - val_loss: 6.6776 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 38/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3698 - accuracy: 0.5542\n",
      "Epoch 38: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.3698 - accuracy: 0.5542 - val_loss: 6.7130 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 39/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3409 - accuracy: 0.5401\n",
      "Epoch 39: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.3409 - accuracy: 0.5401 - val_loss: 6.7427 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 40/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3951 - accuracy: 0.5401\n",
      "Epoch 40: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 1.3951 - accuracy: 0.5401 - val_loss: 6.7648 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 41/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3983 - accuracy: 0.5273\n",
      "Epoch 41: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.3983 - accuracy: 0.5273 - val_loss: 6.7935 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 42/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3811 - accuracy: 0.5460\n",
      "Epoch 42: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.3811 - accuracy: 0.5460 - val_loss: 6.8135 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 43/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3643 - accuracy: 0.5495\n",
      "Epoch 43: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.3643 - accuracy: 0.5495 - val_loss: 6.8394 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 44/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3837 - accuracy: 0.5425\n",
      "Epoch 44: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.3837 - accuracy: 0.5425 - val_loss: 6.8545 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 45/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4196 - accuracy: 0.5234\n",
      "Epoch 45: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.4196 - accuracy: 0.5234 - val_loss: 6.8733 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 46/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4419 - accuracy: 0.5488\n",
      "Epoch 46: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.4419 - accuracy: 0.5488 - val_loss: 6.8904 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 47/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3636 - accuracy: 0.5330\n",
      "Epoch 47: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.3636 - accuracy: 0.5330 - val_loss: 6.9032 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 48/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3765 - accuracy: 0.5366\n",
      "Epoch 48: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.3765 - accuracy: 0.5366 - val_loss: 6.9182 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 49/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3890 - accuracy: 0.5271\n",
      "Epoch 49: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3890 - accuracy: 0.5271 - val_loss: 6.9365 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 50/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3599 - accuracy: 0.5472\n",
      "Epoch 50: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3599 - accuracy: 0.5472 - val_loss: 6.9473 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 51/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3523 - accuracy: 0.5430\n",
      "Epoch 51: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 1.3523 - accuracy: 0.5430 - val_loss: 6.9556 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 52/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3292 - accuracy: 0.5472\n",
      "Epoch 52: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.3292 - accuracy: 0.5472 - val_loss: 6.9621 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 53/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3410 - accuracy: 0.5586\n",
      "Epoch 53: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 1.3410 - accuracy: 0.5586 - val_loss: 6.9658 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 54/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3809 - accuracy: 0.5377\n",
      "Epoch 54: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 1.3809 - accuracy: 0.5377 - val_loss: 6.9739 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 55/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3462 - accuracy: 0.5635\n",
      "Epoch 55: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.3462 - accuracy: 0.5635 - val_loss: 6.9730 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 56/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3954 - accuracy: 0.5322\n",
      "Epoch 56: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 1.3954 - accuracy: 0.5322 - val_loss: 6.9761 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 57/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4165 - accuracy: 0.5186\n",
      "Epoch 57: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.4165 - accuracy: 0.5186 - val_loss: 6.9747 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 58/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3828 - accuracy: 0.5413\n",
      "Epoch 58: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.3828 - accuracy: 0.5413 - val_loss: 6.9743 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 59/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3696 - accuracy: 0.5342\n",
      "Epoch 59: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.3696 - accuracy: 0.5342 - val_loss: 6.9689 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 60/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4281 - accuracy: 0.5307\n",
      "Epoch 60: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4281 - accuracy: 0.5307 - val_loss: 6.9606 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 61/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3161 - accuracy: 0.5578\n",
      "Epoch 61: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.3161 - accuracy: 0.5578 - val_loss: 6.9483 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 62/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3546 - accuracy: 0.5448\n",
      "Epoch 62: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.3546 - accuracy: 0.5448 - val_loss: 6.9438 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 63/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3952 - accuracy: 0.5488\n",
      "Epoch 63: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.3952 - accuracy: 0.5488 - val_loss: 6.9351 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 64/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4223 - accuracy: 0.5295\n",
      "Epoch 64: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.4223 - accuracy: 0.5295 - val_loss: 6.9241 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 65/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3677 - accuracy: 0.5389\n",
      "Epoch 65: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.3677 - accuracy: 0.5389 - val_loss: 6.9146 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 66/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4055 - accuracy: 0.5177\n",
      "Epoch 66: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.4055 - accuracy: 0.5177 - val_loss: 6.8980 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 67/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3769 - accuracy: 0.5264\n",
      "Epoch 67: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.3769 - accuracy: 0.5264 - val_loss: 6.8874 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 68/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3509 - accuracy: 0.5448\n",
      "Epoch 68: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.3509 - accuracy: 0.5448 - val_loss: 6.8752 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 69/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2965 - accuracy: 0.5767\n",
      "Epoch 69: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.2965 - accuracy: 0.5767 - val_loss: 6.8679 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 70/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4095 - accuracy: 0.5189\n",
      "Epoch 70: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4095 - accuracy: 0.5189 - val_loss: 6.8528 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 71/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2955 - accuracy: 0.5542\n",
      "Epoch 71: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 1.2955 - accuracy: 0.5542 - val_loss: 6.8321 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 72/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3762 - accuracy: 0.5142\n",
      "Epoch 72: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.3762 - accuracy: 0.5142 - val_loss: 6.8244 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 73/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4243 - accuracy: 0.5118\n",
      "Epoch 73: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.4243 - accuracy: 0.5118 - val_loss: 6.8084 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 74/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3573 - accuracy: 0.5342\n",
      "Epoch 74: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.3573 - accuracy: 0.5342 - val_loss: 6.7874 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 75/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4017 - accuracy: 0.5307\n",
      "Epoch 75: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.4017 - accuracy: 0.5307 - val_loss: 6.7799 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 76/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3674 - accuracy: 0.5248\n",
      "Epoch 76: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3674 - accuracy: 0.5248 - val_loss: 6.7572 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 77/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3795 - accuracy: 0.5303\n",
      "Epoch 77: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.3795 - accuracy: 0.5303 - val_loss: 6.7381 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 78/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4078 - accuracy: 0.5377\n",
      "Epoch 78: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.4078 - accuracy: 0.5377 - val_loss: 6.7169 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 79/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4009 - accuracy: 0.5436\n",
      "Epoch 79: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.4009 - accuracy: 0.5436 - val_loss: 6.6925 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 80/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4151 - accuracy: 0.5283\n",
      "Epoch 80: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.4151 - accuracy: 0.5283 - val_loss: 6.6662 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 81/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3808 - accuracy: 0.5531\n",
      "Epoch 81: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.3808 - accuracy: 0.5531 - val_loss: 6.6412 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 82/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3158 - accuracy: 0.5401\n",
      "Epoch 82: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.3158 - accuracy: 0.5401 - val_loss: 6.6162 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 83/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4146 - accuracy: 0.5094\n",
      "Epoch 83: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4146 - accuracy: 0.5094 - val_loss: 6.5884 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 84/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3367 - accuracy: 0.5439\n",
      "Epoch 84: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 1.3367 - accuracy: 0.5439 - val_loss: 6.5591 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 85/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3913 - accuracy: 0.5400\n",
      "Epoch 85: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.3913 - accuracy: 0.5400 - val_loss: 6.5285 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 86/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3677 - accuracy: 0.5352\n",
      "Epoch 86: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.3677 - accuracy: 0.5352 - val_loss: 6.5024 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 87/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3386 - accuracy: 0.5554\n",
      "Epoch 87: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.3386 - accuracy: 0.5554 - val_loss: 6.4727 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 88/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3784 - accuracy: 0.5389\n",
      "Epoch 88: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.3784 - accuracy: 0.5389 - val_loss: 6.4439 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 89/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4149 - accuracy: 0.5195\n",
      "Epoch 89: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.4149 - accuracy: 0.5195 - val_loss: 6.4134 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 90/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3420 - accuracy: 0.5613\n",
      "Epoch 90: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3420 - accuracy: 0.5613 - val_loss: 6.3750 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 91/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3577 - accuracy: 0.5531\n",
      "Epoch 91: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.3577 - accuracy: 0.5531 - val_loss: 6.3341 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 92/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3625 - accuracy: 0.5352\n",
      "Epoch 92: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.3625 - accuracy: 0.5352 - val_loss: 6.3026 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 93/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3670 - accuracy: 0.5342\n",
      "Epoch 93: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.3670 - accuracy: 0.5342 - val_loss: 6.2652 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 94/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3016 - accuracy: 0.5625\n",
      "Epoch 94: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.3016 - accuracy: 0.5625 - val_loss: 6.2327 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 95/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3225 - accuracy: 0.5578\n",
      "Epoch 95: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.3225 - accuracy: 0.5578 - val_loss: 6.2005 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 96/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4287 - accuracy: 0.4882\n",
      "Epoch 96: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.4287 - accuracy: 0.4882 - val_loss: 6.1627 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 97/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3378 - accuracy: 0.5472\n",
      "Epoch 97: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.3378 - accuracy: 0.5472 - val_loss: 6.1314 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 98/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3371 - accuracy: 0.5413\n",
      "Epoch 98: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 1.3371 - accuracy: 0.5413 - val_loss: 6.0909 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 99/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2897 - accuracy: 0.5519\n",
      "Epoch 99: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.2897 - accuracy: 0.5519 - val_loss: 6.0477 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 100/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3889 - accuracy: 0.5413\n",
      "Epoch 100: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.3889 - accuracy: 0.5413 - val_loss: 6.0072 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 101/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3069 - accuracy: 0.5601\n",
      "Epoch 101: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.3069 - accuracy: 0.5601 - val_loss: 5.9673 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 102/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3752 - accuracy: 0.5377\n",
      "Epoch 102: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.3752 - accuracy: 0.5377 - val_loss: 5.9328 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 103/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3593 - accuracy: 0.5430\n",
      "Epoch 103: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.3593 - accuracy: 0.5430 - val_loss: 5.8984 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 104/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3479 - accuracy: 0.5318\n",
      "Epoch 104: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3479 - accuracy: 0.5318 - val_loss: 5.8570 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 105/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3278 - accuracy: 0.5719\n",
      "Epoch 105: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3278 - accuracy: 0.5719 - val_loss: 5.8243 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 106/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4237 - accuracy: 0.5271\n",
      "Epoch 106: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.4237 - accuracy: 0.5271 - val_loss: 5.7856 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 107/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3418 - accuracy: 0.5425\n",
      "Epoch 107: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.3418 - accuracy: 0.5425 - val_loss: 5.7388 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 108/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3203 - accuracy: 0.5615\n",
      "Epoch 108: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.3203 - accuracy: 0.5615 - val_loss: 5.7005 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 109/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3284 - accuracy: 0.5401\n",
      "Epoch 109: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.3284 - accuracy: 0.5401 - val_loss: 5.6630 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 110/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3124 - accuracy: 0.5660\n",
      "Epoch 110: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3124 - accuracy: 0.5660 - val_loss: 5.6361 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 111/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3142 - accuracy: 0.5637\n",
      "Epoch 111: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.3142 - accuracy: 0.5637 - val_loss: 5.6034 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 112/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3709 - accuracy: 0.5507\n",
      "Epoch 112: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.3709 - accuracy: 0.5507 - val_loss: 5.5638 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 113/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3037 - accuracy: 0.5590\n",
      "Epoch 113: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.3037 - accuracy: 0.5590 - val_loss: 5.5266 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 114/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2933 - accuracy: 0.5660\n",
      "Epoch 114: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.2933 - accuracy: 0.5660 - val_loss: 5.4922 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 115/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3418 - accuracy: 0.5527\n",
      "Epoch 115: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.3418 - accuracy: 0.5527 - val_loss: 5.4529 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 116/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3298 - accuracy: 0.5625\n",
      "Epoch 116: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.3298 - accuracy: 0.5625 - val_loss: 5.4185 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 117/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3636 - accuracy: 0.5519\n",
      "Epoch 117: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.3636 - accuracy: 0.5519 - val_loss: 5.3890 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 118/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3812 - accuracy: 0.5413\n",
      "Epoch 118: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.3812 - accuracy: 0.5413 - val_loss: 5.3554 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 119/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3497 - accuracy: 0.5295\n",
      "Epoch 119: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.3497 - accuracy: 0.5295 - val_loss: 5.3147 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 120/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3528 - accuracy: 0.5342\n",
      "Epoch 120: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.3528 - accuracy: 0.5342 - val_loss: 5.2786 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 121/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3050 - accuracy: 0.5790\n",
      "Epoch 121: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 1.3050 - accuracy: 0.5790 - val_loss: 5.2379 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 122/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2906 - accuracy: 0.5625\n",
      "Epoch 122: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.2906 - accuracy: 0.5625 - val_loss: 5.2058 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 123/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3411 - accuracy: 0.5566\n",
      "Epoch 123: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.3411 - accuracy: 0.5566 - val_loss: 5.1682 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 124/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3839 - accuracy: 0.5248\n",
      "Epoch 124: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.3839 - accuracy: 0.5248 - val_loss: 5.1292 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 125/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3266 - accuracy: 0.5613\n",
      "Epoch 125: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.3266 - accuracy: 0.5613 - val_loss: 5.0840 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 126/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3467 - accuracy: 0.5483\n",
      "Epoch 126: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.3467 - accuracy: 0.5483 - val_loss: 5.0406 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 127/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3944 - accuracy: 0.5342\n",
      "Epoch 127: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.3944 - accuracy: 0.5342 - val_loss: 5.0011 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 128/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3334 - accuracy: 0.5354\n",
      "Epoch 128: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 1.3334 - accuracy: 0.5354 - val_loss: 4.9635 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 129/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2975 - accuracy: 0.5637\n",
      "Epoch 129: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.2975 - accuracy: 0.5637 - val_loss: 4.9350 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 130/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3661 - accuracy: 0.5377\n",
      "Epoch 130: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 1.3661 - accuracy: 0.5377 - val_loss: 4.8958 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 131/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3445 - accuracy: 0.5436\n",
      "Epoch 131: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 1.3445 - accuracy: 0.5436 - val_loss: 4.8615 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 132/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3237 - accuracy: 0.5460\n",
      "Epoch 132: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 1.3237 - accuracy: 0.5460 - val_loss: 4.8234 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 133/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3567 - accuracy: 0.5377\n",
      "Epoch 133: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.3567 - accuracy: 0.5377 - val_loss: 4.7869 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 134/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3140 - accuracy: 0.5283\n",
      "Epoch 134: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.3140 - accuracy: 0.5283 - val_loss: 4.7617 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 135/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3357 - accuracy: 0.5605\n",
      "Epoch 135: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.3357 - accuracy: 0.5605 - val_loss: 4.7329 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 136/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3412 - accuracy: 0.5566\n",
      "Epoch 136: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 1.3412 - accuracy: 0.5566 - val_loss: 4.7024 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 137/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2296 - accuracy: 0.5837\n",
      "Epoch 137: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 1.2296 - accuracy: 0.5837 - val_loss: 4.6684 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 138/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3416 - accuracy: 0.5519\n",
      "Epoch 138: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 1.3416 - accuracy: 0.5519 - val_loss: 4.6316 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 139/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3543 - accuracy: 0.5342\n",
      "Epoch 139: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 1.3543 - accuracy: 0.5342 - val_loss: 4.6019 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 140/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3227 - accuracy: 0.5283\n",
      "Epoch 140: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 1.3227 - accuracy: 0.5283 - val_loss: 4.5652 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 141/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3251 - accuracy: 0.5295\n",
      "Epoch 141: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 1.3251 - accuracy: 0.5295 - val_loss: 4.5331 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 142/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3324 - accuracy: 0.5495\n",
      "Epoch 142: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 1.3324 - accuracy: 0.5495 - val_loss: 4.4985 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 143/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3243 - accuracy: 0.5519\n",
      "Epoch 143: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 1.3243 - accuracy: 0.5519 - val_loss: 4.4593 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 144/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2415 - accuracy: 0.5790\n",
      "Epoch 144: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 1.2415 - accuracy: 0.5790 - val_loss: 4.4380 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 145/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2488 - accuracy: 0.5684\n",
      "Epoch 145: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 1.2488 - accuracy: 0.5684 - val_loss: 4.4020 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 146/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2878 - accuracy: 0.5507\n",
      "Epoch 146: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 1.2878 - accuracy: 0.5507 - val_loss: 4.3700 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 147/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3340 - accuracy: 0.5518\n",
      "Epoch 147: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 1.3340 - accuracy: 0.5518 - val_loss: 4.3396 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 148/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2925 - accuracy: 0.5448\n",
      "Epoch 148: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 1.2925 - accuracy: 0.5448 - val_loss: 4.3015 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 149/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3128 - accuracy: 0.5498\n",
      "Epoch 149: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 1.3128 - accuracy: 0.5498 - val_loss: 4.2716 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 150/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3525 - accuracy: 0.5472\n",
      "Epoch 150: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 1.3525 - accuracy: 0.5472 - val_loss: 4.2413 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 151/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3542 - accuracy: 0.5248\n",
      "Epoch 151: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 1.3542 - accuracy: 0.5248 - val_loss: 4.2124 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 152/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3502 - accuracy: 0.5448\n",
      "Epoch 152: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 1.3502 - accuracy: 0.5448 - val_loss: 4.1714 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 153/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3436 - accuracy: 0.5377\n",
      "Epoch 153: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 1.3436 - accuracy: 0.5377 - val_loss: 4.1405 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 154/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3360 - accuracy: 0.5519\n",
      "Epoch 154: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 1.3360 - accuracy: 0.5519 - val_loss: 4.1085 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 155/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2659 - accuracy: 0.5542\n",
      "Epoch 155: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.2659 - accuracy: 0.5542 - val_loss: 4.0865 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 156/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3403 - accuracy: 0.5366\n",
      "Epoch 156: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 1.3403 - accuracy: 0.5366 - val_loss: 4.0653 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 157/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2732 - accuracy: 0.5837\n",
      "Epoch 157: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.2732 - accuracy: 0.5837 - val_loss: 4.0398 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 158/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3272 - accuracy: 0.5590\n",
      "Epoch 158: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 1.3272 - accuracy: 0.5590 - val_loss: 4.0152 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 159/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3657 - accuracy: 0.5448\n",
      "Epoch 159: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 1.3657 - accuracy: 0.5448 - val_loss: 3.9944 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 160/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3182 - accuracy: 0.5531\n",
      "Epoch 160: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 1.3182 - accuracy: 0.5531 - val_loss: 3.9701 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 161/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3832 - accuracy: 0.5318\n",
      "Epoch 161: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.3832 - accuracy: 0.5318 - val_loss: 3.9521 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 162/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3426 - accuracy: 0.5330\n",
      "Epoch 162: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.3426 - accuracy: 0.5330 - val_loss: 3.9237 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 163/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3380 - accuracy: 0.5459\n",
      "Epoch 163: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 1.3380 - accuracy: 0.5459 - val_loss: 3.8973 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 164/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3535 - accuracy: 0.5479\n",
      "Epoch 164: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 1.3535 - accuracy: 0.5479 - val_loss: 3.8718 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 165/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3065 - accuracy: 0.5637\n",
      "Epoch 165: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 1.3065 - accuracy: 0.5637 - val_loss: 3.8542 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 166/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3097 - accuracy: 0.5527\n",
      "Epoch 166: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 1.3097 - accuracy: 0.5527 - val_loss: 3.8349 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 167/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2476 - accuracy: 0.5672\n",
      "Epoch 167: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 324ms/step - loss: 1.2476 - accuracy: 0.5672 - val_loss: 3.8141 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 168/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2975 - accuracy: 0.5637\n",
      "Epoch 168: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.2975 - accuracy: 0.5637 - val_loss: 3.7984 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 169/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3619 - accuracy: 0.5425\n",
      "Epoch 169: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 1.3619 - accuracy: 0.5425 - val_loss: 3.7795 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 170/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2947 - accuracy: 0.5425\n",
      "Epoch 170: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 1.2947 - accuracy: 0.5425 - val_loss: 3.7608 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 171/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3548 - accuracy: 0.5389\n",
      "Epoch 171: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 1.3548 - accuracy: 0.5389 - val_loss: 3.7479 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 172/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3069 - accuracy: 0.5542\n",
      "Epoch 172: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 1.3069 - accuracy: 0.5542 - val_loss: 3.7411 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 173/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3022 - accuracy: 0.5590\n",
      "Epoch 173: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.3022 - accuracy: 0.5590 - val_loss: 3.7251 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 174/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2853 - accuracy: 0.5519\n",
      "Epoch 174: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.2853 - accuracy: 0.5519 - val_loss: 3.7057 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 175/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3845 - accuracy: 0.5366\n",
      "Epoch 175: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 1.3845 - accuracy: 0.5366 - val_loss: 3.6869 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 176/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2832 - accuracy: 0.5615\n",
      "Epoch 176: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 1.2832 - accuracy: 0.5615 - val_loss: 3.6787 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 177/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3116 - accuracy: 0.5307\n",
      "Epoch 177: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 1.3116 - accuracy: 0.5307 - val_loss: 3.6656 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 178/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3018 - accuracy: 0.5483\n",
      "Epoch 178: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 1.3018 - accuracy: 0.5483 - val_loss: 3.6439 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 179/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2954 - accuracy: 0.5719\n",
      "Epoch 179: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.2954 - accuracy: 0.5719 - val_loss: 3.6285 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 180/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2794 - accuracy: 0.5531\n",
      "Epoch 180: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.2794 - accuracy: 0.5531 - val_loss: 3.6106 - val_accuracy: 0.3141 - lr: 1.0000e-05\n",
      "Epoch 181/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3213 - accuracy: 0.5542\n",
      "Epoch 181: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.3213 - accuracy: 0.5542 - val_loss: 3.5942 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 182/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2469 - accuracy: 0.5742\n",
      "Epoch 182: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 1.2469 - accuracy: 0.5742 - val_loss: 3.5819 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 183/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3183 - accuracy: 0.5401\n",
      "Epoch 183: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 1.3183 - accuracy: 0.5401 - val_loss: 3.5669 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 184/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2950 - accuracy: 0.5601\n",
      "Epoch 184: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.2950 - accuracy: 0.5601 - val_loss: 3.5417 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 185/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3079 - accuracy: 0.5483\n",
      "Epoch 185: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 1.3079 - accuracy: 0.5483 - val_loss: 3.5353 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 186/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3035 - accuracy: 0.5472\n",
      "Epoch 186: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 1.3035 - accuracy: 0.5472 - val_loss: 3.5184 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 187/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3262 - accuracy: 0.5460\n",
      "Epoch 187: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.3262 - accuracy: 0.5460 - val_loss: 3.5108 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 188/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3594 - accuracy: 0.5330\n",
      "Epoch 188: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.3594 - accuracy: 0.5330 - val_loss: 3.5095 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 189/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2769 - accuracy: 0.5507\n",
      "Epoch 189: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 330ms/step - loss: 1.2769 - accuracy: 0.5507 - val_loss: 3.4972 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 190/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2584 - accuracy: 0.5674\n",
      "Epoch 190: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 332ms/step - loss: 1.2584 - accuracy: 0.5674 - val_loss: 3.4888 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 191/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3043 - accuracy: 0.5613\n",
      "Epoch 191: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 331ms/step - loss: 1.3043 - accuracy: 0.5613 - val_loss: 3.4893 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 192/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2873 - accuracy: 0.5625\n",
      "Epoch 192: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 1.2873 - accuracy: 0.5625 - val_loss: 3.4873 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 193/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3271 - accuracy: 0.5578\n",
      "Epoch 193: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.3271 - accuracy: 0.5578 - val_loss: 3.4797 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 194/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2964 - accuracy: 0.5400\n",
      "Epoch 194: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 1.2964 - accuracy: 0.5400 - val_loss: 3.4717 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 195/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3050 - accuracy: 0.5483\n",
      "Epoch 195: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.3050 - accuracy: 0.5483 - val_loss: 3.4593 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 196/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3481 - accuracy: 0.5366\n",
      "Epoch 196: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.3481 - accuracy: 0.5366 - val_loss: 3.4560 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 197/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3250 - accuracy: 0.5483\n",
      "Epoch 197: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.3250 - accuracy: 0.5483 - val_loss: 3.4540 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 198/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3047 - accuracy: 0.5518\n",
      "Epoch 198: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 1.3047 - accuracy: 0.5518 - val_loss: 3.4500 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 199/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2913 - accuracy: 0.5649\n",
      "Epoch 199: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.2913 - accuracy: 0.5649 - val_loss: 3.4365 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 200/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3056 - accuracy: 0.5342\n",
      "Epoch 200: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 1.3056 - accuracy: 0.5342 - val_loss: 3.4274 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 201/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3051 - accuracy: 0.5527\n",
      "Epoch 201: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 1.3051 - accuracy: 0.5527 - val_loss: 3.4186 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 202/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3019 - accuracy: 0.5613\n",
      "Epoch 202: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.3019 - accuracy: 0.5613 - val_loss: 3.4147 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 203/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2737 - accuracy: 0.5660\n",
      "Epoch 203: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 1.2737 - accuracy: 0.5660 - val_loss: 3.4078 - val_accuracy: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 204/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2888 - accuracy: 0.5460\n",
      "Epoch 204: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 1.2888 - accuracy: 0.5460 - val_loss: 3.3942 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 205/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3172 - accuracy: 0.5719\n",
      "Epoch 205: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 1.3172 - accuracy: 0.5719 - val_loss: 3.3918 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 206/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3115 - accuracy: 0.5519\n",
      "Epoch 206: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.3115 - accuracy: 0.5519 - val_loss: 3.3930 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 207/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3018 - accuracy: 0.5483\n",
      "Epoch 207: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 1.3018 - accuracy: 0.5483 - val_loss: 3.3865 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 208/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3088 - accuracy: 0.5578\n",
      "Epoch 208: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 1.3088 - accuracy: 0.5578 - val_loss: 3.3882 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 209/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2439 - accuracy: 0.5755\n",
      "Epoch 209: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.2439 - accuracy: 0.5755 - val_loss: 3.3856 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 210/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2396 - accuracy: 0.5547\n",
      "Epoch 210: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 1.2396 - accuracy: 0.5547 - val_loss: 3.3795 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 211/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3483 - accuracy: 0.5342\n",
      "Epoch 211: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.3483 - accuracy: 0.5342 - val_loss: 3.3718 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 212/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2787 - accuracy: 0.5527\n",
      "Epoch 212: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 1.2787 - accuracy: 0.5527 - val_loss: 3.3646 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 213/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3103 - accuracy: 0.5469\n",
      "Epoch 213: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 1.3103 - accuracy: 0.5469 - val_loss: 3.3612 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 214/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2992 - accuracy: 0.5601\n",
      "Epoch 214: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.2992 - accuracy: 0.5601 - val_loss: 3.3592 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 215/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3066 - accuracy: 0.5625\n",
      "Epoch 215: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 1.3066 - accuracy: 0.5625 - val_loss: 3.3561 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 216/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2665 - accuracy: 0.5672\n",
      "Epoch 216: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 1.2665 - accuracy: 0.5672 - val_loss: 3.3544 - val_accuracy: 0.3213 - lr: 1.0000e-05\n",
      "Epoch 217/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2952 - accuracy: 0.5531\n",
      "Epoch 217: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 1.2952 - accuracy: 0.5531 - val_loss: 3.3427 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 218/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3097 - accuracy: 0.5708\n",
      "Epoch 218: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.3097 - accuracy: 0.5708 - val_loss: 3.3406 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 219/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3138 - accuracy: 0.5483\n",
      "Epoch 219: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 1.3138 - accuracy: 0.5483 - val_loss: 3.3374 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 220/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2824 - accuracy: 0.5519\n",
      "Epoch 220: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 1.2824 - accuracy: 0.5519 - val_loss: 3.3365 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 221/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2635 - accuracy: 0.5696\n",
      "Epoch 221: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 1.2635 - accuracy: 0.5696 - val_loss: 3.3331 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 222/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3111 - accuracy: 0.5566\n",
      "Epoch 222: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 1.3111 - accuracy: 0.5566 - val_loss: 3.3330 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 223/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2680 - accuracy: 0.5713\n",
      "Epoch 223: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 1.2680 - accuracy: 0.5713 - val_loss: 3.3302 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 224/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2899 - accuracy: 0.5377\n",
      "Epoch 224: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.2899 - accuracy: 0.5377 - val_loss: 3.3273 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 225/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2272 - accuracy: 0.5743\n",
      "Epoch 225: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 324ms/step - loss: 1.2272 - accuracy: 0.5743 - val_loss: 3.3317 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 226/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2639 - accuracy: 0.5601\n",
      "Epoch 226: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.2639 - accuracy: 0.5601 - val_loss: 3.3364 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 227/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2784 - accuracy: 0.5672\n",
      "Epoch 227: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 334ms/step - loss: 1.2784 - accuracy: 0.5672 - val_loss: 3.3343 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 228/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2971 - accuracy: 0.5605\n",
      "Epoch 228: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 1.2971 - accuracy: 0.5605 - val_loss: 3.3347 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 229/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2817 - accuracy: 0.5672\n",
      "Epoch 229: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 1.2817 - accuracy: 0.5672 - val_loss: 3.3286 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 230/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2642 - accuracy: 0.5590\n",
      "Epoch 230: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 1.2642 - accuracy: 0.5590 - val_loss: 3.3246 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 231/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2837 - accuracy: 0.5672\n",
      "Epoch 231: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 1.2837 - accuracy: 0.5672 - val_loss: 3.3204 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 232/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2524 - accuracy: 0.5664\n",
      "Epoch 232: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 1.2524 - accuracy: 0.5664 - val_loss: 3.3213 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 233/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2301 - accuracy: 0.5743\n",
      "Epoch 233: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 1.2301 - accuracy: 0.5743 - val_loss: 3.3125 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 234/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2568 - accuracy: 0.5613\n",
      "Epoch 234: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 1.2568 - accuracy: 0.5613 - val_loss: 3.3122 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 235/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3147 - accuracy: 0.5448\n",
      "Epoch 235: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 1.3147 - accuracy: 0.5448 - val_loss: 3.2994 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 236/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2209 - accuracy: 0.5837\n",
      "Epoch 236: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.2209 - accuracy: 0.5837 - val_loss: 3.2954 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 237/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2940 - accuracy: 0.5672\n",
      "Epoch 237: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.2940 - accuracy: 0.5672 - val_loss: 3.2879 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 238/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2702 - accuracy: 0.5578\n",
      "Epoch 238: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.2702 - accuracy: 0.5578 - val_loss: 3.2708 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 239/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2915 - accuracy: 0.5696\n",
      "Epoch 239: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.2915 - accuracy: 0.5696 - val_loss: 3.2569 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 240/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3051 - accuracy: 0.5507\n",
      "Epoch 240: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 1.3051 - accuracy: 0.5507 - val_loss: 3.2489 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 241/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2799 - accuracy: 0.5566\n",
      "Epoch 241: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 1.2799 - accuracy: 0.5566 - val_loss: 3.2435 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 242/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2704 - accuracy: 0.5554\n",
      "Epoch 242: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 1.2704 - accuracy: 0.5554 - val_loss: 3.2452 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 243/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2464 - accuracy: 0.5586\n",
      "Epoch 243: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 1.2464 - accuracy: 0.5586 - val_loss: 3.2424 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 244/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2139 - accuracy: 0.5979\n",
      "Epoch 244: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.2139 - accuracy: 0.5979 - val_loss: 3.2350 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 245/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2976 - accuracy: 0.5625\n",
      "Epoch 245: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 1.2976 - accuracy: 0.5625 - val_loss: 3.2387 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 246/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2638 - accuracy: 0.5790\n",
      "Epoch 246: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 1.2638 - accuracy: 0.5790 - val_loss: 3.2323 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 247/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2593 - accuracy: 0.5578\n",
      "Epoch 247: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.2593 - accuracy: 0.5578 - val_loss: 3.2281 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 248/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2868 - accuracy: 0.5495\n",
      "Epoch 248: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 1.2868 - accuracy: 0.5495 - val_loss: 3.2309 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 249/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2747 - accuracy: 0.5578\n",
      "Epoch 249: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 1.2747 - accuracy: 0.5578 - val_loss: 3.2254 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 250/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3159 - accuracy: 0.5542\n",
      "Epoch 250: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.3159 - accuracy: 0.5542 - val_loss: 3.2306 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 251/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2974 - accuracy: 0.5507\n",
      "Epoch 251: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 1.2974 - accuracy: 0.5507 - val_loss: 3.2241 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 252/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1802 - accuracy: 0.5601\n",
      "Epoch 252: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 1.1802 - accuracy: 0.5601 - val_loss: 3.2113 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 253/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2834 - accuracy: 0.5601\n",
      "Epoch 253: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.2834 - accuracy: 0.5601 - val_loss: 3.2120 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 254/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3015 - accuracy: 0.5527\n",
      "Epoch 254: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 1.3015 - accuracy: 0.5527 - val_loss: 3.2009 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 255/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2749 - accuracy: 0.5436\n",
      "Epoch 255: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.2749 - accuracy: 0.5436 - val_loss: 3.1911 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 256/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2440 - accuracy: 0.5814\n",
      "Epoch 256: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 1.2440 - accuracy: 0.5814 - val_loss: 3.1834 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 257/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2520 - accuracy: 0.5542\n",
      "Epoch 257: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 1.2520 - accuracy: 0.5542 - val_loss: 3.1855 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 258/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2541 - accuracy: 0.5696\n",
      "Epoch 258: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 1.2541 - accuracy: 0.5696 - val_loss: 3.1835 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 259/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2557 - accuracy: 0.5613\n",
      "Epoch 259: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 1.2557 - accuracy: 0.5613 - val_loss: 3.1719 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 260/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2425 - accuracy: 0.5508\n",
      "Epoch 260: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 1.2425 - accuracy: 0.5508 - val_loss: 3.1660 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 261/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2730 - accuracy: 0.5684\n",
      "Epoch 261: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 1.2730 - accuracy: 0.5684 - val_loss: 3.1667 - val_accuracy: 0.3249 - lr: 1.0000e-05\n",
      "Epoch 262/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3221 - accuracy: 0.5330\n",
      "Epoch 262: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 1.3221 - accuracy: 0.5330 - val_loss: 3.1574 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 263/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2858 - accuracy: 0.5696\n",
      "Epoch 263: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 1.2858 - accuracy: 0.5696 - val_loss: 3.1498 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 264/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2090 - accuracy: 0.5762\n",
      "Epoch 264: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 1.2090 - accuracy: 0.5762 - val_loss: 3.1461 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 265/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2598 - accuracy: 0.5590\n",
      "Epoch 265: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.2598 - accuracy: 0.5590 - val_loss: 3.1400 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 266/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2181 - accuracy: 0.5820\n",
      "Epoch 266: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 1.2181 - accuracy: 0.5820 - val_loss: 3.1362 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 267/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2395 - accuracy: 0.5625\n",
      "Epoch 267: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 1.2395 - accuracy: 0.5625 - val_loss: 3.1299 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 268/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2889 - accuracy: 0.5731\n",
      "Epoch 268: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 1.2889 - accuracy: 0.5731 - val_loss: 3.1263 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 269/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2614 - accuracy: 0.5672\n",
      "Epoch 269: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 1.2614 - accuracy: 0.5672 - val_loss: 3.1267 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 270/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2314 - accuracy: 0.5672\n",
      "Epoch 270: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.2314 - accuracy: 0.5672 - val_loss: 3.1246 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 271/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2306 - accuracy: 0.5938\n",
      "Epoch 271: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 1.2306 - accuracy: 0.5938 - val_loss: 3.1187 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 272/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2939 - accuracy: 0.5495\n",
      "Epoch 272: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 1.2939 - accuracy: 0.5495 - val_loss: 3.1213 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 273/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2518 - accuracy: 0.5649\n",
      "Epoch 273: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 1.2518 - accuracy: 0.5649 - val_loss: 3.1209 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 274/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2794 - accuracy: 0.5625\n",
      "Epoch 274: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 1.2794 - accuracy: 0.5625 - val_loss: 3.1201 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 275/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2422 - accuracy: 0.5778\n",
      "Epoch 275: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 1.2422 - accuracy: 0.5778 - val_loss: 3.1231 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 276/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2155 - accuracy: 0.5849\n",
      "Epoch 276: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.2155 - accuracy: 0.5849 - val_loss: 3.1178 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 277/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2385 - accuracy: 0.5613\n",
      "Epoch 277: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 1.2385 - accuracy: 0.5613 - val_loss: 3.1181 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 278/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2407 - accuracy: 0.5743\n",
      "Epoch 278: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.2407 - accuracy: 0.5743 - val_loss: 3.1167 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 279/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2239 - accuracy: 0.5820\n",
      "Epoch 279: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 1.2239 - accuracy: 0.5820 - val_loss: 3.1164 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 280/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2466 - accuracy: 0.5625\n",
      "Epoch 280: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 1.2466 - accuracy: 0.5625 - val_loss: 3.1169 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 281/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2263 - accuracy: 0.5801\n",
      "Epoch 281: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 1.2263 - accuracy: 0.5801 - val_loss: 3.1157 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 282/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2402 - accuracy: 0.5771\n",
      "Epoch 282: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 1.2402 - accuracy: 0.5771 - val_loss: 3.1149 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 283/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2950 - accuracy: 0.5436\n",
      "Epoch 283: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 1.2950 - accuracy: 0.5436 - val_loss: 3.1093 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 284/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2549 - accuracy: 0.5708\n",
      "Epoch 284: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 1.2549 - accuracy: 0.5708 - val_loss: 3.1073 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 285/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2602 - accuracy: 0.5590\n",
      "Epoch 285: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 1.2602 - accuracy: 0.5590 - val_loss: 3.1052 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 286/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1979 - accuracy: 0.5908\n",
      "Epoch 286: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 1.1979 - accuracy: 0.5908 - val_loss: 3.1025 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 287/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2384 - accuracy: 0.5743\n",
      "Epoch 287: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 1.2384 - accuracy: 0.5743 - val_loss: 3.0973 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 288/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2294 - accuracy: 0.5547\n",
      "Epoch 288: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 1.2294 - accuracy: 0.5547 - val_loss: 3.0878 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 289/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2365 - accuracy: 0.5861\n",
      "Epoch 289: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 1.2365 - accuracy: 0.5861 - val_loss: 3.0824 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 290/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2812 - accuracy: 0.5767\n",
      "Epoch 290: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 1.2812 - accuracy: 0.5767 - val_loss: 3.0768 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 291/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1570 - accuracy: 0.6014\n",
      "Epoch 291: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.1570 - accuracy: 0.6014 - val_loss: 3.0741 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 292/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2191 - accuracy: 0.5731\n",
      "Epoch 292: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.2191 - accuracy: 0.5731 - val_loss: 3.0702 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 293/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2757 - accuracy: 0.5820\n",
      "Epoch 293: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.2757 - accuracy: 0.5820 - val_loss: 3.0720 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 294/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2034 - accuracy: 0.5859\n",
      "Epoch 294: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.2034 - accuracy: 0.5859 - val_loss: 3.0656 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 295/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3361 - accuracy: 0.5413\n",
      "Epoch 295: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.3361 - accuracy: 0.5413 - val_loss: 3.0609 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 296/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2284 - accuracy: 0.5696\n",
      "Epoch 296: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.2284 - accuracy: 0.5696 - val_loss: 3.0508 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 297/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1765 - accuracy: 0.5830\n",
      "Epoch 297: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.1765 - accuracy: 0.5830 - val_loss: 3.0457 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 298/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1938 - accuracy: 0.5879\n",
      "Epoch 298: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 1.1938 - accuracy: 0.5879 - val_loss: 3.0439 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 299/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2695 - accuracy: 0.5719\n",
      "Epoch 299: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.2695 - accuracy: 0.5719 - val_loss: 3.0485 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 300/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2263 - accuracy: 0.5849\n",
      "Epoch 300: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.2263 - accuracy: 0.5849 - val_loss: 3.0515 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 301/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2278 - accuracy: 0.5719\n",
      "Epoch 301: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.2278 - accuracy: 0.5719 - val_loss: 3.0547 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 302/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2406 - accuracy: 0.5790\n",
      "Epoch 302: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.2406 - accuracy: 0.5790 - val_loss: 3.0489 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 303/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2260 - accuracy: 0.5637\n",
      "Epoch 303: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.2260 - accuracy: 0.5637 - val_loss: 3.0467 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 304/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2350 - accuracy: 0.5790\n",
      "Epoch 304: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2350 - accuracy: 0.5790 - val_loss: 3.0496 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 305/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1966 - accuracy: 0.5703\n",
      "Epoch 305: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1966 - accuracy: 0.5703 - val_loss: 3.0538 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 306/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2618 - accuracy: 0.5554\n",
      "Epoch 306: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2618 - accuracy: 0.5554 - val_loss: 3.0585 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 307/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2481 - accuracy: 0.5849\n",
      "Epoch 307: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.2481 - accuracy: 0.5849 - val_loss: 3.0594 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 308/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2244 - accuracy: 0.5790\n",
      "Epoch 308: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.2244 - accuracy: 0.5790 - val_loss: 3.0588 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 309/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1845 - accuracy: 0.6002\n",
      "Epoch 309: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1845 - accuracy: 0.6002 - val_loss: 3.0589 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 310/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2452 - accuracy: 0.5778\n",
      "Epoch 310: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.2452 - accuracy: 0.5778 - val_loss: 3.0654 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 311/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2073 - accuracy: 0.5790\n",
      "Epoch 311: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.2073 - accuracy: 0.5790 - val_loss: 3.0719 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 312/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1942 - accuracy: 0.5979\n",
      "Epoch 312: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1942 - accuracy: 0.5979 - val_loss: 3.0732 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 313/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1734 - accuracy: 0.6097\n",
      "Epoch 313: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.1734 - accuracy: 0.6097 - val_loss: 3.0778 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 314/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2249 - accuracy: 0.5837\n",
      "Epoch 314: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.2249 - accuracy: 0.5837 - val_loss: 3.0746 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 315/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2688 - accuracy: 0.5635\n",
      "Epoch 315: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.2688 - accuracy: 0.5635 - val_loss: 3.0746 - val_accuracy: 0.3285 - lr: 1.0000e-05\n",
      "Epoch 316/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2497 - accuracy: 0.5613\n",
      "Epoch 316: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.2497 - accuracy: 0.5613 - val_loss: 3.0717 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 317/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2523 - accuracy: 0.5837\n",
      "Epoch 317: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2523 - accuracy: 0.5837 - val_loss: 3.0684 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 318/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2318 - accuracy: 0.5801\n",
      "Epoch 318: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.2318 - accuracy: 0.5801 - val_loss: 3.0664 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 319/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2183 - accuracy: 0.5849\n",
      "Epoch 319: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.2183 - accuracy: 0.5849 - val_loss: 3.0615 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 320/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2423 - accuracy: 0.5920\n",
      "Epoch 320: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.2423 - accuracy: 0.5920 - val_loss: 3.0522 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 321/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2508 - accuracy: 0.5825\n",
      "Epoch 321: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.2508 - accuracy: 0.5825 - val_loss: 3.0511 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 322/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2494 - accuracy: 0.5719\n",
      "Epoch 322: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2494 - accuracy: 0.5719 - val_loss: 3.0462 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 323/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1890 - accuracy: 0.5825\n",
      "Epoch 323: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1890 - accuracy: 0.5825 - val_loss: 3.0410 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 324/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2183 - accuracy: 0.5811\n",
      "Epoch 324: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.2183 - accuracy: 0.5811 - val_loss: 3.0344 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 325/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1894 - accuracy: 0.5820\n",
      "Epoch 325: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.1894 - accuracy: 0.5820 - val_loss: 3.0270 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 326/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1934 - accuracy: 0.5908\n",
      "Epoch 326: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.1934 - accuracy: 0.5908 - val_loss: 3.0200 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 327/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2283 - accuracy: 0.5743\n",
      "Epoch 327: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.2283 - accuracy: 0.5743 - val_loss: 3.0112 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 328/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3018 - accuracy: 0.5389\n",
      "Epoch 328: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.3018 - accuracy: 0.5389 - val_loss: 3.0146 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 329/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2469 - accuracy: 0.5767\n",
      "Epoch 329: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2469 - accuracy: 0.5767 - val_loss: 3.0123 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 330/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2199 - accuracy: 0.5873\n",
      "Epoch 330: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.2199 - accuracy: 0.5873 - val_loss: 3.0024 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 331/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2402 - accuracy: 0.5684\n",
      "Epoch 331: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.2402 - accuracy: 0.5684 - val_loss: 2.9996 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 332/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2160 - accuracy: 0.5684\n",
      "Epoch 332: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.2160 - accuracy: 0.5684 - val_loss: 2.9980 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 333/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2558 - accuracy: 0.5684\n",
      "Epoch 333: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.2558 - accuracy: 0.5684 - val_loss: 2.9991 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 334/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2014 - accuracy: 0.6002\n",
      "Epoch 334: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2014 - accuracy: 0.6002 - val_loss: 2.9913 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 335/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2372 - accuracy: 0.5527\n",
      "Epoch 335: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.2372 - accuracy: 0.5527 - val_loss: 2.9862 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 336/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2357 - accuracy: 0.5850\n",
      "Epoch 336: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.2357 - accuracy: 0.5850 - val_loss: 2.9850 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 337/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2742 - accuracy: 0.5672\n",
      "Epoch 337: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.2742 - accuracy: 0.5672 - val_loss: 2.9823 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 338/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2242 - accuracy: 0.5732\n",
      "Epoch 338: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 1.2242 - accuracy: 0.5732 - val_loss: 2.9763 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 339/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1800 - accuracy: 0.5861\n",
      "Epoch 339: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1800 - accuracy: 0.5861 - val_loss: 2.9722 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 340/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2389 - accuracy: 0.5802\n",
      "Epoch 340: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.2389 - accuracy: 0.5802 - val_loss: 2.9662 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 341/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1745 - accuracy: 0.5861\n",
      "Epoch 341: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1745 - accuracy: 0.5861 - val_loss: 2.9621 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 342/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1962 - accuracy: 0.5920\n",
      "Epoch 342: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1962 - accuracy: 0.5920 - val_loss: 2.9601 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 343/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1892 - accuracy: 0.5955\n",
      "Epoch 343: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1892 - accuracy: 0.5955 - val_loss: 2.9637 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 344/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1311 - accuracy: 0.6014\n",
      "Epoch 344: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1311 - accuracy: 0.6014 - val_loss: 2.9670 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 345/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2411 - accuracy: 0.5825\n",
      "Epoch 345: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.2411 - accuracy: 0.5825 - val_loss: 2.9672 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 346/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2212 - accuracy: 0.5861\n",
      "Epoch 346: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2212 - accuracy: 0.5861 - val_loss: 2.9559 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 347/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2034 - accuracy: 0.5991\n",
      "Epoch 347: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.2034 - accuracy: 0.5991 - val_loss: 2.9587 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 348/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2625 - accuracy: 0.5755\n",
      "Epoch 348: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.2625 - accuracy: 0.5755 - val_loss: 2.9620 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 349/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2112 - accuracy: 0.5767\n",
      "Epoch 349: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.2112 - accuracy: 0.5767 - val_loss: 2.9593 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 350/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1814 - accuracy: 0.5814\n",
      "Epoch 350: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1814 - accuracy: 0.5814 - val_loss: 2.9565 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 351/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2317 - accuracy: 0.5767\n",
      "Epoch 351: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.2317 - accuracy: 0.5767 - val_loss: 2.9586 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 352/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1689 - accuracy: 0.5979\n",
      "Epoch 352: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1689 - accuracy: 0.5979 - val_loss: 2.9583 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 353/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2073 - accuracy: 0.5778\n",
      "Epoch 353: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.2073 - accuracy: 0.5778 - val_loss: 2.9610 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 354/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2225 - accuracy: 0.5861\n",
      "Epoch 354: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.2225 - accuracy: 0.5861 - val_loss: 2.9708 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 355/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1867 - accuracy: 0.5967\n",
      "Epoch 355: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1867 - accuracy: 0.5967 - val_loss: 2.9748 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 356/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2252 - accuracy: 0.5825\n",
      "Epoch 356: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.2252 - accuracy: 0.5825 - val_loss: 2.9838 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 357/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1578 - accuracy: 0.6014\n",
      "Epoch 357: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1578 - accuracy: 0.6014 - val_loss: 2.9831 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 358/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2260 - accuracy: 0.5696\n",
      "Epoch 358: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.2260 - accuracy: 0.5696 - val_loss: 2.9766 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 359/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1869 - accuracy: 0.5790\n",
      "Epoch 359: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1869 - accuracy: 0.5790 - val_loss: 2.9654 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 360/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2931 - accuracy: 0.5578\n",
      "Epoch 360: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.2931 - accuracy: 0.5578 - val_loss: 2.9579 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 361/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2418 - accuracy: 0.5767\n",
      "Epoch 361: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.2418 - accuracy: 0.5767 - val_loss: 2.9623 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 362/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1444 - accuracy: 0.5898\n",
      "Epoch 362: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 1.1444 - accuracy: 0.5898 - val_loss: 2.9613 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 363/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2086 - accuracy: 0.5781\n",
      "Epoch 363: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.2086 - accuracy: 0.5781 - val_loss: 2.9605 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 364/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2329 - accuracy: 0.5684\n",
      "Epoch 364: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.2329 - accuracy: 0.5684 - val_loss: 2.9584 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 365/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2188 - accuracy: 0.5825\n",
      "Epoch 365: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.2188 - accuracy: 0.5825 - val_loss: 2.9613 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 366/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1828 - accuracy: 0.5979\n",
      "Epoch 366: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1828 - accuracy: 0.5979 - val_loss: 2.9661 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 367/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1722 - accuracy: 0.5898\n",
      "Epoch 367: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1722 - accuracy: 0.5898 - val_loss: 2.9683 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 368/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2519 - accuracy: 0.5719\n",
      "Epoch 368: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 1.2519 - accuracy: 0.5719 - val_loss: 2.9666 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 369/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1971 - accuracy: 0.5825\n",
      "Epoch 369: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1971 - accuracy: 0.5825 - val_loss: 2.9602 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 370/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2367 - accuracy: 0.5723\n",
      "Epoch 370: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.2367 - accuracy: 0.5723 - val_loss: 2.9623 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 371/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1890 - accuracy: 0.5672\n",
      "Epoch 371: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1890 - accuracy: 0.5672 - val_loss: 2.9581 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 372/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1598 - accuracy: 0.5755\n",
      "Epoch 372: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1598 - accuracy: 0.5755 - val_loss: 2.9545 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 373/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1474 - accuracy: 0.5873\n",
      "Epoch 373: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1474 - accuracy: 0.5873 - val_loss: 2.9543 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 374/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2073 - accuracy: 0.5991\n",
      "Epoch 374: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.2073 - accuracy: 0.5991 - val_loss: 2.9595 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 375/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1657 - accuracy: 0.6073\n",
      "Epoch 375: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1657 - accuracy: 0.6073 - val_loss: 2.9586 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 376/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2122 - accuracy: 0.5814\n",
      "Epoch 376: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.2122 - accuracy: 0.5814 - val_loss: 2.9581 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 377/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1207 - accuracy: 0.6250\n",
      "Epoch 377: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.1207 - accuracy: 0.6250 - val_loss: 2.9586 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 378/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1678 - accuracy: 0.5790\n",
      "Epoch 378: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1678 - accuracy: 0.5790 - val_loss: 2.9487 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 379/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1881 - accuracy: 0.5802\n",
      "Epoch 379: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1881 - accuracy: 0.5802 - val_loss: 2.9456 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 380/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2048 - accuracy: 0.5590\n",
      "Epoch 380: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.2048 - accuracy: 0.5590 - val_loss: 2.9511 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 381/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2550 - accuracy: 0.5708\n",
      "Epoch 381: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.2550 - accuracy: 0.5708 - val_loss: 2.9488 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 382/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1671 - accuracy: 0.5977\n",
      "Epoch 382: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.1671 - accuracy: 0.5977 - val_loss: 2.9493 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 383/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2081 - accuracy: 0.5837\n",
      "Epoch 383: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.2081 - accuracy: 0.5837 - val_loss: 2.9426 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 384/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2034 - accuracy: 0.5991\n",
      "Epoch 384: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.2034 - accuracy: 0.5991 - val_loss: 2.9382 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 385/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2250 - accuracy: 0.5790\n",
      "Epoch 385: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.2250 - accuracy: 0.5790 - val_loss: 2.9348 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 386/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1892 - accuracy: 0.5814\n",
      "Epoch 386: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 1.1892 - accuracy: 0.5814 - val_loss: 2.9252 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 387/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2142 - accuracy: 0.5660\n",
      "Epoch 387: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 1.2142 - accuracy: 0.5660 - val_loss: 2.9273 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 388/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1589 - accuracy: 0.6097\n",
      "Epoch 388: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 1.1589 - accuracy: 0.6097 - val_loss: 2.9245 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 389/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1891 - accuracy: 0.5830\n",
      "Epoch 389: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.1891 - accuracy: 0.5830 - val_loss: 2.9164 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 390/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1865 - accuracy: 0.5884\n",
      "Epoch 390: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.1865 - accuracy: 0.5884 - val_loss: 2.9090 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 391/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2025 - accuracy: 0.5708\n",
      "Epoch 391: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 1.2025 - accuracy: 0.5708 - val_loss: 2.9123 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 392/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2162 - accuracy: 0.5625\n",
      "Epoch 392: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.2162 - accuracy: 0.5625 - val_loss: 2.8992 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 393/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1938 - accuracy: 0.5696\n",
      "Epoch 393: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1938 - accuracy: 0.5696 - val_loss: 2.8970 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 394/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2250 - accuracy: 0.5755\n",
      "Epoch 394: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.2250 - accuracy: 0.5755 - val_loss: 2.8961 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 395/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1910 - accuracy: 0.5986\n",
      "Epoch 395: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1910 - accuracy: 0.5986 - val_loss: 2.8917 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 396/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1915 - accuracy: 0.5719\n",
      "Epoch 396: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1915 - accuracy: 0.5719 - val_loss: 2.8892 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 397/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1695 - accuracy: 0.6002\n",
      "Epoch 397: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.1695 - accuracy: 0.6002 - val_loss: 2.8892 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 398/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1722 - accuracy: 0.5979\n",
      "Epoch 398: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.1722 - accuracy: 0.5979 - val_loss: 2.8879 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 399/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1743 - accuracy: 0.5825\n",
      "Epoch 399: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1743 - accuracy: 0.5825 - val_loss: 2.8858 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 400/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1332 - accuracy: 0.6026\n",
      "Epoch 400: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.1332 - accuracy: 0.6026 - val_loss: 2.8839 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 401/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1879 - accuracy: 0.5908\n",
      "Epoch 401: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.1879 - accuracy: 0.5908 - val_loss: 2.8760 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 402/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1657 - accuracy: 0.5957\n",
      "Epoch 402: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.1657 - accuracy: 0.5957 - val_loss: 2.8758 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 403/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2511 - accuracy: 0.5814\n",
      "Epoch 403: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 1.2511 - accuracy: 0.5814 - val_loss: 2.8822 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 404/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2443 - accuracy: 0.5649\n",
      "Epoch 404: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.2443 - accuracy: 0.5649 - val_loss: 2.8870 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 405/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1813 - accuracy: 0.6014\n",
      "Epoch 405: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1813 - accuracy: 0.6014 - val_loss: 2.8891 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 406/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1594 - accuracy: 0.5920\n",
      "Epoch 406: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.1594 - accuracy: 0.5920 - val_loss: 2.8829 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 407/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1928 - accuracy: 0.5896\n",
      "Epoch 407: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.1928 - accuracy: 0.5896 - val_loss: 2.8788 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 408/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.5986\n",
      "Epoch 408: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.1712 - accuracy: 0.5986 - val_loss: 2.8789 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 409/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1626 - accuracy: 0.6002\n",
      "Epoch 409: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1626 - accuracy: 0.6002 - val_loss: 2.8933 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 410/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1758 - accuracy: 0.6002\n",
      "Epoch 410: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 1.1758 - accuracy: 0.6002 - val_loss: 2.9007 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 411/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1852 - accuracy: 0.5873\n",
      "Epoch 411: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1852 - accuracy: 0.5873 - val_loss: 2.9034 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 412/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1647 - accuracy: 0.5979\n",
      "Epoch 412: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.1647 - accuracy: 0.5979 - val_loss: 2.8932 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 413/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1966 - accuracy: 0.5928\n",
      "Epoch 413: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1966 - accuracy: 0.5928 - val_loss: 2.8921 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 414/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1854 - accuracy: 0.5861\n",
      "Epoch 414: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1854 - accuracy: 0.5861 - val_loss: 2.8866 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 415/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2182 - accuracy: 0.5920\n",
      "Epoch 415: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.2182 - accuracy: 0.5920 - val_loss: 2.8897 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 416/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2086 - accuracy: 0.5778\n",
      "Epoch 416: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.2086 - accuracy: 0.5778 - val_loss: 2.8857 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 417/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1063 - accuracy: 0.6073\n",
      "Epoch 417: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.1063 - accuracy: 0.6073 - val_loss: 2.8873 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 418/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2153 - accuracy: 0.5767\n",
      "Epoch 418: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2153 - accuracy: 0.5767 - val_loss: 2.8860 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 419/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1789 - accuracy: 0.5840\n",
      "Epoch 419: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1789 - accuracy: 0.5840 - val_loss: 2.8855 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 420/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1830 - accuracy: 0.5879\n",
      "Epoch 420: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.1830 - accuracy: 0.5879 - val_loss: 2.8834 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 421/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2220 - accuracy: 0.5802\n",
      "Epoch 421: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.2220 - accuracy: 0.5802 - val_loss: 2.8781 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 422/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1514 - accuracy: 0.5837\n",
      "Epoch 422: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1514 - accuracy: 0.5837 - val_loss: 2.8675 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 423/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1911 - accuracy: 0.5996\n",
      "Epoch 423: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.1911 - accuracy: 0.5996 - val_loss: 2.8607 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 424/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1724 - accuracy: 0.5896\n",
      "Epoch 424: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1724 - accuracy: 0.5896 - val_loss: 2.8563 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 425/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1792 - accuracy: 0.6026\n",
      "Epoch 425: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1792 - accuracy: 0.6026 - val_loss: 2.8604 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 426/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1577 - accuracy: 0.5967\n",
      "Epoch 426: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.1577 - accuracy: 0.5967 - val_loss: 2.8591 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 427/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1814 - accuracy: 0.5928\n",
      "Epoch 427: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.1814 - accuracy: 0.5928 - val_loss: 2.8574 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 428/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2114 - accuracy: 0.5672\n",
      "Epoch 428: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.2114 - accuracy: 0.5672 - val_loss: 2.8545 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 429/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1112 - accuracy: 0.6250\n",
      "Epoch 429: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1112 - accuracy: 0.6250 - val_loss: 2.8438 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 430/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2109 - accuracy: 0.5625\n",
      "Epoch 430: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.2109 - accuracy: 0.5625 - val_loss: 2.8375 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 431/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1667 - accuracy: 0.5861\n",
      "Epoch 431: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1667 - accuracy: 0.5861 - val_loss: 2.8239 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 432/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2159 - accuracy: 0.5837\n",
      "Epoch 432: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.2159 - accuracy: 0.5837 - val_loss: 2.8214 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 433/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1512 - accuracy: 0.5932\n",
      "Epoch 433: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1512 - accuracy: 0.5932 - val_loss: 2.8237 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 434/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1869 - accuracy: 0.5957\n",
      "Epoch 434: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1869 - accuracy: 0.5957 - val_loss: 2.8232 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 435/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1506 - accuracy: 0.6002\n",
      "Epoch 435: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1506 - accuracy: 0.6002 - val_loss: 2.8092 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 436/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1808 - accuracy: 0.5873\n",
      "Epoch 436: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1808 - accuracy: 0.5873 - val_loss: 2.8013 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 437/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1875 - accuracy: 0.5755\n",
      "Epoch 437: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.1875 - accuracy: 0.5755 - val_loss: 2.7943 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 438/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1769 - accuracy: 0.6016\n",
      "Epoch 438: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1769 - accuracy: 0.6016 - val_loss: 2.7957 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 439/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1576 - accuracy: 0.5884\n",
      "Epoch 439: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.1576 - accuracy: 0.5884 - val_loss: 2.8014 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 440/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1983 - accuracy: 0.5837\n",
      "Epoch 440: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1983 - accuracy: 0.5837 - val_loss: 2.7962 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 441/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1416 - accuracy: 0.6097\n",
      "Epoch 441: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1416 - accuracy: 0.6097 - val_loss: 2.7965 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 442/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2090 - accuracy: 0.5742\n",
      "Epoch 442: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.2090 - accuracy: 0.5742 - val_loss: 2.8030 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 443/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1866 - accuracy: 0.5778\n",
      "Epoch 443: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1866 - accuracy: 0.5778 - val_loss: 2.8142 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 444/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1540 - accuracy: 0.6061\n",
      "Epoch 444: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1540 - accuracy: 0.6061 - val_loss: 2.8123 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 445/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1746 - accuracy: 0.5979\n",
      "Epoch 445: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.1746 - accuracy: 0.5979 - val_loss: 2.8170 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 446/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2425 - accuracy: 0.5778\n",
      "Epoch 446: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.2425 - accuracy: 0.5778 - val_loss: 2.8149 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 447/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1864 - accuracy: 0.5955\n",
      "Epoch 447: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.1864 - accuracy: 0.5955 - val_loss: 2.8069 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 448/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1698 - accuracy: 0.5790\n",
      "Epoch 448: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1698 - accuracy: 0.5790 - val_loss: 2.8016 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 449/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1553 - accuracy: 0.5928\n",
      "Epoch 449: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.1553 - accuracy: 0.5928 - val_loss: 2.7996 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 450/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1573 - accuracy: 0.6014\n",
      "Epoch 450: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.1573 - accuracy: 0.6014 - val_loss: 2.7987 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 451/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1795 - accuracy: 0.6050\n",
      "Epoch 451: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1795 - accuracy: 0.6050 - val_loss: 2.7974 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 452/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1676 - accuracy: 0.5873\n",
      "Epoch 452: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1676 - accuracy: 0.5873 - val_loss: 2.7961 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 453/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1679 - accuracy: 0.6014\n",
      "Epoch 453: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1679 - accuracy: 0.6014 - val_loss: 2.7927 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 454/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2014 - accuracy: 0.5645\n",
      "Epoch 454: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 1.2014 - accuracy: 0.5645 - val_loss: 2.7898 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 455/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.6073\n",
      "Epoch 455: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1712 - accuracy: 0.6073 - val_loss: 2.7911 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 456/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1645 - accuracy: 0.5947\n",
      "Epoch 456: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.1645 - accuracy: 0.5947 - val_loss: 2.7942 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 457/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1483 - accuracy: 0.5884\n",
      "Epoch 457: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1483 - accuracy: 0.5884 - val_loss: 2.7916 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 458/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1584 - accuracy: 0.5802\n",
      "Epoch 458: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1584 - accuracy: 0.5802 - val_loss: 2.7917 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 459/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1426 - accuracy: 0.5873\n",
      "Epoch 459: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1426 - accuracy: 0.5873 - val_loss: 2.8044 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 460/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1588 - accuracy: 0.5928\n",
      "Epoch 460: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 1.1588 - accuracy: 0.5928 - val_loss: 2.8026 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 461/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1856 - accuracy: 0.5755\n",
      "Epoch 461: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.1856 - accuracy: 0.5755 - val_loss: 2.8036 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 462/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1518 - accuracy: 0.6097\n",
      "Epoch 462: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1518 - accuracy: 0.6097 - val_loss: 2.8018 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 463/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1576 - accuracy: 0.5884\n",
      "Epoch 463: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.1576 - accuracy: 0.5884 - val_loss: 2.8034 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 464/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1790 - accuracy: 0.5898\n",
      "Epoch 464: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.1790 - accuracy: 0.5898 - val_loss: 2.8029 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 465/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1764 - accuracy: 0.5943\n",
      "Epoch 465: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1764 - accuracy: 0.5943 - val_loss: 2.8071 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 466/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0332 - accuracy: 0.6226\n",
      "Epoch 466: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.0332 - accuracy: 0.6226 - val_loss: 2.8068 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 467/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1422 - accuracy: 0.5979\n",
      "Epoch 467: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.1422 - accuracy: 0.5979 - val_loss: 2.8038 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 468/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1198 - accuracy: 0.5967\n",
      "Epoch 468: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1198 - accuracy: 0.5967 - val_loss: 2.7972 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 469/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1543 - accuracy: 0.5859\n",
      "Epoch 469: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.1543 - accuracy: 0.5859 - val_loss: 2.7923 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 470/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1078 - accuracy: 0.6026\n",
      "Epoch 470: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1078 - accuracy: 0.6026 - val_loss: 2.7915 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 471/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1964 - accuracy: 0.5861\n",
      "Epoch 471: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1964 - accuracy: 0.5861 - val_loss: 2.7864 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 472/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2233 - accuracy: 0.5637\n",
      "Epoch 472: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.2233 - accuracy: 0.5637 - val_loss: 2.7884 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 473/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1515 - accuracy: 0.5920\n",
      "Epoch 473: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.1515 - accuracy: 0.5920 - val_loss: 2.7854 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 474/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1842 - accuracy: 0.5932\n",
      "Epoch 474: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.1842 - accuracy: 0.5932 - val_loss: 2.7837 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 475/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1098 - accuracy: 0.6038\n",
      "Epoch 475: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.1098 - accuracy: 0.6038 - val_loss: 2.7771 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 476/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1471 - accuracy: 0.6026\n",
      "Epoch 476: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1471 - accuracy: 0.6026 - val_loss: 2.7786 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 477/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1253 - accuracy: 0.6108\n",
      "Epoch 477: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1253 - accuracy: 0.6108 - val_loss: 2.7703 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 478/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1986 - accuracy: 0.5837\n",
      "Epoch 478: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1986 - accuracy: 0.5837 - val_loss: 2.7749 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 479/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1458 - accuracy: 0.6038\n",
      "Epoch 479: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.1458 - accuracy: 0.6038 - val_loss: 2.7729 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 480/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1424 - accuracy: 0.6262\n",
      "Epoch 480: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.1424 - accuracy: 0.6262 - val_loss: 2.7732 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 481/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1445 - accuracy: 0.5977\n",
      "Epoch 481: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1445 - accuracy: 0.5977 - val_loss: 2.7718 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 482/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1901 - accuracy: 0.5790\n",
      "Epoch 482: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1901 - accuracy: 0.5790 - val_loss: 2.7752 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 483/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1565 - accuracy: 0.5849\n",
      "Epoch 483: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1565 - accuracy: 0.5849 - val_loss: 2.7759 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 484/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1215 - accuracy: 0.6215\n",
      "Epoch 484: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.1215 - accuracy: 0.6215 - val_loss: 2.7792 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 485/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1180 - accuracy: 0.5979\n",
      "Epoch 485: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1180 - accuracy: 0.5979 - val_loss: 2.7864 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 486/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1533 - accuracy: 0.6016\n",
      "Epoch 486: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1533 - accuracy: 0.6016 - val_loss: 2.7931 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 487/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1437 - accuracy: 0.6156\n",
      "Epoch 487: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1437 - accuracy: 0.6156 - val_loss: 2.7974 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 488/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1487 - accuracy: 0.6002\n",
      "Epoch 488: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1487 - accuracy: 0.6002 - val_loss: 2.8030 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 489/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2180 - accuracy: 0.5778\n",
      "Epoch 489: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.2180 - accuracy: 0.5778 - val_loss: 2.8038 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 490/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1054 - accuracy: 0.6120\n",
      "Epoch 490: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.1054 - accuracy: 0.6120 - val_loss: 2.8030 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 491/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1719 - accuracy: 0.5615\n",
      "Epoch 491: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.1719 - accuracy: 0.5615 - val_loss: 2.8130 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 492/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1415 - accuracy: 0.5920\n",
      "Epoch 492: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1415 - accuracy: 0.5920 - val_loss: 2.8184 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 493/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1011 - accuracy: 0.6108\n",
      "Epoch 493: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1011 - accuracy: 0.6108 - val_loss: 2.8295 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 494/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1575 - accuracy: 0.6055\n",
      "Epoch 494: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1575 - accuracy: 0.6055 - val_loss: 2.8320 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 495/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1408 - accuracy: 0.6050\n",
      "Epoch 495: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1408 - accuracy: 0.6050 - val_loss: 2.8306 - val_accuracy: 0.3321 - lr: 1.0000e-05\n",
      "Epoch 496/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1697 - accuracy: 0.5861\n",
      "Epoch 496: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.1697 - accuracy: 0.5861 - val_loss: 2.8221 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 497/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1428 - accuracy: 0.6038\n",
      "Epoch 497: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1428 - accuracy: 0.6038 - val_loss: 2.8197 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 498/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1517 - accuracy: 0.6108\n",
      "Epoch 498: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1517 - accuracy: 0.6108 - val_loss: 2.8107 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 499/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1604 - accuracy: 0.5896\n",
      "Epoch 499: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1604 - accuracy: 0.5896 - val_loss: 2.8045 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 500/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0925 - accuracy: 0.6073\n",
      "Epoch 500: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0925 - accuracy: 0.6073 - val_loss: 2.7974 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 501/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1612 - accuracy: 0.5967\n",
      "Epoch 501: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1612 - accuracy: 0.5967 - val_loss: 2.7912 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 502/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1528 - accuracy: 0.6132\n",
      "Epoch 502: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.1528 - accuracy: 0.6132 - val_loss: 2.7855 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 503/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1180 - accuracy: 0.6162\n",
      "Epoch 503: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1180 - accuracy: 0.6162 - val_loss: 2.7853 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 504/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1767 - accuracy: 0.5908\n",
      "Epoch 504: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1767 - accuracy: 0.5908 - val_loss: 2.7841 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 505/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1426 - accuracy: 0.6026\n",
      "Epoch 505: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1426 - accuracy: 0.6026 - val_loss: 2.7845 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 506/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1170 - accuracy: 0.6215\n",
      "Epoch 506: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.1170 - accuracy: 0.6215 - val_loss: 2.7758 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 507/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1439 - accuracy: 0.5955\n",
      "Epoch 507: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1439 - accuracy: 0.5955 - val_loss: 2.7759 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 508/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1665 - accuracy: 0.5896\n",
      "Epoch 508: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1665 - accuracy: 0.5896 - val_loss: 2.7811 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 509/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1694 - accuracy: 0.6045\n",
      "Epoch 509: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 1.1694 - accuracy: 0.6045 - val_loss: 2.7809 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 510/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1778 - accuracy: 0.5979\n",
      "Epoch 510: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.1778 - accuracy: 0.5979 - val_loss: 2.7890 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 511/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1080 - accuracy: 0.6179\n",
      "Epoch 511: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.1080 - accuracy: 0.6179 - val_loss: 2.7928 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 512/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1654 - accuracy: 0.5896\n",
      "Epoch 512: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1654 - accuracy: 0.5896 - val_loss: 2.7967 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 513/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1215 - accuracy: 0.6055\n",
      "Epoch 513: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.1215 - accuracy: 0.6055 - val_loss: 2.7905 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 514/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1260 - accuracy: 0.6097\n",
      "Epoch 514: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.1260 - accuracy: 0.6097 - val_loss: 2.7845 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 515/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1716 - accuracy: 0.5873\n",
      "Epoch 515: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.1716 - accuracy: 0.5873 - val_loss: 2.7789 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 516/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1462 - accuracy: 0.6191\n",
      "Epoch 516: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1462 - accuracy: 0.6191 - val_loss: 2.7806 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 517/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1150 - accuracy: 0.6085\n",
      "Epoch 517: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1150 - accuracy: 0.6085 - val_loss: 2.7696 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 518/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1470 - accuracy: 0.5943\n",
      "Epoch 518: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.1470 - accuracy: 0.5943 - val_loss: 2.7650 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 519/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1151 - accuracy: 0.6055\n",
      "Epoch 519: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1151 - accuracy: 0.6055 - val_loss: 2.7563 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 520/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1321 - accuracy: 0.6025\n",
      "Epoch 520: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1321 - accuracy: 0.6025 - val_loss: 2.7552 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 521/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1223 - accuracy: 0.6038\n",
      "Epoch 521: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.1223 - accuracy: 0.6038 - val_loss: 2.7542 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 522/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2052 - accuracy: 0.5991\n",
      "Epoch 522: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.2052 - accuracy: 0.5991 - val_loss: 2.7505 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 523/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1225 - accuracy: 0.6179\n",
      "Epoch 523: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.1225 - accuracy: 0.6179 - val_loss: 2.7478 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 524/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1572 - accuracy: 0.5991\n",
      "Epoch 524: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.1572 - accuracy: 0.5991 - val_loss: 2.7419 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 525/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1296 - accuracy: 0.5986\n",
      "Epoch 525: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 1.1296 - accuracy: 0.5986 - val_loss: 2.7395 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 526/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0994 - accuracy: 0.6120\n",
      "Epoch 526: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.0994 - accuracy: 0.6120 - val_loss: 2.7324 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 527/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1556 - accuracy: 0.5967\n",
      "Epoch 527: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.1556 - accuracy: 0.5967 - val_loss: 2.7268 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 528/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1333 - accuracy: 0.6016\n",
      "Epoch 528: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1333 - accuracy: 0.6016 - val_loss: 2.7242 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 529/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1292 - accuracy: 0.5991\n",
      "Epoch 529: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.1292 - accuracy: 0.5991 - val_loss: 2.7177 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 530/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1283 - accuracy: 0.6179\n",
      "Epoch 530: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1283 - accuracy: 0.6179 - val_loss: 2.7092 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 531/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1857 - accuracy: 0.5790\n",
      "Epoch 531: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.1857 - accuracy: 0.5790 - val_loss: 2.7069 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 532/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1552 - accuracy: 0.5918\n",
      "Epoch 532: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1552 - accuracy: 0.5918 - val_loss: 2.7076 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 533/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1199 - accuracy: 0.6002\n",
      "Epoch 533: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.1199 - accuracy: 0.6002 - val_loss: 2.7132 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 534/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1493 - accuracy: 0.6002\n",
      "Epoch 534: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.1493 - accuracy: 0.6002 - val_loss: 2.7036 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 535/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1380 - accuracy: 0.6026\n",
      "Epoch 535: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1380 - accuracy: 0.6026 - val_loss: 2.7106 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 536/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1363 - accuracy: 0.6097\n",
      "Epoch 536: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1363 - accuracy: 0.6097 - val_loss: 2.6974 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 537/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1401 - accuracy: 0.6038\n",
      "Epoch 537: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1401 - accuracy: 0.6038 - val_loss: 2.7021 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 538/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1359 - accuracy: 0.5996\n",
      "Epoch 538: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.1359 - accuracy: 0.5996 - val_loss: 2.7012 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 539/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1360 - accuracy: 0.6026\n",
      "Epoch 539: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 1.1360 - accuracy: 0.6026 - val_loss: 2.7141 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 540/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2091 - accuracy: 0.5778\n",
      "Epoch 540: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.2091 - accuracy: 0.5778 - val_loss: 2.7185 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 541/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1378 - accuracy: 0.6144\n",
      "Epoch 541: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1378 - accuracy: 0.6144 - val_loss: 2.7269 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 542/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1025 - accuracy: 0.6132\n",
      "Epoch 542: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.1025 - accuracy: 0.6132 - val_loss: 2.7202 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 543/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1186 - accuracy: 0.6179\n",
      "Epoch 543: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1186 - accuracy: 0.6179 - val_loss: 2.7166 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 544/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1175 - accuracy: 0.6120\n",
      "Epoch 544: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1175 - accuracy: 0.6120 - val_loss: 2.7100 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 545/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1387 - accuracy: 0.5943\n",
      "Epoch 545: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.1387 - accuracy: 0.5943 - val_loss: 2.7011 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 546/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0683 - accuracy: 0.6321\n",
      "Epoch 546: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0683 - accuracy: 0.6321 - val_loss: 2.6936 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 547/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1439 - accuracy: 0.6179\n",
      "Epoch 547: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1439 - accuracy: 0.6179 - val_loss: 2.6920 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 548/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1534 - accuracy: 0.5790\n",
      "Epoch 548: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.1534 - accuracy: 0.5790 - val_loss: 2.6899 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 549/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1598 - accuracy: 0.5967\n",
      "Epoch 549: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.1598 - accuracy: 0.5967 - val_loss: 2.6877 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 550/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1135 - accuracy: 0.6132\n",
      "Epoch 550: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1135 - accuracy: 0.6132 - val_loss: 2.6935 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 551/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1180 - accuracy: 0.6215\n",
      "Epoch 551: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.1180 - accuracy: 0.6215 - val_loss: 2.6938 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 552/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1083 - accuracy: 0.6152\n",
      "Epoch 552: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.1083 - accuracy: 0.6152 - val_loss: 2.6907 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 553/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1405 - accuracy: 0.6120\n",
      "Epoch 553: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1405 - accuracy: 0.6120 - val_loss: 2.6883 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 554/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1206 - accuracy: 0.6002\n",
      "Epoch 554: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1206 - accuracy: 0.6002 - val_loss: 2.6930 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 555/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1348 - accuracy: 0.6038\n",
      "Epoch 555: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.1348 - accuracy: 0.6038 - val_loss: 2.6937 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 556/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1424 - accuracy: 0.5967\n",
      "Epoch 556: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1424 - accuracy: 0.5967 - val_loss: 2.6956 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 557/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0930 - accuracy: 0.6167\n",
      "Epoch 557: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 1.0930 - accuracy: 0.6167 - val_loss: 2.6926 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 558/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0956 - accuracy: 0.5967\n",
      "Epoch 558: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0956 - accuracy: 0.5967 - val_loss: 2.6889 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 559/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1231 - accuracy: 0.6226\n",
      "Epoch 559: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1231 - accuracy: 0.6226 - val_loss: 2.6778 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 560/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0829 - accuracy: 0.6156\n",
      "Epoch 560: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0829 - accuracy: 0.6156 - val_loss: 2.6799 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 561/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0783 - accuracy: 0.6167\n",
      "Epoch 561: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.0783 - accuracy: 0.6167 - val_loss: 2.6803 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 562/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1268 - accuracy: 0.6097\n",
      "Epoch 562: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.1268 - accuracy: 0.6097 - val_loss: 2.6754 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 563/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1313 - accuracy: 0.6108\n",
      "Epoch 563: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.1313 - accuracy: 0.6108 - val_loss: 2.6639 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 564/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1115 - accuracy: 0.5979\n",
      "Epoch 564: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1115 - accuracy: 0.5979 - val_loss: 2.6563 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 565/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0757 - accuracy: 0.6415\n",
      "Epoch 565: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.0757 - accuracy: 0.6415 - val_loss: 2.6524 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 566/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1327 - accuracy: 0.6026\n",
      "Epoch 566: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1327 - accuracy: 0.6026 - val_loss: 2.6442 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 567/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0714 - accuracy: 0.6167\n",
      "Epoch 567: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0714 - accuracy: 0.6167 - val_loss: 2.6364 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 568/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1119 - accuracy: 0.6016\n",
      "Epoch 568: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.1119 - accuracy: 0.6016 - val_loss: 2.6313 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 569/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1291 - accuracy: 0.6002\n",
      "Epoch 569: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.1291 - accuracy: 0.6002 - val_loss: 2.6278 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 570/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1248 - accuracy: 0.6050\n",
      "Epoch 570: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1248 - accuracy: 0.6050 - val_loss: 2.6255 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 571/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1071 - accuracy: 0.6274\n",
      "Epoch 571: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.1071 - accuracy: 0.6274 - val_loss: 2.6269 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 572/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1730 - accuracy: 0.5825\n",
      "Epoch 572: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1730 - accuracy: 0.5825 - val_loss: 2.6190 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 573/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1491 - accuracy: 0.5814\n",
      "Epoch 573: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.1491 - accuracy: 0.5814 - val_loss: 2.6114 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 574/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1070 - accuracy: 0.6333\n",
      "Epoch 574: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1070 - accuracy: 0.6333 - val_loss: 2.6076 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 575/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0514 - accuracy: 0.6274\n",
      "Epoch 575: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0514 - accuracy: 0.6274 - val_loss: 2.6155 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 576/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1391 - accuracy: 0.6045\n",
      "Epoch 576: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1391 - accuracy: 0.6045 - val_loss: 2.6137 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 577/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0883 - accuracy: 0.6144\n",
      "Epoch 577: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0883 - accuracy: 0.6144 - val_loss: 2.6171 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 578/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0739 - accuracy: 0.6162\n",
      "Epoch 578: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.0739 - accuracy: 0.6162 - val_loss: 2.6163 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 579/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0878 - accuracy: 0.6120\n",
      "Epoch 579: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.0878 - accuracy: 0.6120 - val_loss: 2.6163 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 580/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1711 - accuracy: 0.5861\n",
      "Epoch 580: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1711 - accuracy: 0.5861 - val_loss: 2.6220 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 581/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1957 - accuracy: 0.5672\n",
      "Epoch 581: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.1957 - accuracy: 0.5672 - val_loss: 2.6187 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 582/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0845 - accuracy: 0.6191\n",
      "Epoch 582: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.0845 - accuracy: 0.6191 - val_loss: 2.6210 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 583/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0775 - accuracy: 0.6250\n",
      "Epoch 583: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0775 - accuracy: 0.6250 - val_loss: 2.6183 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 584/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1937 - accuracy: 0.6014\n",
      "Epoch 584: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1937 - accuracy: 0.6014 - val_loss: 2.6223 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 585/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1130 - accuracy: 0.6108\n",
      "Epoch 585: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1130 - accuracy: 0.6108 - val_loss: 2.6249 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 586/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1092 - accuracy: 0.6144\n",
      "Epoch 586: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.1092 - accuracy: 0.6144 - val_loss: 2.6223 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 587/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0613 - accuracy: 0.6203\n",
      "Epoch 587: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.0613 - accuracy: 0.6203 - val_loss: 2.6211 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 588/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0690 - accuracy: 0.6285\n",
      "Epoch 588: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0690 - accuracy: 0.6285 - val_loss: 2.6302 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 589/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1359 - accuracy: 0.6061\n",
      "Epoch 589: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.1359 - accuracy: 0.6061 - val_loss: 2.6370 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 590/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1013 - accuracy: 0.6260\n",
      "Epoch 590: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1013 - accuracy: 0.6260 - val_loss: 2.6470 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 591/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1078 - accuracy: 0.6132\n",
      "Epoch 591: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1078 - accuracy: 0.6132 - val_loss: 2.6548 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 592/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0866 - accuracy: 0.6073\n",
      "Epoch 592: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0866 - accuracy: 0.6073 - val_loss: 2.6648 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 593/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1306 - accuracy: 0.6203\n",
      "Epoch 593: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1306 - accuracy: 0.6203 - val_loss: 2.6723 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 594/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1235 - accuracy: 0.5920\n",
      "Epoch 594: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1235 - accuracy: 0.5920 - val_loss: 2.6745 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 595/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1122 - accuracy: 0.6050\n",
      "Epoch 595: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.1122 - accuracy: 0.6050 - val_loss: 2.6794 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 596/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1157 - accuracy: 0.6182\n",
      "Epoch 596: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.1157 - accuracy: 0.6182 - val_loss: 2.6758 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 597/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1300 - accuracy: 0.6167\n",
      "Epoch 597: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.1300 - accuracy: 0.6167 - val_loss: 2.6726 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 598/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0891 - accuracy: 0.6415\n",
      "Epoch 598: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.0891 - accuracy: 0.6415 - val_loss: 2.6655 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 599/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1072 - accuracy: 0.6143\n",
      "Epoch 599: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.1072 - accuracy: 0.6143 - val_loss: 2.6624 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 600/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0881 - accuracy: 0.6108\n",
      "Epoch 600: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0881 - accuracy: 0.6108 - val_loss: 2.6570 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 601/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1669 - accuracy: 0.5955\n",
      "Epoch 601: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1669 - accuracy: 0.5955 - val_loss: 2.6596 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 602/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1123 - accuracy: 0.6144\n",
      "Epoch 602: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 1.1123 - accuracy: 0.6144 - val_loss: 2.6643 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 603/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1216 - accuracy: 0.6299\n",
      "Epoch 603: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 1.1216 - accuracy: 0.6299 - val_loss: 2.6692 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 604/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0477 - accuracy: 0.6238\n",
      "Epoch 604: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0477 - accuracy: 0.6238 - val_loss: 2.6711 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 605/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0857 - accuracy: 0.6179\n",
      "Epoch 605: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0857 - accuracy: 0.6179 - val_loss: 2.6581 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 606/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0904 - accuracy: 0.6144\n",
      "Epoch 606: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0904 - accuracy: 0.6144 - val_loss: 2.6596 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 607/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1002 - accuracy: 0.6026\n",
      "Epoch 607: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1002 - accuracy: 0.6026 - val_loss: 2.6609 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 608/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1378 - accuracy: 0.6026\n",
      "Epoch 608: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.1378 - accuracy: 0.6026 - val_loss: 2.6591 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 609/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0954 - accuracy: 0.6250\n",
      "Epoch 609: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.0954 - accuracy: 0.6250 - val_loss: 2.6519 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 610/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1256 - accuracy: 0.6085\n",
      "Epoch 610: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.1256 - accuracy: 0.6085 - val_loss: 2.6594 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 611/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0844 - accuracy: 0.6226\n",
      "Epoch 611: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0844 - accuracy: 0.6226 - val_loss: 2.6595 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 612/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1229 - accuracy: 0.6221\n",
      "Epoch 612: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.1229 - accuracy: 0.6221 - val_loss: 2.6543 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 613/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1338 - accuracy: 0.6108\n",
      "Epoch 613: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.1338 - accuracy: 0.6108 - val_loss: 2.6600 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 614/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1268 - accuracy: 0.6144\n",
      "Epoch 614: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.1268 - accuracy: 0.6144 - val_loss: 2.6544 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 615/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1139 - accuracy: 0.6085\n",
      "Epoch 615: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.1139 - accuracy: 0.6085 - val_loss: 2.6510 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 616/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1065 - accuracy: 0.6074\n",
      "Epoch 616: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.1065 - accuracy: 0.6074 - val_loss: 2.6536 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 617/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1035 - accuracy: 0.6038\n",
      "Epoch 617: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.1035 - accuracy: 0.6038 - val_loss: 2.6516 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 618/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1127 - accuracy: 0.6309\n",
      "Epoch 618: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1127 - accuracy: 0.6309 - val_loss: 2.6547 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 619/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0900 - accuracy: 0.6133\n",
      "Epoch 619: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.0900 - accuracy: 0.6133 - val_loss: 2.6476 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 620/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1481 - accuracy: 0.5861\n",
      "Epoch 620: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.1481 - accuracy: 0.5861 - val_loss: 2.6392 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 621/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0495 - accuracy: 0.6297\n",
      "Epoch 621: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0495 - accuracy: 0.6297 - val_loss: 2.6371 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 622/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1076 - accuracy: 0.5991\n",
      "Epoch 622: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.1076 - accuracy: 0.5991 - val_loss: 2.6282 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 623/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0442 - accuracy: 0.6380\n",
      "Epoch 623: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0442 - accuracy: 0.6380 - val_loss: 2.6117 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 624/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0803 - accuracy: 0.6167\n",
      "Epoch 624: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0803 - accuracy: 0.6167 - val_loss: 2.6102 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 625/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0922 - accuracy: 0.6179\n",
      "Epoch 625: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0922 - accuracy: 0.6179 - val_loss: 2.6092 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 626/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1087 - accuracy: 0.6179\n",
      "Epoch 626: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.1087 - accuracy: 0.6179 - val_loss: 2.6107 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 627/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1058 - accuracy: 0.6191\n",
      "Epoch 627: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 1.1058 - accuracy: 0.6191 - val_loss: 2.6053 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 628/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1157 - accuracy: 0.5979\n",
      "Epoch 628: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.1157 - accuracy: 0.5979 - val_loss: 2.6031 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 629/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0754 - accuracy: 0.6203\n",
      "Epoch 629: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0754 - accuracy: 0.6203 - val_loss: 2.5990 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 630/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1187 - accuracy: 0.5967\n",
      "Epoch 630: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1187 - accuracy: 0.5967 - val_loss: 2.5936 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 631/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0966 - accuracy: 0.6061\n",
      "Epoch 631: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.0966 - accuracy: 0.6061 - val_loss: 2.5984 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 632/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1265 - accuracy: 0.5920\n",
      "Epoch 632: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1265 - accuracy: 0.5920 - val_loss: 2.5936 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 633/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0616 - accuracy: 0.6344\n",
      "Epoch 633: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0616 - accuracy: 0.6344 - val_loss: 2.5912 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 634/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0547 - accuracy: 0.6333\n",
      "Epoch 634: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0547 - accuracy: 0.6333 - val_loss: 2.5832 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 635/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0625 - accuracy: 0.6215\n",
      "Epoch 635: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0625 - accuracy: 0.6215 - val_loss: 2.5856 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 636/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0952 - accuracy: 0.6085\n",
      "Epoch 636: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.0952 - accuracy: 0.6085 - val_loss: 2.5805 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 637/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0804 - accuracy: 0.6309\n",
      "Epoch 637: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0804 - accuracy: 0.6309 - val_loss: 2.5773 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 638/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1410 - accuracy: 0.6061\n",
      "Epoch 638: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.1410 - accuracy: 0.6061 - val_loss: 2.5823 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 639/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0877 - accuracy: 0.6144\n",
      "Epoch 639: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.0877 - accuracy: 0.6144 - val_loss: 2.5860 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 640/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1066 - accuracy: 0.6038\n",
      "Epoch 640: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.1066 - accuracy: 0.6038 - val_loss: 2.5987 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 641/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1141 - accuracy: 0.5947\n",
      "Epoch 641: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 1.1141 - accuracy: 0.5947 - val_loss: 2.6036 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 642/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1735 - accuracy: 0.6108\n",
      "Epoch 642: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1735 - accuracy: 0.6108 - val_loss: 2.6109 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 643/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0638 - accuracy: 0.6211\n",
      "Epoch 643: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0638 - accuracy: 0.6211 - val_loss: 2.6148 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 644/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0729 - accuracy: 0.6344\n",
      "Epoch 644: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0729 - accuracy: 0.6344 - val_loss: 2.6153 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 645/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0696 - accuracy: 0.6191\n",
      "Epoch 645: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0696 - accuracy: 0.6191 - val_loss: 2.6146 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 646/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0587 - accuracy: 0.6250\n",
      "Epoch 646: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0587 - accuracy: 0.6250 - val_loss: 2.6164 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 647/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1093 - accuracy: 0.6097\n",
      "Epoch 647: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.1093 - accuracy: 0.6097 - val_loss: 2.6190 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 648/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0820 - accuracy: 0.6025\n",
      "Epoch 648: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 1.0820 - accuracy: 0.6025 - val_loss: 2.6198 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 649/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1209 - accuracy: 0.6038\n",
      "Epoch 649: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.1209 - accuracy: 0.6038 - val_loss: 2.6120 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 650/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0732 - accuracy: 0.6250\n",
      "Epoch 650: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.0732 - accuracy: 0.6250 - val_loss: 2.6109 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 651/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0729 - accuracy: 0.6368\n",
      "Epoch 651: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0729 - accuracy: 0.6368 - val_loss: 2.6034 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 652/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1165 - accuracy: 0.6203\n",
      "Epoch 652: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1165 - accuracy: 0.6203 - val_loss: 2.5947 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 653/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0728 - accuracy: 0.6297\n",
      "Epoch 653: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0728 - accuracy: 0.6297 - val_loss: 2.5856 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 654/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0348 - accuracy: 0.6289\n",
      "Epoch 654: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0348 - accuracy: 0.6289 - val_loss: 2.5778 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 655/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0740 - accuracy: 0.6299\n",
      "Epoch 655: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0740 - accuracy: 0.6299 - val_loss: 2.5688 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 656/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1095 - accuracy: 0.5979\n",
      "Epoch 656: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.1095 - accuracy: 0.5979 - val_loss: 2.5638 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 657/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0587 - accuracy: 0.6285\n",
      "Epoch 657: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.0587 - accuracy: 0.6285 - val_loss: 2.5568 - val_accuracy: 0.3357 - lr: 1.0000e-05\n",
      "Epoch 658/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1069 - accuracy: 0.6073\n",
      "Epoch 658: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.1069 - accuracy: 0.6073 - val_loss: 2.5460 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 659/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0953 - accuracy: 0.6203\n",
      "Epoch 659: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.0953 - accuracy: 0.6203 - val_loss: 2.5342 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 660/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0772 - accuracy: 0.6179\n",
      "Epoch 660: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0772 - accuracy: 0.6179 - val_loss: 2.5341 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 661/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0992 - accuracy: 0.6108\n",
      "Epoch 661: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0992 - accuracy: 0.6108 - val_loss: 2.5358 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 662/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1453 - accuracy: 0.5908\n",
      "Epoch 662: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.1453 - accuracy: 0.5908 - val_loss: 2.5374 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 663/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0497 - accuracy: 0.6285\n",
      "Epoch 663: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0497 - accuracy: 0.6285 - val_loss: 2.5349 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 664/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1115 - accuracy: 0.6380\n",
      "Epoch 664: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1115 - accuracy: 0.6380 - val_loss: 2.5376 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 665/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1095 - accuracy: 0.6016\n",
      "Epoch 665: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.1095 - accuracy: 0.6016 - val_loss: 2.5443 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 666/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1126 - accuracy: 0.6262\n",
      "Epoch 666: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 1.1126 - accuracy: 0.6262 - val_loss: 2.5440 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 667/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0766 - accuracy: 0.6132\n",
      "Epoch 667: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0766 - accuracy: 0.6132 - val_loss: 2.5475 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 668/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0735 - accuracy: 0.6104\n",
      "Epoch 668: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.0735 - accuracy: 0.6104 - val_loss: 2.5542 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 669/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0632 - accuracy: 0.6333\n",
      "Epoch 669: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0632 - accuracy: 0.6333 - val_loss: 2.5526 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 670/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1038 - accuracy: 0.6156\n",
      "Epoch 670: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1038 - accuracy: 0.6156 - val_loss: 2.5448 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 671/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0811 - accuracy: 0.6132\n",
      "Epoch 671: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0811 - accuracy: 0.6132 - val_loss: 2.5452 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 672/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1040 - accuracy: 0.6073\n",
      "Epoch 672: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.1040 - accuracy: 0.6073 - val_loss: 2.5458 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 673/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0639 - accuracy: 0.6344\n",
      "Epoch 673: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0639 - accuracy: 0.6344 - val_loss: 2.5536 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 674/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1256 - accuracy: 0.6238\n",
      "Epoch 674: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.1256 - accuracy: 0.6238 - val_loss: 2.5606 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 675/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1040 - accuracy: 0.6215\n",
      "Epoch 675: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.1040 - accuracy: 0.6215 - val_loss: 2.5608 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 676/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0805 - accuracy: 0.6274\n",
      "Epoch 676: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0805 - accuracy: 0.6274 - val_loss: 2.5588 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 677/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1013 - accuracy: 0.6094\n",
      "Epoch 677: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 1.1013 - accuracy: 0.6094 - val_loss: 2.5595 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 678/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0543 - accuracy: 0.6285\n",
      "Epoch 678: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.0543 - accuracy: 0.6285 - val_loss: 2.5556 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 679/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0645 - accuracy: 0.6415\n",
      "Epoch 679: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.0645 - accuracy: 0.6415 - val_loss: 2.5521 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 680/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0792 - accuracy: 0.6309\n",
      "Epoch 680: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 1.0792 - accuracy: 0.6309 - val_loss: 2.5530 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 681/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0554 - accuracy: 0.6191\n",
      "Epoch 681: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0554 - accuracy: 0.6191 - val_loss: 2.5419 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 682/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1705 - accuracy: 0.5991\n",
      "Epoch 682: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.1705 - accuracy: 0.5991 - val_loss: 2.5360 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 683/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1613 - accuracy: 0.5884\n",
      "Epoch 683: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1613 - accuracy: 0.5884 - val_loss: 2.5282 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 684/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0508 - accuracy: 0.6415\n",
      "Epoch 684: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.0508 - accuracy: 0.6415 - val_loss: 2.5200 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 685/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0531 - accuracy: 0.6250\n",
      "Epoch 685: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0531 - accuracy: 0.6250 - val_loss: 2.5171 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 686/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0752 - accuracy: 0.6297\n",
      "Epoch 686: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.0752 - accuracy: 0.6297 - val_loss: 2.5309 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 687/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0602 - accuracy: 0.6321\n",
      "Epoch 687: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0602 - accuracy: 0.6321 - val_loss: 2.5350 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 688/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0966 - accuracy: 0.6133\n",
      "Epoch 688: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0966 - accuracy: 0.6133 - val_loss: 2.5301 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 689/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1517 - accuracy: 0.5837\n",
      "Epoch 689: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.1517 - accuracy: 0.5837 - val_loss: 2.5185 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 690/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1029 - accuracy: 0.6226\n",
      "Epoch 690: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1029 - accuracy: 0.6226 - val_loss: 2.5141 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 691/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0999 - accuracy: 0.6270\n",
      "Epoch 691: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0999 - accuracy: 0.6270 - val_loss: 2.5077 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 692/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0807 - accuracy: 0.6108\n",
      "Epoch 692: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0807 - accuracy: 0.6108 - val_loss: 2.5131 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 693/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0684 - accuracy: 0.6299\n",
      "Epoch 693: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 1.0684 - accuracy: 0.6299 - val_loss: 2.5213 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 694/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0980 - accuracy: 0.6356\n",
      "Epoch 694: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0980 - accuracy: 0.6356 - val_loss: 2.5236 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 695/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0270 - accuracy: 0.6380\n",
      "Epoch 695: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0270 - accuracy: 0.6380 - val_loss: 2.5316 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 696/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0944 - accuracy: 0.6179\n",
      "Epoch 696: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0944 - accuracy: 0.6179 - val_loss: 2.5345 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 697/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0998 - accuracy: 0.6120\n",
      "Epoch 697: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0998 - accuracy: 0.6120 - val_loss: 2.5401 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 698/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0724 - accuracy: 0.6152\n",
      "Epoch 698: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 1.0724 - accuracy: 0.6152 - val_loss: 2.5401 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 699/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0982 - accuracy: 0.6050\n",
      "Epoch 699: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0982 - accuracy: 0.6050 - val_loss: 2.5434 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 700/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0003 - accuracy: 0.6675\n",
      "Epoch 700: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.0003 - accuracy: 0.6675 - val_loss: 2.5465 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 701/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1091 - accuracy: 0.6415\n",
      "Epoch 701: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.1091 - accuracy: 0.6415 - val_loss: 2.5491 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 702/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0353 - accuracy: 0.6462\n",
      "Epoch 702: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0353 - accuracy: 0.6462 - val_loss: 2.5558 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 703/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1196 - accuracy: 0.5979\n",
      "Epoch 703: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.1196 - accuracy: 0.5979 - val_loss: 2.5515 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 704/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0766 - accuracy: 0.6309\n",
      "Epoch 704: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0766 - accuracy: 0.6309 - val_loss: 2.5508 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 705/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0434 - accuracy: 0.6260\n",
      "Epoch 705: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.0434 - accuracy: 0.6260 - val_loss: 2.5542 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 706/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0580 - accuracy: 0.6387\n",
      "Epoch 706: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 1.0580 - accuracy: 0.6387 - val_loss: 2.5602 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 707/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0498 - accuracy: 0.6191\n",
      "Epoch 707: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.0498 - accuracy: 0.6191 - val_loss: 2.5701 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 708/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0381 - accuracy: 0.6156\n",
      "Epoch 708: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0381 - accuracy: 0.6156 - val_loss: 2.5649 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 709/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0806 - accuracy: 0.6279\n",
      "Epoch 709: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0806 - accuracy: 0.6279 - val_loss: 2.5664 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 710/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0710 - accuracy: 0.6297\n",
      "Epoch 710: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0710 - accuracy: 0.6297 - val_loss: 2.5677 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 711/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0985 - accuracy: 0.5873\n",
      "Epoch 711: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 1.0985 - accuracy: 0.5873 - val_loss: 2.5632 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 712/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0552 - accuracy: 0.6191\n",
      "Epoch 712: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 1.0552 - accuracy: 0.6191 - val_loss: 2.5598 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 713/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0536 - accuracy: 0.6226\n",
      "Epoch 713: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0536 - accuracy: 0.6226 - val_loss: 2.5610 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 714/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0937 - accuracy: 0.6179\n",
      "Epoch 714: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0937 - accuracy: 0.6179 - val_loss: 2.5635 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 715/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0634 - accuracy: 0.6201\n",
      "Epoch 715: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0634 - accuracy: 0.6201 - val_loss: 2.5577 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 716/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0385 - accuracy: 0.6333\n",
      "Epoch 716: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0385 - accuracy: 0.6333 - val_loss: 2.5493 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 717/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0840 - accuracy: 0.6061\n",
      "Epoch 717: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 1.0840 - accuracy: 0.6061 - val_loss: 2.5465 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 718/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0919 - accuracy: 0.6368\n",
      "Epoch 718: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0919 - accuracy: 0.6368 - val_loss: 2.5362 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 719/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0697 - accuracy: 0.6230\n",
      "Epoch 719: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 1.0697 - accuracy: 0.6230 - val_loss: 2.5336 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 720/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0873 - accuracy: 0.6250\n",
      "Epoch 720: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 1.0873 - accuracy: 0.6250 - val_loss: 2.5248 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 721/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0871 - accuracy: 0.6061\n",
      "Epoch 721: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 1.0871 - accuracy: 0.6061 - val_loss: 2.5116 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 722/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0560 - accuracy: 0.6309\n",
      "Epoch 722: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0560 - accuracy: 0.6309 - val_loss: 2.5074 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 723/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0562 - accuracy: 0.6392\n",
      "Epoch 723: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0562 - accuracy: 0.6392 - val_loss: 2.5096 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 724/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0889 - accuracy: 0.6074\n",
      "Epoch 724: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0889 - accuracy: 0.6074 - val_loss: 2.5080 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 725/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0545 - accuracy: 0.6427\n",
      "Epoch 725: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0545 - accuracy: 0.6427 - val_loss: 2.5086 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 726/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0395 - accuracy: 0.6262\n",
      "Epoch 726: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0395 - accuracy: 0.6262 - val_loss: 2.5119 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 727/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0783 - accuracy: 0.5979\n",
      "Epoch 727: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0783 - accuracy: 0.5979 - val_loss: 2.5232 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 728/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0689 - accuracy: 0.6191\n",
      "Epoch 728: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0689 - accuracy: 0.6191 - val_loss: 2.5253 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 729/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0535 - accuracy: 0.6297\n",
      "Epoch 729: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0535 - accuracy: 0.6297 - val_loss: 2.5238 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 730/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0627 - accuracy: 0.6221\n",
      "Epoch 730: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0627 - accuracy: 0.6221 - val_loss: 2.5152 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 731/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1073 - accuracy: 0.6002\n",
      "Epoch 731: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.1073 - accuracy: 0.6002 - val_loss: 2.5135 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 732/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0607 - accuracy: 0.6368\n",
      "Epoch 732: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0607 - accuracy: 0.6368 - val_loss: 2.5126 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 733/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0606 - accuracy: 0.6179\n",
      "Epoch 733: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 1.0606 - accuracy: 0.6179 - val_loss: 2.5163 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 734/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0801 - accuracy: 0.6097\n",
      "Epoch 734: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0801 - accuracy: 0.6097 - val_loss: 2.5302 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 735/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0811 - accuracy: 0.6203\n",
      "Epoch 735: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0811 - accuracy: 0.6203 - val_loss: 2.5357 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 736/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0291 - accuracy: 0.6387\n",
      "Epoch 736: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.0291 - accuracy: 0.6387 - val_loss: 2.5386 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 737/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0722 - accuracy: 0.6179\n",
      "Epoch 737: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0722 - accuracy: 0.6179 - val_loss: 2.5427 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 738/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1065 - accuracy: 0.6156\n",
      "Epoch 738: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.1065 - accuracy: 0.6156 - val_loss: 2.5461 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 739/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1034 - accuracy: 0.5967\n",
      "Epoch 739: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.1034 - accuracy: 0.5967 - val_loss: 2.5410 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 740/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0816 - accuracy: 0.6113\n",
      "Epoch 740: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 1.0816 - accuracy: 0.6113 - val_loss: 2.5309 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 741/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0439 - accuracy: 0.6416\n",
      "Epoch 741: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 1.0439 - accuracy: 0.6416 - val_loss: 2.5226 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 742/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0556 - accuracy: 0.6285\n",
      "Epoch 742: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0556 - accuracy: 0.6285 - val_loss: 2.5054 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 743/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0475 - accuracy: 0.6250\n",
      "Epoch 743: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 1.0475 - accuracy: 0.6250 - val_loss: 2.4924 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 744/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0604 - accuracy: 0.6108\n",
      "Epoch 744: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0604 - accuracy: 0.6108 - val_loss: 2.4812 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 745/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0745 - accuracy: 0.6321\n",
      "Epoch 745: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0745 - accuracy: 0.6321 - val_loss: 2.4666 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 746/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0277 - accuracy: 0.6309\n",
      "Epoch 746: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 1.0277 - accuracy: 0.6309 - val_loss: 2.4654 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 747/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0470 - accuracy: 0.6368\n",
      "Epoch 747: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.0470 - accuracy: 0.6368 - val_loss: 2.4613 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 748/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0650 - accuracy: 0.6368\n",
      "Epoch 748: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.0650 - accuracy: 0.6368 - val_loss: 2.4603 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 749/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0611 - accuracy: 0.6238\n",
      "Epoch 749: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0611 - accuracy: 0.6238 - val_loss: 2.4655 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 750/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0704 - accuracy: 0.6211\n",
      "Epoch 750: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 1.0704 - accuracy: 0.6211 - val_loss: 2.4656 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 751/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0637 - accuracy: 0.6230\n",
      "Epoch 751: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 1.0637 - accuracy: 0.6230 - val_loss: 2.4692 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 752/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1074 - accuracy: 0.6191\n",
      "Epoch 752: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.1074 - accuracy: 0.6191 - val_loss: 2.4680 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 753/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0298 - accuracy: 0.6297\n",
      "Epoch 753: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 1.0298 - accuracy: 0.6297 - val_loss: 2.4706 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 754/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0775 - accuracy: 0.6203\n",
      "Epoch 754: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 1.0775 - accuracy: 0.6203 - val_loss: 2.4666 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 755/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0711 - accuracy: 0.6262\n",
      "Epoch 755: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0711 - accuracy: 0.6262 - val_loss: 2.4603 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 756/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0644 - accuracy: 0.6262\n",
      "Epoch 756: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0644 - accuracy: 0.6262 - val_loss: 2.4519 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 757/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0547 - accuracy: 0.6050\n",
      "Epoch 757: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0547 - accuracy: 0.6050 - val_loss: 2.4449 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 758/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0512 - accuracy: 0.6356\n",
      "Epoch 758: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0512 - accuracy: 0.6356 - val_loss: 2.4414 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 759/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0648 - accuracy: 0.6367\n",
      "Epoch 759: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0648 - accuracy: 0.6367 - val_loss: 2.4414 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 760/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0732 - accuracy: 0.6215\n",
      "Epoch 760: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0732 - accuracy: 0.6215 - val_loss: 2.4428 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 761/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0779 - accuracy: 0.6226\n",
      "Epoch 761: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.0779 - accuracy: 0.6226 - val_loss: 2.4411 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 762/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0179 - accuracy: 0.6602\n",
      "Epoch 762: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0179 - accuracy: 0.6602 - val_loss: 2.4440 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 763/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0347 - accuracy: 0.6309\n",
      "Epoch 763: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0347 - accuracy: 0.6309 - val_loss: 2.4483 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 764/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0831 - accuracy: 0.6050\n",
      "Epoch 764: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0831 - accuracy: 0.6050 - val_loss: 2.4498 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 765/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0635 - accuracy: 0.6368\n",
      "Epoch 765: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 1.0635 - accuracy: 0.6368 - val_loss: 2.4630 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 766/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0432 - accuracy: 0.6396\n",
      "Epoch 766: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 1.0432 - accuracy: 0.6396 - val_loss: 2.4698 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 767/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0451 - accuracy: 0.6297\n",
      "Epoch 767: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.0451 - accuracy: 0.6297 - val_loss: 2.4746 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 768/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0528 - accuracy: 0.6274\n",
      "Epoch 768: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0528 - accuracy: 0.6274 - val_loss: 2.4793 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 769/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0295 - accuracy: 0.6439\n",
      "Epoch 769: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0295 - accuracy: 0.6439 - val_loss: 2.4937 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 770/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0824 - accuracy: 0.6226\n",
      "Epoch 770: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0824 - accuracy: 0.6226 - val_loss: 2.5058 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 771/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.6439\n",
      "Epoch 771: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 1.0101 - accuracy: 0.6439 - val_loss: 2.5099 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 772/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0457 - accuracy: 0.6415\n",
      "Epoch 772: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 1.0457 - accuracy: 0.6415 - val_loss: 2.5093 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 773/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0237 - accuracy: 0.6380\n",
      "Epoch 773: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0237 - accuracy: 0.6380 - val_loss: 2.5112 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 774/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0557 - accuracy: 0.6348\n",
      "Epoch 774: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0557 - accuracy: 0.6348 - val_loss: 2.5076 - val_accuracy: 0.3394 - lr: 1.0000e-05\n",
      "Epoch 775/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0383 - accuracy: 0.6406\n",
      "Epoch 775: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.0383 - accuracy: 0.6406 - val_loss: 2.5032 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 776/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0824 - accuracy: 0.6215\n",
      "Epoch 776: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0824 - accuracy: 0.6215 - val_loss: 2.5006 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 777/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0252 - accuracy: 0.6475\n",
      "Epoch 777: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0252 - accuracy: 0.6475 - val_loss: 2.4895 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 778/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0691 - accuracy: 0.6415\n",
      "Epoch 778: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 1.0691 - accuracy: 0.6415 - val_loss: 2.4734 - val_accuracy: 0.3430 - lr: 1.0000e-05\n",
      "Epoch 779/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0392 - accuracy: 0.6297\n",
      "Epoch 779: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0392 - accuracy: 0.6297 - val_loss: 2.4600 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 780/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0143 - accuracy: 0.6580\n",
      "Epoch 780: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.0143 - accuracy: 0.6580 - val_loss: 2.4530 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 781/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0432 - accuracy: 0.6250\n",
      "Epoch 781: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0432 - accuracy: 0.6250 - val_loss: 2.4503 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 782/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0597 - accuracy: 0.6191\n",
      "Epoch 782: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0597 - accuracy: 0.6191 - val_loss: 2.4417 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 783/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0716 - accuracy: 0.6191\n",
      "Epoch 783: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.0716 - accuracy: 0.6191 - val_loss: 2.4375 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 784/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0576 - accuracy: 0.6474\n",
      "Epoch 784: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0576 - accuracy: 0.6474 - val_loss: 2.4430 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 785/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1020 - accuracy: 0.6226\n",
      "Epoch 785: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.1020 - accuracy: 0.6226 - val_loss: 2.4508 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 786/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0368 - accuracy: 0.6392\n",
      "Epoch 786: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0368 - accuracy: 0.6392 - val_loss: 2.4482 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 787/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0534 - accuracy: 0.6274\n",
      "Epoch 787: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 1.0534 - accuracy: 0.6274 - val_loss: 2.4467 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 788/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0597 - accuracy: 0.6321\n",
      "Epoch 788: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0597 - accuracy: 0.6321 - val_loss: 2.4485 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 789/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0926 - accuracy: 0.6120\n",
      "Epoch 789: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.0926 - accuracy: 0.6120 - val_loss: 2.4525 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 790/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0773 - accuracy: 0.6167\n",
      "Epoch 790: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.0773 - accuracy: 0.6167 - val_loss: 2.4509 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 791/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0195 - accuracy: 0.6533\n",
      "Epoch 791: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0195 - accuracy: 0.6533 - val_loss: 2.4404 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 792/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1219 - accuracy: 0.6108\n",
      "Epoch 792: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.1219 - accuracy: 0.6108 - val_loss: 2.4342 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 793/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0184 - accuracy: 0.6380\n",
      "Epoch 793: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0184 - accuracy: 0.6380 - val_loss: 2.4143 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 794/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0459 - accuracy: 0.6274\n",
      "Epoch 794: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 1.0459 - accuracy: 0.6274 - val_loss: 2.4108 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 795/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0570 - accuracy: 0.6392\n",
      "Epoch 795: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0570 - accuracy: 0.6392 - val_loss: 2.4003 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 796/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0387 - accuracy: 0.6238\n",
      "Epoch 796: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.0387 - accuracy: 0.6238 - val_loss: 2.4024 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 797/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0592 - accuracy: 0.6338\n",
      "Epoch 797: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0592 - accuracy: 0.6338 - val_loss: 2.4066 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 798/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0486 - accuracy: 0.6309\n",
      "Epoch 798: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0486 - accuracy: 0.6309 - val_loss: 2.4113 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 799/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0353 - accuracy: 0.6380\n",
      "Epoch 799: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0353 - accuracy: 0.6380 - val_loss: 2.4141 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 800/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0195 - accuracy: 0.6450\n",
      "Epoch 800: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 1.0195 - accuracy: 0.6450 - val_loss: 2.4137 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 801/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0595 - accuracy: 0.6226\n",
      "Epoch 801: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0595 - accuracy: 0.6226 - val_loss: 2.4087 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 802/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0411 - accuracy: 0.6262\n",
      "Epoch 802: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.0411 - accuracy: 0.6262 - val_loss: 2.4050 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 803/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1163 - accuracy: 0.6297\n",
      "Epoch 803: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.1163 - accuracy: 0.6297 - val_loss: 2.3864 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 804/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0144 - accuracy: 0.6309\n",
      "Epoch 804: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0144 - accuracy: 0.6309 - val_loss: 2.3755 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 805/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0186 - accuracy: 0.6521\n",
      "Epoch 805: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0186 - accuracy: 0.6521 - val_loss: 2.3759 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 806/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0336 - accuracy: 0.6450\n",
      "Epoch 806: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0336 - accuracy: 0.6450 - val_loss: 2.3722 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 807/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0798 - accuracy: 0.6285\n",
      "Epoch 807: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 1.0798 - accuracy: 0.6285 - val_loss: 2.3766 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 808/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0083 - accuracy: 0.6494\n",
      "Epoch 808: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 1.0083 - accuracy: 0.6494 - val_loss: 2.3832 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 809/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0439 - accuracy: 0.6439\n",
      "Epoch 809: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0439 - accuracy: 0.6439 - val_loss: 2.3886 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 810/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0573 - accuracy: 0.6309\n",
      "Epoch 810: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0573 - accuracy: 0.6309 - val_loss: 2.3907 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 811/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0556 - accuracy: 0.6274\n",
      "Epoch 811: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0556 - accuracy: 0.6274 - val_loss: 2.3972 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 812/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0217 - accuracy: 0.6474\n",
      "Epoch 812: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0217 - accuracy: 0.6474 - val_loss: 2.4041 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 813/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0218 - accuracy: 0.6439\n",
      "Epoch 813: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0218 - accuracy: 0.6439 - val_loss: 2.4232 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 814/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.6504\n",
      "Epoch 814: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.0049 - accuracy: 0.6504 - val_loss: 2.4387 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 815/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0273 - accuracy: 0.6215\n",
      "Epoch 815: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.0273 - accuracy: 0.6215 - val_loss: 2.4539 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 816/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0467 - accuracy: 0.6450\n",
      "Epoch 816: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0467 - accuracy: 0.6450 - val_loss: 2.4518 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 817/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0574 - accuracy: 0.6108\n",
      "Epoch 817: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 1.0574 - accuracy: 0.6108 - val_loss: 2.4480 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 818/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0067 - accuracy: 0.6474\n",
      "Epoch 818: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0067 - accuracy: 0.6474 - val_loss: 2.4465 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 819/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0587 - accuracy: 0.6167\n",
      "Epoch 819: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0587 - accuracy: 0.6167 - val_loss: 2.4416 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 820/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0227 - accuracy: 0.6462\n",
      "Epoch 820: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 1.0227 - accuracy: 0.6462 - val_loss: 2.4330 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 821/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0512 - accuracy: 0.6415\n",
      "Epoch 821: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0512 - accuracy: 0.6415 - val_loss: 2.4278 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 822/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0451 - accuracy: 0.6215\n",
      "Epoch 822: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.0451 - accuracy: 0.6215 - val_loss: 2.4305 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 823/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0681 - accuracy: 0.6215\n",
      "Epoch 823: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 1.0681 - accuracy: 0.6215 - val_loss: 2.4317 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 824/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0234 - accuracy: 0.6509\n",
      "Epoch 824: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0234 - accuracy: 0.6509 - val_loss: 2.4227 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 825/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.6557\n",
      "Epoch 825: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.0006 - accuracy: 0.6557 - val_loss: 2.4068 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 826/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1029 - accuracy: 0.6016\n",
      "Epoch 826: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 1.1029 - accuracy: 0.6016 - val_loss: 2.3957 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 827/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0432 - accuracy: 0.6309\n",
      "Epoch 827: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 1.0432 - accuracy: 0.6309 - val_loss: 2.3829 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 828/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0716 - accuracy: 0.6061\n",
      "Epoch 828: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.0716 - accuracy: 0.6061 - val_loss: 2.3766 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 829/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0413 - accuracy: 0.6403\n",
      "Epoch 829: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 1.0413 - accuracy: 0.6403 - val_loss: 2.3859 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 830/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0577 - accuracy: 0.6450\n",
      "Epoch 830: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 1.0577 - accuracy: 0.6450 - val_loss: 2.3968 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 831/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0176 - accuracy: 0.6367\n",
      "Epoch 831: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 1.0176 - accuracy: 0.6367 - val_loss: 2.4073 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 832/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0481 - accuracy: 0.6445\n",
      "Epoch 832: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 1.0481 - accuracy: 0.6445 - val_loss: 2.4147 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 833/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0437 - accuracy: 0.6392\n",
      "Epoch 833: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.0437 - accuracy: 0.6392 - val_loss: 2.4230 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 834/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0052 - accuracy: 0.6450\n",
      "Epoch 834: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0052 - accuracy: 0.6450 - val_loss: 2.4256 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 835/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0147 - accuracy: 0.6356\n",
      "Epoch 835: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0147 - accuracy: 0.6356 - val_loss: 2.4237 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 836/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0491 - accuracy: 0.6344\n",
      "Epoch 836: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0491 - accuracy: 0.6344 - val_loss: 2.4232 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 837/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9954 - accuracy: 0.6403\n",
      "Epoch 837: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9954 - accuracy: 0.6403 - val_loss: 2.4159 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 838/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0715 - accuracy: 0.6521\n",
      "Epoch 838: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.0715 - accuracy: 0.6521 - val_loss: 2.4109 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 839/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0310 - accuracy: 0.6356\n",
      "Epoch 839: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 1.0310 - accuracy: 0.6356 - val_loss: 2.4012 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 840/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9994 - accuracy: 0.6439\n",
      "Epoch 840: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.9994 - accuracy: 0.6439 - val_loss: 2.3855 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 841/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0482 - accuracy: 0.6436\n",
      "Epoch 841: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.0482 - accuracy: 0.6436 - val_loss: 2.3827 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 842/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0248 - accuracy: 0.6486\n",
      "Epoch 842: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0248 - accuracy: 0.6486 - val_loss: 2.3863 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 843/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0551 - accuracy: 0.6328\n",
      "Epoch 843: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 1.0551 - accuracy: 0.6328 - val_loss: 2.3916 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 844/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0435 - accuracy: 0.6191\n",
      "Epoch 844: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0435 - accuracy: 0.6191 - val_loss: 2.3948 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 845/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0435 - accuracy: 0.6474\n",
      "Epoch 845: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0435 - accuracy: 0.6474 - val_loss: 2.4014 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 846/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0617 - accuracy: 0.6094\n",
      "Epoch 846: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0617 - accuracy: 0.6094 - val_loss: 2.4092 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 847/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0336 - accuracy: 0.6427\n",
      "Epoch 847: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0336 - accuracy: 0.6427 - val_loss: 2.4085 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 848/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0200 - accuracy: 0.6333\n",
      "Epoch 848: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0200 - accuracy: 0.6333 - val_loss: 2.4134 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 849/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0591 - accuracy: 0.6465\n",
      "Epoch 849: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 1.0591 - accuracy: 0.6465 - val_loss: 2.4087 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 850/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0492 - accuracy: 0.6221\n",
      "Epoch 850: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0492 - accuracy: 0.6221 - val_loss: 2.4016 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 851/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0362 - accuracy: 0.6309\n",
      "Epoch 851: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 1.0362 - accuracy: 0.6309 - val_loss: 2.4014 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 852/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0524 - accuracy: 0.6509\n",
      "Epoch 852: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 1.0524 - accuracy: 0.6509 - val_loss: 2.4024 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 853/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9830 - accuracy: 0.6533\n",
      "Epoch 853: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9830 - accuracy: 0.6533 - val_loss: 2.4071 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 854/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0545 - accuracy: 0.6344\n",
      "Epoch 854: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0545 - accuracy: 0.6344 - val_loss: 2.4025 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 855/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0487 - accuracy: 0.6462\n",
      "Epoch 855: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 1.0487 - accuracy: 0.6462 - val_loss: 2.3908 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 856/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0467 - accuracy: 0.6250\n",
      "Epoch 856: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.0467 - accuracy: 0.6250 - val_loss: 2.3896 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 857/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0365 - accuracy: 0.6545\n",
      "Epoch 857: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0365 - accuracy: 0.6545 - val_loss: 2.3871 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 858/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0221 - accuracy: 0.6427\n",
      "Epoch 858: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0221 - accuracy: 0.6427 - val_loss: 2.3741 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 859/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.6580\n",
      "Epoch 859: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.0350 - accuracy: 0.6580 - val_loss: 2.3694 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 860/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0111 - accuracy: 0.6450\n",
      "Epoch 860: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 1.0111 - accuracy: 0.6450 - val_loss: 2.3649 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 861/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0475 - accuracy: 0.6328\n",
      "Epoch 861: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.0475 - accuracy: 0.6328 - val_loss: 2.3619 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 862/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9985 - accuracy: 0.6462\n",
      "Epoch 862: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9985 - accuracy: 0.6462 - val_loss: 2.3585 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 863/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.6368\n",
      "Epoch 863: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0340 - accuracy: 0.6368 - val_loss: 2.3597 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 864/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0299 - accuracy: 0.6486\n",
      "Epoch 864: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 1.0299 - accuracy: 0.6486 - val_loss: 2.3551 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 865/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9970 - accuracy: 0.6580\n",
      "Epoch 865: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9970 - accuracy: 0.6580 - val_loss: 2.3556 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 866/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.6486\n",
      "Epoch 866: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0081 - accuracy: 0.6486 - val_loss: 2.3596 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 867/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0207 - accuracy: 0.6465\n",
      "Epoch 867: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0207 - accuracy: 0.6465 - val_loss: 2.3637 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 868/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0290 - accuracy: 0.6403\n",
      "Epoch 868: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0290 - accuracy: 0.6403 - val_loss: 2.3743 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 869/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0838 - accuracy: 0.6061\n",
      "Epoch 869: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 1.0838 - accuracy: 0.6061 - val_loss: 2.3834 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 870/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0139 - accuracy: 0.6368\n",
      "Epoch 870: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.0139 - accuracy: 0.6368 - val_loss: 2.3885 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 871/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0057 - accuracy: 0.6427\n",
      "Epoch 871: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 1.0057 - accuracy: 0.6427 - val_loss: 2.3898 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 872/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0155 - accuracy: 0.6462\n",
      "Epoch 872: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0155 - accuracy: 0.6462 - val_loss: 2.3876 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 873/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0305 - accuracy: 0.6356\n",
      "Epoch 873: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0305 - accuracy: 0.6356 - val_loss: 2.3849 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 874/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0389 - accuracy: 0.6392\n",
      "Epoch 874: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0389 - accuracy: 0.6392 - val_loss: 2.3750 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 875/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9984 - accuracy: 0.6639\n",
      "Epoch 875: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9984 - accuracy: 0.6639 - val_loss: 2.3758 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 876/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0272 - accuracy: 0.6344\n",
      "Epoch 876: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 1.0272 - accuracy: 0.6344 - val_loss: 2.3704 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 877/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0439 - accuracy: 0.6321\n",
      "Epoch 877: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0439 - accuracy: 0.6321 - val_loss: 2.3601 - val_accuracy: 0.3466 - lr: 1.0000e-05\n",
      "Epoch 878/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0281 - accuracy: 0.6533\n",
      "Epoch 878: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 1.0281 - accuracy: 0.6533 - val_loss: 2.3432 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 879/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0206 - accuracy: 0.6285\n",
      "Epoch 879: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 1.0206 - accuracy: 0.6285 - val_loss: 2.3347 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 880/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0264 - accuracy: 0.6309\n",
      "Epoch 880: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.0264 - accuracy: 0.6309 - val_loss: 2.3326 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 881/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.6179\n",
      "Epoch 881: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0126 - accuracy: 0.6179 - val_loss: 2.3310 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 882/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0169 - accuracy: 0.6568\n",
      "Epoch 882: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0169 - accuracy: 0.6568 - val_loss: 2.3296 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 883/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0378 - accuracy: 0.6380\n",
      "Epoch 883: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.0378 - accuracy: 0.6380 - val_loss: 2.3475 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 884/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9957 - accuracy: 0.6557\n",
      "Epoch 884: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.9957 - accuracy: 0.6557 - val_loss: 2.3607 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 885/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0357 - accuracy: 0.6333\n",
      "Epoch 885: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0357 - accuracy: 0.6333 - val_loss: 2.3664 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 886/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.6462\n",
      "Epoch 886: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 1.0054 - accuracy: 0.6462 - val_loss: 2.3654 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 887/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9732 - accuracy: 0.6474\n",
      "Epoch 887: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9732 - accuracy: 0.6474 - val_loss: 2.3605 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 888/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9971 - accuracy: 0.6436\n",
      "Epoch 888: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9971 - accuracy: 0.6436 - val_loss: 2.3566 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 889/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0273 - accuracy: 0.6486\n",
      "Epoch 889: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 1.0273 - accuracy: 0.6486 - val_loss: 2.3538 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 890/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0247 - accuracy: 0.6344\n",
      "Epoch 890: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 1.0247 - accuracy: 0.6344 - val_loss: 2.3407 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 891/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0297 - accuracy: 0.6380\n",
      "Epoch 891: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0297 - accuracy: 0.6380 - val_loss: 2.3373 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 892/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0173 - accuracy: 0.6396\n",
      "Epoch 892: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.0173 - accuracy: 0.6396 - val_loss: 2.3370 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 893/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.6262\n",
      "Epoch 893: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0073 - accuracy: 0.6262 - val_loss: 2.3269 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 894/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9744 - accuracy: 0.6545\n",
      "Epoch 894: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9744 - accuracy: 0.6545 - val_loss: 2.3227 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 895/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9750 - accuracy: 0.6396\n",
      "Epoch 895: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9750 - accuracy: 0.6396 - val_loss: 2.3222 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 896/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9374 - accuracy: 0.6651\n",
      "Epoch 896: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.9374 - accuracy: 0.6651 - val_loss: 2.3245 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 897/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0406 - accuracy: 0.6297\n",
      "Epoch 897: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0406 - accuracy: 0.6297 - val_loss: 2.3214 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 898/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0510 - accuracy: 0.6509\n",
      "Epoch 898: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.0510 - accuracy: 0.6509 - val_loss: 2.3133 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 899/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0195 - accuracy: 0.6474\n",
      "Epoch 899: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 1.0195 - accuracy: 0.6474 - val_loss: 2.3107 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 900/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9980 - accuracy: 0.6663\n",
      "Epoch 900: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9980 - accuracy: 0.6663 - val_loss: 2.3097 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 901/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0173 - accuracy: 0.6450\n",
      "Epoch 901: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0173 - accuracy: 0.6450 - val_loss: 2.2915 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 902/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9989 - accuracy: 0.6639\n",
      "Epoch 902: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.9989 - accuracy: 0.6639 - val_loss: 2.2680 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 903/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0237 - accuracy: 0.6321\n",
      "Epoch 903: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 1.0237 - accuracy: 0.6321 - val_loss: 2.2594 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 904/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0309 - accuracy: 0.6321\n",
      "Epoch 904: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.0309 - accuracy: 0.6321 - val_loss: 2.2594 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 905/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.6602\n",
      "Epoch 905: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.9746 - accuracy: 0.6602 - val_loss: 2.2535 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 906/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.6504\n",
      "Epoch 906: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.0044 - accuracy: 0.6504 - val_loss: 2.2526 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 907/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0066 - accuracy: 0.6415\n",
      "Epoch 907: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0066 - accuracy: 0.6415 - val_loss: 2.2528 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 908/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9785 - accuracy: 0.6639\n",
      "Epoch 908: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.9785 - accuracy: 0.6639 - val_loss: 2.2610 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 909/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9965 - accuracy: 0.6616\n",
      "Epoch 909: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9965 - accuracy: 0.6616 - val_loss: 2.2738 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 910/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0008 - accuracy: 0.6455\n",
      "Epoch 910: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.0008 - accuracy: 0.6455 - val_loss: 2.2771 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 911/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.6675\n",
      "Epoch 911: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0047 - accuracy: 0.6675 - val_loss: 2.2843 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 912/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0058 - accuracy: 0.6533\n",
      "Epoch 912: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.0058 - accuracy: 0.6533 - val_loss: 2.2913 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 913/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0099 - accuracy: 0.6403\n",
      "Epoch 913: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0099 - accuracy: 0.6403 - val_loss: 2.2943 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 914/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0456 - accuracy: 0.6238\n",
      "Epoch 914: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0456 - accuracy: 0.6238 - val_loss: 2.2904 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 915/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9863 - accuracy: 0.6650\n",
      "Epoch 915: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.9863 - accuracy: 0.6650 - val_loss: 2.2880 - val_accuracy: 0.3502 - lr: 1.0000e-05\n",
      "Epoch 916/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.6533\n",
      "Epoch 916: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9802 - accuracy: 0.6533 - val_loss: 2.2820 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 917/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0098 - accuracy: 0.6309\n",
      "Epoch 917: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 1.0098 - accuracy: 0.6309 - val_loss: 2.2737 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 918/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9793 - accuracy: 0.6462\n",
      "Epoch 918: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.9793 - accuracy: 0.6462 - val_loss: 2.2721 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 919/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.6262\n",
      "Epoch 919: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 1.0158 - accuracy: 0.6262 - val_loss: 2.2704 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 920/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9941 - accuracy: 0.6498\n",
      "Epoch 920: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9941 - accuracy: 0.6498 - val_loss: 2.2693 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 921/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0279 - accuracy: 0.6415\n",
      "Epoch 921: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.0279 - accuracy: 0.6415 - val_loss: 2.2735 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 922/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0163 - accuracy: 0.6494\n",
      "Epoch 922: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.0163 - accuracy: 0.6494 - val_loss: 2.2838 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 923/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0210 - accuracy: 0.6179\n",
      "Epoch 923: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0210 - accuracy: 0.6179 - val_loss: 2.2877 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 924/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0290 - accuracy: 0.6250\n",
      "Epoch 924: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 1.0290 - accuracy: 0.6250 - val_loss: 2.2862 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 925/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.6486\n",
      "Epoch 925: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.0092 - accuracy: 0.6486 - val_loss: 2.2840 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 926/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9470 - accuracy: 0.6639\n",
      "Epoch 926: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.9470 - accuracy: 0.6639 - val_loss: 2.2855 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 927/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9730 - accuracy: 0.6592\n",
      "Epoch 927: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9730 - accuracy: 0.6592 - val_loss: 2.3007 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 928/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9739 - accuracy: 0.6675\n",
      "Epoch 928: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.9739 - accuracy: 0.6675 - val_loss: 2.3077 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 929/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9571 - accuracy: 0.6568\n",
      "Epoch 929: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9571 - accuracy: 0.6568 - val_loss: 2.2989 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 930/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9341 - accuracy: 0.6757\n",
      "Epoch 930: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9341 - accuracy: 0.6757 - val_loss: 2.2859 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 931/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9786 - accuracy: 0.6568\n",
      "Epoch 931: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9786 - accuracy: 0.6568 - val_loss: 2.2805 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 932/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9817 - accuracy: 0.6475\n",
      "Epoch 932: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.9817 - accuracy: 0.6475 - val_loss: 2.2767 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 933/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0002 - accuracy: 0.6406\n",
      "Epoch 933: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 1.0002 - accuracy: 0.6406 - val_loss: 2.2767 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 934/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0177 - accuracy: 0.6509\n",
      "Epoch 934: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 1.0177 - accuracy: 0.6509 - val_loss: 2.2867 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 935/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0227 - accuracy: 0.6403\n",
      "Epoch 935: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0227 - accuracy: 0.6403 - val_loss: 2.2942 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 936/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0067 - accuracy: 0.6462\n",
      "Epoch 936: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0067 - accuracy: 0.6462 - val_loss: 2.2989 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 937/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9855 - accuracy: 0.6357\n",
      "Epoch 937: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9855 - accuracy: 0.6357 - val_loss: 2.3019 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 938/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9777 - accuracy: 0.6533\n",
      "Epoch 938: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9777 - accuracy: 0.6533 - val_loss: 2.3086 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 939/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9672 - accuracy: 0.6650\n",
      "Epoch 939: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.9672 - accuracy: 0.6650 - val_loss: 2.3137 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 940/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0494 - accuracy: 0.6474\n",
      "Epoch 940: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.0494 - accuracy: 0.6474 - val_loss: 2.3229 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 941/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9989 - accuracy: 0.6521\n",
      "Epoch 941: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9989 - accuracy: 0.6521 - val_loss: 2.3342 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 942/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0133 - accuracy: 0.6639\n",
      "Epoch 942: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0133 - accuracy: 0.6639 - val_loss: 2.3371 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 943/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0149 - accuracy: 0.6455\n",
      "Epoch 943: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 1.0149 - accuracy: 0.6455 - val_loss: 2.3350 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 944/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9868 - accuracy: 0.6582\n",
      "Epoch 944: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.9868 - accuracy: 0.6582 - val_loss: 2.3268 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 945/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9996 - accuracy: 0.6450\n",
      "Epoch 945: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.9996 - accuracy: 0.6450 - val_loss: 2.3224 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 946/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0228 - accuracy: 0.6486\n",
      "Epoch 946: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0228 - accuracy: 0.6486 - val_loss: 2.3198 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 947/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0475 - accuracy: 0.6403\n",
      "Epoch 947: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.0475 - accuracy: 0.6403 - val_loss: 2.3142 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 948/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9865 - accuracy: 0.6450\n",
      "Epoch 948: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.9865 - accuracy: 0.6450 - val_loss: 2.3048 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 949/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9957 - accuracy: 0.6568\n",
      "Epoch 949: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9957 - accuracy: 0.6568 - val_loss: 2.3071 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 950/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0591 - accuracy: 0.6226\n",
      "Epoch 950: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 1.0591 - accuracy: 0.6226 - val_loss: 2.3075 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 951/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9595 - accuracy: 0.6486\n",
      "Epoch 951: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9595 - accuracy: 0.6486 - val_loss: 2.3033 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 952/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9866 - accuracy: 0.6663\n",
      "Epoch 952: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.9866 - accuracy: 0.6663 - val_loss: 2.2971 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 953/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9618 - accuracy: 0.6733\n",
      "Epoch 953: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9618 - accuracy: 0.6733 - val_loss: 2.2841 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 954/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.6710\n",
      "Epoch 954: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9779 - accuracy: 0.6710 - val_loss: 2.2724 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 955/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9597 - accuracy: 0.6582\n",
      "Epoch 955: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9597 - accuracy: 0.6582 - val_loss: 2.2661 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 956/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.6521\n",
      "Epoch 956: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9885 - accuracy: 0.6521 - val_loss: 2.2636 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 957/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9530 - accuracy: 0.6851\n",
      "Epoch 957: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9530 - accuracy: 0.6851 - val_loss: 2.2675 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 958/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0275 - accuracy: 0.6406\n",
      "Epoch 958: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0275 - accuracy: 0.6406 - val_loss: 2.2710 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 959/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0276 - accuracy: 0.6274\n",
      "Epoch 959: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 1.0276 - accuracy: 0.6274 - val_loss: 2.2731 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 960/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9921 - accuracy: 0.6450\n",
      "Epoch 960: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.9921 - accuracy: 0.6450 - val_loss: 2.2700 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 961/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9791 - accuracy: 0.6675\n",
      "Epoch 961: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9791 - accuracy: 0.6675 - val_loss: 2.2713 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 962/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9795 - accuracy: 0.6602\n",
      "Epoch 962: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.9795 - accuracy: 0.6602 - val_loss: 2.2762 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 963/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9706 - accuracy: 0.6545\n",
      "Epoch 963: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.9706 - accuracy: 0.6545 - val_loss: 2.2743 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 964/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0105 - accuracy: 0.6543\n",
      "Epoch 964: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 1.0105 - accuracy: 0.6543 - val_loss: 2.2715 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 965/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9735 - accuracy: 0.6498\n",
      "Epoch 965: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9735 - accuracy: 0.6498 - val_loss: 2.2726 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 966/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0189 - accuracy: 0.6545\n",
      "Epoch 966: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 1.0189 - accuracy: 0.6545 - val_loss: 2.2717 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 967/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9669 - accuracy: 0.6580\n",
      "Epoch 967: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.9669 - accuracy: 0.6580 - val_loss: 2.2716 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 968/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0274 - accuracy: 0.6191\n",
      "Epoch 968: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0274 - accuracy: 0.6191 - val_loss: 2.2736 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 969/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0270 - accuracy: 0.6392\n",
      "Epoch 969: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.0270 - accuracy: 0.6392 - val_loss: 2.2613 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 970/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9960 - accuracy: 0.6543\n",
      "Epoch 970: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.9960 - accuracy: 0.6543 - val_loss: 2.2562 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 971/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0222 - accuracy: 0.6344\n",
      "Epoch 971: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.0222 - accuracy: 0.6344 - val_loss: 2.2557 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 972/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9727 - accuracy: 0.6484\n",
      "Epoch 972: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.9727 - accuracy: 0.6484 - val_loss: 2.2509 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 973/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9846 - accuracy: 0.6592\n",
      "Epoch 973: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9846 - accuracy: 0.6592 - val_loss: 2.2411 - val_accuracy: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 974/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.6557\n",
      "Epoch 974: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9900 - accuracy: 0.6557 - val_loss: 2.2320 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 975/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9810 - accuracy: 0.6627\n",
      "Epoch 975: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.9810 - accuracy: 0.6627 - val_loss: 2.2323 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 976/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9930 - accuracy: 0.6592\n",
      "Epoch 976: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9930 - accuracy: 0.6592 - val_loss: 2.2264 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 977/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9949 - accuracy: 0.6663\n",
      "Epoch 977: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.9949 - accuracy: 0.6663 - val_loss: 2.2195 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
      "Epoch 978/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9882 - accuracy: 0.6604\n",
      "Epoch 978: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.9882 - accuracy: 0.6604 - val_loss: 2.2078 - val_accuracy: 0.3610 - lr: 1.0000e-05\n",
      "Epoch 979/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0258 - accuracy: 0.6450\n",
      "Epoch 979: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.0258 - accuracy: 0.6450 - val_loss: 2.2066 - val_accuracy: 0.3610 - lr: 1.0000e-05\n",
      "Epoch 980/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9647 - accuracy: 0.6415\n",
      "Epoch 980: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9647 - accuracy: 0.6415 - val_loss: 2.2034 - val_accuracy: 0.3610 - lr: 1.0000e-05\n",
      "Epoch 981/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9890 - accuracy: 0.6509\n",
      "Epoch 981: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9890 - accuracy: 0.6509 - val_loss: 2.2071 - val_accuracy: 0.3610 - lr: 1.0000e-05\n",
      "Epoch 982/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0080 - accuracy: 0.6368\n",
      "Epoch 982: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.0080 - accuracy: 0.6368 - val_loss: 2.2032 - val_accuracy: 0.3610 - lr: 1.0000e-05\n",
      "Epoch 983/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0378 - accuracy: 0.6403\n",
      "Epoch 983: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0378 - accuracy: 0.6403 - val_loss: 2.1918 - val_accuracy: 0.3610 - lr: 1.0000e-05\n",
      "Epoch 984/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0476 - accuracy: 0.6250\n",
      "Epoch 984: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0476 - accuracy: 0.6250 - val_loss: 2.1730 - val_accuracy: 0.3610 - lr: 1.0000e-05\n",
      "Epoch 985/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9473 - accuracy: 0.6580\n",
      "Epoch 985: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.9473 - accuracy: 0.6580 - val_loss: 2.1644 - val_accuracy: 0.3682 - lr: 1.0000e-05\n",
      "Epoch 986/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0059 - accuracy: 0.6475\n",
      "Epoch 986: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 1.0059 - accuracy: 0.6475 - val_loss: 2.1568 - val_accuracy: 0.3682 - lr: 1.0000e-05\n",
      "Epoch 987/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9697 - accuracy: 0.6733\n",
      "Epoch 987: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9697 - accuracy: 0.6733 - val_loss: 2.1549 - val_accuracy: 0.3682 - lr: 1.0000e-05\n",
      "Epoch 988/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0296 - accuracy: 0.6285\n",
      "Epoch 988: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.0296 - accuracy: 0.6285 - val_loss: 2.1519 - val_accuracy: 0.3682 - lr: 1.0000e-05\n",
      "Epoch 989/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9961 - accuracy: 0.6509\n",
      "Epoch 989: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.9961 - accuracy: 0.6509 - val_loss: 2.1447 - val_accuracy: 0.3682 - lr: 1.0000e-05\n",
      "Epoch 990/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9917 - accuracy: 0.6475\n",
      "Epoch 990: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.9917 - accuracy: 0.6475 - val_loss: 2.1396 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 991/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9652 - accuracy: 0.6568\n",
      "Epoch 991: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.9652 - accuracy: 0.6568 - val_loss: 2.1402 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 992/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9851 - accuracy: 0.6592\n",
      "Epoch 992: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.9851 - accuracy: 0.6592 - val_loss: 2.1474 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 993/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9839 - accuracy: 0.6592\n",
      "Epoch 993: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9839 - accuracy: 0.6592 - val_loss: 2.1593 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 994/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0144 - accuracy: 0.6357\n",
      "Epoch 994: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 1.0144 - accuracy: 0.6357 - val_loss: 2.1739 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 995/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9511 - accuracy: 0.6639\n",
      "Epoch 995: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.9511 - accuracy: 0.6639 - val_loss: 2.1907 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 996/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9933 - accuracy: 0.6580\n",
      "Epoch 996: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.9933 - accuracy: 0.6580 - val_loss: 2.2036 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 997/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9932 - accuracy: 0.6474\n",
      "Epoch 997: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.9932 - accuracy: 0.6474 - val_loss: 2.2139 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 998/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9686 - accuracy: 0.6616\n",
      "Epoch 998: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.9686 - accuracy: 0.6616 - val_loss: 2.2228 - val_accuracy: 0.3646 - lr: 1.0000e-05\n",
      "Epoch 999/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0307 - accuracy: 0.6403\n",
      "Epoch 999: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.0307 - accuracy: 0.6403 - val_loss: 2.2334 - val_accuracy: 0.3646 - lr: 1.0000e-05\n",
      "Epoch 1000/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0395 - accuracy: 0.6392\n",
      "Epoch 1000: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0395 - accuracy: 0.6392 - val_loss: 2.2318 - val_accuracy: 0.3646 - lr: 1.0000e-05\n",
      "Epoch 1001/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9502 - accuracy: 0.6580\n",
      "Epoch 1001: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.9502 - accuracy: 0.6580 - val_loss: 2.2198 - val_accuracy: 0.3646 - lr: 1.0000e-05\n",
      "Epoch 1002/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0034 - accuracy: 0.6533\n",
      "Epoch 1002: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.0034 - accuracy: 0.6533 - val_loss: 2.2177 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1003/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9764 - accuracy: 0.6439\n",
      "Epoch 1003: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.9764 - accuracy: 0.6439 - val_loss: 2.2182 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1004/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9828 - accuracy: 0.6533\n",
      "Epoch 1004: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.9828 - accuracy: 0.6533 - val_loss: 2.2091 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1005/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0212 - accuracy: 0.6274\n",
      "Epoch 1005: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 1.0212 - accuracy: 0.6274 - val_loss: 2.2092 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1006/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9729 - accuracy: 0.6521\n",
      "Epoch 1006: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9729 - accuracy: 0.6521 - val_loss: 2.2132 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1007/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9256 - accuracy: 0.6875\n",
      "Epoch 1007: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9256 - accuracy: 0.6875 - val_loss: 2.2127 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1008/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.6439\n",
      "Epoch 1008: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.0126 - accuracy: 0.6439 - val_loss: 2.2138 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1009/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9955 - accuracy: 0.6415\n",
      "Epoch 1009: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9955 - accuracy: 0.6415 - val_loss: 2.2069 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1010/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9663 - accuracy: 0.6562\n",
      "Epoch 1010: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.9663 - accuracy: 0.6562 - val_loss: 2.1978 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1011/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0008 - accuracy: 0.6403\n",
      "Epoch 1011: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 1.0008 - accuracy: 0.6403 - val_loss: 2.1959 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1012/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0035 - accuracy: 0.6498\n",
      "Epoch 1012: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0035 - accuracy: 0.6498 - val_loss: 2.1840 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1013/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0113 - accuracy: 0.6498\n",
      "Epoch 1013: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.0113 - accuracy: 0.6498 - val_loss: 2.1699 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1014/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9939 - accuracy: 0.6348\n",
      "Epoch 1014: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9939 - accuracy: 0.6348 - val_loss: 2.1684 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1015/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9881 - accuracy: 0.6426\n",
      "Epoch 1015: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.9881 - accuracy: 0.6426 - val_loss: 2.1741 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1016/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0236 - accuracy: 0.6436\n",
      "Epoch 1016: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 1.0236 - accuracy: 0.6436 - val_loss: 2.1732 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1017/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0061 - accuracy: 0.6445\n",
      "Epoch 1017: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0061 - accuracy: 0.6445 - val_loss: 2.1729 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1018/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9785 - accuracy: 0.6639\n",
      "Epoch 1018: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.9785 - accuracy: 0.6639 - val_loss: 2.1776 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1019/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9733 - accuracy: 0.6474\n",
      "Epoch 1019: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.9733 - accuracy: 0.6474 - val_loss: 2.1963 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1020/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.6639\n",
      "Epoch 1020: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.0081 - accuracy: 0.6639 - val_loss: 2.1989 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1021/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9594 - accuracy: 0.6616\n",
      "Epoch 1021: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9594 - accuracy: 0.6616 - val_loss: 2.1999 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1022/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9635 - accuracy: 0.6533\n",
      "Epoch 1022: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.9635 - accuracy: 0.6533 - val_loss: 2.1955 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1023/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.6474\n",
      "Epoch 1023: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.0271 - accuracy: 0.6474 - val_loss: 2.1851 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1024/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0016 - accuracy: 0.6344\n",
      "Epoch 1024: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0016 - accuracy: 0.6344 - val_loss: 2.1789 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1025/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9619 - accuracy: 0.6521\n",
      "Epoch 1025: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9619 - accuracy: 0.6521 - val_loss: 2.1782 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1026/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0220 - accuracy: 0.6462\n",
      "Epoch 1026: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 1.0220 - accuracy: 0.6462 - val_loss: 2.1930 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1027/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9853 - accuracy: 0.6580\n",
      "Epoch 1027: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.9853 - accuracy: 0.6580 - val_loss: 2.2104 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1028/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9567 - accuracy: 0.6582\n",
      "Epoch 1028: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.9567 - accuracy: 0.6582 - val_loss: 2.2217 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1029/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9489 - accuracy: 0.6663\n",
      "Epoch 1029: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9489 - accuracy: 0.6663 - val_loss: 2.2252 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1030/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9573 - accuracy: 0.6663\n",
      "Epoch 1030: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9573 - accuracy: 0.6663 - val_loss: 2.2250 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1031/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9870 - accuracy: 0.6377\n",
      "Epoch 1031: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9870 - accuracy: 0.6377 - val_loss: 2.2192 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1032/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9914 - accuracy: 0.6462\n",
      "Epoch 1032: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9914 - accuracy: 0.6462 - val_loss: 2.2150 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1033/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9979 - accuracy: 0.6533\n",
      "Epoch 1033: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9979 - accuracy: 0.6533 - val_loss: 2.2109 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1034/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0061 - accuracy: 0.6396\n",
      "Epoch 1034: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 1.0061 - accuracy: 0.6396 - val_loss: 2.2056 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1035/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9608 - accuracy: 0.6675\n",
      "Epoch 1035: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9608 - accuracy: 0.6675 - val_loss: 2.2042 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1036/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9401 - accuracy: 0.6651\n",
      "Epoch 1036: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.9401 - accuracy: 0.6651 - val_loss: 2.2096 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1037/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0303 - accuracy: 0.6392\n",
      "Epoch 1037: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 1.0303 - accuracy: 0.6392 - val_loss: 2.2158 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1038/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9918 - accuracy: 0.6392\n",
      "Epoch 1038: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9918 - accuracy: 0.6392 - val_loss: 2.2112 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1039/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9989 - accuracy: 0.6521\n",
      "Epoch 1039: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.9989 - accuracy: 0.6521 - val_loss: 2.2114 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1040/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9880 - accuracy: 0.6439\n",
      "Epoch 1040: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.9880 - accuracy: 0.6439 - val_loss: 2.2105 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1041/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9458 - accuracy: 0.6592\n",
      "Epoch 1041: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9458 - accuracy: 0.6592 - val_loss: 2.2121 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1042/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0149 - accuracy: 0.6521\n",
      "Epoch 1042: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 1.0149 - accuracy: 0.6521 - val_loss: 2.2067 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1043/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9672 - accuracy: 0.6557\n",
      "Epoch 1043: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.9672 - accuracy: 0.6557 - val_loss: 2.1973 - val_accuracy: 0.3718 - lr: 1.0000e-05\n",
      "Epoch 1044/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0216 - accuracy: 0.6427\n",
      "Epoch 1044: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0216 - accuracy: 0.6427 - val_loss: 2.1877 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1045/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9898 - accuracy: 0.6639\n",
      "Epoch 1045: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9898 - accuracy: 0.6639 - val_loss: 2.1823 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1046/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9577 - accuracy: 0.6777\n",
      "Epoch 1046: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9577 - accuracy: 0.6777 - val_loss: 2.1751 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1047/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9418 - accuracy: 0.6663\n",
      "Epoch 1047: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9418 - accuracy: 0.6663 - val_loss: 2.1666 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1048/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9566 - accuracy: 0.6757\n",
      "Epoch 1048: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.9566 - accuracy: 0.6757 - val_loss: 2.1585 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1049/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9896 - accuracy: 0.6651\n",
      "Epoch 1049: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9896 - accuracy: 0.6651 - val_loss: 2.1433 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1050/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9335 - accuracy: 0.6651\n",
      "Epoch 1050: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9335 - accuracy: 0.6651 - val_loss: 2.1246 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1051/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9813 - accuracy: 0.6651\n",
      "Epoch 1051: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.9813 - accuracy: 0.6651 - val_loss: 2.1207 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1052/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0106 - accuracy: 0.6368\n",
      "Epoch 1052: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 1.0106 - accuracy: 0.6368 - val_loss: 2.1169 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1053/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9733 - accuracy: 0.6494\n",
      "Epoch 1053: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9733 - accuracy: 0.6494 - val_loss: 2.1195 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1054/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9954 - accuracy: 0.6568\n",
      "Epoch 1054: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9954 - accuracy: 0.6568 - val_loss: 2.1140 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1055/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.6392\n",
      "Epoch 1055: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.9885 - accuracy: 0.6392 - val_loss: 2.1085 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1056/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9543 - accuracy: 0.6611\n",
      "Epoch 1056: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9543 - accuracy: 0.6611 - val_loss: 2.1022 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1057/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9501 - accuracy: 0.6474\n",
      "Epoch 1057: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9501 - accuracy: 0.6474 - val_loss: 2.0974 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1058/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9431 - accuracy: 0.6557\n",
      "Epoch 1058: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9431 - accuracy: 0.6557 - val_loss: 2.0879 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1059/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9691 - accuracy: 0.6641\n",
      "Epoch 1059: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.9691 - accuracy: 0.6641 - val_loss: 2.0817 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1060/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9483 - accuracy: 0.6675\n",
      "Epoch 1060: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9483 - accuracy: 0.6675 - val_loss: 2.0757 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1061/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9652 - accuracy: 0.6367\n",
      "Epoch 1061: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9652 - accuracy: 0.6367 - val_loss: 2.0645 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1062/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9265 - accuracy: 0.6781\n",
      "Epoch 1062: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.9265 - accuracy: 0.6781 - val_loss: 2.0509 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1063/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9371 - accuracy: 0.6557\n",
      "Epoch 1063: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.9371 - accuracy: 0.6557 - val_loss: 2.0467 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1064/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9836 - accuracy: 0.6580\n",
      "Epoch 1064: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.9836 - accuracy: 0.6580 - val_loss: 2.0438 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1065/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.6611\n",
      "Epoch 1065: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.9983 - accuracy: 0.6611 - val_loss: 2.0537 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1066/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0087 - accuracy: 0.6392\n",
      "Epoch 1066: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0087 - accuracy: 0.6392 - val_loss: 2.0641 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1067/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9812 - accuracy: 0.6521\n",
      "Epoch 1067: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9812 - accuracy: 0.6521 - val_loss: 2.0771 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1068/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9261 - accuracy: 0.6757\n",
      "Epoch 1068: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.9261 - accuracy: 0.6757 - val_loss: 2.0875 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1069/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9411 - accuracy: 0.6722\n",
      "Epoch 1069: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9411 - accuracy: 0.6722 - val_loss: 2.0984 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1070/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9358 - accuracy: 0.6650\n",
      "Epoch 1070: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.9358 - accuracy: 0.6650 - val_loss: 2.0980 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1071/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9553 - accuracy: 0.6616\n",
      "Epoch 1071: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.9553 - accuracy: 0.6616 - val_loss: 2.0966 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1072/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9799 - accuracy: 0.6486\n",
      "Epoch 1072: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9799 - accuracy: 0.6486 - val_loss: 2.0821 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1073/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9606 - accuracy: 0.6545\n",
      "Epoch 1073: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9606 - accuracy: 0.6545 - val_loss: 2.0880 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1074/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.6521\n",
      "Epoch 1074: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.9747 - accuracy: 0.6521 - val_loss: 2.0951 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1075/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9456 - accuracy: 0.6616\n",
      "Epoch 1075: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9456 - accuracy: 0.6616 - val_loss: 2.1046 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1076/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9184 - accuracy: 0.6781\n",
      "Epoch 1076: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9184 - accuracy: 0.6781 - val_loss: 2.1069 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1077/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9494 - accuracy: 0.6663\n",
      "Epoch 1077: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.9494 - accuracy: 0.6663 - val_loss: 2.1126 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1078/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.6641\n",
      "Epoch 1078: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.9607 - accuracy: 0.6641 - val_loss: 2.1220 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1079/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9731 - accuracy: 0.6498\n",
      "Epoch 1079: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.9731 - accuracy: 0.6498 - val_loss: 2.1382 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1080/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9447 - accuracy: 0.6639\n",
      "Epoch 1080: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.9447 - accuracy: 0.6639 - val_loss: 2.1480 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1081/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9645 - accuracy: 0.6698\n",
      "Epoch 1081: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9645 - accuracy: 0.6698 - val_loss: 2.1518 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1082/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9593 - accuracy: 0.6486\n",
      "Epoch 1082: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.9593 - accuracy: 0.6486 - val_loss: 2.1530 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1083/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9650 - accuracy: 0.6651\n",
      "Epoch 1083: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.9650 - accuracy: 0.6651 - val_loss: 2.1499 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1084/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9740 - accuracy: 0.6651\n",
      "Epoch 1084: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9740 - accuracy: 0.6651 - val_loss: 2.1447 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1085/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9652 - accuracy: 0.6604\n",
      "Epoch 1085: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.9652 - accuracy: 0.6604 - val_loss: 2.1336 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1086/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9115 - accuracy: 0.6710\n",
      "Epoch 1086: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.9115 - accuracy: 0.6710 - val_loss: 2.1225 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1087/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9613 - accuracy: 0.6604\n",
      "Epoch 1087: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.9613 - accuracy: 0.6604 - val_loss: 2.1238 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1088/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9321 - accuracy: 0.6828\n",
      "Epoch 1088: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.9321 - accuracy: 0.6828 - val_loss: 2.1271 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1089/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0289 - accuracy: 0.6368\n",
      "Epoch 1089: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.0289 - accuracy: 0.6368 - val_loss: 2.1345 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1090/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.6533\n",
      "Epoch 1090: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.9607 - accuracy: 0.6533 - val_loss: 2.1368 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1091/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9337 - accuracy: 0.6604\n",
      "Epoch 1091: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.9337 - accuracy: 0.6604 - val_loss: 2.1502 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1092/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9582 - accuracy: 0.6733\n",
      "Epoch 1092: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9582 - accuracy: 0.6733 - val_loss: 2.1608 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1093/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0010 - accuracy: 0.6415\n",
      "Epoch 1093: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 1.0010 - accuracy: 0.6415 - val_loss: 2.1613 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1094/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9660 - accuracy: 0.6498\n",
      "Epoch 1094: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.9660 - accuracy: 0.6498 - val_loss: 2.1595 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1095/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9328 - accuracy: 0.6698\n",
      "Epoch 1095: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.9328 - accuracy: 0.6698 - val_loss: 2.1570 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1096/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9735 - accuracy: 0.6675\n",
      "Epoch 1096: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9735 - accuracy: 0.6675 - val_loss: 2.1542 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1097/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9484 - accuracy: 0.6557\n",
      "Epoch 1097: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9484 - accuracy: 0.6557 - val_loss: 2.1508 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1098/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.6545\n",
      "Epoch 1098: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.9713 - accuracy: 0.6545 - val_loss: 2.1596 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1099/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9427 - accuracy: 0.6675\n",
      "Epoch 1099: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9427 - accuracy: 0.6675 - val_loss: 2.1673 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1100/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9727 - accuracy: 0.6604\n",
      "Epoch 1100: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.9727 - accuracy: 0.6604 - val_loss: 2.1669 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1101/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9683 - accuracy: 0.6498\n",
      "Epoch 1101: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9683 - accuracy: 0.6498 - val_loss: 2.1626 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1102/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9704 - accuracy: 0.6557\n",
      "Epoch 1102: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.9704 - accuracy: 0.6557 - val_loss: 2.1775 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1103/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9377 - accuracy: 0.6887\n",
      "Epoch 1103: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.9377 - accuracy: 0.6887 - val_loss: 2.1836 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1104/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9892 - accuracy: 0.6533\n",
      "Epoch 1104: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.9892 - accuracy: 0.6533 - val_loss: 2.1879 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1105/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9505 - accuracy: 0.6611\n",
      "Epoch 1105: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9505 - accuracy: 0.6611 - val_loss: 2.1909 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1106/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0009 - accuracy: 0.6545\n",
      "Epoch 1106: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.0009 - accuracy: 0.6545 - val_loss: 2.1914 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1107/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9776 - accuracy: 0.6611\n",
      "Epoch 1107: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.9776 - accuracy: 0.6611 - val_loss: 2.1909 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1108/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9369 - accuracy: 0.6686\n",
      "Epoch 1108: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9369 - accuracy: 0.6686 - val_loss: 2.1869 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1109/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9521 - accuracy: 0.6545\n",
      "Epoch 1109: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.9521 - accuracy: 0.6545 - val_loss: 2.1759 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1110/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9412 - accuracy: 0.6521\n",
      "Epoch 1110: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.9412 - accuracy: 0.6521 - val_loss: 2.1628 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1111/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9826 - accuracy: 0.6722\n",
      "Epoch 1111: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9826 - accuracy: 0.6722 - val_loss: 2.1557 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1112/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9771 - accuracy: 0.6745\n",
      "Epoch 1112: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9771 - accuracy: 0.6745 - val_loss: 2.1483 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1113/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9751 - accuracy: 0.6509\n",
      "Epoch 1113: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9751 - accuracy: 0.6509 - val_loss: 2.1393 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1114/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9580 - accuracy: 0.6543\n",
      "Epoch 1114: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.9580 - accuracy: 0.6543 - val_loss: 2.1419 - val_accuracy: 0.3755 - lr: 1.0000e-05\n",
      "Epoch 1115/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9485 - accuracy: 0.6851\n",
      "Epoch 1115: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9485 - accuracy: 0.6851 - val_loss: 2.1339 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1116/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9712 - accuracy: 0.6450\n",
      "Epoch 1116: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.9712 - accuracy: 0.6450 - val_loss: 2.1240 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1117/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9959 - accuracy: 0.6486\n",
      "Epoch 1117: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.9959 - accuracy: 0.6486 - val_loss: 2.1178 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1118/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9682 - accuracy: 0.6651\n",
      "Epoch 1118: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.9682 - accuracy: 0.6651 - val_loss: 2.1133 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1119/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9408 - accuracy: 0.6875\n",
      "Epoch 1119: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9408 - accuracy: 0.6875 - val_loss: 2.1093 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1120/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9090 - accuracy: 0.6804\n",
      "Epoch 1120: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.9090 - accuracy: 0.6804 - val_loss: 2.1179 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1121/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.6738\n",
      "Epoch 1121: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.9524 - accuracy: 0.6738 - val_loss: 2.1221 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1122/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.6745\n",
      "Epoch 1122: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9428 - accuracy: 0.6745 - val_loss: 2.1214 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1123/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9834 - accuracy: 0.6521\n",
      "Epoch 1123: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9834 - accuracy: 0.6521 - val_loss: 2.1183 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1124/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9313 - accuracy: 0.6651\n",
      "Epoch 1124: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.9313 - accuracy: 0.6651 - val_loss: 2.1047 - val_accuracy: 0.3791 - lr: 1.0000e-05\n",
      "Epoch 1125/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9631 - accuracy: 0.6863\n",
      "Epoch 1125: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.9631 - accuracy: 0.6863 - val_loss: 2.0949 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1126/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9710 - accuracy: 0.6344\n",
      "Epoch 1126: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9710 - accuracy: 0.6344 - val_loss: 2.0951 - val_accuracy: 0.3827 - lr: 1.0000e-05\n",
      "Epoch 1127/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9658 - accuracy: 0.6356\n",
      "Epoch 1127: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9658 - accuracy: 0.6356 - val_loss: 2.0916 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1128/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9418 - accuracy: 0.6804\n",
      "Epoch 1128: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.9418 - accuracy: 0.6804 - val_loss: 2.0878 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1129/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9464 - accuracy: 0.6698\n",
      "Epoch 1129: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.9464 - accuracy: 0.6698 - val_loss: 2.0938 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1130/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9585 - accuracy: 0.6689\n",
      "Epoch 1130: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.9585 - accuracy: 0.6689 - val_loss: 2.0996 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1131/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9307 - accuracy: 0.6627\n",
      "Epoch 1131: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9307 - accuracy: 0.6627 - val_loss: 2.1018 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1132/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9478 - accuracy: 0.6699\n",
      "Epoch 1132: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.9478 - accuracy: 0.6699 - val_loss: 2.0986 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1133/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9684 - accuracy: 0.6686\n",
      "Epoch 1133: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9684 - accuracy: 0.6686 - val_loss: 2.1039 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1134/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9809 - accuracy: 0.6533\n",
      "Epoch 1134: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9809 - accuracy: 0.6533 - val_loss: 2.1040 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1135/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9569 - accuracy: 0.6604\n",
      "Epoch 1135: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.9569 - accuracy: 0.6604 - val_loss: 2.1122 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1136/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9322 - accuracy: 0.6792\n",
      "Epoch 1136: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.9322 - accuracy: 0.6792 - val_loss: 2.1184 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1137/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9686 - accuracy: 0.6455\n",
      "Epoch 1137: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.9686 - accuracy: 0.6455 - val_loss: 2.1186 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1138/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0065 - accuracy: 0.6462\n",
      "Epoch 1138: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 1.0065 - accuracy: 0.6462 - val_loss: 2.1171 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1139/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9610 - accuracy: 0.6663\n",
      "Epoch 1139: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.9610 - accuracy: 0.6663 - val_loss: 2.1088 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1140/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9924 - accuracy: 0.6462\n",
      "Epoch 1140: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9924 - accuracy: 0.6462 - val_loss: 2.0968 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1141/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9831 - accuracy: 0.6733\n",
      "Epoch 1141: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.9831 - accuracy: 0.6733 - val_loss: 2.0891 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1142/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9078 - accuracy: 0.6851\n",
      "Epoch 1142: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.9078 - accuracy: 0.6851 - val_loss: 2.0815 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1143/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9489 - accuracy: 0.6621\n",
      "Epoch 1143: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.9489 - accuracy: 0.6621 - val_loss: 2.0761 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1144/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9242 - accuracy: 0.6797\n",
      "Epoch 1144: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.9242 - accuracy: 0.6797 - val_loss: 2.0714 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1145/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9424 - accuracy: 0.6699\n",
      "Epoch 1145: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9424 - accuracy: 0.6699 - val_loss: 2.0746 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1146/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9236 - accuracy: 0.6680\n",
      "Epoch 1146: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.9236 - accuracy: 0.6680 - val_loss: 2.0774 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1147/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9893 - accuracy: 0.6592\n",
      "Epoch 1147: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.9893 - accuracy: 0.6592 - val_loss: 2.0752 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1148/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9517 - accuracy: 0.6533\n",
      "Epoch 1148: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.9517 - accuracy: 0.6533 - val_loss: 2.0721 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1149/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9422 - accuracy: 0.6769\n",
      "Epoch 1149: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.9422 - accuracy: 0.6769 - val_loss: 2.0657 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1150/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9423 - accuracy: 0.6582\n",
      "Epoch 1150: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9423 - accuracy: 0.6582 - val_loss: 2.0598 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1151/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9001 - accuracy: 0.6804\n",
      "Epoch 1151: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9001 - accuracy: 0.6804 - val_loss: 2.0569 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1152/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9610 - accuracy: 0.6675\n",
      "Epoch 1152: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9610 - accuracy: 0.6675 - val_loss: 2.0626 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1153/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9637 - accuracy: 0.6670\n",
      "Epoch 1153: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.9637 - accuracy: 0.6670 - val_loss: 2.0605 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1154/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9516 - accuracy: 0.6680\n",
      "Epoch 1154: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.9516 - accuracy: 0.6680 - val_loss: 2.0555 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1155/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9544 - accuracy: 0.6769\n",
      "Epoch 1155: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9544 - accuracy: 0.6769 - val_loss: 2.0495 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1156/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9217 - accuracy: 0.6934\n",
      "Epoch 1156: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.9217 - accuracy: 0.6934 - val_loss: 2.0360 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1157/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9702 - accuracy: 0.6521\n",
      "Epoch 1157: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.9702 - accuracy: 0.6521 - val_loss: 2.0296 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1158/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8908 - accuracy: 0.7017\n",
      "Epoch 1158: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.8908 - accuracy: 0.7017 - val_loss: 2.0208 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1159/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9255 - accuracy: 0.6710\n",
      "Epoch 1159: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9255 - accuracy: 0.6710 - val_loss: 2.0092 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1160/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9132 - accuracy: 0.6787\n",
      "Epoch 1160: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9132 - accuracy: 0.6787 - val_loss: 2.0063 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1161/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9809 - accuracy: 0.6498\n",
      "Epoch 1161: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9809 - accuracy: 0.6498 - val_loss: 2.0158 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1162/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9730 - accuracy: 0.6616\n",
      "Epoch 1162: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.9730 - accuracy: 0.6616 - val_loss: 2.0161 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1163/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9650 - accuracy: 0.6521\n",
      "Epoch 1163: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.9650 - accuracy: 0.6521 - val_loss: 2.0050 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1164/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9477 - accuracy: 0.6592\n",
      "Epoch 1164: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.9477 - accuracy: 0.6592 - val_loss: 2.0104 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1165/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9568 - accuracy: 0.6533\n",
      "Epoch 1165: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.9568 - accuracy: 0.6533 - val_loss: 2.0087 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1166/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9346 - accuracy: 0.6722\n",
      "Epoch 1166: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.9346 - accuracy: 0.6722 - val_loss: 2.0172 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1167/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9245 - accuracy: 0.6722\n",
      "Epoch 1167: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9245 - accuracy: 0.6722 - val_loss: 2.0196 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1168/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9084 - accuracy: 0.6840\n",
      "Epoch 1168: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.9084 - accuracy: 0.6840 - val_loss: 2.0181 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1169/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9349 - accuracy: 0.6733\n",
      "Epoch 1169: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.9349 - accuracy: 0.6733 - val_loss: 2.0163 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1170/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9653 - accuracy: 0.6602\n",
      "Epoch 1170: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.9653 - accuracy: 0.6602 - val_loss: 2.0132 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1171/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9450 - accuracy: 0.6875\n",
      "Epoch 1171: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9450 - accuracy: 0.6875 - val_loss: 2.0120 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1172/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9304 - accuracy: 0.6840\n",
      "Epoch 1172: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9304 - accuracy: 0.6840 - val_loss: 2.0089 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1173/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9406 - accuracy: 0.6663\n",
      "Epoch 1173: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9406 - accuracy: 0.6663 - val_loss: 2.0103 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1174/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8648 - accuracy: 0.6863\n",
      "Epoch 1174: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.8648 - accuracy: 0.6863 - val_loss: 2.0007 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1175/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.6745\n",
      "Epoch 1175: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.9368 - accuracy: 0.6745 - val_loss: 2.0022 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1176/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9630 - accuracy: 0.6686\n",
      "Epoch 1176: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.9630 - accuracy: 0.6686 - val_loss: 2.0105 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1177/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9532 - accuracy: 0.6698\n",
      "Epoch 1177: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.9532 - accuracy: 0.6698 - val_loss: 2.0165 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1178/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8996 - accuracy: 0.6934\n",
      "Epoch 1178: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8996 - accuracy: 0.6934 - val_loss: 2.0184 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1179/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9089 - accuracy: 0.6733\n",
      "Epoch 1179: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.9089 - accuracy: 0.6733 - val_loss: 2.0184 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1180/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9189 - accuracy: 0.6781\n",
      "Epoch 1180: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.9189 - accuracy: 0.6781 - val_loss: 2.0231 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1181/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9541 - accuracy: 0.6616\n",
      "Epoch 1181: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.9541 - accuracy: 0.6616 - val_loss: 2.0211 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1182/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9421 - accuracy: 0.6698\n",
      "Epoch 1182: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.9421 - accuracy: 0.6698 - val_loss: 2.0267 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1183/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9441 - accuracy: 0.6698\n",
      "Epoch 1183: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.9441 - accuracy: 0.6698 - val_loss: 2.0333 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1184/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.6769\n",
      "Epoch 1184: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.9215 - accuracy: 0.6769 - val_loss: 2.0463 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1185/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9175 - accuracy: 0.6828\n",
      "Epoch 1185: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.9175 - accuracy: 0.6828 - val_loss: 2.0463 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1186/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9445 - accuracy: 0.6781\n",
      "Epoch 1186: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.9445 - accuracy: 0.6781 - val_loss: 2.0529 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1187/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9420 - accuracy: 0.6663\n",
      "Epoch 1187: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.9420 - accuracy: 0.6663 - val_loss: 2.0580 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1188/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9394 - accuracy: 0.6580\n",
      "Epoch 1188: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.9394 - accuracy: 0.6580 - val_loss: 2.0616 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1189/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9554 - accuracy: 0.6733\n",
      "Epoch 1189: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.9554 - accuracy: 0.6733 - val_loss: 2.0595 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1190/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9016 - accuracy: 0.6855\n",
      "Epoch 1190: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9016 - accuracy: 0.6855 - val_loss: 2.0517 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1191/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9617 - accuracy: 0.6439\n",
      "Epoch 1191: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.9617 - accuracy: 0.6439 - val_loss: 2.0448 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1192/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9382 - accuracy: 0.6686\n",
      "Epoch 1192: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.9382 - accuracy: 0.6686 - val_loss: 2.0385 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1193/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9423 - accuracy: 0.6639\n",
      "Epoch 1193: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.9423 - accuracy: 0.6639 - val_loss: 2.0383 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1194/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9284 - accuracy: 0.6816\n",
      "Epoch 1194: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.9284 - accuracy: 0.6816 - val_loss: 2.0327 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1195/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9353 - accuracy: 0.6698\n",
      "Epoch 1195: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.9353 - accuracy: 0.6698 - val_loss: 2.0366 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1196/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9498 - accuracy: 0.6840\n",
      "Epoch 1196: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.9498 - accuracy: 0.6840 - val_loss: 2.0354 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1197/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9421 - accuracy: 0.6722\n",
      "Epoch 1197: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.9421 - accuracy: 0.6722 - val_loss: 2.0242 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1198/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9227 - accuracy: 0.6675\n",
      "Epoch 1198: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.9227 - accuracy: 0.6675 - val_loss: 2.0071 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1199/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.6663\n",
      "Epoch 1199: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.9607 - accuracy: 0.6663 - val_loss: 1.9902 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1200/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9400 - accuracy: 0.6557\n",
      "Epoch 1200: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.9400 - accuracy: 0.6557 - val_loss: 1.9862 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1201/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9230 - accuracy: 0.6592\n",
      "Epoch 1201: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.9230 - accuracy: 0.6592 - val_loss: 1.9856 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1202/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8747 - accuracy: 0.6899\n",
      "Epoch 1202: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8747 - accuracy: 0.6899 - val_loss: 1.9842 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1203/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9311 - accuracy: 0.6710\n",
      "Epoch 1203: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.9311 - accuracy: 0.6710 - val_loss: 1.9823 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1204/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.6604\n",
      "Epoch 1204: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.9643 - accuracy: 0.6604 - val_loss: 1.9792 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1205/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9475 - accuracy: 0.6639\n",
      "Epoch 1205: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.9475 - accuracy: 0.6639 - val_loss: 1.9846 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1206/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9398 - accuracy: 0.6675\n",
      "Epoch 1206: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.9398 - accuracy: 0.6675 - val_loss: 1.9857 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1207/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9744 - accuracy: 0.6602\n",
      "Epoch 1207: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.9744 - accuracy: 0.6602 - val_loss: 1.9865 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1208/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9177 - accuracy: 0.6521\n",
      "Epoch 1208: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.9177 - accuracy: 0.6521 - val_loss: 2.0008 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1209/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9065 - accuracy: 0.6769\n",
      "Epoch 1209: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.9065 - accuracy: 0.6769 - val_loss: 2.0225 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1210/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9149 - accuracy: 0.6769\n",
      "Epoch 1210: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.9149 - accuracy: 0.6769 - val_loss: 2.0334 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1211/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8982 - accuracy: 0.6816\n",
      "Epoch 1211: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.8982 - accuracy: 0.6816 - val_loss: 2.0394 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1212/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9207 - accuracy: 0.6840\n",
      "Epoch 1212: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.9207 - accuracy: 0.6840 - val_loss: 2.0401 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1213/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9628 - accuracy: 0.6686\n",
      "Epoch 1213: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9628 - accuracy: 0.6686 - val_loss: 2.0443 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1214/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9393 - accuracy: 0.6675\n",
      "Epoch 1214: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9393 - accuracy: 0.6675 - val_loss: 2.0433 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1215/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9627 - accuracy: 0.6816\n",
      "Epoch 1215: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.9627 - accuracy: 0.6816 - val_loss: 2.0396 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1216/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9306 - accuracy: 0.6509\n",
      "Epoch 1216: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.9306 - accuracy: 0.6509 - val_loss: 2.0469 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1217/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9688 - accuracy: 0.6616\n",
      "Epoch 1217: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.9688 - accuracy: 0.6616 - val_loss: 2.0529 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1218/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9701 - accuracy: 0.6533\n",
      "Epoch 1218: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9701 - accuracy: 0.6533 - val_loss: 2.0463 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1219/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9146 - accuracy: 0.6792\n",
      "Epoch 1219: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9146 - accuracy: 0.6792 - val_loss: 2.0366 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1220/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9299 - accuracy: 0.6663\n",
      "Epoch 1220: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9299 - accuracy: 0.6663 - val_loss: 2.0264 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1221/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9190 - accuracy: 0.6792\n",
      "Epoch 1221: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9190 - accuracy: 0.6792 - val_loss: 2.0223 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1222/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9597 - accuracy: 0.6486\n",
      "Epoch 1222: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.9597 - accuracy: 0.6486 - val_loss: 2.0064 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1223/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9296 - accuracy: 0.6733\n",
      "Epoch 1223: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9296 - accuracy: 0.6733 - val_loss: 1.9948 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1224/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9022 - accuracy: 0.6769\n",
      "Epoch 1224: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9022 - accuracy: 0.6769 - val_loss: 1.9910 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1225/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9553 - accuracy: 0.6769\n",
      "Epoch 1225: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9553 - accuracy: 0.6769 - val_loss: 1.9853 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1226/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9128 - accuracy: 0.6836\n",
      "Epoch 1226: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.9128 - accuracy: 0.6836 - val_loss: 1.9845 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1227/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9388 - accuracy: 0.6627\n",
      "Epoch 1227: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.9388 - accuracy: 0.6627 - val_loss: 1.9860 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1228/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9034 - accuracy: 0.6769\n",
      "Epoch 1228: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.9034 - accuracy: 0.6769 - val_loss: 1.9934 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1229/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8884 - accuracy: 0.6934\n",
      "Epoch 1229: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.8884 - accuracy: 0.6934 - val_loss: 1.9965 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1230/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9319 - accuracy: 0.6651\n",
      "Epoch 1230: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.9319 - accuracy: 0.6651 - val_loss: 2.0056 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1231/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9156 - accuracy: 0.6910\n",
      "Epoch 1231: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9156 - accuracy: 0.6910 - val_loss: 2.0047 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1232/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9571 - accuracy: 0.6686\n",
      "Epoch 1232: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.9571 - accuracy: 0.6686 - val_loss: 1.9950 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1233/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9172 - accuracy: 0.6710\n",
      "Epoch 1233: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9172 - accuracy: 0.6710 - val_loss: 1.9832 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1234/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.6745\n",
      "Epoch 1234: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9104 - accuracy: 0.6745 - val_loss: 1.9652 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1235/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8945 - accuracy: 0.6934\n",
      "Epoch 1235: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8945 - accuracy: 0.6934 - val_loss: 1.9502 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1236/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9336 - accuracy: 0.6686\n",
      "Epoch 1236: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.9336 - accuracy: 0.6686 - val_loss: 1.9453 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1237/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9261 - accuracy: 0.6748\n",
      "Epoch 1237: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.9261 - accuracy: 0.6748 - val_loss: 1.9472 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1238/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9150 - accuracy: 0.6698\n",
      "Epoch 1238: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9150 - accuracy: 0.6698 - val_loss: 1.9494 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1239/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8655 - accuracy: 0.6946\n",
      "Epoch 1239: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.8655 - accuracy: 0.6946 - val_loss: 1.9419 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1240/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9449 - accuracy: 0.6745\n",
      "Epoch 1240: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9449 - accuracy: 0.6745 - val_loss: 1.9400 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1241/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9345 - accuracy: 0.6639\n",
      "Epoch 1241: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.9345 - accuracy: 0.6639 - val_loss: 1.9301 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1242/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9845 - accuracy: 0.6533\n",
      "Epoch 1242: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9845 - accuracy: 0.6533 - val_loss: 1.9298 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1243/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9304 - accuracy: 0.6663\n",
      "Epoch 1243: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.9304 - accuracy: 0.6663 - val_loss: 1.9291 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1244/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9405 - accuracy: 0.6545\n",
      "Epoch 1244: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.9405 - accuracy: 0.6545 - val_loss: 1.9271 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1245/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9396 - accuracy: 0.6604\n",
      "Epoch 1245: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9396 - accuracy: 0.6604 - val_loss: 1.9265 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1246/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9531 - accuracy: 0.6557\n",
      "Epoch 1246: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9531 - accuracy: 0.6557 - val_loss: 1.9225 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1247/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9012 - accuracy: 0.6816\n",
      "Epoch 1247: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9012 - accuracy: 0.6816 - val_loss: 1.9264 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1248/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8993 - accuracy: 0.6958\n",
      "Epoch 1248: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.8993 - accuracy: 0.6958 - val_loss: 1.9417 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1249/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9179 - accuracy: 0.6887\n",
      "Epoch 1249: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9179 - accuracy: 0.6887 - val_loss: 1.9557 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1250/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9540 - accuracy: 0.6484\n",
      "Epoch 1250: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.9540 - accuracy: 0.6484 - val_loss: 1.9590 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1251/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.6804\n",
      "Epoch 1251: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.9237 - accuracy: 0.6804 - val_loss: 1.9553 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1252/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8919 - accuracy: 0.6993\n",
      "Epoch 1252: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8919 - accuracy: 0.6993 - val_loss: 1.9633 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1253/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9624 - accuracy: 0.6580\n",
      "Epoch 1253: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.9624 - accuracy: 0.6580 - val_loss: 1.9662 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1254/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9326 - accuracy: 0.6887\n",
      "Epoch 1254: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9326 - accuracy: 0.6887 - val_loss: 1.9600 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1255/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9164 - accuracy: 0.6816\n",
      "Epoch 1255: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.9164 - accuracy: 0.6816 - val_loss: 1.9671 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1256/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9151 - accuracy: 0.6698\n",
      "Epoch 1256: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.9151 - accuracy: 0.6698 - val_loss: 1.9877 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1257/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9467 - accuracy: 0.6639\n",
      "Epoch 1257: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.9467 - accuracy: 0.6639 - val_loss: 1.9954 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1258/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9605 - accuracy: 0.6415\n",
      "Epoch 1258: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9605 - accuracy: 0.6415 - val_loss: 2.0049 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1259/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9233 - accuracy: 0.6627\n",
      "Epoch 1259: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9233 - accuracy: 0.6627 - val_loss: 2.0097 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1260/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8967 - accuracy: 0.6899\n",
      "Epoch 1260: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.8967 - accuracy: 0.6899 - val_loss: 2.0124 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1261/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9630 - accuracy: 0.6710\n",
      "Epoch 1261: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.9630 - accuracy: 0.6710 - val_loss: 2.0162 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1262/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8731 - accuracy: 0.6863\n",
      "Epoch 1262: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8731 - accuracy: 0.6863 - val_loss: 2.0151 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1263/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9222 - accuracy: 0.6733\n",
      "Epoch 1263: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9222 - accuracy: 0.6733 - val_loss: 2.0125 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1264/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9548 - accuracy: 0.6580\n",
      "Epoch 1264: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9548 - accuracy: 0.6580 - val_loss: 2.0106 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1265/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8800 - accuracy: 0.6887\n",
      "Epoch 1265: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.8800 - accuracy: 0.6887 - val_loss: 2.0138 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1266/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9343 - accuracy: 0.6710\n",
      "Epoch 1266: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9343 - accuracy: 0.6710 - val_loss: 2.0088 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1267/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8874 - accuracy: 0.7002\n",
      "Epoch 1267: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.8874 - accuracy: 0.7002 - val_loss: 1.9988 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1268/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9559 - accuracy: 0.6757\n",
      "Epoch 1268: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.9559 - accuracy: 0.6757 - val_loss: 1.9912 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1269/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8964 - accuracy: 0.7028\n",
      "Epoch 1269: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8964 - accuracy: 0.7028 - val_loss: 1.9746 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1270/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.6745\n",
      "Epoch 1270: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.9044 - accuracy: 0.6745 - val_loss: 1.9697 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1271/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9255 - accuracy: 0.6639\n",
      "Epoch 1271: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9255 - accuracy: 0.6639 - val_loss: 1.9632 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1272/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9178 - accuracy: 0.6757\n",
      "Epoch 1272: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9178 - accuracy: 0.6757 - val_loss: 1.9556 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1273/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8850 - accuracy: 0.6851\n",
      "Epoch 1273: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.8850 - accuracy: 0.6851 - val_loss: 1.9493 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1274/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9171 - accuracy: 0.6745\n",
      "Epoch 1274: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.9171 - accuracy: 0.6745 - val_loss: 1.9520 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1275/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8916 - accuracy: 0.6969\n",
      "Epoch 1275: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8916 - accuracy: 0.6969 - val_loss: 1.9566 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1276/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9386 - accuracy: 0.6698\n",
      "Epoch 1276: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9386 - accuracy: 0.6698 - val_loss: 1.9724 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1277/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9180 - accuracy: 0.6722\n",
      "Epoch 1277: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9180 - accuracy: 0.6722 - val_loss: 1.9879 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1278/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9451 - accuracy: 0.6663\n",
      "Epoch 1278: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.9451 - accuracy: 0.6663 - val_loss: 1.9961 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1279/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9415 - accuracy: 0.6745\n",
      "Epoch 1279: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.9415 - accuracy: 0.6745 - val_loss: 1.9976 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1280/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8881 - accuracy: 0.6816\n",
      "Epoch 1280: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8881 - accuracy: 0.6816 - val_loss: 2.0016 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1281/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9852 - accuracy: 0.6722\n",
      "Epoch 1281: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9852 - accuracy: 0.6722 - val_loss: 2.0095 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1282/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9104 - accuracy: 0.6777\n",
      "Epoch 1282: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.9104 - accuracy: 0.6777 - val_loss: 2.0077 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1283/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8893 - accuracy: 0.6846\n",
      "Epoch 1283: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8893 - accuracy: 0.6846 - val_loss: 2.0082 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1284/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9147 - accuracy: 0.6840\n",
      "Epoch 1284: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9147 - accuracy: 0.6840 - val_loss: 2.0128 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1285/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9061 - accuracy: 0.6816\n",
      "Epoch 1285: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.9061 - accuracy: 0.6816 - val_loss: 2.0171 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1286/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8732 - accuracy: 0.6899\n",
      "Epoch 1286: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8732 - accuracy: 0.6899 - val_loss: 2.0220 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1287/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9259 - accuracy: 0.6875\n",
      "Epoch 1287: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.9259 - accuracy: 0.6875 - val_loss: 2.0260 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1288/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9029 - accuracy: 0.6922\n",
      "Epoch 1288: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9029 - accuracy: 0.6922 - val_loss: 2.0232 - val_accuracy: 0.3863 - lr: 1.0000e-05\n",
      "Epoch 1289/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8916 - accuracy: 0.6875\n",
      "Epoch 1289: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8916 - accuracy: 0.6875 - val_loss: 2.0206 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1290/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9513 - accuracy: 0.6639\n",
      "Epoch 1290: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9513 - accuracy: 0.6639 - val_loss: 2.0150 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1291/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9000 - accuracy: 0.6875\n",
      "Epoch 1291: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.9000 - accuracy: 0.6875 - val_loss: 2.0147 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1292/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9134 - accuracy: 0.6722\n",
      "Epoch 1292: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9134 - accuracy: 0.6722 - val_loss: 2.0147 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1293/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8942 - accuracy: 0.6807\n",
      "Epoch 1293: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.8942 - accuracy: 0.6807 - val_loss: 2.0094 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1294/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9613 - accuracy: 0.6521\n",
      "Epoch 1294: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9613 - accuracy: 0.6521 - val_loss: 1.9974 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1295/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8877 - accuracy: 0.7064\n",
      "Epoch 1295: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8877 - accuracy: 0.7064 - val_loss: 1.9833 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1296/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9115 - accuracy: 0.6709\n",
      "Epoch 1296: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.9115 - accuracy: 0.6709 - val_loss: 1.9824 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1297/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9036 - accuracy: 0.6781\n",
      "Epoch 1297: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.9036 - accuracy: 0.6781 - val_loss: 1.9792 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1298/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9259 - accuracy: 0.6851\n",
      "Epoch 1298: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9259 - accuracy: 0.6851 - val_loss: 1.9726 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1299/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8816 - accuracy: 0.7017\n",
      "Epoch 1299: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.8816 - accuracy: 0.7017 - val_loss: 1.9662 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1300/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.6651\n",
      "Epoch 1300: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9162 - accuracy: 0.6651 - val_loss: 1.9540 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1301/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9390 - accuracy: 0.6722\n",
      "Epoch 1301: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9390 - accuracy: 0.6722 - val_loss: 1.9499 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1302/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9380 - accuracy: 0.6650\n",
      "Epoch 1302: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.9380 - accuracy: 0.6650 - val_loss: 1.9476 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1303/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8768 - accuracy: 0.6946\n",
      "Epoch 1303: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8768 - accuracy: 0.6946 - val_loss: 1.9470 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1304/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9276 - accuracy: 0.6757\n",
      "Epoch 1304: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.9276 - accuracy: 0.6757 - val_loss: 1.9440 - val_accuracy: 0.4043 - lr: 1.0000e-05\n",
      "Epoch 1305/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8899 - accuracy: 0.6675\n",
      "Epoch 1305: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8899 - accuracy: 0.6675 - val_loss: 1.9495 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1306/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9210 - accuracy: 0.6840\n",
      "Epoch 1306: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.9210 - accuracy: 0.6840 - val_loss: 1.9577 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1307/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9411 - accuracy: 0.6474\n",
      "Epoch 1307: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.9411 - accuracy: 0.6474 - val_loss: 1.9690 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1308/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9410 - accuracy: 0.6887\n",
      "Epoch 1308: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.9410 - accuracy: 0.6887 - val_loss: 1.9821 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1309/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9411 - accuracy: 0.6699\n",
      "Epoch 1309: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.9411 - accuracy: 0.6699 - val_loss: 1.9854 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1310/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9453 - accuracy: 0.6757\n",
      "Epoch 1310: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.9453 - accuracy: 0.6757 - val_loss: 1.9878 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1311/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9303 - accuracy: 0.6710\n",
      "Epoch 1311: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.9303 - accuracy: 0.6710 - val_loss: 1.9903 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1312/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9304 - accuracy: 0.6604\n",
      "Epoch 1312: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9304 - accuracy: 0.6604 - val_loss: 1.9838 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1313/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9604 - accuracy: 0.6604\n",
      "Epoch 1313: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.9604 - accuracy: 0.6604 - val_loss: 1.9729 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1314/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9283 - accuracy: 0.6722\n",
      "Epoch 1314: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.9283 - accuracy: 0.6722 - val_loss: 1.9589 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1315/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8730 - accuracy: 0.6904\n",
      "Epoch 1315: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8730 - accuracy: 0.6904 - val_loss: 1.9553 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1316/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.6710\n",
      "Epoch 1316: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9237 - accuracy: 0.6710 - val_loss: 1.9590 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1317/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8963 - accuracy: 0.6826\n",
      "Epoch 1317: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.8963 - accuracy: 0.6826 - val_loss: 1.9580 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1318/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.6651\n",
      "Epoch 1318: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9215 - accuracy: 0.6651 - val_loss: 1.9519 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1319/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9334 - accuracy: 0.6698\n",
      "Epoch 1319: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.9334 - accuracy: 0.6698 - val_loss: 1.9435 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1320/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9300 - accuracy: 0.6686\n",
      "Epoch 1320: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9300 - accuracy: 0.6686 - val_loss: 1.9487 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1321/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8817 - accuracy: 0.6958\n",
      "Epoch 1321: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.8817 - accuracy: 0.6958 - val_loss: 1.9613 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1322/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.7005\n",
      "Epoch 1322: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8853 - accuracy: 0.7005 - val_loss: 1.9723 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1323/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9098 - accuracy: 0.6910\n",
      "Epoch 1323: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.9098 - accuracy: 0.6910 - val_loss: 1.9797 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1324/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9419 - accuracy: 0.6533\n",
      "Epoch 1324: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9419 - accuracy: 0.6533 - val_loss: 1.9843 - val_accuracy: 0.3899 - lr: 1.0000e-05\n",
      "Epoch 1325/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9045 - accuracy: 0.6757\n",
      "Epoch 1325: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9045 - accuracy: 0.6757 - val_loss: 1.9737 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1326/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9080 - accuracy: 0.6781\n",
      "Epoch 1326: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.9080 - accuracy: 0.6781 - val_loss: 1.9654 - val_accuracy: 0.3935 - lr: 1.0000e-05\n",
      "Epoch 1327/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9009 - accuracy: 0.6675\n",
      "Epoch 1327: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.9009 - accuracy: 0.6675 - val_loss: 1.9535 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1328/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9179 - accuracy: 0.6686\n",
      "Epoch 1328: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9179 - accuracy: 0.6686 - val_loss: 1.9487 - val_accuracy: 0.3971 - lr: 1.0000e-05\n",
      "Epoch 1329/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9278 - accuracy: 0.6840\n",
      "Epoch 1329: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.9278 - accuracy: 0.6840 - val_loss: 1.9437 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1330/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9101 - accuracy: 0.6722\n",
      "Epoch 1330: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9101 - accuracy: 0.6722 - val_loss: 1.9380 - val_accuracy: 0.4007 - lr: 1.0000e-05\n",
      "Epoch 1331/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8768 - accuracy: 0.6887\n",
      "Epoch 1331: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8768 - accuracy: 0.6887 - val_loss: 1.9348 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1332/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8685 - accuracy: 0.6922\n",
      "Epoch 1332: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8685 - accuracy: 0.6922 - val_loss: 1.9291 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1333/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9141 - accuracy: 0.6781\n",
      "Epoch 1333: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.9141 - accuracy: 0.6781 - val_loss: 1.9222 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1334/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8799 - accuracy: 0.6863\n",
      "Epoch 1334: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8799 - accuracy: 0.6863 - val_loss: 1.9184 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1335/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9117 - accuracy: 0.6699\n",
      "Epoch 1335: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.9117 - accuracy: 0.6699 - val_loss: 1.9156 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1336/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8757 - accuracy: 0.6958\n",
      "Epoch 1336: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.8757 - accuracy: 0.6958 - val_loss: 1.9113 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1337/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8813 - accuracy: 0.6992\n",
      "Epoch 1337: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8813 - accuracy: 0.6992 - val_loss: 1.9184 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1338/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8742 - accuracy: 0.7040\n",
      "Epoch 1338: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8742 - accuracy: 0.7040 - val_loss: 1.9153 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1339/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8974 - accuracy: 0.6816\n",
      "Epoch 1339: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8974 - accuracy: 0.6816 - val_loss: 1.9215 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1340/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8880 - accuracy: 0.6910\n",
      "Epoch 1340: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.8880 - accuracy: 0.6910 - val_loss: 1.9191 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1341/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9222 - accuracy: 0.6745\n",
      "Epoch 1341: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.9222 - accuracy: 0.6745 - val_loss: 1.9094 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1342/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9106 - accuracy: 0.6804\n",
      "Epoch 1342: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.9106 - accuracy: 0.6804 - val_loss: 1.9130 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1343/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9753 - accuracy: 0.6663\n",
      "Epoch 1343: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.9753 - accuracy: 0.6663 - val_loss: 1.9098 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1344/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9200 - accuracy: 0.6729\n",
      "Epoch 1344: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.9200 - accuracy: 0.6729 - val_loss: 1.8980 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1345/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9087 - accuracy: 0.6748\n",
      "Epoch 1345: val_loss did not improve from 1.88900\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9087 - accuracy: 0.6748 - val_loss: 1.8909 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1346/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9002 - accuracy: 0.6797\n",
      "Epoch 1346: val_loss improved from 1.88900 to 1.88730, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.9002 - accuracy: 0.6797 - val_loss: 1.8873 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1347/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9194 - accuracy: 0.6580\n",
      "Epoch 1347: val_loss improved from 1.88730 to 1.87794, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9194 - accuracy: 0.6580 - val_loss: 1.8779 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1348/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9188 - accuracy: 0.6836\n",
      "Epoch 1348: val_loss improved from 1.87794 to 1.87497, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.9188 - accuracy: 0.6836 - val_loss: 1.8750 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1349/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9238 - accuracy: 0.6698\n",
      "Epoch 1349: val_loss improved from 1.87497 to 1.86453, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.9238 - accuracy: 0.6698 - val_loss: 1.8645 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1350/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8966 - accuracy: 0.6851\n",
      "Epoch 1350: val_loss improved from 1.86453 to 1.86217, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8966 - accuracy: 0.6851 - val_loss: 1.8622 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1351/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9253 - accuracy: 0.6663\n",
      "Epoch 1351: val_loss improved from 1.86217 to 1.85869, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.9253 - accuracy: 0.6663 - val_loss: 1.8587 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1352/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9278 - accuracy: 0.6660\n",
      "Epoch 1352: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.9278 - accuracy: 0.6660 - val_loss: 1.8606 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1353/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8921 - accuracy: 0.6943\n",
      "Epoch 1353: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8921 - accuracy: 0.6943 - val_loss: 1.8636 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1354/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8888 - accuracy: 0.6840\n",
      "Epoch 1354: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8888 - accuracy: 0.6840 - val_loss: 1.8697 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1355/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9293 - accuracy: 0.6686\n",
      "Epoch 1355: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9293 - accuracy: 0.6686 - val_loss: 1.8821 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1356/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9174 - accuracy: 0.6804\n",
      "Epoch 1356: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9174 - accuracy: 0.6804 - val_loss: 1.8947 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1357/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9217 - accuracy: 0.6840\n",
      "Epoch 1357: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.9217 - accuracy: 0.6840 - val_loss: 1.9021 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1358/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8676 - accuracy: 0.6781\n",
      "Epoch 1358: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8676 - accuracy: 0.6781 - val_loss: 1.9039 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1359/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8841 - accuracy: 0.6934\n",
      "Epoch 1359: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8841 - accuracy: 0.6934 - val_loss: 1.9203 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1360/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9433 - accuracy: 0.6521\n",
      "Epoch 1360: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.9433 - accuracy: 0.6521 - val_loss: 1.9244 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1361/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9205 - accuracy: 0.6899\n",
      "Epoch 1361: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9205 - accuracy: 0.6899 - val_loss: 1.9262 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1362/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9715 - accuracy: 0.6639\n",
      "Epoch 1362: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.9715 - accuracy: 0.6639 - val_loss: 1.9258 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1363/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9497 - accuracy: 0.6769\n",
      "Epoch 1363: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.9497 - accuracy: 0.6769 - val_loss: 1.9307 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1364/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9141 - accuracy: 0.6781\n",
      "Epoch 1364: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9141 - accuracy: 0.6781 - val_loss: 1.9433 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1365/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8775 - accuracy: 0.7017\n",
      "Epoch 1365: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8775 - accuracy: 0.7017 - val_loss: 1.9515 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1366/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8852 - accuracy: 0.6934\n",
      "Epoch 1366: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8852 - accuracy: 0.6934 - val_loss: 1.9567 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1367/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8757 - accuracy: 0.6758\n",
      "Epoch 1367: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8757 - accuracy: 0.6758 - val_loss: 1.9552 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1368/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9002 - accuracy: 0.6781\n",
      "Epoch 1368: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9002 - accuracy: 0.6781 - val_loss: 1.9451 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1369/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9057 - accuracy: 0.6828\n",
      "Epoch 1369: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9057 - accuracy: 0.6828 - val_loss: 1.9247 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1370/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9067 - accuracy: 0.6699\n",
      "Epoch 1370: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9067 - accuracy: 0.6699 - val_loss: 1.9082 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1371/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8946 - accuracy: 0.6840\n",
      "Epoch 1371: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8946 - accuracy: 0.6840 - val_loss: 1.8979 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1372/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9026 - accuracy: 0.6922\n",
      "Epoch 1372: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.9026 - accuracy: 0.6922 - val_loss: 1.9021 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1373/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9291 - accuracy: 0.6660\n",
      "Epoch 1373: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.9291 - accuracy: 0.6660 - val_loss: 1.9060 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1374/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8565 - accuracy: 0.6934\n",
      "Epoch 1374: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.8565 - accuracy: 0.6934 - val_loss: 1.9081 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1375/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8984 - accuracy: 0.6910\n",
      "Epoch 1375: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8984 - accuracy: 0.6910 - val_loss: 1.9152 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1376/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.6910\n",
      "Epoch 1376: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8846 - accuracy: 0.6910 - val_loss: 1.9281 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1377/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8831 - accuracy: 0.6816\n",
      "Epoch 1377: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.8831 - accuracy: 0.6816 - val_loss: 1.9466 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1378/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8666 - accuracy: 0.6816\n",
      "Epoch 1378: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.8666 - accuracy: 0.6816 - val_loss: 1.9466 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1379/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8942 - accuracy: 0.6816\n",
      "Epoch 1379: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.8942 - accuracy: 0.6816 - val_loss: 1.9375 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1380/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8762 - accuracy: 0.6851\n",
      "Epoch 1380: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8762 - accuracy: 0.6851 - val_loss: 1.9248 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1381/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9342 - accuracy: 0.6698\n",
      "Epoch 1381: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.9342 - accuracy: 0.6698 - val_loss: 1.9092 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1382/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8679 - accuracy: 0.6981\n",
      "Epoch 1382: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8679 - accuracy: 0.6981 - val_loss: 1.8987 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1383/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8888 - accuracy: 0.6875\n",
      "Epoch 1383: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.8888 - accuracy: 0.6875 - val_loss: 1.8813 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1384/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8992 - accuracy: 0.6904\n",
      "Epoch 1384: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8992 - accuracy: 0.6904 - val_loss: 1.8770 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1385/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8969 - accuracy: 0.6865\n",
      "Epoch 1385: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8969 - accuracy: 0.6865 - val_loss: 1.8763 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1386/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9036 - accuracy: 0.6887\n",
      "Epoch 1386: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.9036 - accuracy: 0.6887 - val_loss: 1.8730 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1387/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.6899\n",
      "Epoch 1387: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8753 - accuracy: 0.6899 - val_loss: 1.8670 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1388/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9019 - accuracy: 0.6748\n",
      "Epoch 1388: val_loss did not improve from 1.85869\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.9019 - accuracy: 0.6748 - val_loss: 1.8607 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1389/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8750 - accuracy: 0.6887\n",
      "Epoch 1389: val_loss improved from 1.85869 to 1.85180, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.8750 - accuracy: 0.6887 - val_loss: 1.8518 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1390/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9102 - accuracy: 0.6887\n",
      "Epoch 1390: val_loss improved from 1.85180 to 1.84511, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9102 - accuracy: 0.6887 - val_loss: 1.8451 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1391/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9170 - accuracy: 0.6816\n",
      "Epoch 1391: val_loss improved from 1.84511 to 1.84131, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9170 - accuracy: 0.6816 - val_loss: 1.8413 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1392/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9232 - accuracy: 0.6816\n",
      "Epoch 1392: val_loss improved from 1.84131 to 1.83643, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.9232 - accuracy: 0.6816 - val_loss: 1.8364 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1393/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8914 - accuracy: 0.7005\n",
      "Epoch 1393: val_loss improved from 1.83643 to 1.83248, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8914 - accuracy: 0.7005 - val_loss: 1.8325 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1394/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9061 - accuracy: 0.6816\n",
      "Epoch 1394: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.9061 - accuracy: 0.6816 - val_loss: 1.8460 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1395/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8700 - accuracy: 0.7012\n",
      "Epoch 1395: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8700 - accuracy: 0.7012 - val_loss: 1.8579 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1396/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8976 - accuracy: 0.6899\n",
      "Epoch 1396: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.8976 - accuracy: 0.6899 - val_loss: 1.8694 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1397/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8745 - accuracy: 0.7040\n",
      "Epoch 1397: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8745 - accuracy: 0.7040 - val_loss: 1.8801 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1398/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9204 - accuracy: 0.6709\n",
      "Epoch 1398: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.9204 - accuracy: 0.6709 - val_loss: 1.8761 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1399/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8874 - accuracy: 0.6899\n",
      "Epoch 1399: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8874 - accuracy: 0.6899 - val_loss: 1.8686 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1400/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8944 - accuracy: 0.6807\n",
      "Epoch 1400: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.8944 - accuracy: 0.6807 - val_loss: 1.8662 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1401/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8944 - accuracy: 0.6910\n",
      "Epoch 1401: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.8944 - accuracy: 0.6910 - val_loss: 1.8700 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1402/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8792 - accuracy: 0.6993\n",
      "Epoch 1402: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.8792 - accuracy: 0.6993 - val_loss: 1.8817 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1403/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8547 - accuracy: 0.7087\n",
      "Epoch 1403: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8547 - accuracy: 0.7087 - val_loss: 1.8839 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1404/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8801 - accuracy: 0.7005\n",
      "Epoch 1404: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8801 - accuracy: 0.7005 - val_loss: 1.8820 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1405/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8842 - accuracy: 0.6792\n",
      "Epoch 1405: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8842 - accuracy: 0.6792 - val_loss: 1.8713 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1406/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.6969\n",
      "Epoch 1406: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8645 - accuracy: 0.6969 - val_loss: 1.8773 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1407/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8951 - accuracy: 0.6826\n",
      "Epoch 1407: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.8951 - accuracy: 0.6826 - val_loss: 1.8833 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1408/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9128 - accuracy: 0.6769\n",
      "Epoch 1408: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.9128 - accuracy: 0.6769 - val_loss: 1.9008 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1409/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9332 - accuracy: 0.6733\n",
      "Epoch 1409: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.9332 - accuracy: 0.6733 - val_loss: 1.9252 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1410/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9046 - accuracy: 0.6828\n",
      "Epoch 1410: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.9046 - accuracy: 0.6828 - val_loss: 1.9490 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1411/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9312 - accuracy: 0.6851\n",
      "Epoch 1411: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.9312 - accuracy: 0.6851 - val_loss: 1.9672 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1412/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8768 - accuracy: 0.7028\n",
      "Epoch 1412: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8768 - accuracy: 0.7028 - val_loss: 1.9756 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1413/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9048 - accuracy: 0.6840\n",
      "Epoch 1413: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9048 - accuracy: 0.6840 - val_loss: 1.9780 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1414/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8555 - accuracy: 0.6953\n",
      "Epoch 1414: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.8555 - accuracy: 0.6953 - val_loss: 1.9734 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1415/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9004 - accuracy: 0.6722\n",
      "Epoch 1415: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.9004 - accuracy: 0.6722 - val_loss: 1.9674 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1416/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8831 - accuracy: 0.6855\n",
      "Epoch 1416: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.8831 - accuracy: 0.6855 - val_loss: 1.9554 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1417/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8791 - accuracy: 0.6946\n",
      "Epoch 1417: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8791 - accuracy: 0.6946 - val_loss: 1.9395 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1418/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9180 - accuracy: 0.6580\n",
      "Epoch 1418: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.9180 - accuracy: 0.6580 - val_loss: 1.9235 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1419/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9205 - accuracy: 0.6710\n",
      "Epoch 1419: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9205 - accuracy: 0.6710 - val_loss: 1.9158 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1420/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8875 - accuracy: 0.6922\n",
      "Epoch 1420: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.8875 - accuracy: 0.6922 - val_loss: 1.9058 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1421/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8886 - accuracy: 0.7017\n",
      "Epoch 1421: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8886 - accuracy: 0.7017 - val_loss: 1.8826 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1422/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8910 - accuracy: 0.6863\n",
      "Epoch 1422: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8910 - accuracy: 0.6863 - val_loss: 1.8643 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1423/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8575 - accuracy: 0.7075\n",
      "Epoch 1423: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8575 - accuracy: 0.7075 - val_loss: 1.8523 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1424/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8855 - accuracy: 0.6863\n",
      "Epoch 1424: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8855 - accuracy: 0.6863 - val_loss: 1.8433 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1425/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9056 - accuracy: 0.6777\n",
      "Epoch 1425: val_loss did not improve from 1.83248\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.9056 - accuracy: 0.6777 - val_loss: 1.8343 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1426/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8958 - accuracy: 0.6748\n",
      "Epoch 1426: val_loss improved from 1.83248 to 1.82958, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8958 - accuracy: 0.6748 - val_loss: 1.8296 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1427/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8583 - accuracy: 0.6969\n",
      "Epoch 1427: val_loss improved from 1.82958 to 1.82561, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8583 - accuracy: 0.6969 - val_loss: 1.8256 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1428/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8612 - accuracy: 0.6899\n",
      "Epoch 1428: val_loss did not improve from 1.82561\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.8612 - accuracy: 0.6899 - val_loss: 1.8258 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1429/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8958 - accuracy: 0.6729\n",
      "Epoch 1429: val_loss did not improve from 1.82561\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.8958 - accuracy: 0.6729 - val_loss: 1.8338 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1430/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8517 - accuracy: 0.7005\n",
      "Epoch 1430: val_loss did not improve from 1.82561\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8517 - accuracy: 0.7005 - val_loss: 1.8328 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1431/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8626 - accuracy: 0.6922\n",
      "Epoch 1431: val_loss did not improve from 1.82561\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.8626 - accuracy: 0.6922 - val_loss: 1.8329 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1432/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8883 - accuracy: 0.7064\n",
      "Epoch 1432: val_loss improved from 1.82561 to 1.82421, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8883 - accuracy: 0.7064 - val_loss: 1.8242 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1433/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8964 - accuracy: 0.6840\n",
      "Epoch 1433: val_loss improved from 1.82421 to 1.81279, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8964 - accuracy: 0.6840 - val_loss: 1.8128 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1434/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8756 - accuracy: 0.6958\n",
      "Epoch 1434: val_loss improved from 1.81279 to 1.81093, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.8756 - accuracy: 0.6958 - val_loss: 1.8109 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1435/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9000 - accuracy: 0.6757\n",
      "Epoch 1435: val_loss did not improve from 1.81093\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.9000 - accuracy: 0.6757 - val_loss: 1.8156 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1436/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8809 - accuracy: 0.6958\n",
      "Epoch 1436: val_loss did not improve from 1.81093\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8809 - accuracy: 0.6958 - val_loss: 1.8271 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1437/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8661 - accuracy: 0.7087\n",
      "Epoch 1437: val_loss did not improve from 1.81093\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8661 - accuracy: 0.7087 - val_loss: 1.8345 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1438/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9020 - accuracy: 0.6710\n",
      "Epoch 1438: val_loss did not improve from 1.81093\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.9020 - accuracy: 0.6710 - val_loss: 1.8413 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1439/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8638 - accuracy: 0.6993\n",
      "Epoch 1439: val_loss did not improve from 1.81093\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8638 - accuracy: 0.6993 - val_loss: 1.8375 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1440/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.6910\n",
      "Epoch 1440: val_loss did not improve from 1.81093\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.8753 - accuracy: 0.6910 - val_loss: 1.8330 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1441/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9119 - accuracy: 0.6851\n",
      "Epoch 1441: val_loss did not improve from 1.81093\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9119 - accuracy: 0.6851 - val_loss: 1.8249 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1442/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9023 - accuracy: 0.6840\n",
      "Epoch 1442: val_loss did not improve from 1.81093\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9023 - accuracy: 0.6840 - val_loss: 1.8151 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1443/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8955 - accuracy: 0.6792\n",
      "Epoch 1443: val_loss improved from 1.81093 to 1.80988, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8955 - accuracy: 0.6792 - val_loss: 1.8099 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1444/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8623 - accuracy: 0.6934\n",
      "Epoch 1444: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8623 - accuracy: 0.6934 - val_loss: 1.8134 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1445/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8886 - accuracy: 0.7017\n",
      "Epoch 1445: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8886 - accuracy: 0.7017 - val_loss: 1.8206 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1446/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9059 - accuracy: 0.6851\n",
      "Epoch 1446: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9059 - accuracy: 0.6851 - val_loss: 1.8404 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1447/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9012 - accuracy: 0.6797\n",
      "Epoch 1447: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.9012 - accuracy: 0.6797 - val_loss: 1.8553 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1448/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8940 - accuracy: 0.6899\n",
      "Epoch 1448: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.8940 - accuracy: 0.6899 - val_loss: 1.8557 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1449/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8652 - accuracy: 0.6922\n",
      "Epoch 1449: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8652 - accuracy: 0.6922 - val_loss: 1.8568 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1450/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9321 - accuracy: 0.6616\n",
      "Epoch 1450: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.9321 - accuracy: 0.6616 - val_loss: 1.8498 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1451/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.6781\n",
      "Epoch 1451: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8937 - accuracy: 0.6781 - val_loss: 1.8484 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1452/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8747 - accuracy: 0.6863\n",
      "Epoch 1452: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8747 - accuracy: 0.6863 - val_loss: 1.8508 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1453/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8799 - accuracy: 0.6851\n",
      "Epoch 1453: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.8799 - accuracy: 0.6851 - val_loss: 1.8577 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1454/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.6792\n",
      "Epoch 1454: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8937 - accuracy: 0.6792 - val_loss: 1.8691 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1455/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8483 - accuracy: 0.7064\n",
      "Epoch 1455: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8483 - accuracy: 0.7064 - val_loss: 1.8846 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1456/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.6899\n",
      "Epoch 1456: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.8525 - accuracy: 0.6899 - val_loss: 1.8949 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1457/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8568 - accuracy: 0.6946\n",
      "Epoch 1457: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8568 - accuracy: 0.6946 - val_loss: 1.9019 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1458/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8928 - accuracy: 0.6757\n",
      "Epoch 1458: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8928 - accuracy: 0.6757 - val_loss: 1.9055 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1459/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8839 - accuracy: 0.6946\n",
      "Epoch 1459: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8839 - accuracy: 0.6946 - val_loss: 1.9088 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1460/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9141 - accuracy: 0.6733\n",
      "Epoch 1460: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.9141 - accuracy: 0.6733 - val_loss: 1.9013 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1461/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8951 - accuracy: 0.6787\n",
      "Epoch 1461: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8951 - accuracy: 0.6787 - val_loss: 1.8968 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1462/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.6943\n",
      "Epoch 1462: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.8670 - accuracy: 0.6943 - val_loss: 1.8992 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1463/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8205 - accuracy: 0.7087\n",
      "Epoch 1463: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8205 - accuracy: 0.7087 - val_loss: 1.8924 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1464/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8781 - accuracy: 0.6887\n",
      "Epoch 1464: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8781 - accuracy: 0.6887 - val_loss: 1.9041 - val_accuracy: 0.4152 - lr: 1.0000e-05\n",
      "Epoch 1465/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8752 - accuracy: 0.6863\n",
      "Epoch 1465: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8752 - accuracy: 0.6863 - val_loss: 1.9088 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1466/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8769 - accuracy: 0.6887\n",
      "Epoch 1466: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8769 - accuracy: 0.6887 - val_loss: 1.8939 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1467/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8544 - accuracy: 0.7111\n",
      "Epoch 1467: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8544 - accuracy: 0.7111 - val_loss: 1.8843 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1468/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8817 - accuracy: 0.6698\n",
      "Epoch 1468: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8817 - accuracy: 0.6698 - val_loss: 1.8824 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1469/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8957 - accuracy: 0.6680\n",
      "Epoch 1469: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.8957 - accuracy: 0.6680 - val_loss: 1.8802 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1470/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8706 - accuracy: 0.7064\n",
      "Epoch 1470: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.8706 - accuracy: 0.7064 - val_loss: 1.8783 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1471/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8766 - accuracy: 0.6733\n",
      "Epoch 1471: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8766 - accuracy: 0.6733 - val_loss: 1.8658 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1472/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.6875\n",
      "Epoch 1472: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.8985 - accuracy: 0.6875 - val_loss: 1.8419 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1473/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8543 - accuracy: 0.7012\n",
      "Epoch 1473: val_loss did not improve from 1.80988\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.8543 - accuracy: 0.7012 - val_loss: 1.8200 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1474/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8744 - accuracy: 0.6981\n",
      "Epoch 1474: val_loss improved from 1.80988 to 1.80587, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8744 - accuracy: 0.6981 - val_loss: 1.8059 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1475/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8844 - accuracy: 0.6840\n",
      "Epoch 1475: val_loss improved from 1.80587 to 1.79510, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8844 - accuracy: 0.6840 - val_loss: 1.7951 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1476/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8538 - accuracy: 0.7017\n",
      "Epoch 1476: val_loss improved from 1.79510 to 1.78969, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8538 - accuracy: 0.7017 - val_loss: 1.7897 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1477/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8451 - accuracy: 0.7005\n",
      "Epoch 1477: val_loss improved from 1.78969 to 1.78920, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.8451 - accuracy: 0.7005 - val_loss: 1.7892 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1478/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8519 - accuracy: 0.7134\n",
      "Epoch 1478: val_loss improved from 1.78920 to 1.78842, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8519 - accuracy: 0.7134 - val_loss: 1.7884 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1479/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9293 - accuracy: 0.6710\n",
      "Epoch 1479: val_loss improved from 1.78842 to 1.78531, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9293 - accuracy: 0.6710 - val_loss: 1.7853 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1480/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8821 - accuracy: 0.6958\n",
      "Epoch 1480: val_loss improved from 1.78531 to 1.77116, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.8821 - accuracy: 0.6958 - val_loss: 1.7712 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1481/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8834 - accuracy: 0.6722\n",
      "Epoch 1481: val_loss improved from 1.77116 to 1.76655, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8834 - accuracy: 0.6722 - val_loss: 1.7666 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1482/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8930 - accuracy: 0.6922\n",
      "Epoch 1482: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8930 - accuracy: 0.6922 - val_loss: 1.7666 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1483/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.6899\n",
      "Epoch 1483: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.8846 - accuracy: 0.6899 - val_loss: 1.7689 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1484/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8576 - accuracy: 0.6899\n",
      "Epoch 1484: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.8576 - accuracy: 0.6899 - val_loss: 1.7836 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1485/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8733 - accuracy: 0.6899\n",
      "Epoch 1485: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8733 - accuracy: 0.6899 - val_loss: 1.7981 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1486/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8858 - accuracy: 0.6840\n",
      "Epoch 1486: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.8858 - accuracy: 0.6840 - val_loss: 1.8059 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1487/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8588 - accuracy: 0.6828\n",
      "Epoch 1487: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.8588 - accuracy: 0.6828 - val_loss: 1.8088 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1488/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8710 - accuracy: 0.6969\n",
      "Epoch 1488: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8710 - accuracy: 0.6969 - val_loss: 1.8158 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1489/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8538 - accuracy: 0.7017\n",
      "Epoch 1489: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8538 - accuracy: 0.7017 - val_loss: 1.8220 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1490/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8582 - accuracy: 0.6993\n",
      "Epoch 1490: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8582 - accuracy: 0.6993 - val_loss: 1.8233 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1491/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8747 - accuracy: 0.6885\n",
      "Epoch 1491: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8747 - accuracy: 0.6885 - val_loss: 1.8274 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1492/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8762 - accuracy: 0.7017\n",
      "Epoch 1492: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.8762 - accuracy: 0.7017 - val_loss: 1.8352 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1493/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.6863\n",
      "Epoch 1493: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.9050 - accuracy: 0.6863 - val_loss: 1.8472 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1494/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9086 - accuracy: 0.6604\n",
      "Epoch 1494: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.9086 - accuracy: 0.6604 - val_loss: 1.8594 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1495/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8963 - accuracy: 0.6698\n",
      "Epoch 1495: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8963 - accuracy: 0.6698 - val_loss: 1.8707 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1496/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8963 - accuracy: 0.6748\n",
      "Epoch 1496: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.8963 - accuracy: 0.6748 - val_loss: 1.8798 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1497/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9012 - accuracy: 0.6769\n",
      "Epoch 1497: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.9012 - accuracy: 0.6769 - val_loss: 1.8889 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1498/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8622 - accuracy: 0.6787\n",
      "Epoch 1498: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.8622 - accuracy: 0.6787 - val_loss: 1.8970 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1499/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8656 - accuracy: 0.6969\n",
      "Epoch 1499: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8656 - accuracy: 0.6969 - val_loss: 1.8935 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1500/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9095 - accuracy: 0.6792\n",
      "Epoch 1500: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.9095 - accuracy: 0.6792 - val_loss: 1.8860 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1501/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9088 - accuracy: 0.6777\n",
      "Epoch 1501: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.9088 - accuracy: 0.6777 - val_loss: 1.8811 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1502/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8762 - accuracy: 0.6993\n",
      "Epoch 1502: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8762 - accuracy: 0.6993 - val_loss: 1.8859 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1503/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9071 - accuracy: 0.6757\n",
      "Epoch 1503: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.9071 - accuracy: 0.6757 - val_loss: 1.8826 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1504/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8897 - accuracy: 0.6733\n",
      "Epoch 1504: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8897 - accuracy: 0.6733 - val_loss: 1.8782 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1505/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8769 - accuracy: 0.6840\n",
      "Epoch 1505: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8769 - accuracy: 0.6840 - val_loss: 1.8668 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1506/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8709 - accuracy: 0.6875\n",
      "Epoch 1506: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8709 - accuracy: 0.6875 - val_loss: 1.8488 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1507/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8741 - accuracy: 0.6875\n",
      "Epoch 1507: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.8741 - accuracy: 0.6875 - val_loss: 1.8333 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1508/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8698 - accuracy: 0.6895\n",
      "Epoch 1508: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.8698 - accuracy: 0.6895 - val_loss: 1.8326 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1509/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8169 - accuracy: 0.7158\n",
      "Epoch 1509: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.8169 - accuracy: 0.7158 - val_loss: 1.8182 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1510/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8996 - accuracy: 0.6663\n",
      "Epoch 1510: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.8996 - accuracy: 0.6663 - val_loss: 1.8040 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1511/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8840 - accuracy: 0.6722\n",
      "Epoch 1511: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8840 - accuracy: 0.6722 - val_loss: 1.8011 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1512/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8616 - accuracy: 0.6910\n",
      "Epoch 1512: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8616 - accuracy: 0.6910 - val_loss: 1.7971 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1513/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8767 - accuracy: 0.6816\n",
      "Epoch 1513: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.8767 - accuracy: 0.6816 - val_loss: 1.7924 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1514/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8611 - accuracy: 0.6969\n",
      "Epoch 1514: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8611 - accuracy: 0.6969 - val_loss: 1.7909 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1515/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8646 - accuracy: 0.6946\n",
      "Epoch 1515: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.8646 - accuracy: 0.6946 - val_loss: 1.8010 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1516/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9332 - accuracy: 0.6686\n",
      "Epoch 1516: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9332 - accuracy: 0.6686 - val_loss: 1.8102 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1517/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8448 - accuracy: 0.6816\n",
      "Epoch 1517: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8448 - accuracy: 0.6816 - val_loss: 1.7995 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1518/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9197 - accuracy: 0.6616\n",
      "Epoch 1518: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.9197 - accuracy: 0.6616 - val_loss: 1.7865 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1519/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8241 - accuracy: 0.7158\n",
      "Epoch 1519: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.8241 - accuracy: 0.7158 - val_loss: 1.7763 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1520/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8568 - accuracy: 0.6953\n",
      "Epoch 1520: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.8568 - accuracy: 0.6953 - val_loss: 1.7744 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1521/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8550 - accuracy: 0.6895\n",
      "Epoch 1521: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.8550 - accuracy: 0.6895 - val_loss: 1.7778 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1522/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8632 - accuracy: 0.6953\n",
      "Epoch 1522: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.8632 - accuracy: 0.6953 - val_loss: 1.7844 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1523/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8524 - accuracy: 0.7109\n",
      "Epoch 1523: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.8524 - accuracy: 0.7109 - val_loss: 1.7976 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1524/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8605 - accuracy: 0.7052\n",
      "Epoch 1524: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8605 - accuracy: 0.7052 - val_loss: 1.8100 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1525/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8844 - accuracy: 0.7005\n",
      "Epoch 1525: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8844 - accuracy: 0.7005 - val_loss: 1.8220 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1526/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.6969\n",
      "Epoch 1526: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.8749 - accuracy: 0.6969 - val_loss: 1.8385 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1527/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.7005\n",
      "Epoch 1527: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.8670 - accuracy: 0.7005 - val_loss: 1.8396 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1528/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8823 - accuracy: 0.6922\n",
      "Epoch 1528: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8823 - accuracy: 0.6922 - val_loss: 1.8372 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1529/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8405 - accuracy: 0.7052\n",
      "Epoch 1529: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.8405 - accuracy: 0.7052 - val_loss: 1.8435 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1530/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8793 - accuracy: 0.6828\n",
      "Epoch 1530: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8793 - accuracy: 0.6828 - val_loss: 1.8467 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1531/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8927 - accuracy: 0.6663\n",
      "Epoch 1531: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8927 - accuracy: 0.6663 - val_loss: 1.8383 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1532/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8696 - accuracy: 0.6981\n",
      "Epoch 1532: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8696 - accuracy: 0.6981 - val_loss: 1.8381 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1533/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8557 - accuracy: 0.6981\n",
      "Epoch 1533: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8557 - accuracy: 0.6981 - val_loss: 1.8373 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1534/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8426 - accuracy: 0.7134\n",
      "Epoch 1534: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8426 - accuracy: 0.7134 - val_loss: 1.8371 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1535/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8326 - accuracy: 0.7052\n",
      "Epoch 1535: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8326 - accuracy: 0.7052 - val_loss: 1.8414 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1536/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8713 - accuracy: 0.6922\n",
      "Epoch 1536: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8713 - accuracy: 0.6922 - val_loss: 1.8346 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1537/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8209 - accuracy: 0.7358\n",
      "Epoch 1537: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.8209 - accuracy: 0.7358 - val_loss: 1.8315 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1538/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8544 - accuracy: 0.6910\n",
      "Epoch 1538: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8544 - accuracy: 0.6910 - val_loss: 1.8304 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1539/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8807 - accuracy: 0.6851\n",
      "Epoch 1539: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8807 - accuracy: 0.6851 - val_loss: 1.8331 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1540/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9054 - accuracy: 0.6804\n",
      "Epoch 1540: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.9054 - accuracy: 0.6804 - val_loss: 1.8322 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1541/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8448 - accuracy: 0.6885\n",
      "Epoch 1541: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.8448 - accuracy: 0.6885 - val_loss: 1.8262 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1542/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8756 - accuracy: 0.6863\n",
      "Epoch 1542: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.8756 - accuracy: 0.6863 - val_loss: 1.8279 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1543/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8890 - accuracy: 0.6804\n",
      "Epoch 1543: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8890 - accuracy: 0.6804 - val_loss: 1.8365 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1544/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8414 - accuracy: 0.7111\n",
      "Epoch 1544: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8414 - accuracy: 0.7111 - val_loss: 1.8448 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1545/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8703 - accuracy: 0.6851\n",
      "Epoch 1545: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8703 - accuracy: 0.6851 - val_loss: 1.8571 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1546/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8701 - accuracy: 0.6899\n",
      "Epoch 1546: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8701 - accuracy: 0.6899 - val_loss: 1.8618 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1547/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8384 - accuracy: 0.7052\n",
      "Epoch 1547: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8384 - accuracy: 0.7052 - val_loss: 1.8529 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1548/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8676 - accuracy: 0.6769\n",
      "Epoch 1548: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8676 - accuracy: 0.6769 - val_loss: 1.8616 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1549/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8350 - accuracy: 0.7111\n",
      "Epoch 1549: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.8350 - accuracy: 0.7111 - val_loss: 1.8695 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1550/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8517 - accuracy: 0.6992\n",
      "Epoch 1550: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8517 - accuracy: 0.6992 - val_loss: 1.8771 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1551/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8487 - accuracy: 0.7099\n",
      "Epoch 1551: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8487 - accuracy: 0.7099 - val_loss: 1.8833 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1552/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8673 - accuracy: 0.6922\n",
      "Epoch 1552: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.8673 - accuracy: 0.6922 - val_loss: 1.9008 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1553/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8658 - accuracy: 0.7021\n",
      "Epoch 1553: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.8658 - accuracy: 0.7021 - val_loss: 1.9066 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1554/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8490 - accuracy: 0.7205\n",
      "Epoch 1554: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.8490 - accuracy: 0.7205 - val_loss: 1.8941 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1555/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8813 - accuracy: 0.6816\n",
      "Epoch 1555: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8813 - accuracy: 0.6816 - val_loss: 1.8904 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1556/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8531 - accuracy: 0.6981\n",
      "Epoch 1556: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8531 - accuracy: 0.6981 - val_loss: 1.8956 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1557/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.6840\n",
      "Epoch 1557: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8670 - accuracy: 0.6840 - val_loss: 1.9153 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1558/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8173 - accuracy: 0.7229\n",
      "Epoch 1558: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.8173 - accuracy: 0.7229 - val_loss: 1.9246 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1559/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8462 - accuracy: 0.6973\n",
      "Epoch 1559: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.8462 - accuracy: 0.6973 - val_loss: 1.9235 - val_accuracy: 0.4079 - lr: 1.0000e-05\n",
      "Epoch 1560/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8624 - accuracy: 0.6973\n",
      "Epoch 1560: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.8624 - accuracy: 0.6973 - val_loss: 1.9224 - val_accuracy: 0.4116 - lr: 1.0000e-05\n",
      "Epoch 1561/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.7040\n",
      "Epoch 1561: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8372 - accuracy: 0.7040 - val_loss: 1.9128 - val_accuracy: 0.4188 - lr: 1.0000e-05\n",
      "Epoch 1562/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8110 - accuracy: 0.7146\n",
      "Epoch 1562: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.8110 - accuracy: 0.7146 - val_loss: 1.8980 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1563/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8820 - accuracy: 0.6899\n",
      "Epoch 1563: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8820 - accuracy: 0.6899 - val_loss: 1.8807 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1564/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8894 - accuracy: 0.6863\n",
      "Epoch 1564: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.8894 - accuracy: 0.6863 - val_loss: 1.8685 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1565/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8584 - accuracy: 0.7075\n",
      "Epoch 1565: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8584 - accuracy: 0.7075 - val_loss: 1.8543 - val_accuracy: 0.4224 - lr: 1.0000e-05\n",
      "Epoch 1566/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.7182\n",
      "Epoch 1566: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8433 - accuracy: 0.7182 - val_loss: 1.8442 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1567/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.7031\n",
      "Epoch 1567: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8321 - accuracy: 0.7031 - val_loss: 1.8374 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1568/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8742 - accuracy: 0.6887\n",
      "Epoch 1568: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.8742 - accuracy: 0.6887 - val_loss: 1.8314 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1569/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9071 - accuracy: 0.6745\n",
      "Epoch 1569: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9071 - accuracy: 0.6745 - val_loss: 1.8229 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1570/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.6946\n",
      "Epoch 1570: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8415 - accuracy: 0.6946 - val_loss: 1.8313 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1571/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8169 - accuracy: 0.7099\n",
      "Epoch 1571: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8169 - accuracy: 0.7099 - val_loss: 1.8346 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1572/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.6982\n",
      "Epoch 1572: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.8670 - accuracy: 0.6982 - val_loss: 1.8309 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1573/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8741 - accuracy: 0.6946\n",
      "Epoch 1573: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8741 - accuracy: 0.6946 - val_loss: 1.8387 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1574/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8712 - accuracy: 0.7005\n",
      "Epoch 1574: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8712 - accuracy: 0.7005 - val_loss: 1.8492 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1575/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8696 - accuracy: 0.6769\n",
      "Epoch 1575: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8696 - accuracy: 0.6769 - val_loss: 1.8536 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1576/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8660 - accuracy: 0.6993\n",
      "Epoch 1576: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8660 - accuracy: 0.6993 - val_loss: 1.8475 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1577/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8414 - accuracy: 0.7075\n",
      "Epoch 1577: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8414 - accuracy: 0.7075 - val_loss: 1.8464 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1578/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8592 - accuracy: 0.6993\n",
      "Epoch 1578: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.8592 - accuracy: 0.6993 - val_loss: 1.8308 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1579/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8724 - accuracy: 0.6851\n",
      "Epoch 1579: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8724 - accuracy: 0.6851 - val_loss: 1.8208 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1580/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8797 - accuracy: 0.6769\n",
      "Epoch 1580: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8797 - accuracy: 0.6769 - val_loss: 1.8029 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1581/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8582 - accuracy: 0.7028\n",
      "Epoch 1581: val_loss did not improve from 1.76655\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8582 - accuracy: 0.7028 - val_loss: 1.7867 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1582/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8667 - accuracy: 0.6816\n",
      "Epoch 1582: val_loss improved from 1.76655 to 1.76636, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.8667 - accuracy: 0.6816 - val_loss: 1.7664 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1583/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8522 - accuracy: 0.7123\n",
      "Epoch 1583: val_loss improved from 1.76636 to 1.75331, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8522 - accuracy: 0.7123 - val_loss: 1.7533 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1584/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8723 - accuracy: 0.7002\n",
      "Epoch 1584: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.8723 - accuracy: 0.7002 - val_loss: 1.7592 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1585/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8410 - accuracy: 0.7109\n",
      "Epoch 1585: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.8410 - accuracy: 0.7109 - val_loss: 1.7654 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1586/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8420 - accuracy: 0.7288\n",
      "Epoch 1586: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.8420 - accuracy: 0.7288 - val_loss: 1.7695 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1587/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8551 - accuracy: 0.6953\n",
      "Epoch 1587: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.8551 - accuracy: 0.6953 - val_loss: 1.7747 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1588/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8530 - accuracy: 0.6958\n",
      "Epoch 1588: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8530 - accuracy: 0.6958 - val_loss: 1.7803 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1589/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9109 - accuracy: 0.6840\n",
      "Epoch 1589: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9109 - accuracy: 0.6840 - val_loss: 1.7917 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1590/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8807 - accuracy: 0.6904\n",
      "Epoch 1590: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8807 - accuracy: 0.6904 - val_loss: 1.7999 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1591/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8418 - accuracy: 0.6922\n",
      "Epoch 1591: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8418 - accuracy: 0.6922 - val_loss: 1.7979 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1592/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8695 - accuracy: 0.6863\n",
      "Epoch 1592: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.8695 - accuracy: 0.6863 - val_loss: 1.7962 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1593/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8388 - accuracy: 0.7129\n",
      "Epoch 1593: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.8388 - accuracy: 0.7129 - val_loss: 1.8052 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1594/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8355 - accuracy: 0.6993\n",
      "Epoch 1594: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8355 - accuracy: 0.6993 - val_loss: 1.8111 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1595/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8800 - accuracy: 0.6934\n",
      "Epoch 1595: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8800 - accuracy: 0.6934 - val_loss: 1.8179 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1596/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8682 - accuracy: 0.7052\n",
      "Epoch 1596: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.8682 - accuracy: 0.7052 - val_loss: 1.8368 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1597/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8558 - accuracy: 0.6895\n",
      "Epoch 1597: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.8558 - accuracy: 0.6895 - val_loss: 1.8466 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1598/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8573 - accuracy: 0.6910\n",
      "Epoch 1598: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8573 - accuracy: 0.6910 - val_loss: 1.8548 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1599/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8416 - accuracy: 0.7087\n",
      "Epoch 1599: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8416 - accuracy: 0.7087 - val_loss: 1.8518 - val_accuracy: 0.4260 - lr: 1.0000e-05\n",
      "Epoch 1600/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8802 - accuracy: 0.6910\n",
      "Epoch 1600: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8802 - accuracy: 0.6910 - val_loss: 1.8443 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1601/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.6804\n",
      "Epoch 1601: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8690 - accuracy: 0.6804 - val_loss: 1.8222 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1602/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8601 - accuracy: 0.6934\n",
      "Epoch 1602: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8601 - accuracy: 0.6934 - val_loss: 1.8076 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1603/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8382 - accuracy: 0.7052\n",
      "Epoch 1603: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.8382 - accuracy: 0.7052 - val_loss: 1.7991 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1604/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8385 - accuracy: 0.7017\n",
      "Epoch 1604: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8385 - accuracy: 0.7017 - val_loss: 1.7866 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1605/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8473 - accuracy: 0.6981\n",
      "Epoch 1605: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8473 - accuracy: 0.6981 - val_loss: 1.7844 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1606/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8542 - accuracy: 0.6958\n",
      "Epoch 1606: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8542 - accuracy: 0.6958 - val_loss: 1.7813 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1607/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8671 - accuracy: 0.6993\n",
      "Epoch 1607: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.8671 - accuracy: 0.6993 - val_loss: 1.7851 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1608/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8621 - accuracy: 0.6958\n",
      "Epoch 1608: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8621 - accuracy: 0.6958 - val_loss: 1.7860 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1609/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9052 - accuracy: 0.6875\n",
      "Epoch 1609: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.9052 - accuracy: 0.6875 - val_loss: 1.7976 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1610/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8751 - accuracy: 0.6910\n",
      "Epoch 1610: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.8751 - accuracy: 0.6910 - val_loss: 1.8084 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1611/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8398 - accuracy: 0.6958\n",
      "Epoch 1611: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8398 - accuracy: 0.6958 - val_loss: 1.8215 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1612/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8838 - accuracy: 0.6875\n",
      "Epoch 1612: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.8838 - accuracy: 0.6875 - val_loss: 1.8268 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1613/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8888 - accuracy: 0.6804\n",
      "Epoch 1613: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8888 - accuracy: 0.6804 - val_loss: 1.8294 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1614/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8603 - accuracy: 0.6946\n",
      "Epoch 1614: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8603 - accuracy: 0.6946 - val_loss: 1.8353 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1615/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8558 - accuracy: 0.6910\n",
      "Epoch 1615: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.8558 - accuracy: 0.6910 - val_loss: 1.8392 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1616/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8469 - accuracy: 0.6946\n",
      "Epoch 1616: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8469 - accuracy: 0.6946 - val_loss: 1.8392 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1617/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8695 - accuracy: 0.6863\n",
      "Epoch 1617: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.8695 - accuracy: 0.6863 - val_loss: 1.8357 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1618/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8474 - accuracy: 0.7100\n",
      "Epoch 1618: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.8474 - accuracy: 0.7100 - val_loss: 1.8308 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1619/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8549 - accuracy: 0.6863\n",
      "Epoch 1619: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8549 - accuracy: 0.6863 - val_loss: 1.8300 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1620/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8783 - accuracy: 0.6946\n",
      "Epoch 1620: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8783 - accuracy: 0.6946 - val_loss: 1.8334 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1621/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8378 - accuracy: 0.7111\n",
      "Epoch 1621: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.8378 - accuracy: 0.7111 - val_loss: 1.8364 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1622/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8515 - accuracy: 0.6840\n",
      "Epoch 1622: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8515 - accuracy: 0.6840 - val_loss: 1.8378 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1623/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8368 - accuracy: 0.6958\n",
      "Epoch 1623: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8368 - accuracy: 0.6958 - val_loss: 1.8431 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1624/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8442 - accuracy: 0.7123\n",
      "Epoch 1624: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8442 - accuracy: 0.7123 - val_loss: 1.8516 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1625/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8454 - accuracy: 0.6969\n",
      "Epoch 1625: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.8454 - accuracy: 0.6969 - val_loss: 1.8385 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1626/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8491 - accuracy: 0.6910\n",
      "Epoch 1626: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8491 - accuracy: 0.6910 - val_loss: 1.8298 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1627/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8340 - accuracy: 0.6981\n",
      "Epoch 1627: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.8340 - accuracy: 0.6981 - val_loss: 1.8143 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1628/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8587 - accuracy: 0.6953\n",
      "Epoch 1628: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.8587 - accuracy: 0.6953 - val_loss: 1.8067 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1629/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8539 - accuracy: 0.6895\n",
      "Epoch 1629: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.8539 - accuracy: 0.6895 - val_loss: 1.7957 - val_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 1630/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8529 - accuracy: 0.7028\n",
      "Epoch 1630: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.8529 - accuracy: 0.7028 - val_loss: 1.7898 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1631/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8661 - accuracy: 0.6863\n",
      "Epoch 1631: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8661 - accuracy: 0.6863 - val_loss: 1.7930 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1632/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8481 - accuracy: 0.6816\n",
      "Epoch 1632: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8481 - accuracy: 0.6816 - val_loss: 1.7837 - val_accuracy: 0.4332 - lr: 1.0000e-05\n",
      "Epoch 1633/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8507 - accuracy: 0.7041\n",
      "Epoch 1633: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.8507 - accuracy: 0.7041 - val_loss: 1.7751 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1634/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8674 - accuracy: 0.6887\n",
      "Epoch 1634: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8674 - accuracy: 0.6887 - val_loss: 1.7663 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1635/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8501 - accuracy: 0.6840\n",
      "Epoch 1635: val_loss did not improve from 1.75331\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8501 - accuracy: 0.6840 - val_loss: 1.7556 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1636/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8495 - accuracy: 0.6910\n",
      "Epoch 1636: val_loss improved from 1.75331 to 1.74979, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.8495 - accuracy: 0.6910 - val_loss: 1.7498 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1637/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8281 - accuracy: 0.7158\n",
      "Epoch 1637: val_loss improved from 1.74979 to 1.74226, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8281 - accuracy: 0.7158 - val_loss: 1.7423 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1638/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8177 - accuracy: 0.7087\n",
      "Epoch 1638: val_loss improved from 1.74226 to 1.73703, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8177 - accuracy: 0.7087 - val_loss: 1.7370 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1639/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8357 - accuracy: 0.6993\n",
      "Epoch 1639: val_loss improved from 1.73703 to 1.73357, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8357 - accuracy: 0.6993 - val_loss: 1.7336 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1640/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8162 - accuracy: 0.7099\n",
      "Epoch 1640: val_loss improved from 1.73357 to 1.72413, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8162 - accuracy: 0.7099 - val_loss: 1.7241 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1641/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8873 - accuracy: 0.6804\n",
      "Epoch 1641: val_loss did not improve from 1.72413\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.8873 - accuracy: 0.6804 - val_loss: 1.7244 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1642/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8110 - accuracy: 0.7100\n",
      "Epoch 1642: val_loss improved from 1.72413 to 1.71980, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.8110 - accuracy: 0.7100 - val_loss: 1.7198 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1643/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8425 - accuracy: 0.7041\n",
      "Epoch 1643: val_loss improved from 1.71980 to 1.71786, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8425 - accuracy: 0.7041 - val_loss: 1.7179 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1644/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9048 - accuracy: 0.6675\n",
      "Epoch 1644: val_loss improved from 1.71786 to 1.71431, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.9048 - accuracy: 0.6675 - val_loss: 1.7143 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1645/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8468 - accuracy: 0.7100\n",
      "Epoch 1645: val_loss improved from 1.71431 to 1.71063, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8468 - accuracy: 0.7100 - val_loss: 1.7106 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1646/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8530 - accuracy: 0.7041\n",
      "Epoch 1646: val_loss improved from 1.71063 to 1.70648, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.8530 - accuracy: 0.7041 - val_loss: 1.7065 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1647/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8294 - accuracy: 0.7028\n",
      "Epoch 1647: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.8294 - accuracy: 0.7028 - val_loss: 1.7123 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1648/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8449 - accuracy: 0.7017\n",
      "Epoch 1648: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.8449 - accuracy: 0.7017 - val_loss: 1.7285 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1649/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8183 - accuracy: 0.7170\n",
      "Epoch 1649: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8183 - accuracy: 0.7170 - val_loss: 1.7396 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1650/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8493 - accuracy: 0.7111\n",
      "Epoch 1650: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.8493 - accuracy: 0.7111 - val_loss: 1.7513 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1651/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8171 - accuracy: 0.7146\n",
      "Epoch 1651: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8171 - accuracy: 0.7146 - val_loss: 1.7622 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1652/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8625 - accuracy: 0.6836\n",
      "Epoch 1652: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8625 - accuracy: 0.6836 - val_loss: 1.7721 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1653/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8522 - accuracy: 0.6895\n",
      "Epoch 1653: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8522 - accuracy: 0.6895 - val_loss: 1.7778 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1654/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8177 - accuracy: 0.7064\n",
      "Epoch 1654: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8177 - accuracy: 0.7064 - val_loss: 1.7702 - val_accuracy: 0.4368 - lr: 1.0000e-05\n",
      "Epoch 1655/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8595 - accuracy: 0.6969\n",
      "Epoch 1655: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8595 - accuracy: 0.6969 - val_loss: 1.7668 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1656/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8252 - accuracy: 0.7193\n",
      "Epoch 1656: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8252 - accuracy: 0.7193 - val_loss: 1.7588 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1657/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8187 - accuracy: 0.7276\n",
      "Epoch 1657: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8187 - accuracy: 0.7276 - val_loss: 1.7528 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1658/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8578 - accuracy: 0.7087\n",
      "Epoch 1658: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8578 - accuracy: 0.7087 - val_loss: 1.7502 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1659/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8102 - accuracy: 0.7064\n",
      "Epoch 1659: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8102 - accuracy: 0.7064 - val_loss: 1.7452 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1660/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8201 - accuracy: 0.7170\n",
      "Epoch 1660: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8201 - accuracy: 0.7170 - val_loss: 1.7427 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1661/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8668 - accuracy: 0.6828\n",
      "Epoch 1661: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8668 - accuracy: 0.6828 - val_loss: 1.7347 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1662/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7934 - accuracy: 0.7193\n",
      "Epoch 1662: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7934 - accuracy: 0.7193 - val_loss: 1.7397 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1663/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8530 - accuracy: 0.7100\n",
      "Epoch 1663: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.8530 - accuracy: 0.7100 - val_loss: 1.7421 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1664/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8925 - accuracy: 0.6899\n",
      "Epoch 1664: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.8925 - accuracy: 0.6899 - val_loss: 1.7455 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1665/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8091 - accuracy: 0.7111\n",
      "Epoch 1665: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.8091 - accuracy: 0.7111 - val_loss: 1.7455 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1666/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8181 - accuracy: 0.7080\n",
      "Epoch 1666: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8181 - accuracy: 0.7080 - val_loss: 1.7493 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1667/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8796 - accuracy: 0.6934\n",
      "Epoch 1667: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.8796 - accuracy: 0.6934 - val_loss: 1.7542 - val_accuracy: 0.4404 - lr: 1.0000e-05\n",
      "Epoch 1668/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8365 - accuracy: 0.7012\n",
      "Epoch 1668: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.8365 - accuracy: 0.7012 - val_loss: 1.7543 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1669/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8135 - accuracy: 0.6969\n",
      "Epoch 1669: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8135 - accuracy: 0.6969 - val_loss: 1.7493 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1670/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8664 - accuracy: 0.6958\n",
      "Epoch 1670: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8664 - accuracy: 0.6958 - val_loss: 1.7497 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1671/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8160 - accuracy: 0.7061\n",
      "Epoch 1671: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8160 - accuracy: 0.7061 - val_loss: 1.7487 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1672/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8518 - accuracy: 0.7064\n",
      "Epoch 1672: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8518 - accuracy: 0.7064 - val_loss: 1.7420 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1673/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8576 - accuracy: 0.6946\n",
      "Epoch 1673: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.8576 - accuracy: 0.6946 - val_loss: 1.7226 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1674/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8213 - accuracy: 0.7123\n",
      "Epoch 1674: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.8213 - accuracy: 0.7123 - val_loss: 1.7189 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1675/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8338 - accuracy: 0.7052\n",
      "Epoch 1675: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.8338 - accuracy: 0.7052 - val_loss: 1.7229 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1676/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8036 - accuracy: 0.7111\n",
      "Epoch 1676: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8036 - accuracy: 0.7111 - val_loss: 1.7246 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1677/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8615 - accuracy: 0.7064\n",
      "Epoch 1677: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8615 - accuracy: 0.7064 - val_loss: 1.7246 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1678/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8426 - accuracy: 0.6958\n",
      "Epoch 1678: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.8426 - accuracy: 0.6958 - val_loss: 1.7304 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1679/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8446 - accuracy: 0.6958\n",
      "Epoch 1679: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8446 - accuracy: 0.6958 - val_loss: 1.7351 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1680/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8713 - accuracy: 0.6722\n",
      "Epoch 1680: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.8713 - accuracy: 0.6722 - val_loss: 1.7323 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1681/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8622 - accuracy: 0.6963\n",
      "Epoch 1681: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8622 - accuracy: 0.6963 - val_loss: 1.7278 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1682/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8309 - accuracy: 0.7111\n",
      "Epoch 1682: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8309 - accuracy: 0.7111 - val_loss: 1.7322 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1683/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8211 - accuracy: 0.7075\n",
      "Epoch 1683: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8211 - accuracy: 0.7075 - val_loss: 1.7354 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1684/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8513 - accuracy: 0.6946\n",
      "Epoch 1684: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.8513 - accuracy: 0.6946 - val_loss: 1.7341 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1685/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8140 - accuracy: 0.7168\n",
      "Epoch 1685: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8140 - accuracy: 0.7168 - val_loss: 1.7364 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1686/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8621 - accuracy: 0.6887\n",
      "Epoch 1686: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8621 - accuracy: 0.6887 - val_loss: 1.7451 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1687/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8279 - accuracy: 0.6958\n",
      "Epoch 1687: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8279 - accuracy: 0.6958 - val_loss: 1.7478 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1688/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8456 - accuracy: 0.7099\n",
      "Epoch 1688: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8456 - accuracy: 0.7099 - val_loss: 1.7474 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1689/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8444 - accuracy: 0.7134\n",
      "Epoch 1689: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8444 - accuracy: 0.7134 - val_loss: 1.7461 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1690/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8040 - accuracy: 0.7123\n",
      "Epoch 1690: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8040 - accuracy: 0.7123 - val_loss: 1.7375 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1691/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8264 - accuracy: 0.7193\n",
      "Epoch 1691: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8264 - accuracy: 0.7193 - val_loss: 1.7260 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1692/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8088 - accuracy: 0.7170\n",
      "Epoch 1692: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8088 - accuracy: 0.7170 - val_loss: 1.7211 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1693/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.7193\n",
      "Epoch 1693: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.8372 - accuracy: 0.7193 - val_loss: 1.7193 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1694/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8545 - accuracy: 0.6910\n",
      "Epoch 1694: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.8545 - accuracy: 0.6910 - val_loss: 1.7214 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1695/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8562 - accuracy: 0.6804\n",
      "Epoch 1695: val_loss did not improve from 1.70648\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.8562 - accuracy: 0.6804 - val_loss: 1.7110 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1696/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8333 - accuracy: 0.6934\n",
      "Epoch 1696: val_loss improved from 1.70648 to 1.68518, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.8333 - accuracy: 0.6934 - val_loss: 1.6852 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1697/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8300 - accuracy: 0.7064\n",
      "Epoch 1697: val_loss improved from 1.68518 to 1.66740, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8300 - accuracy: 0.7064 - val_loss: 1.6674 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1698/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.6922\n",
      "Epoch 1698: val_loss improved from 1.66740 to 1.66075, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8737 - accuracy: 0.6922 - val_loss: 1.6607 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1699/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7882 - accuracy: 0.7205\n",
      "Epoch 1699: val_loss improved from 1.66075 to 1.65742, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7882 - accuracy: 0.7205 - val_loss: 1.6574 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1700/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8413 - accuracy: 0.6969\n",
      "Epoch 1700: val_loss improved from 1.65742 to 1.65154, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8413 - accuracy: 0.6969 - val_loss: 1.6515 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1701/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8102 - accuracy: 0.7111\n",
      "Epoch 1701: val_loss improved from 1.65154 to 1.64567, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.8102 - accuracy: 0.7111 - val_loss: 1.6457 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1702/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8473 - accuracy: 0.6969\n",
      "Epoch 1702: val_loss improved from 1.64567 to 1.64234, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.8473 - accuracy: 0.6969 - val_loss: 1.6423 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1703/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8502 - accuracy: 0.6969\n",
      "Epoch 1703: val_loss improved from 1.64234 to 1.64117, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8502 - accuracy: 0.6969 - val_loss: 1.6412 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1704/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8486 - accuracy: 0.6887\n",
      "Epoch 1704: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8486 - accuracy: 0.6887 - val_loss: 1.6421 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1705/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8457 - accuracy: 0.6958\n",
      "Epoch 1705: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8457 - accuracy: 0.6958 - val_loss: 1.6517 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1706/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8358 - accuracy: 0.7090\n",
      "Epoch 1706: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.8358 - accuracy: 0.7090 - val_loss: 1.6535 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1707/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.6963\n",
      "Epoch 1707: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8645 - accuracy: 0.6963 - val_loss: 1.6534 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1708/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8773 - accuracy: 0.6899\n",
      "Epoch 1708: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8773 - accuracy: 0.6899 - val_loss: 1.6587 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1709/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8492 - accuracy: 0.7017\n",
      "Epoch 1709: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8492 - accuracy: 0.7017 - val_loss: 1.6758 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1710/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8103 - accuracy: 0.7146\n",
      "Epoch 1710: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.8103 - accuracy: 0.7146 - val_loss: 1.6868 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1711/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.7123\n",
      "Epoch 1711: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8386 - accuracy: 0.7123 - val_loss: 1.6848 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1712/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8246 - accuracy: 0.7205\n",
      "Epoch 1712: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.8246 - accuracy: 0.7205 - val_loss: 1.6772 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1713/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8282 - accuracy: 0.7075\n",
      "Epoch 1713: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.8282 - accuracy: 0.7075 - val_loss: 1.6818 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1714/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8627 - accuracy: 0.6851\n",
      "Epoch 1714: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8627 - accuracy: 0.6851 - val_loss: 1.6820 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1715/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8205 - accuracy: 0.7119\n",
      "Epoch 1715: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.8205 - accuracy: 0.7119 - val_loss: 1.6836 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1716/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8120 - accuracy: 0.6958\n",
      "Epoch 1716: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.8120 - accuracy: 0.6958 - val_loss: 1.6993 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1717/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8546 - accuracy: 0.6969\n",
      "Epoch 1717: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8546 - accuracy: 0.6969 - val_loss: 1.7105 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1718/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8409 - accuracy: 0.6992\n",
      "Epoch 1718: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.8409 - accuracy: 0.6992 - val_loss: 1.7232 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1719/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8325 - accuracy: 0.7017\n",
      "Epoch 1719: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8325 - accuracy: 0.7017 - val_loss: 1.7370 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1720/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8234 - accuracy: 0.6992\n",
      "Epoch 1720: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.8234 - accuracy: 0.6992 - val_loss: 1.7481 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1721/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8172 - accuracy: 0.7323\n",
      "Epoch 1721: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8172 - accuracy: 0.7323 - val_loss: 1.7570 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1722/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8473 - accuracy: 0.7012\n",
      "Epoch 1722: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.8473 - accuracy: 0.7012 - val_loss: 1.7529 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1723/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8213 - accuracy: 0.6981\n",
      "Epoch 1723: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8213 - accuracy: 0.6981 - val_loss: 1.7555 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1724/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8350 - accuracy: 0.6982\n",
      "Epoch 1724: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8350 - accuracy: 0.6982 - val_loss: 1.7570 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1725/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8022 - accuracy: 0.7052\n",
      "Epoch 1725: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8022 - accuracy: 0.7052 - val_loss: 1.7543 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1726/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8061 - accuracy: 0.7111\n",
      "Epoch 1726: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.8061 - accuracy: 0.7111 - val_loss: 1.7565 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1727/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8269 - accuracy: 0.7028\n",
      "Epoch 1727: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8269 - accuracy: 0.7028 - val_loss: 1.7612 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1728/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7917 - accuracy: 0.7311\n",
      "Epoch 1728: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7917 - accuracy: 0.7311 - val_loss: 1.7484 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1729/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8121 - accuracy: 0.7193\n",
      "Epoch 1729: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.8121 - accuracy: 0.7193 - val_loss: 1.7324 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1730/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8296 - accuracy: 0.7064\n",
      "Epoch 1730: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8296 - accuracy: 0.7064 - val_loss: 1.7255 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1731/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8070 - accuracy: 0.7090\n",
      "Epoch 1731: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.8070 - accuracy: 0.7090 - val_loss: 1.7185 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1732/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8482 - accuracy: 0.6922\n",
      "Epoch 1732: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8482 - accuracy: 0.6922 - val_loss: 1.7169 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1733/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8232 - accuracy: 0.7158\n",
      "Epoch 1733: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.8232 - accuracy: 0.7158 - val_loss: 1.7140 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1734/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.7264\n",
      "Epoch 1734: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8321 - accuracy: 0.7264 - val_loss: 1.7040 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1735/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8518 - accuracy: 0.6969\n",
      "Epoch 1735: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.8518 - accuracy: 0.6969 - val_loss: 1.6872 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1736/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8204 - accuracy: 0.7158\n",
      "Epoch 1736: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.8204 - accuracy: 0.7158 - val_loss: 1.6729 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1737/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8179 - accuracy: 0.7193\n",
      "Epoch 1737: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8179 - accuracy: 0.7193 - val_loss: 1.6664 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1738/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8407 - accuracy: 0.7193\n",
      "Epoch 1738: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8407 - accuracy: 0.7193 - val_loss: 1.6631 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1739/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8456 - accuracy: 0.7146\n",
      "Epoch 1739: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8456 - accuracy: 0.7146 - val_loss: 1.6609 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1740/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8809 - accuracy: 0.6885\n",
      "Epoch 1740: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8809 - accuracy: 0.6885 - val_loss: 1.6614 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1741/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8503 - accuracy: 0.7111\n",
      "Epoch 1741: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8503 - accuracy: 0.7111 - val_loss: 1.6532 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1742/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8024 - accuracy: 0.7087\n",
      "Epoch 1742: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8024 - accuracy: 0.7087 - val_loss: 1.6623 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1743/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8117 - accuracy: 0.7123\n",
      "Epoch 1743: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8117 - accuracy: 0.7123 - val_loss: 1.6711 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1744/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8468 - accuracy: 0.7146\n",
      "Epoch 1744: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.8468 - accuracy: 0.7146 - val_loss: 1.6823 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1745/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8100 - accuracy: 0.7139\n",
      "Epoch 1745: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8100 - accuracy: 0.7139 - val_loss: 1.7005 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1746/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8138 - accuracy: 0.7148\n",
      "Epoch 1746: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.8138 - accuracy: 0.7148 - val_loss: 1.7170 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1747/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8210 - accuracy: 0.7241\n",
      "Epoch 1747: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8210 - accuracy: 0.7241 - val_loss: 1.7320 - val_accuracy: 0.4549 - lr: 1.0000e-05\n",
      "Epoch 1748/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7994 - accuracy: 0.7241\n",
      "Epoch 1748: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.7994 - accuracy: 0.7241 - val_loss: 1.7540 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1749/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8277 - accuracy: 0.7182\n",
      "Epoch 1749: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8277 - accuracy: 0.7182 - val_loss: 1.7645 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1750/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8083 - accuracy: 0.7229\n",
      "Epoch 1750: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8083 - accuracy: 0.7229 - val_loss: 1.7731 - val_accuracy: 0.4440 - lr: 1.0000e-05\n",
      "Epoch 1751/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8064 - accuracy: 0.7335\n",
      "Epoch 1751: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8064 - accuracy: 0.7335 - val_loss: 1.7679 - val_accuracy: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 1752/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8063 - accuracy: 0.7111\n",
      "Epoch 1752: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.8063 - accuracy: 0.7111 - val_loss: 1.7563 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1753/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8644 - accuracy: 0.7064\n",
      "Epoch 1753: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8644 - accuracy: 0.7064 - val_loss: 1.7562 - val_accuracy: 0.4513 - lr: 1.0000e-05\n",
      "Epoch 1754/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8077 - accuracy: 0.7170\n",
      "Epoch 1754: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8077 - accuracy: 0.7170 - val_loss: 1.7373 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1755/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8303 - accuracy: 0.7148\n",
      "Epoch 1755: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.8303 - accuracy: 0.7148 - val_loss: 1.7061 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1756/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8085 - accuracy: 0.7288\n",
      "Epoch 1756: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.8085 - accuracy: 0.7288 - val_loss: 1.6873 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1757/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8067 - accuracy: 0.7193\n",
      "Epoch 1757: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8067 - accuracy: 0.7193 - val_loss: 1.6815 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1758/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8272 - accuracy: 0.6922\n",
      "Epoch 1758: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8272 - accuracy: 0.6922 - val_loss: 1.6725 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1759/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8151 - accuracy: 0.7109\n",
      "Epoch 1759: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8151 - accuracy: 0.7109 - val_loss: 1.6646 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1760/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8241 - accuracy: 0.7129\n",
      "Epoch 1760: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8241 - accuracy: 0.7129 - val_loss: 1.6647 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1761/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8257 - accuracy: 0.7170\n",
      "Epoch 1761: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.8257 - accuracy: 0.7170 - val_loss: 1.6646 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1762/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8068 - accuracy: 0.7005\n",
      "Epoch 1762: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8068 - accuracy: 0.7005 - val_loss: 1.6621 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1763/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8448 - accuracy: 0.7070\n",
      "Epoch 1763: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.8448 - accuracy: 0.7070 - val_loss: 1.6588 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1764/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8263 - accuracy: 0.7099\n",
      "Epoch 1764: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8263 - accuracy: 0.7099 - val_loss: 1.6673 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1765/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8570 - accuracy: 0.7090\n",
      "Epoch 1765: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8570 - accuracy: 0.7090 - val_loss: 1.6717 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1766/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8164 - accuracy: 0.7119\n",
      "Epoch 1766: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.8164 - accuracy: 0.7119 - val_loss: 1.6634 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1767/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7889 - accuracy: 0.7323\n",
      "Epoch 1767: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7889 - accuracy: 0.7323 - val_loss: 1.6584 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1768/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.7005\n",
      "Epoch 1768: val_loss did not improve from 1.64117\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8857 - accuracy: 0.7005 - val_loss: 1.6477 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1769/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8470 - accuracy: 0.7002\n",
      "Epoch 1769: val_loss improved from 1.64117 to 1.64092, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.8470 - accuracy: 0.7002 - val_loss: 1.6409 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1770/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8302 - accuracy: 0.7087\n",
      "Epoch 1770: val_loss improved from 1.64092 to 1.63297, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8302 - accuracy: 0.7087 - val_loss: 1.6330 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1771/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8251 - accuracy: 0.6992\n",
      "Epoch 1771: val_loss improved from 1.63297 to 1.62891, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.8251 - accuracy: 0.6992 - val_loss: 1.6289 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1772/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8175 - accuracy: 0.7158\n",
      "Epoch 1772: val_loss did not improve from 1.62891\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8175 - accuracy: 0.7158 - val_loss: 1.6300 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1773/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8192 - accuracy: 0.7146\n",
      "Epoch 1773: val_loss did not improve from 1.62891\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8192 - accuracy: 0.7146 - val_loss: 1.6387 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1774/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8250 - accuracy: 0.7052\n",
      "Epoch 1774: val_loss did not improve from 1.62891\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8250 - accuracy: 0.7052 - val_loss: 1.6465 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1775/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7874 - accuracy: 0.7394\n",
      "Epoch 1775: val_loss did not improve from 1.62891\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7874 - accuracy: 0.7394 - val_loss: 1.6487 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1776/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8171 - accuracy: 0.6969\n",
      "Epoch 1776: val_loss did not improve from 1.62891\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8171 - accuracy: 0.6969 - val_loss: 1.6529 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1777/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8255 - accuracy: 0.7134\n",
      "Epoch 1777: val_loss did not improve from 1.62891\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8255 - accuracy: 0.7134 - val_loss: 1.6452 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1778/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7986 - accuracy: 0.7311\n",
      "Epoch 1778: val_loss did not improve from 1.62891\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7986 - accuracy: 0.7311 - val_loss: 1.6414 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1779/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8111 - accuracy: 0.7134\n",
      "Epoch 1779: val_loss did not improve from 1.62891\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8111 - accuracy: 0.7134 - val_loss: 1.6416 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1780/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8083 - accuracy: 0.7075\n",
      "Epoch 1780: val_loss improved from 1.62891 to 1.62507, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8083 - accuracy: 0.7075 - val_loss: 1.6251 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1781/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8276 - accuracy: 0.7193\n",
      "Epoch 1781: val_loss improved from 1.62507 to 1.61716, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8276 - accuracy: 0.7193 - val_loss: 1.6172 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1782/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.7323\n",
      "Epoch 1782: val_loss improved from 1.61716 to 1.61302, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7752 - accuracy: 0.7323 - val_loss: 1.6130 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1783/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8368 - accuracy: 0.6934\n",
      "Epoch 1783: val_loss improved from 1.61302 to 1.60563, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.8368 - accuracy: 0.6934 - val_loss: 1.6056 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1784/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8087 - accuracy: 0.7005\n",
      "Epoch 1784: val_loss improved from 1.60563 to 1.60359, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8087 - accuracy: 0.7005 - val_loss: 1.6036 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1785/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8767 - accuracy: 0.6993\n",
      "Epoch 1785: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8767 - accuracy: 0.6993 - val_loss: 1.6177 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1786/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8051 - accuracy: 0.7170\n",
      "Epoch 1786: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8051 - accuracy: 0.7170 - val_loss: 1.6304 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1787/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8139 - accuracy: 0.6863\n",
      "Epoch 1787: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8139 - accuracy: 0.6863 - val_loss: 1.6375 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1788/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7992 - accuracy: 0.7170\n",
      "Epoch 1788: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7992 - accuracy: 0.7170 - val_loss: 1.6386 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1789/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8176 - accuracy: 0.7188\n",
      "Epoch 1789: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.8176 - accuracy: 0.7188 - val_loss: 1.6376 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1790/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8282 - accuracy: 0.7061\n",
      "Epoch 1790: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.8282 - accuracy: 0.7061 - val_loss: 1.6314 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1791/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8253 - accuracy: 0.6993\n",
      "Epoch 1791: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.8253 - accuracy: 0.6993 - val_loss: 1.6192 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1792/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7999 - accuracy: 0.7031\n",
      "Epoch 1792: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7999 - accuracy: 0.7031 - val_loss: 1.6177 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1793/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7874 - accuracy: 0.7300\n",
      "Epoch 1793: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7874 - accuracy: 0.7300 - val_loss: 1.6104 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1794/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8155 - accuracy: 0.7193\n",
      "Epoch 1794: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8155 - accuracy: 0.7193 - val_loss: 1.6109 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1795/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8303 - accuracy: 0.7017\n",
      "Epoch 1795: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8303 - accuracy: 0.7017 - val_loss: 1.6133 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1796/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7891 - accuracy: 0.7241\n",
      "Epoch 1796: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7891 - accuracy: 0.7241 - val_loss: 1.6178 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1797/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8212 - accuracy: 0.7111\n",
      "Epoch 1797: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8212 - accuracy: 0.7111 - val_loss: 1.6221 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1798/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8380 - accuracy: 0.6922\n",
      "Epoch 1798: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8380 - accuracy: 0.6922 - val_loss: 1.6336 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1799/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8221 - accuracy: 0.7017\n",
      "Epoch 1799: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.8221 - accuracy: 0.7017 - val_loss: 1.6455 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1800/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8297 - accuracy: 0.6934\n",
      "Epoch 1800: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.8297 - accuracy: 0.6934 - val_loss: 1.6575 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1801/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8208 - accuracy: 0.7134\n",
      "Epoch 1801: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8208 - accuracy: 0.7134 - val_loss: 1.6573 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1802/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8123 - accuracy: 0.7252\n",
      "Epoch 1802: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 0.8123 - accuracy: 0.7252 - val_loss: 1.6472 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1803/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7842 - accuracy: 0.7370\n",
      "Epoch 1803: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7842 - accuracy: 0.7370 - val_loss: 1.6463 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1804/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7945 - accuracy: 0.7182\n",
      "Epoch 1804: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7945 - accuracy: 0.7182 - val_loss: 1.6508 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1805/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8236 - accuracy: 0.7197\n",
      "Epoch 1805: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.8236 - accuracy: 0.7197 - val_loss: 1.6530 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1806/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8385 - accuracy: 0.7002\n",
      "Epoch 1806: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8385 - accuracy: 0.7002 - val_loss: 1.6550 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1807/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8016 - accuracy: 0.7193\n",
      "Epoch 1807: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8016 - accuracy: 0.7193 - val_loss: 1.6529 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1808/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8397 - accuracy: 0.7028\n",
      "Epoch 1808: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8397 - accuracy: 0.7028 - val_loss: 1.6589 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1809/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7949 - accuracy: 0.7158\n",
      "Epoch 1809: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7949 - accuracy: 0.7158 - val_loss: 1.6696 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1810/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8487 - accuracy: 0.6899\n",
      "Epoch 1810: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8487 - accuracy: 0.6899 - val_loss: 1.6725 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1811/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7676 - accuracy: 0.7300\n",
      "Epoch 1811: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7676 - accuracy: 0.7300 - val_loss: 1.6763 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1812/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8164 - accuracy: 0.7119\n",
      "Epoch 1812: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.8164 - accuracy: 0.7119 - val_loss: 1.6818 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1813/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8198 - accuracy: 0.6969\n",
      "Epoch 1813: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.8198 - accuracy: 0.6969 - val_loss: 1.6899 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1814/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8436 - accuracy: 0.7134\n",
      "Epoch 1814: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8436 - accuracy: 0.7134 - val_loss: 1.6992 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1815/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8285 - accuracy: 0.7148\n",
      "Epoch 1815: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.8285 - accuracy: 0.7148 - val_loss: 1.6987 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1816/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8117 - accuracy: 0.7090\n",
      "Epoch 1816: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8117 - accuracy: 0.7090 - val_loss: 1.6925 - val_accuracy: 0.4585 - lr: 1.0000e-05\n",
      "Epoch 1817/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.7170\n",
      "Epoch 1817: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.7967 - accuracy: 0.7170 - val_loss: 1.6775 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1818/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8244 - accuracy: 0.7178\n",
      "Epoch 1818: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.8244 - accuracy: 0.7178 - val_loss: 1.6684 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1819/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8768 - accuracy: 0.6757\n",
      "Epoch 1819: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8768 - accuracy: 0.6757 - val_loss: 1.6566 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1820/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8573 - accuracy: 0.6875\n",
      "Epoch 1820: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8573 - accuracy: 0.6875 - val_loss: 1.6515 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1821/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8578 - accuracy: 0.6958\n",
      "Epoch 1821: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8578 - accuracy: 0.6958 - val_loss: 1.6479 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1822/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8189 - accuracy: 0.7229\n",
      "Epoch 1822: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.8189 - accuracy: 0.7229 - val_loss: 1.6383 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1823/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7957 - accuracy: 0.7252\n",
      "Epoch 1823: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7957 - accuracy: 0.7252 - val_loss: 1.6321 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1824/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7918 - accuracy: 0.7197\n",
      "Epoch 1824: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7918 - accuracy: 0.7197 - val_loss: 1.6287 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1825/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7499 - accuracy: 0.7358\n",
      "Epoch 1825: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.7499 - accuracy: 0.7358 - val_loss: 1.6242 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1826/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8090 - accuracy: 0.7040\n",
      "Epoch 1826: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8090 - accuracy: 0.7040 - val_loss: 1.6186 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1827/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8076 - accuracy: 0.7288\n",
      "Epoch 1827: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8076 - accuracy: 0.7288 - val_loss: 1.6244 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1828/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7872 - accuracy: 0.7182\n",
      "Epoch 1828: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7872 - accuracy: 0.7182 - val_loss: 1.6368 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1829/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8189 - accuracy: 0.6981\n",
      "Epoch 1829: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8189 - accuracy: 0.6981 - val_loss: 1.6537 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1830/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7637 - accuracy: 0.7347\n",
      "Epoch 1830: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7637 - accuracy: 0.7347 - val_loss: 1.6544 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1831/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8091 - accuracy: 0.7182\n",
      "Epoch 1831: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.8091 - accuracy: 0.7182 - val_loss: 1.6473 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1832/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8392 - accuracy: 0.6946\n",
      "Epoch 1832: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8392 - accuracy: 0.6946 - val_loss: 1.6363 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1833/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8167 - accuracy: 0.7087\n",
      "Epoch 1833: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8167 - accuracy: 0.7087 - val_loss: 1.6271 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1834/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.7236\n",
      "Epoch 1834: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.7743 - accuracy: 0.7236 - val_loss: 1.6189 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1835/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8383 - accuracy: 0.7168\n",
      "Epoch 1835: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8383 - accuracy: 0.7168 - val_loss: 1.6136 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1836/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7975 - accuracy: 0.7266\n",
      "Epoch 1836: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7975 - accuracy: 0.7266 - val_loss: 1.6204 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1837/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7762 - accuracy: 0.7193\n",
      "Epoch 1837: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7762 - accuracy: 0.7193 - val_loss: 1.6320 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1838/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8084 - accuracy: 0.7061\n",
      "Epoch 1838: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8084 - accuracy: 0.7061 - val_loss: 1.6446 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1839/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8295 - accuracy: 0.7017\n",
      "Epoch 1839: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8295 - accuracy: 0.7017 - val_loss: 1.6515 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1840/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8345 - accuracy: 0.7111\n",
      "Epoch 1840: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8345 - accuracy: 0.7111 - val_loss: 1.6519 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1841/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7434 - accuracy: 0.7358\n",
      "Epoch 1841: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7434 - accuracy: 0.7358 - val_loss: 1.6520 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1842/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7900 - accuracy: 0.7129\n",
      "Epoch 1842: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.7900 - accuracy: 0.7129 - val_loss: 1.6539 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1843/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8059 - accuracy: 0.6993\n",
      "Epoch 1843: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8059 - accuracy: 0.6993 - val_loss: 1.6467 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1844/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8141 - accuracy: 0.7080\n",
      "Epoch 1844: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8141 - accuracy: 0.7080 - val_loss: 1.6403 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1845/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7881 - accuracy: 0.7229\n",
      "Epoch 1845: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7881 - accuracy: 0.7229 - val_loss: 1.6375 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1846/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7563 - accuracy: 0.7441\n",
      "Epoch 1846: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7563 - accuracy: 0.7441 - val_loss: 1.6421 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1847/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7918 - accuracy: 0.7168\n",
      "Epoch 1847: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7918 - accuracy: 0.7168 - val_loss: 1.6467 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1848/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8539 - accuracy: 0.7075\n",
      "Epoch 1848: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8539 - accuracy: 0.7075 - val_loss: 1.6461 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1849/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7521 - accuracy: 0.7347\n",
      "Epoch 1849: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7521 - accuracy: 0.7347 - val_loss: 1.6470 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1850/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8055 - accuracy: 0.7158\n",
      "Epoch 1850: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8055 - accuracy: 0.7158 - val_loss: 1.6425 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1851/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8175 - accuracy: 0.7099\n",
      "Epoch 1851: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8175 - accuracy: 0.7099 - val_loss: 1.6414 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1852/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8141 - accuracy: 0.7111\n",
      "Epoch 1852: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.8141 - accuracy: 0.7111 - val_loss: 1.6333 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1853/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7796 - accuracy: 0.7182\n",
      "Epoch 1853: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7796 - accuracy: 0.7182 - val_loss: 1.6333 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1854/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8265 - accuracy: 0.7158\n",
      "Epoch 1854: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8265 - accuracy: 0.7158 - val_loss: 1.6341 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1855/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8211 - accuracy: 0.7075\n",
      "Epoch 1855: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.8211 - accuracy: 0.7075 - val_loss: 1.6315 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1856/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.6993\n",
      "Epoch 1856: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8386 - accuracy: 0.6993 - val_loss: 1.6318 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1857/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8279 - accuracy: 0.7040\n",
      "Epoch 1857: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.8279 - accuracy: 0.7040 - val_loss: 1.6447 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1858/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8131 - accuracy: 0.7075\n",
      "Epoch 1858: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.8131 - accuracy: 0.7075 - val_loss: 1.6499 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1859/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8168 - accuracy: 0.7005\n",
      "Epoch 1859: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.8168 - accuracy: 0.7005 - val_loss: 1.6556 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1860/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8055 - accuracy: 0.7087\n",
      "Epoch 1860: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.8055 - accuracy: 0.7087 - val_loss: 1.6631 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1861/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7957 - accuracy: 0.7205\n",
      "Epoch 1861: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7957 - accuracy: 0.7205 - val_loss: 1.6536 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1862/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7871 - accuracy: 0.7300\n",
      "Epoch 1862: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7871 - accuracy: 0.7300 - val_loss: 1.6409 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1863/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8117 - accuracy: 0.7182\n",
      "Epoch 1863: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.8117 - accuracy: 0.7182 - val_loss: 1.6383 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1864/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7994 - accuracy: 0.7182\n",
      "Epoch 1864: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7994 - accuracy: 0.7182 - val_loss: 1.6366 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1865/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8096 - accuracy: 0.7276\n",
      "Epoch 1865: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8096 - accuracy: 0.7276 - val_loss: 1.6248 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1866/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7909 - accuracy: 0.7139\n",
      "Epoch 1866: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7909 - accuracy: 0.7139 - val_loss: 1.6209 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1867/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8360 - accuracy: 0.6958\n",
      "Epoch 1867: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8360 - accuracy: 0.6958 - val_loss: 1.6219 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1868/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.7139\n",
      "Epoch 1868: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8012 - accuracy: 0.7139 - val_loss: 1.6201 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1869/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.7158\n",
      "Epoch 1869: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8012 - accuracy: 0.7158 - val_loss: 1.6259 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1870/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7893 - accuracy: 0.7182\n",
      "Epoch 1870: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7893 - accuracy: 0.7182 - val_loss: 1.6448 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1871/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8053 - accuracy: 0.7207\n",
      "Epoch 1871: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8053 - accuracy: 0.7207 - val_loss: 1.6549 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1872/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8123 - accuracy: 0.7100\n",
      "Epoch 1872: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.8123 - accuracy: 0.7100 - val_loss: 1.6617 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1873/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7710 - accuracy: 0.7335\n",
      "Epoch 1873: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7710 - accuracy: 0.7335 - val_loss: 1.6588 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1874/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8083 - accuracy: 0.7188\n",
      "Epoch 1874: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.8083 - accuracy: 0.7188 - val_loss: 1.6440 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1875/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8225 - accuracy: 0.7170\n",
      "Epoch 1875: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.8225 - accuracy: 0.7170 - val_loss: 1.6237 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1876/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8099 - accuracy: 0.7017\n",
      "Epoch 1876: val_loss did not improve from 1.60359\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.8099 - accuracy: 0.7017 - val_loss: 1.6085 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1877/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8135 - accuracy: 0.7099\n",
      "Epoch 1877: val_loss improved from 1.60359 to 1.59187, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8135 - accuracy: 0.7099 - val_loss: 1.5919 - val_accuracy: 0.4801 - lr: 1.0000e-05\n",
      "Epoch 1878/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7702 - accuracy: 0.7305\n",
      "Epoch 1878: val_loss improved from 1.59187 to 1.58198, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7702 - accuracy: 0.7305 - val_loss: 1.5820 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1879/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8126 - accuracy: 0.7123\n",
      "Epoch 1879: val_loss improved from 1.58198 to 1.57970, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.8126 - accuracy: 0.7123 - val_loss: 1.5797 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1880/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8164 - accuracy: 0.7146\n",
      "Epoch 1880: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8164 - accuracy: 0.7146 - val_loss: 1.5820 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1881/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8021 - accuracy: 0.7229\n",
      "Epoch 1881: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.8021 - accuracy: 0.7229 - val_loss: 1.5906 - val_accuracy: 0.4801 - lr: 1.0000e-05\n",
      "Epoch 1882/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8092 - accuracy: 0.7005\n",
      "Epoch 1882: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8092 - accuracy: 0.7005 - val_loss: 1.5975 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1883/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7903 - accuracy: 0.7188\n",
      "Epoch 1883: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.7903 - accuracy: 0.7188 - val_loss: 1.6012 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1884/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7953 - accuracy: 0.7288\n",
      "Epoch 1884: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7953 - accuracy: 0.7288 - val_loss: 1.6118 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1885/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7942 - accuracy: 0.7241\n",
      "Epoch 1885: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7942 - accuracy: 0.7241 - val_loss: 1.6109 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1886/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7453\n",
      "Epoch 1886: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7646 - accuracy: 0.7453 - val_loss: 1.6112 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1887/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8134 - accuracy: 0.7052\n",
      "Epoch 1887: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8134 - accuracy: 0.7052 - val_loss: 1.6233 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1888/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8020 - accuracy: 0.7099\n",
      "Epoch 1888: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.8020 - accuracy: 0.7099 - val_loss: 1.6320 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1889/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8109 - accuracy: 0.7148\n",
      "Epoch 1889: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8109 - accuracy: 0.7148 - val_loss: 1.6445 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1890/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.7064\n",
      "Epoch 1890: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.8062 - accuracy: 0.7064 - val_loss: 1.6475 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1891/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8067 - accuracy: 0.7070\n",
      "Epoch 1891: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8067 - accuracy: 0.7070 - val_loss: 1.6447 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1892/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7938 - accuracy: 0.7146\n",
      "Epoch 1892: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7938 - accuracy: 0.7146 - val_loss: 1.6402 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1893/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8156 - accuracy: 0.7323\n",
      "Epoch 1893: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8156 - accuracy: 0.7323 - val_loss: 1.6338 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1894/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.7324\n",
      "Epoch 1894: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7525 - accuracy: 0.7324 - val_loss: 1.6259 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1895/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7809 - accuracy: 0.7241\n",
      "Epoch 1895: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.7809 - accuracy: 0.7241 - val_loss: 1.6199 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1896/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7820 - accuracy: 0.7170\n",
      "Epoch 1896: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.7820 - accuracy: 0.7170 - val_loss: 1.6221 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1897/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7922 - accuracy: 0.7229\n",
      "Epoch 1897: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.7922 - accuracy: 0.7229 - val_loss: 1.6222 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1898/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7962 - accuracy: 0.7252\n",
      "Epoch 1898: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7962 - accuracy: 0.7252 - val_loss: 1.6244 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1899/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8160 - accuracy: 0.7182\n",
      "Epoch 1899: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8160 - accuracy: 0.7182 - val_loss: 1.6257 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1900/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8061 - accuracy: 0.7241\n",
      "Epoch 1900: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8061 - accuracy: 0.7241 - val_loss: 1.6325 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1901/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7910 - accuracy: 0.7285\n",
      "Epoch 1901: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.7910 - accuracy: 0.7285 - val_loss: 1.6396 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1902/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8036 - accuracy: 0.7264\n",
      "Epoch 1902: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8036 - accuracy: 0.7264 - val_loss: 1.6524 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1903/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8361 - accuracy: 0.7031\n",
      "Epoch 1903: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8361 - accuracy: 0.7031 - val_loss: 1.6556 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1904/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7995 - accuracy: 0.7051\n",
      "Epoch 1904: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7995 - accuracy: 0.7051 - val_loss: 1.6599 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1905/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7729 - accuracy: 0.7217\n",
      "Epoch 1905: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7729 - accuracy: 0.7217 - val_loss: 1.6537 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1906/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7762 - accuracy: 0.7205\n",
      "Epoch 1906: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7762 - accuracy: 0.7205 - val_loss: 1.6480 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1907/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7569 - accuracy: 0.7417\n",
      "Epoch 1907: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.7569 - accuracy: 0.7417 - val_loss: 1.6424 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1908/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7888 - accuracy: 0.7276\n",
      "Epoch 1908: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.7888 - accuracy: 0.7276 - val_loss: 1.6433 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1909/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8277 - accuracy: 0.7064\n",
      "Epoch 1909: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.8277 - accuracy: 0.7064 - val_loss: 1.6428 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1910/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8081 - accuracy: 0.7051\n",
      "Epoch 1910: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.8081 - accuracy: 0.7051 - val_loss: 1.6363 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1911/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8037 - accuracy: 0.7028\n",
      "Epoch 1911: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8037 - accuracy: 0.7028 - val_loss: 1.6273 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1912/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8111 - accuracy: 0.6992\n",
      "Epoch 1912: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8111 - accuracy: 0.6992 - val_loss: 1.6257 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1913/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8416 - accuracy: 0.6969\n",
      "Epoch 1913: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8416 - accuracy: 0.6969 - val_loss: 1.6181 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1914/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7867 - accuracy: 0.7276\n",
      "Epoch 1914: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7867 - accuracy: 0.7276 - val_loss: 1.6071 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1915/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8045 - accuracy: 0.7170\n",
      "Epoch 1915: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8045 - accuracy: 0.7170 - val_loss: 1.5946 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1916/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8422 - accuracy: 0.6887\n",
      "Epoch 1916: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.8422 - accuracy: 0.6887 - val_loss: 1.5886 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1917/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8187 - accuracy: 0.7182\n",
      "Epoch 1917: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8187 - accuracy: 0.7182 - val_loss: 1.5857 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1918/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.7217\n",
      "Epoch 1918: val_loss did not improve from 1.57970\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8062 - accuracy: 0.7217 - val_loss: 1.5798 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 1919/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7729 - accuracy: 0.7300\n",
      "Epoch 1919: val_loss improved from 1.57970 to 1.57510, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7729 - accuracy: 0.7300 - val_loss: 1.5751 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 1920/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7964 - accuracy: 0.7134\n",
      "Epoch 1920: val_loss did not improve from 1.57510\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7964 - accuracy: 0.7134 - val_loss: 1.5759 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 1921/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8266 - accuracy: 0.6934\n",
      "Epoch 1921: val_loss did not improve from 1.57510\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.8266 - accuracy: 0.6934 - val_loss: 1.5784 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1922/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8034 - accuracy: 0.7264\n",
      "Epoch 1922: val_loss improved from 1.57510 to 1.57357, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.8034 - accuracy: 0.7264 - val_loss: 1.5736 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 1923/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7807 - accuracy: 0.7087\n",
      "Epoch 1923: val_loss improved from 1.57357 to 1.57222, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7807 - accuracy: 0.7087 - val_loss: 1.5722 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 1924/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7855 - accuracy: 0.7146\n",
      "Epoch 1924: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7855 - accuracy: 0.7146 - val_loss: 1.5760 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 1925/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8263 - accuracy: 0.7158\n",
      "Epoch 1925: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8263 - accuracy: 0.7158 - val_loss: 1.5814 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 1926/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7782 - accuracy: 0.7335\n",
      "Epoch 1926: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7782 - accuracy: 0.7335 - val_loss: 1.5958 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1927/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8312 - accuracy: 0.6863\n",
      "Epoch 1927: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.8312 - accuracy: 0.6863 - val_loss: 1.6134 - val_accuracy: 0.4801 - lr: 1.0000e-05\n",
      "Epoch 1928/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7964 - accuracy: 0.6969\n",
      "Epoch 1928: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7964 - accuracy: 0.6969 - val_loss: 1.6366 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1929/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7952 - accuracy: 0.7119\n",
      "Epoch 1929: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7952 - accuracy: 0.7119 - val_loss: 1.6547 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1930/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7837 - accuracy: 0.7305\n",
      "Epoch 1930: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7837 - accuracy: 0.7305 - val_loss: 1.6664 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1931/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8480 - accuracy: 0.7028\n",
      "Epoch 1931: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.8480 - accuracy: 0.7028 - val_loss: 1.6801 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1932/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7915 - accuracy: 0.7090\n",
      "Epoch 1932: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.7915 - accuracy: 0.7090 - val_loss: 1.6923 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1933/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8129 - accuracy: 0.7205\n",
      "Epoch 1933: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8129 - accuracy: 0.7205 - val_loss: 1.6965 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1934/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.7205\n",
      "Epoch 1934: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7976 - accuracy: 0.7205 - val_loss: 1.6988 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1935/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8405 - accuracy: 0.6981\n",
      "Epoch 1935: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8405 - accuracy: 0.6981 - val_loss: 1.7150 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1936/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7942 - accuracy: 0.7288\n",
      "Epoch 1936: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7942 - accuracy: 0.7288 - val_loss: 1.7233 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1937/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7977 - accuracy: 0.7300\n",
      "Epoch 1937: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7977 - accuracy: 0.7300 - val_loss: 1.7266 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1938/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7966 - accuracy: 0.7207\n",
      "Epoch 1938: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7966 - accuracy: 0.7207 - val_loss: 1.7232 - val_accuracy: 0.4621 - lr: 1.0000e-05\n",
      "Epoch 1939/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.7334\n",
      "Epoch 1939: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7781 - accuracy: 0.7334 - val_loss: 1.7110 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1940/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7981 - accuracy: 0.7182\n",
      "Epoch 1940: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7981 - accuracy: 0.7182 - val_loss: 1.7013 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1941/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7722 - accuracy: 0.7335\n",
      "Epoch 1941: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7722 - accuracy: 0.7335 - val_loss: 1.6900 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1942/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.7205\n",
      "Epoch 1942: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7997 - accuracy: 0.7205 - val_loss: 1.6871 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1943/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8087 - accuracy: 0.7158\n",
      "Epoch 1943: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.8087 - accuracy: 0.7158 - val_loss: 1.6759 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1944/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7912 - accuracy: 0.7146\n",
      "Epoch 1944: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7912 - accuracy: 0.7146 - val_loss: 1.6785 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1945/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.7193\n",
      "Epoch 1945: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7997 - accuracy: 0.7193 - val_loss: 1.6741 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1946/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7778 - accuracy: 0.7382\n",
      "Epoch 1946: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7778 - accuracy: 0.7382 - val_loss: 1.6744 - val_accuracy: 0.4657 - lr: 1.0000e-05\n",
      "Epoch 1947/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8105 - accuracy: 0.7123\n",
      "Epoch 1947: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8105 - accuracy: 0.7123 - val_loss: 1.6709 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1948/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8183 - accuracy: 0.7146\n",
      "Epoch 1948: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8183 - accuracy: 0.7146 - val_loss: 1.6686 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 1949/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7906 - accuracy: 0.7205\n",
      "Epoch 1949: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7906 - accuracy: 0.7205 - val_loss: 1.6549 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1950/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7820 - accuracy: 0.7241\n",
      "Epoch 1950: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7820 - accuracy: 0.7241 - val_loss: 1.6383 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 1951/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7959 - accuracy: 0.7241\n",
      "Epoch 1951: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7959 - accuracy: 0.7241 - val_loss: 1.6279 - val_accuracy: 0.4801 - lr: 1.0000e-05\n",
      "Epoch 1952/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.7193\n",
      "Epoch 1952: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.7781 - accuracy: 0.7193 - val_loss: 1.6153 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1953/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7848 - accuracy: 0.7168\n",
      "Epoch 1953: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.7848 - accuracy: 0.7168 - val_loss: 1.6085 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1954/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.6934\n",
      "Epoch 1954: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.8525 - accuracy: 0.6934 - val_loss: 1.6057 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1955/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7658 - accuracy: 0.7300\n",
      "Epoch 1955: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7658 - accuracy: 0.7300 - val_loss: 1.6014 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1956/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8099 - accuracy: 0.7193\n",
      "Epoch 1956: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8099 - accuracy: 0.7193 - val_loss: 1.6047 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1957/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7559 - accuracy: 0.7358\n",
      "Epoch 1957: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7559 - accuracy: 0.7358 - val_loss: 1.6059 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1958/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8063 - accuracy: 0.7090\n",
      "Epoch 1958: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.8063 - accuracy: 0.7090 - val_loss: 1.6016 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1959/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.7311\n",
      "Epoch 1959: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7963 - accuracy: 0.7311 - val_loss: 1.6011 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 1960/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8197 - accuracy: 0.7158\n",
      "Epoch 1960: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8197 - accuracy: 0.7158 - val_loss: 1.5997 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1961/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8106 - accuracy: 0.7099\n",
      "Epoch 1961: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8106 - accuracy: 0.7099 - val_loss: 1.5949 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1962/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8093 - accuracy: 0.7134\n",
      "Epoch 1962: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8093 - accuracy: 0.7134 - val_loss: 1.5950 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1963/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8160 - accuracy: 0.7099\n",
      "Epoch 1963: val_loss did not improve from 1.57222\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.8160 - accuracy: 0.7099 - val_loss: 1.5814 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1964/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8210 - accuracy: 0.7064\n",
      "Epoch 1964: val_loss improved from 1.57222 to 1.56550, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8210 - accuracy: 0.7064 - val_loss: 1.5655 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1965/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7770 - accuracy: 0.7205\n",
      "Epoch 1965: val_loss improved from 1.56550 to 1.55107, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7770 - accuracy: 0.7205 - val_loss: 1.5511 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1966/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7193\n",
      "Epoch 1966: val_loss improved from 1.55107 to 1.54660, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.7646 - accuracy: 0.7193 - val_loss: 1.5466 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1967/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7803 - accuracy: 0.7205\n",
      "Epoch 1967: val_loss improved from 1.54660 to 1.54175, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7803 - accuracy: 0.7205 - val_loss: 1.5417 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 1968/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7814 - accuracy: 0.7256\n",
      "Epoch 1968: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7814 - accuracy: 0.7256 - val_loss: 1.5460 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1969/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.7323\n",
      "Epoch 1969: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.7779 - accuracy: 0.7323 - val_loss: 1.5502 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1970/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8051 - accuracy: 0.7182\n",
      "Epoch 1970: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.8051 - accuracy: 0.7182 - val_loss: 1.5584 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1971/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8067 - accuracy: 0.7207\n",
      "Epoch 1971: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.8067 - accuracy: 0.7207 - val_loss: 1.5629 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1972/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7666 - accuracy: 0.7276\n",
      "Epoch 1972: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7666 - accuracy: 0.7276 - val_loss: 1.5742 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1973/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7908 - accuracy: 0.7288\n",
      "Epoch 1973: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 0.7908 - accuracy: 0.7288 - val_loss: 1.5738 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1974/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7748 - accuracy: 0.7324\n",
      "Epoch 1974: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7748 - accuracy: 0.7324 - val_loss: 1.5691 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1975/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7716 - accuracy: 0.7207\n",
      "Epoch 1975: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.7716 - accuracy: 0.7207 - val_loss: 1.5641 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1976/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7919 - accuracy: 0.7193\n",
      "Epoch 1976: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7919 - accuracy: 0.7193 - val_loss: 1.5631 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1977/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8046 - accuracy: 0.7168\n",
      "Epoch 1977: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.8046 - accuracy: 0.7168 - val_loss: 1.5685 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1978/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7792 - accuracy: 0.7241\n",
      "Epoch 1978: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7792 - accuracy: 0.7241 - val_loss: 1.5708 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1979/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7810 - accuracy: 0.7217\n",
      "Epoch 1979: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7810 - accuracy: 0.7217 - val_loss: 1.5674 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1980/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7921 - accuracy: 0.7229\n",
      "Epoch 1980: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7921 - accuracy: 0.7229 - val_loss: 1.5677 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1981/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7603 - accuracy: 0.7288\n",
      "Epoch 1981: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7603 - accuracy: 0.7288 - val_loss: 1.5751 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1982/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7852 - accuracy: 0.7158\n",
      "Epoch 1982: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7852 - accuracy: 0.7158 - val_loss: 1.5729 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1983/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7600 - accuracy: 0.7394\n",
      "Epoch 1983: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7600 - accuracy: 0.7394 - val_loss: 1.5661 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1984/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7715 - accuracy: 0.7311\n",
      "Epoch 1984: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7715 - accuracy: 0.7311 - val_loss: 1.5610 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1985/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7864 - accuracy: 0.7300\n",
      "Epoch 1985: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7864 - accuracy: 0.7300 - val_loss: 1.5653 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1986/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8195 - accuracy: 0.7040\n",
      "Epoch 1986: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8195 - accuracy: 0.7040 - val_loss: 1.5820 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1987/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7634 - accuracy: 0.7241\n",
      "Epoch 1987: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7634 - accuracy: 0.7241 - val_loss: 1.5827 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 1988/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7576 - accuracy: 0.7335\n",
      "Epoch 1988: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7576 - accuracy: 0.7335 - val_loss: 1.5862 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 1989/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7884 - accuracy: 0.7100\n",
      "Epoch 1989: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.7884 - accuracy: 0.7100 - val_loss: 1.5848 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 1990/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.7276\n",
      "Epoch 1990: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7911 - accuracy: 0.7276 - val_loss: 1.5881 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 1991/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7517 - accuracy: 0.7524\n",
      "Epoch 1991: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7517 - accuracy: 0.7524 - val_loss: 1.5979 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1992/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7482 - accuracy: 0.7465\n",
      "Epoch 1992: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7482 - accuracy: 0.7465 - val_loss: 1.6049 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1993/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7648 - accuracy: 0.7266\n",
      "Epoch 1993: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7648 - accuracy: 0.7266 - val_loss: 1.6142 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1994/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8286 - accuracy: 0.7052\n",
      "Epoch 1994: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.8286 - accuracy: 0.7052 - val_loss: 1.6273 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 1995/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7857 - accuracy: 0.7197\n",
      "Epoch 1995: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.7857 - accuracy: 0.7197 - val_loss: 1.6463 - val_accuracy: 0.4801 - lr: 1.0000e-05\n",
      "Epoch 1996/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7987 - accuracy: 0.7146\n",
      "Epoch 1996: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7987 - accuracy: 0.7146 - val_loss: 1.6595 - val_accuracy: 0.4801 - lr: 1.0000e-05\n",
      "Epoch 1997/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8243 - accuracy: 0.7252\n",
      "Epoch 1997: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.8243 - accuracy: 0.7252 - val_loss: 1.6862 - val_accuracy: 0.4801 - lr: 1.0000e-05\n",
      "Epoch 1998/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7755 - accuracy: 0.7276\n",
      "Epoch 1998: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7755 - accuracy: 0.7276 - val_loss: 1.7119 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 1999/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8001 - accuracy: 0.7188\n",
      "Epoch 1999: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.8001 - accuracy: 0.7188 - val_loss: 1.7265 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 2000/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7490 - accuracy: 0.7429\n",
      "Epoch 2000: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.7490 - accuracy: 0.7429 - val_loss: 1.7358 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 2001/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7596 - accuracy: 0.7264\n",
      "Epoch 2001: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7596 - accuracy: 0.7264 - val_loss: 1.7406 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 2002/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7682 - accuracy: 0.7182\n",
      "Epoch 2002: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7682 - accuracy: 0.7182 - val_loss: 1.7397 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 2003/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7812 - accuracy: 0.7129\n",
      "Epoch 2003: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.7812 - accuracy: 0.7129 - val_loss: 1.7344 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 2004/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7865 - accuracy: 0.7394\n",
      "Epoch 2004: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7865 - accuracy: 0.7394 - val_loss: 1.7264 - val_accuracy: 0.4693 - lr: 1.0000e-05\n",
      "Epoch 2005/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7896 - accuracy: 0.7123\n",
      "Epoch 2005: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.7896 - accuracy: 0.7123 - val_loss: 1.7183 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 2006/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7916 - accuracy: 0.7178\n",
      "Epoch 2006: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.7916 - accuracy: 0.7178 - val_loss: 1.7039 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 2007/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7787 - accuracy: 0.7347\n",
      "Epoch 2007: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7787 - accuracy: 0.7347 - val_loss: 1.6933 - val_accuracy: 0.4729 - lr: 1.0000e-05\n",
      "Epoch 2008/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7616 - accuracy: 0.7594\n",
      "Epoch 2008: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7616 - accuracy: 0.7594 - val_loss: 1.6788 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 2009/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8302 - accuracy: 0.7075\n",
      "Epoch 2009: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.8302 - accuracy: 0.7075 - val_loss: 1.6665 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 2010/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7952 - accuracy: 0.7119\n",
      "Epoch 2010: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7952 - accuracy: 0.7119 - val_loss: 1.6528 - val_accuracy: 0.4765 - lr: 1.0000e-05\n",
      "Epoch 2011/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.7335\n",
      "Epoch 2011: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.7601 - accuracy: 0.7335 - val_loss: 1.6334 - val_accuracy: 0.4801 - lr: 1.0000e-05\n",
      "Epoch 2012/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7861 - accuracy: 0.7264\n",
      "Epoch 2012: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7861 - accuracy: 0.7264 - val_loss: 1.6172 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2013/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7502 - accuracy: 0.7429\n",
      "Epoch 2013: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7502 - accuracy: 0.7429 - val_loss: 1.6040 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 2014/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7543 - accuracy: 0.7370\n",
      "Epoch 2014: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7543 - accuracy: 0.7370 - val_loss: 1.5947 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2015/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7953 - accuracy: 0.7217\n",
      "Epoch 2015: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7953 - accuracy: 0.7217 - val_loss: 1.5856 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2016/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7830 - accuracy: 0.7288\n",
      "Epoch 2016: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7830 - accuracy: 0.7288 - val_loss: 1.5737 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2017/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.7275\n",
      "Epoch 2017: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7476 - accuracy: 0.7275 - val_loss: 1.5684 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2018/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7870 - accuracy: 0.7335\n",
      "Epoch 2018: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7870 - accuracy: 0.7335 - val_loss: 1.5725 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2019/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7934 - accuracy: 0.7064\n",
      "Epoch 2019: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7934 - accuracy: 0.7064 - val_loss: 1.5752 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2020/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7687 - accuracy: 0.7412\n",
      "Epoch 2020: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7687 - accuracy: 0.7412 - val_loss: 1.5830 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2021/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7729 - accuracy: 0.7300\n",
      "Epoch 2021: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7729 - accuracy: 0.7300 - val_loss: 1.5821 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2022/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7526 - accuracy: 0.7205\n",
      "Epoch 2022: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.7526 - accuracy: 0.7205 - val_loss: 1.5881 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2023/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7500 - accuracy: 0.7335\n",
      "Epoch 2023: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7500 - accuracy: 0.7335 - val_loss: 1.5950 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2024/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7745 - accuracy: 0.7311\n",
      "Epoch 2024: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7745 - accuracy: 0.7311 - val_loss: 1.5791 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2025/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8024 - accuracy: 0.7123\n",
      "Epoch 2025: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.8024 - accuracy: 0.7123 - val_loss: 1.5629 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2026/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7920 - accuracy: 0.7217\n",
      "Epoch 2026: val_loss did not improve from 1.54175\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7920 - accuracy: 0.7217 - val_loss: 1.5418 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2027/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7924 - accuracy: 0.6981\n",
      "Epoch 2027: val_loss improved from 1.54175 to 1.53128, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7924 - accuracy: 0.6981 - val_loss: 1.5313 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2028/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7858 - accuracy: 0.7335\n",
      "Epoch 2028: val_loss improved from 1.53128 to 1.52422, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7858 - accuracy: 0.7335 - val_loss: 1.5242 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2029/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.7441\n",
      "Epoch 2029: val_loss improved from 1.52422 to 1.52054, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7397 - accuracy: 0.7441 - val_loss: 1.5205 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2030/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.7241\n",
      "Epoch 2030: val_loss improved from 1.52054 to 1.51994, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8033 - accuracy: 0.7241 - val_loss: 1.5199 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2031/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.7429\n",
      "Epoch 2031: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7452 - accuracy: 0.7429 - val_loss: 1.5211 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2032/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7581 - accuracy: 0.7344\n",
      "Epoch 2032: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7581 - accuracy: 0.7344 - val_loss: 1.5228 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2033/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7700 - accuracy: 0.7207\n",
      "Epoch 2033: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.7700 - accuracy: 0.7207 - val_loss: 1.5302 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2034/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7864 - accuracy: 0.7227\n",
      "Epoch 2034: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.7864 - accuracy: 0.7227 - val_loss: 1.5301 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2035/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7895 - accuracy: 0.7188\n",
      "Epoch 2035: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.7895 - accuracy: 0.7188 - val_loss: 1.5307 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2036/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7713 - accuracy: 0.7335\n",
      "Epoch 2036: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.7713 - accuracy: 0.7335 - val_loss: 1.5354 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2037/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7960 - accuracy: 0.7217\n",
      "Epoch 2037: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7960 - accuracy: 0.7217 - val_loss: 1.5399 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2038/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7573 - accuracy: 0.7347\n",
      "Epoch 2038: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7573 - accuracy: 0.7347 - val_loss: 1.5472 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2039/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7938 - accuracy: 0.7382\n",
      "Epoch 2039: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.7938 - accuracy: 0.7382 - val_loss: 1.5515 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2040/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7720 - accuracy: 0.7241\n",
      "Epoch 2040: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.7720 - accuracy: 0.7241 - val_loss: 1.5495 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2041/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.7158\n",
      "Epoch 2041: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7758 - accuracy: 0.7158 - val_loss: 1.5501 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2042/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8010 - accuracy: 0.7052\n",
      "Epoch 2042: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.8010 - accuracy: 0.7052 - val_loss: 1.5528 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2043/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8068 - accuracy: 0.7099\n",
      "Epoch 2043: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8068 - accuracy: 0.7099 - val_loss: 1.5466 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2044/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7645 - accuracy: 0.7347\n",
      "Epoch 2044: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7645 - accuracy: 0.7347 - val_loss: 1.5464 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2045/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8143 - accuracy: 0.7087\n",
      "Epoch 2045: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.8143 - accuracy: 0.7087 - val_loss: 1.5393 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2046/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.7417\n",
      "Epoch 2046: val_loss did not improve from 1.51994\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7647 - accuracy: 0.7417 - val_loss: 1.5229 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2047/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7518 - accuracy: 0.7412\n",
      "Epoch 2047: val_loss improved from 1.51994 to 1.51021, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7518 - accuracy: 0.7412 - val_loss: 1.5102 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2048/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.7500\n",
      "Epoch 2048: val_loss improved from 1.51021 to 1.50097, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.7227 - accuracy: 0.7500 - val_loss: 1.5010 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2049/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8004 - accuracy: 0.7236\n",
      "Epoch 2049: val_loss did not improve from 1.50097\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.8004 - accuracy: 0.7236 - val_loss: 1.5032 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2050/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7736 - accuracy: 0.7370\n",
      "Epoch 2050: val_loss did not improve from 1.50097\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7736 - accuracy: 0.7370 - val_loss: 1.5035 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2051/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7829 - accuracy: 0.7323\n",
      "Epoch 2051: val_loss did not improve from 1.50097\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7829 - accuracy: 0.7323 - val_loss: 1.5014 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2052/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.7241\n",
      "Epoch 2052: val_loss improved from 1.50097 to 1.49786, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7743 - accuracy: 0.7241 - val_loss: 1.4979 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2053/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7745 - accuracy: 0.7266\n",
      "Epoch 2053: val_loss improved from 1.49786 to 1.49554, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.7745 - accuracy: 0.7266 - val_loss: 1.4955 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2054/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.7305\n",
      "Epoch 2054: val_loss improved from 1.49554 to 1.49426, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7626 - accuracy: 0.7305 - val_loss: 1.4943 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2055/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7649 - accuracy: 0.7275\n",
      "Epoch 2055: val_loss improved from 1.49426 to 1.48683, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7649 - accuracy: 0.7275 - val_loss: 1.4868 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2056/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7760 - accuracy: 0.7170\n",
      "Epoch 2056: val_loss improved from 1.48683 to 1.48118, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7760 - accuracy: 0.7170 - val_loss: 1.4812 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2057/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.7453\n",
      "Epoch 2057: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7198 - accuracy: 0.7453 - val_loss: 1.4825 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2058/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7855 - accuracy: 0.7064\n",
      "Epoch 2058: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7855 - accuracy: 0.7064 - val_loss: 1.4973 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2059/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7800 - accuracy: 0.7148\n",
      "Epoch 2059: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7800 - accuracy: 0.7148 - val_loss: 1.5081 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2060/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7990 - accuracy: 0.7134\n",
      "Epoch 2060: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7990 - accuracy: 0.7134 - val_loss: 1.5108 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2061/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7508 - accuracy: 0.7276\n",
      "Epoch 2061: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.7508 - accuracy: 0.7276 - val_loss: 1.5101 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2062/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8037 - accuracy: 0.7100\n",
      "Epoch 2062: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.8037 - accuracy: 0.7100 - val_loss: 1.5137 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2063/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7774 - accuracy: 0.7370\n",
      "Epoch 2063: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.7774 - accuracy: 0.7370 - val_loss: 1.5187 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2064/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.7335\n",
      "Epoch 2064: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7672 - accuracy: 0.7335 - val_loss: 1.5199 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2065/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7516 - accuracy: 0.7461\n",
      "Epoch 2065: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.7516 - accuracy: 0.7461 - val_loss: 1.5233 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2066/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7975 - accuracy: 0.7099\n",
      "Epoch 2066: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.7975 - accuracy: 0.7099 - val_loss: 1.5104 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2067/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8182 - accuracy: 0.7087\n",
      "Epoch 2067: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.8182 - accuracy: 0.7087 - val_loss: 1.4947 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2068/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7314 - accuracy: 0.7358\n",
      "Epoch 2068: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7314 - accuracy: 0.7358 - val_loss: 1.4904 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2069/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8066 - accuracy: 0.7146\n",
      "Epoch 2069: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8066 - accuracy: 0.7146 - val_loss: 1.4920 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2070/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7774 - accuracy: 0.7252\n",
      "Epoch 2070: val_loss did not improve from 1.48118\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.7774 - accuracy: 0.7252 - val_loss: 1.4831 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2071/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7733 - accuracy: 0.7229\n",
      "Epoch 2071: val_loss improved from 1.48118 to 1.48057, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7733 - accuracy: 0.7229 - val_loss: 1.4806 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2072/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7415 - accuracy: 0.7347\n",
      "Epoch 2072: val_loss improved from 1.48057 to 1.47603, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7415 - accuracy: 0.7347 - val_loss: 1.4760 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2073/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7309 - accuracy: 0.7370\n",
      "Epoch 2073: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7309 - accuracy: 0.7370 - val_loss: 1.4820 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2074/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7736 - accuracy: 0.7406\n",
      "Epoch 2074: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7736 - accuracy: 0.7406 - val_loss: 1.4884 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2075/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7629 - accuracy: 0.7264\n",
      "Epoch 2075: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7629 - accuracy: 0.7264 - val_loss: 1.4861 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2076/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7834 - accuracy: 0.7182\n",
      "Epoch 2076: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7834 - accuracy: 0.7182 - val_loss: 1.4982 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2077/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7508 - accuracy: 0.7370\n",
      "Epoch 2077: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7508 - accuracy: 0.7370 - val_loss: 1.5064 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2078/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7793 - accuracy: 0.7111\n",
      "Epoch 2078: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7793 - accuracy: 0.7111 - val_loss: 1.5196 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2079/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7766 - accuracy: 0.7205\n",
      "Epoch 2079: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7766 - accuracy: 0.7205 - val_loss: 1.5326 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2080/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7884 - accuracy: 0.7193\n",
      "Epoch 2080: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.7884 - accuracy: 0.7193 - val_loss: 1.5380 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2081/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7269 - accuracy: 0.7476\n",
      "Epoch 2081: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7269 - accuracy: 0.7476 - val_loss: 1.5390 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2082/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.7417\n",
      "Epoch 2082: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.7176 - accuracy: 0.7417 - val_loss: 1.5452 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2083/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7810 - accuracy: 0.7300\n",
      "Epoch 2083: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7810 - accuracy: 0.7300 - val_loss: 1.5610 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2084/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8287 - accuracy: 0.7075\n",
      "Epoch 2084: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8287 - accuracy: 0.7075 - val_loss: 1.5771 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2085/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7485 - accuracy: 0.7370\n",
      "Epoch 2085: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7485 - accuracy: 0.7370 - val_loss: 1.5816 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2086/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7627 - accuracy: 0.7344\n",
      "Epoch 2086: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.7627 - accuracy: 0.7344 - val_loss: 1.5852 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2087/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8069 - accuracy: 0.7099\n",
      "Epoch 2087: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.8069 - accuracy: 0.7099 - val_loss: 1.5816 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2088/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7929 - accuracy: 0.7229\n",
      "Epoch 2088: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7929 - accuracy: 0.7229 - val_loss: 1.5795 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2089/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7852 - accuracy: 0.7146\n",
      "Epoch 2089: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7852 - accuracy: 0.7146 - val_loss: 1.5948 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2090/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8029 - accuracy: 0.7323\n",
      "Epoch 2090: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.8029 - accuracy: 0.7323 - val_loss: 1.6159 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2091/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7478 - accuracy: 0.7311\n",
      "Epoch 2091: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7478 - accuracy: 0.7311 - val_loss: 1.6244 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 2092/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7773 - accuracy: 0.7205\n",
      "Epoch 2092: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7773 - accuracy: 0.7205 - val_loss: 1.6389 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 2093/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7301 - accuracy: 0.7453\n",
      "Epoch 2093: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7301 - accuracy: 0.7453 - val_loss: 1.6488 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 2094/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7664 - accuracy: 0.7170\n",
      "Epoch 2094: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7664 - accuracy: 0.7170 - val_loss: 1.6440 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 2095/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7629 - accuracy: 0.7323\n",
      "Epoch 2095: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7629 - accuracy: 0.7323 - val_loss: 1.6368 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 2096/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8088 - accuracy: 0.7217\n",
      "Epoch 2096: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.8088 - accuracy: 0.7217 - val_loss: 1.6332 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 2097/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7811 - accuracy: 0.7123\n",
      "Epoch 2097: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.7811 - accuracy: 0.7123 - val_loss: 1.6248 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2098/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7574 - accuracy: 0.7311\n",
      "Epoch 2098: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7574 - accuracy: 0.7311 - val_loss: 1.6171 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2099/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.7311\n",
      "Epoch 2099: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7626 - accuracy: 0.7311 - val_loss: 1.6091 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2100/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.7500\n",
      "Epoch 2100: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7342 - accuracy: 0.7500 - val_loss: 1.6065 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2101/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7719 - accuracy: 0.7193\n",
      "Epoch 2101: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7719 - accuracy: 0.7193 - val_loss: 1.6134 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 2102/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7569 - accuracy: 0.7358\n",
      "Epoch 2102: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7569 - accuracy: 0.7358 - val_loss: 1.6176 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2103/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7850 - accuracy: 0.7205\n",
      "Epoch 2103: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7850 - accuracy: 0.7205 - val_loss: 1.6104 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Epoch 2104/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8083 - accuracy: 0.7146\n",
      "Epoch 2104: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8083 - accuracy: 0.7146 - val_loss: 1.6036 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2105/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7489 - accuracy: 0.7363\n",
      "Epoch 2105: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7489 - accuracy: 0.7363 - val_loss: 1.5972 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2106/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.7217\n",
      "Epoch 2106: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.7835 - accuracy: 0.7217 - val_loss: 1.5835 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2107/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7283 - accuracy: 0.7441\n",
      "Epoch 2107: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.7283 - accuracy: 0.7441 - val_loss: 1.5705 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2108/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7390 - accuracy: 0.7252\n",
      "Epoch 2108: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7390 - accuracy: 0.7252 - val_loss: 1.5480 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2109/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7737 - accuracy: 0.7295\n",
      "Epoch 2109: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7737 - accuracy: 0.7295 - val_loss: 1.5337 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2110/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7810 - accuracy: 0.7246\n",
      "Epoch 2110: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7810 - accuracy: 0.7246 - val_loss: 1.5296 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2111/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8095 - accuracy: 0.6981\n",
      "Epoch 2111: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8095 - accuracy: 0.6981 - val_loss: 1.5290 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2112/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7294 - accuracy: 0.7417\n",
      "Epoch 2112: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7294 - accuracy: 0.7417 - val_loss: 1.5361 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2113/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7343 - accuracy: 0.7500\n",
      "Epoch 2113: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.7343 - accuracy: 0.7500 - val_loss: 1.5341 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2114/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7775 - accuracy: 0.7252\n",
      "Epoch 2114: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.7775 - accuracy: 0.7252 - val_loss: 1.5322 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2115/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.7300\n",
      "Epoch 2115: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.7387 - accuracy: 0.7300 - val_loss: 1.5303 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2116/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.7146\n",
      "Epoch 2116: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8042 - accuracy: 0.7146 - val_loss: 1.5416 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2117/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7747 - accuracy: 0.7252\n",
      "Epoch 2117: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.7747 - accuracy: 0.7252 - val_loss: 1.5409 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2118/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7682 - accuracy: 0.7193\n",
      "Epoch 2118: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.7682 - accuracy: 0.7193 - val_loss: 1.5310 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2119/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7656 - accuracy: 0.7252\n",
      "Epoch 2119: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7656 - accuracy: 0.7252 - val_loss: 1.5223 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2120/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7332 - accuracy: 0.7453\n",
      "Epoch 2120: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7332 - accuracy: 0.7453 - val_loss: 1.5231 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2121/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7583 - accuracy: 0.7275\n",
      "Epoch 2121: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7583 - accuracy: 0.7275 - val_loss: 1.5249 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2122/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7853 - accuracy: 0.7229\n",
      "Epoch 2122: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7853 - accuracy: 0.7229 - val_loss: 1.5355 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2123/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7493 - accuracy: 0.7382\n",
      "Epoch 2123: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7493 - accuracy: 0.7382 - val_loss: 1.5452 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2124/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.7594\n",
      "Epoch 2124: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7213 - accuracy: 0.7594 - val_loss: 1.5431 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2125/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7553 - accuracy: 0.7344\n",
      "Epoch 2125: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.7553 - accuracy: 0.7344 - val_loss: 1.5438 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2126/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7531 - accuracy: 0.7300\n",
      "Epoch 2126: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7531 - accuracy: 0.7300 - val_loss: 1.5438 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2127/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8056 - accuracy: 0.7182\n",
      "Epoch 2127: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8056 - accuracy: 0.7182 - val_loss: 1.5537 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2128/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7451 - accuracy: 0.7288\n",
      "Epoch 2128: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7451 - accuracy: 0.7288 - val_loss: 1.5759 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2129/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7954 - accuracy: 0.6958\n",
      "Epoch 2129: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7954 - accuracy: 0.6958 - val_loss: 1.5804 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2130/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7144 - accuracy: 0.7476\n",
      "Epoch 2130: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7144 - accuracy: 0.7476 - val_loss: 1.5836 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2131/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7956 - accuracy: 0.7087\n",
      "Epoch 2131: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7956 - accuracy: 0.7087 - val_loss: 1.5795 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2132/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7837 - accuracy: 0.7158\n",
      "Epoch 2132: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.7837 - accuracy: 0.7158 - val_loss: 1.5814 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2133/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.7028\n",
      "Epoch 2133: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.7879 - accuracy: 0.7028 - val_loss: 1.5808 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2134/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7488 - accuracy: 0.7406\n",
      "Epoch 2134: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.7488 - accuracy: 0.7406 - val_loss: 1.5832 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2135/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7681 - accuracy: 0.7382\n",
      "Epoch 2135: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7681 - accuracy: 0.7382 - val_loss: 1.6064 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2136/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7481 - accuracy: 0.7335\n",
      "Epoch 2136: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7481 - accuracy: 0.7335 - val_loss: 1.6185 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2137/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7120 - accuracy: 0.7547\n",
      "Epoch 2137: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.7120 - accuracy: 0.7547 - val_loss: 1.6305 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2138/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7850 - accuracy: 0.7080\n",
      "Epoch 2138: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.7850 - accuracy: 0.7080 - val_loss: 1.6318 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2139/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7320 - accuracy: 0.7417\n",
      "Epoch 2139: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7320 - accuracy: 0.7417 - val_loss: 1.6268 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2140/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7634 - accuracy: 0.7252\n",
      "Epoch 2140: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7634 - accuracy: 0.7252 - val_loss: 1.6169 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2141/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7140 - accuracy: 0.7583\n",
      "Epoch 2141: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.7140 - accuracy: 0.7583 - val_loss: 1.6163 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2142/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7429 - accuracy: 0.7500\n",
      "Epoch 2142: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7429 - accuracy: 0.7500 - val_loss: 1.6161 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2143/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8192 - accuracy: 0.7123\n",
      "Epoch 2143: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8192 - accuracy: 0.7123 - val_loss: 1.6306 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2144/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7526 - accuracy: 0.7288\n",
      "Epoch 2144: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.7526 - accuracy: 0.7288 - val_loss: 1.6486 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 2145/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7705 - accuracy: 0.7358\n",
      "Epoch 2145: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7705 - accuracy: 0.7358 - val_loss: 1.6709 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 2146/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7918 - accuracy: 0.7178\n",
      "Epoch 2146: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7918 - accuracy: 0.7178 - val_loss: 1.6795 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 2147/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.7412\n",
      "Epoch 2147: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.7542 - accuracy: 0.7412 - val_loss: 1.6829 - val_accuracy: 0.4874 - lr: 1.0000e-05\n",
      "Epoch 2148/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7658 - accuracy: 0.7347\n",
      "Epoch 2148: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.7658 - accuracy: 0.7347 - val_loss: 1.6738 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 2149/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7936 - accuracy: 0.7182\n",
      "Epoch 2149: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7936 - accuracy: 0.7182 - val_loss: 1.6487 - val_accuracy: 0.4838 - lr: 1.0000e-05\n",
      "Epoch 2150/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7690 - accuracy: 0.7429\n",
      "Epoch 2150: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7690 - accuracy: 0.7429 - val_loss: 1.6223 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2151/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7612 - accuracy: 0.7358\n",
      "Epoch 2151: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7612 - accuracy: 0.7358 - val_loss: 1.5995 - val_accuracy: 0.4946 - lr: 1.0000e-05\n",
      "Epoch 2152/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7432 - accuracy: 0.7335\n",
      "Epoch 2152: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7432 - accuracy: 0.7335 - val_loss: 1.5793 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2153/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7594 - accuracy: 0.7323\n",
      "Epoch 2153: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.7594 - accuracy: 0.7323 - val_loss: 1.5695 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2154/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7731 - accuracy: 0.7300\n",
      "Epoch 2154: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7731 - accuracy: 0.7300 - val_loss: 1.5640 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2155/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7762 - accuracy: 0.7229\n",
      "Epoch 2155: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7762 - accuracy: 0.7229 - val_loss: 1.5426 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2156/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7406\n",
      "Epoch 2156: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7646 - accuracy: 0.7406 - val_loss: 1.5291 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2157/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7349 - accuracy: 0.7429\n",
      "Epoch 2157: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.7349 - accuracy: 0.7429 - val_loss: 1.5345 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2158/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7511 - accuracy: 0.7347\n",
      "Epoch 2158: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7511 - accuracy: 0.7347 - val_loss: 1.5397 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2159/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7512 - accuracy: 0.7205\n",
      "Epoch 2159: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7512 - accuracy: 0.7205 - val_loss: 1.5446 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2160/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7661 - accuracy: 0.7288\n",
      "Epoch 2160: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7661 - accuracy: 0.7288 - val_loss: 1.5430 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2161/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7352 - accuracy: 0.7323\n",
      "Epoch 2161: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7352 - accuracy: 0.7323 - val_loss: 1.5338 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2162/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7597 - accuracy: 0.7382\n",
      "Epoch 2162: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7597 - accuracy: 0.7382 - val_loss: 1.5211 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2163/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7170\n",
      "Epoch 2163: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7646 - accuracy: 0.7170 - val_loss: 1.5094 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2164/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7504 - accuracy: 0.7441\n",
      "Epoch 2164: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.7504 - accuracy: 0.7441 - val_loss: 1.5101 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2165/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7756 - accuracy: 0.7288\n",
      "Epoch 2165: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.7756 - accuracy: 0.7288 - val_loss: 1.5207 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2166/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7351 - accuracy: 0.7334\n",
      "Epoch 2166: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.7351 - accuracy: 0.7334 - val_loss: 1.5426 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2167/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7757 - accuracy: 0.7193\n",
      "Epoch 2167: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7757 - accuracy: 0.7193 - val_loss: 1.5522 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2168/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7755 - accuracy: 0.7229\n",
      "Epoch 2168: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7755 - accuracy: 0.7229 - val_loss: 1.5617 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2169/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7496 - accuracy: 0.7382\n",
      "Epoch 2169: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7496 - accuracy: 0.7382 - val_loss: 1.5595 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2170/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7219 - accuracy: 0.7524\n",
      "Epoch 2170: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.7219 - accuracy: 0.7524 - val_loss: 1.5469 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2171/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7417 - accuracy: 0.7441\n",
      "Epoch 2171: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7417 - accuracy: 0.7441 - val_loss: 1.5380 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2172/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7739 - accuracy: 0.7417\n",
      "Epoch 2172: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.7739 - accuracy: 0.7417 - val_loss: 1.5295 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2173/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7429 - accuracy: 0.7453\n",
      "Epoch 2173: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.7429 - accuracy: 0.7453 - val_loss: 1.5290 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2174/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7265 - accuracy: 0.7535\n",
      "Epoch 2174: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7265 - accuracy: 0.7535 - val_loss: 1.5386 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2175/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7413 - accuracy: 0.7417\n",
      "Epoch 2175: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7413 - accuracy: 0.7417 - val_loss: 1.5389 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2176/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7551 - accuracy: 0.7300\n",
      "Epoch 2176: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7551 - accuracy: 0.7300 - val_loss: 1.5400 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2177/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7636 - accuracy: 0.7246\n",
      "Epoch 2177: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7636 - accuracy: 0.7246 - val_loss: 1.5501 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2178/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7864 - accuracy: 0.7075\n",
      "Epoch 2178: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7864 - accuracy: 0.7075 - val_loss: 1.5600 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2179/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7703 - accuracy: 0.7264\n",
      "Epoch 2179: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7703 - accuracy: 0.7264 - val_loss: 1.5739 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2180/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7326 - accuracy: 0.7382\n",
      "Epoch 2180: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7326 - accuracy: 0.7382 - val_loss: 1.5749 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2181/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7638 - accuracy: 0.7300\n",
      "Epoch 2181: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.7638 - accuracy: 0.7300 - val_loss: 1.5737 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2182/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7899 - accuracy: 0.7236\n",
      "Epoch 2182: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7899 - accuracy: 0.7236 - val_loss: 1.5722 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2183/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7206 - accuracy: 0.7488\n",
      "Epoch 2183: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.7206 - accuracy: 0.7488 - val_loss: 1.5756 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2184/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7423 - accuracy: 0.7382\n",
      "Epoch 2184: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7423 - accuracy: 0.7382 - val_loss: 1.5793 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2185/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7648 - accuracy: 0.7252\n",
      "Epoch 2185: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7648 - accuracy: 0.7252 - val_loss: 1.5902 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2186/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7536 - accuracy: 0.7451\n",
      "Epoch 2186: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.7536 - accuracy: 0.7451 - val_loss: 1.5946 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2187/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.7500\n",
      "Epoch 2187: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7381 - accuracy: 0.7500 - val_loss: 1.5906 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2188/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7545 - accuracy: 0.7347\n",
      "Epoch 2188: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.7545 - accuracy: 0.7347 - val_loss: 1.5858 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2189/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7924 - accuracy: 0.7087\n",
      "Epoch 2189: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7924 - accuracy: 0.7087 - val_loss: 1.5851 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2190/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7670 - accuracy: 0.7373\n",
      "Epoch 2190: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.7670 - accuracy: 0.7373 - val_loss: 1.5902 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2191/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7440 - accuracy: 0.7453\n",
      "Epoch 2191: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7440 - accuracy: 0.7453 - val_loss: 1.5854 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2192/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7697 - accuracy: 0.7324\n",
      "Epoch 2192: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.7697 - accuracy: 0.7324 - val_loss: 1.5698 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2193/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.7052\n",
      "Epoch 2193: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8042 - accuracy: 0.7052 - val_loss: 1.5640 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2194/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7589 - accuracy: 0.7288\n",
      "Epoch 2194: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.7589 - accuracy: 0.7288 - val_loss: 1.5616 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2195/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7923 - accuracy: 0.7229\n",
      "Epoch 2195: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.7923 - accuracy: 0.7229 - val_loss: 1.5462 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2196/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7780 - accuracy: 0.7276\n",
      "Epoch 2196: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.7780 - accuracy: 0.7276 - val_loss: 1.5272 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2197/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7332 - accuracy: 0.7583\n",
      "Epoch 2197: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.7332 - accuracy: 0.7583 - val_loss: 1.5027 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2198/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7462 - accuracy: 0.7193\n",
      "Epoch 2198: val_loss did not improve from 1.47603\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7462 - accuracy: 0.7193 - val_loss: 1.4816 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2199/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7518 - accuracy: 0.7394\n",
      "Epoch 2199: val_loss improved from 1.47603 to 1.47566, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7518 - accuracy: 0.7394 - val_loss: 1.4757 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2200/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7447 - accuracy: 0.7441\n",
      "Epoch 2200: val_loss improved from 1.47566 to 1.46992, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7447 - accuracy: 0.7441 - val_loss: 1.4699 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2201/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.7373\n",
      "Epoch 2201: val_loss improved from 1.46992 to 1.46367, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7514 - accuracy: 0.7373 - val_loss: 1.4637 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2202/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7396 - accuracy: 0.7358\n",
      "Epoch 2202: val_loss improved from 1.46367 to 1.45595, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7396 - accuracy: 0.7358 - val_loss: 1.4559 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2203/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7487 - accuracy: 0.7300\n",
      "Epoch 2203: val_loss improved from 1.45595 to 1.45039, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7487 - accuracy: 0.7300 - val_loss: 1.4504 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2204/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7650 - accuracy: 0.7300\n",
      "Epoch 2204: val_loss improved from 1.45039 to 1.44496, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7650 - accuracy: 0.7300 - val_loss: 1.4450 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2205/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7404 - accuracy: 0.7393\n",
      "Epoch 2205: val_loss improved from 1.44496 to 1.43898, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7404 - accuracy: 0.7393 - val_loss: 1.4390 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2206/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7409 - accuracy: 0.7394\n",
      "Epoch 2206: val_loss improved from 1.43898 to 1.43794, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7409 - accuracy: 0.7394 - val_loss: 1.4379 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2207/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7418 - accuracy: 0.7429\n",
      "Epoch 2207: val_loss improved from 1.43794 to 1.43365, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7418 - accuracy: 0.7429 - val_loss: 1.4337 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2208/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7243 - accuracy: 0.7535\n",
      "Epoch 2208: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7243 - accuracy: 0.7535 - val_loss: 1.4406 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2209/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7372 - accuracy: 0.7465\n",
      "Epoch 2209: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7372 - accuracy: 0.7465 - val_loss: 1.4557 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2210/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7769 - accuracy: 0.7358\n",
      "Epoch 2210: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7769 - accuracy: 0.7358 - val_loss: 1.4760 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2211/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7310 - accuracy: 0.7370\n",
      "Epoch 2211: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.7310 - accuracy: 0.7370 - val_loss: 1.5029 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2212/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7653 - accuracy: 0.7040\n",
      "Epoch 2212: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7653 - accuracy: 0.7040 - val_loss: 1.5173 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2213/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7540 - accuracy: 0.7182\n",
      "Epoch 2213: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7540 - accuracy: 0.7182 - val_loss: 1.5294 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2214/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7747 - accuracy: 0.7241\n",
      "Epoch 2214: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.7747 - accuracy: 0.7241 - val_loss: 1.5341 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2215/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7593 - accuracy: 0.7347\n",
      "Epoch 2215: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7593 - accuracy: 0.7347 - val_loss: 1.5438 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2216/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7194 - accuracy: 0.7524\n",
      "Epoch 2216: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.7194 - accuracy: 0.7524 - val_loss: 1.5523 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2217/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7417 - accuracy: 0.7347\n",
      "Epoch 2217: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7417 - accuracy: 0.7347 - val_loss: 1.5518 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2218/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7627 - accuracy: 0.7363\n",
      "Epoch 2218: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7627 - accuracy: 0.7363 - val_loss: 1.5409 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2219/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7304 - accuracy: 0.7335\n",
      "Epoch 2219: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.7304 - accuracy: 0.7335 - val_loss: 1.5335 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2220/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7484 - accuracy: 0.7461\n",
      "Epoch 2220: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7484 - accuracy: 0.7461 - val_loss: 1.5329 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2221/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7217 - accuracy: 0.7571\n",
      "Epoch 2221: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7217 - accuracy: 0.7571 - val_loss: 1.5280 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2222/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7578 - accuracy: 0.7264\n",
      "Epoch 2222: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.7578 - accuracy: 0.7264 - val_loss: 1.5283 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2223/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7372 - accuracy: 0.7406\n",
      "Epoch 2223: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7372 - accuracy: 0.7406 - val_loss: 1.5393 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2224/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7327 - accuracy: 0.7236\n",
      "Epoch 2224: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.7327 - accuracy: 0.7236 - val_loss: 1.5474 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2225/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7631 - accuracy: 0.7111\n",
      "Epoch 2225: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7631 - accuracy: 0.7111 - val_loss: 1.5476 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2226/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7848 - accuracy: 0.7276\n",
      "Epoch 2226: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7848 - accuracy: 0.7276 - val_loss: 1.5497 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2227/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7695 - accuracy: 0.7241\n",
      "Epoch 2227: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.7695 - accuracy: 0.7241 - val_loss: 1.5644 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2228/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7629 - accuracy: 0.7288\n",
      "Epoch 2228: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7629 - accuracy: 0.7288 - val_loss: 1.5771 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2229/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7844 - accuracy: 0.7241\n",
      "Epoch 2229: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.7844 - accuracy: 0.7241 - val_loss: 1.5780 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2230/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.7205\n",
      "Epoch 2230: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7622 - accuracy: 0.7205 - val_loss: 1.5695 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2231/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.7429\n",
      "Epoch 2231: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7218 - accuracy: 0.7429 - val_loss: 1.5666 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2232/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7429 - accuracy: 0.7323\n",
      "Epoch 2232: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7429 - accuracy: 0.7323 - val_loss: 1.5776 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2233/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7671 - accuracy: 0.7323\n",
      "Epoch 2233: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.7671 - accuracy: 0.7323 - val_loss: 1.6000 - val_accuracy: 0.5018 - lr: 1.0000e-05\n",
      "Epoch 2234/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7564 - accuracy: 0.7417\n",
      "Epoch 2234: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7564 - accuracy: 0.7417 - val_loss: 1.6134 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2235/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.7417\n",
      "Epoch 2235: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7279 - accuracy: 0.7417 - val_loss: 1.6013 - val_accuracy: 0.4982 - lr: 1.0000e-05\n",
      "Epoch 2236/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7628 - accuracy: 0.7323\n",
      "Epoch 2236: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7628 - accuracy: 0.7323 - val_loss: 1.6000 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2237/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7334\n",
      "Epoch 2237: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7646 - accuracy: 0.7334 - val_loss: 1.5996 - val_accuracy: 0.5054 - lr: 1.0000e-05\n",
      "Epoch 2238/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.7383\n",
      "Epoch 2238: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7460 - accuracy: 0.7383 - val_loss: 1.5940 - val_accuracy: 0.5090 - lr: 1.0000e-05\n",
      "Epoch 2239/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7990 - accuracy: 0.7252\n",
      "Epoch 2239: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.7990 - accuracy: 0.7252 - val_loss: 1.5712 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2240/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7513 - accuracy: 0.7354\n",
      "Epoch 2240: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7513 - accuracy: 0.7354 - val_loss: 1.5531 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2241/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7702 - accuracy: 0.7217\n",
      "Epoch 2241: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7702 - accuracy: 0.7217 - val_loss: 1.5362 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2242/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7424 - accuracy: 0.7252\n",
      "Epoch 2242: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7424 - accuracy: 0.7252 - val_loss: 1.5210 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2243/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7491 - accuracy: 0.7241\n",
      "Epoch 2243: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7491 - accuracy: 0.7241 - val_loss: 1.5189 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2244/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.7347\n",
      "Epoch 2244: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7246 - accuracy: 0.7347 - val_loss: 1.5119 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2245/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7678 - accuracy: 0.7417\n",
      "Epoch 2245: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7678 - accuracy: 0.7417 - val_loss: 1.5065 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2246/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7272 - accuracy: 0.7406\n",
      "Epoch 2246: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7272 - accuracy: 0.7406 - val_loss: 1.5108 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2247/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7887 - accuracy: 0.7168\n",
      "Epoch 2247: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.7887 - accuracy: 0.7168 - val_loss: 1.5132 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2248/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7096 - accuracy: 0.7559\n",
      "Epoch 2248: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7096 - accuracy: 0.7559 - val_loss: 1.5136 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2249/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7398 - accuracy: 0.7300\n",
      "Epoch 2249: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.7398 - accuracy: 0.7300 - val_loss: 1.5130 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2250/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7506 - accuracy: 0.7335\n",
      "Epoch 2250: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7506 - accuracy: 0.7335 - val_loss: 1.5029 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2251/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7416 - accuracy: 0.7382\n",
      "Epoch 2251: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7416 - accuracy: 0.7382 - val_loss: 1.4961 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2252/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7332 - accuracy: 0.7358\n",
      "Epoch 2252: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7332 - accuracy: 0.7358 - val_loss: 1.5053 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2253/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7482 - accuracy: 0.7422\n",
      "Epoch 2253: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7482 - accuracy: 0.7422 - val_loss: 1.5024 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2254/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.7429\n",
      "Epoch 2254: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7486 - accuracy: 0.7429 - val_loss: 1.5060 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2255/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7499 - accuracy: 0.7335\n",
      "Epoch 2255: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7499 - accuracy: 0.7335 - val_loss: 1.5144 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2256/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.7311\n",
      "Epoch 2256: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7605 - accuracy: 0.7311 - val_loss: 1.5204 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2257/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7242 - accuracy: 0.7594\n",
      "Epoch 2257: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7242 - accuracy: 0.7594 - val_loss: 1.5232 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2258/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7491 - accuracy: 0.7512\n",
      "Epoch 2258: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7491 - accuracy: 0.7512 - val_loss: 1.5234 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2259/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7336 - accuracy: 0.7429\n",
      "Epoch 2259: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7336 - accuracy: 0.7429 - val_loss: 1.5240 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2260/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7578 - accuracy: 0.7246\n",
      "Epoch 2260: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7578 - accuracy: 0.7246 - val_loss: 1.5229 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2261/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7338 - accuracy: 0.7363\n",
      "Epoch 2261: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7338 - accuracy: 0.7363 - val_loss: 1.5206 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2262/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7473 - accuracy: 0.7383\n",
      "Epoch 2262: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7473 - accuracy: 0.7383 - val_loss: 1.5209 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2263/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7602 - accuracy: 0.7276\n",
      "Epoch 2263: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7602 - accuracy: 0.7276 - val_loss: 1.5258 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2264/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7046 - accuracy: 0.7476\n",
      "Epoch 2264: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7046 - accuracy: 0.7476 - val_loss: 1.5217 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2265/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.7393\n",
      "Epoch 2265: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.7381 - accuracy: 0.7393 - val_loss: 1.5258 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2266/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7160 - accuracy: 0.7547\n",
      "Epoch 2266: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7160 - accuracy: 0.7547 - val_loss: 1.5361 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2267/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7599 - accuracy: 0.7300\n",
      "Epoch 2267: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7599 - accuracy: 0.7300 - val_loss: 1.5467 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2268/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7577 - accuracy: 0.7276\n",
      "Epoch 2268: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.7577 - accuracy: 0.7276 - val_loss: 1.5370 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2269/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7371 - accuracy: 0.7311\n",
      "Epoch 2269: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7371 - accuracy: 0.7311 - val_loss: 1.5301 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2270/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7666 - accuracy: 0.7323\n",
      "Epoch 2270: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7666 - accuracy: 0.7323 - val_loss: 1.5207 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2271/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.7665\n",
      "Epoch 2271: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6988 - accuracy: 0.7665 - val_loss: 1.5074 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2272/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7407 - accuracy: 0.7382\n",
      "Epoch 2272: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.7407 - accuracy: 0.7382 - val_loss: 1.4914 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2273/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7581 - accuracy: 0.7394\n",
      "Epoch 2273: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.7581 - accuracy: 0.7394 - val_loss: 1.4741 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2274/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.7406\n",
      "Epoch 2274: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7514 - accuracy: 0.7406 - val_loss: 1.4534 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2275/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.7170\n",
      "Epoch 2275: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.7375 - accuracy: 0.7170 - val_loss: 1.4371 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2276/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7734 - accuracy: 0.7134\n",
      "Epoch 2276: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7734 - accuracy: 0.7134 - val_loss: 1.4357 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2277/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7670 - accuracy: 0.7217\n",
      "Epoch 2277: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7670 - accuracy: 0.7217 - val_loss: 1.4424 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2278/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7377 - accuracy: 0.7382\n",
      "Epoch 2278: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7377 - accuracy: 0.7382 - val_loss: 1.4550 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2279/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7618 - accuracy: 0.7217\n",
      "Epoch 2279: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7618 - accuracy: 0.7217 - val_loss: 1.4497 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2280/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.7382\n",
      "Epoch 2280: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7226 - accuracy: 0.7382 - val_loss: 1.4506 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2281/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7410 - accuracy: 0.7276\n",
      "Epoch 2281: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7410 - accuracy: 0.7276 - val_loss: 1.4504 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2282/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7305 - accuracy: 0.7300\n",
      "Epoch 2282: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7305 - accuracy: 0.7300 - val_loss: 1.4551 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2283/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7392 - accuracy: 0.7193\n",
      "Epoch 2283: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7392 - accuracy: 0.7193 - val_loss: 1.4708 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2284/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7398 - accuracy: 0.7285\n",
      "Epoch 2284: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7398 - accuracy: 0.7285 - val_loss: 1.4844 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2285/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7403 - accuracy: 0.7335\n",
      "Epoch 2285: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7403 - accuracy: 0.7335 - val_loss: 1.5006 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2286/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7695 - accuracy: 0.7300\n",
      "Epoch 2286: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7695 - accuracy: 0.7300 - val_loss: 1.5151 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2287/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7356 - accuracy: 0.7476\n",
      "Epoch 2287: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7356 - accuracy: 0.7476 - val_loss: 1.5299 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2288/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.7370\n",
      "Epoch 2288: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7368 - accuracy: 0.7370 - val_loss: 1.5411 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2289/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7400 - accuracy: 0.7453\n",
      "Epoch 2289: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7400 - accuracy: 0.7453 - val_loss: 1.5478 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2290/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7199 - accuracy: 0.7512\n",
      "Epoch 2290: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7199 - accuracy: 0.7512 - val_loss: 1.5657 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2291/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7418 - accuracy: 0.7383\n",
      "Epoch 2291: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.7418 - accuracy: 0.7383 - val_loss: 1.5811 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2292/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7464 - accuracy: 0.7335\n",
      "Epoch 2292: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7464 - accuracy: 0.7335 - val_loss: 1.5908 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2293/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.7441\n",
      "Epoch 2293: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7078 - accuracy: 0.7441 - val_loss: 1.5922 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2294/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.7465\n",
      "Epoch 2294: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7307 - accuracy: 0.7465 - val_loss: 1.5839 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2295/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7454 - accuracy: 0.7358\n",
      "Epoch 2295: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7454 - accuracy: 0.7358 - val_loss: 1.5870 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2296/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7272 - accuracy: 0.7453\n",
      "Epoch 2296: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7272 - accuracy: 0.7453 - val_loss: 1.5714 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2297/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.7535\n",
      "Epoch 2297: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7169 - accuracy: 0.7535 - val_loss: 1.5611 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2298/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.7571\n",
      "Epoch 2298: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7342 - accuracy: 0.7571 - val_loss: 1.5511 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2299/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7350 - accuracy: 0.7311\n",
      "Epoch 2299: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7350 - accuracy: 0.7311 - val_loss: 1.5459 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2300/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7454 - accuracy: 0.7412\n",
      "Epoch 2300: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.7454 - accuracy: 0.7412 - val_loss: 1.5371 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2301/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.7370\n",
      "Epoch 2301: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7525 - accuracy: 0.7370 - val_loss: 1.5314 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2302/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7396 - accuracy: 0.7335\n",
      "Epoch 2302: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.7396 - accuracy: 0.7335 - val_loss: 1.5213 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2303/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.7441\n",
      "Epoch 2303: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7031 - accuracy: 0.7441 - val_loss: 1.5174 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2304/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6810 - accuracy: 0.7382\n",
      "Epoch 2304: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.6810 - accuracy: 0.7382 - val_loss: 1.5232 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2305/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7753 - accuracy: 0.7205\n",
      "Epoch 2305: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7753 - accuracy: 0.7205 - val_loss: 1.5276 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2306/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7487 - accuracy: 0.7311\n",
      "Epoch 2306: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7487 - accuracy: 0.7311 - val_loss: 1.5327 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2307/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7980 - accuracy: 0.7217\n",
      "Epoch 2307: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7980 - accuracy: 0.7217 - val_loss: 1.5347 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2308/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.7441\n",
      "Epoch 2308: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7052 - accuracy: 0.7441 - val_loss: 1.5336 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2309/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7439 - accuracy: 0.7358\n",
      "Epoch 2309: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.7439 - accuracy: 0.7358 - val_loss: 1.5311 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2310/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7401 - accuracy: 0.7394\n",
      "Epoch 2310: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7401 - accuracy: 0.7394 - val_loss: 1.5326 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2311/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.7335\n",
      "Epoch 2311: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7082 - accuracy: 0.7335 - val_loss: 1.5450 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2312/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7427 - accuracy: 0.7394\n",
      "Epoch 2312: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7427 - accuracy: 0.7394 - val_loss: 1.5622 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2313/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7577 - accuracy: 0.7288\n",
      "Epoch 2313: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7577 - accuracy: 0.7288 - val_loss: 1.5743 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2314/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7401 - accuracy: 0.7461\n",
      "Epoch 2314: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7401 - accuracy: 0.7461 - val_loss: 1.5804 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2315/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7663 - accuracy: 0.7323\n",
      "Epoch 2315: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7663 - accuracy: 0.7323 - val_loss: 1.5913 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2316/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7737 - accuracy: 0.7205\n",
      "Epoch 2316: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7737 - accuracy: 0.7205 - val_loss: 1.5803 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2317/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.7630\n",
      "Epoch 2317: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6936 - accuracy: 0.7630 - val_loss: 1.5519 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2318/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7576 - accuracy: 0.7241\n",
      "Epoch 2318: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7576 - accuracy: 0.7241 - val_loss: 1.5246 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2319/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7268 - accuracy: 0.7559\n",
      "Epoch 2319: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7268 - accuracy: 0.7559 - val_loss: 1.5050 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2320/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7494 - accuracy: 0.7432\n",
      "Epoch 2320: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7494 - accuracy: 0.7432 - val_loss: 1.4914 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2321/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7588 - accuracy: 0.7344\n",
      "Epoch 2321: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7588 - accuracy: 0.7344 - val_loss: 1.4830 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2322/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7445 - accuracy: 0.7363\n",
      "Epoch 2322: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7445 - accuracy: 0.7363 - val_loss: 1.4759 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2323/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7369 - accuracy: 0.7266\n",
      "Epoch 2323: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7369 - accuracy: 0.7266 - val_loss: 1.4702 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2324/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7337 - accuracy: 0.7417\n",
      "Epoch 2324: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7337 - accuracy: 0.7417 - val_loss: 1.4671 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2325/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7763 - accuracy: 0.7227\n",
      "Epoch 2325: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.7763 - accuracy: 0.7227 - val_loss: 1.4709 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2326/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.7524\n",
      "Epoch 2326: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7048 - accuracy: 0.7524 - val_loss: 1.4835 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2327/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7554 - accuracy: 0.7441\n",
      "Epoch 2327: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.7554 - accuracy: 0.7441 - val_loss: 1.4973 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2328/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7739 - accuracy: 0.7275\n",
      "Epoch 2328: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7739 - accuracy: 0.7275 - val_loss: 1.4999 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2329/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.7394\n",
      "Epoch 2329: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7105 - accuracy: 0.7394 - val_loss: 1.4983 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2330/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7136 - accuracy: 0.7429\n",
      "Epoch 2330: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7136 - accuracy: 0.7429 - val_loss: 1.4944 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2331/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7321 - accuracy: 0.7311\n",
      "Epoch 2331: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7321 - accuracy: 0.7311 - val_loss: 1.4903 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2332/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7712 - accuracy: 0.6981\n",
      "Epoch 2332: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7712 - accuracy: 0.6981 - val_loss: 1.4858 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2333/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7420 - accuracy: 0.7406\n",
      "Epoch 2333: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7420 - accuracy: 0.7406 - val_loss: 1.4769 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2334/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7124 - accuracy: 0.7402\n",
      "Epoch 2334: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.7124 - accuracy: 0.7402 - val_loss: 1.4770 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2335/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.7344\n",
      "Epoch 2335: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.7542 - accuracy: 0.7344 - val_loss: 1.4887 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2336/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7391 - accuracy: 0.7529\n",
      "Epoch 2336: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7391 - accuracy: 0.7529 - val_loss: 1.5008 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2337/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7541 - accuracy: 0.7300\n",
      "Epoch 2337: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7541 - accuracy: 0.7300 - val_loss: 1.5091 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2338/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7321 - accuracy: 0.7382\n",
      "Epoch 2338: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7321 - accuracy: 0.7382 - val_loss: 1.5078 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2339/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7210 - accuracy: 0.7524\n",
      "Epoch 2339: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7210 - accuracy: 0.7524 - val_loss: 1.5013 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2340/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7749 - accuracy: 0.7264\n",
      "Epoch 2340: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7749 - accuracy: 0.7264 - val_loss: 1.4876 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2341/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7327 - accuracy: 0.7335\n",
      "Epoch 2341: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7327 - accuracy: 0.7335 - val_loss: 1.4647 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2342/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7536 - accuracy: 0.7323\n",
      "Epoch 2342: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.7536 - accuracy: 0.7323 - val_loss: 1.4484 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2343/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7324 - accuracy: 0.7311\n",
      "Epoch 2343: val_loss did not improve from 1.43365\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7324 - accuracy: 0.7311 - val_loss: 1.4379 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2344/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.7288\n",
      "Epoch 2344: val_loss improved from 1.43365 to 1.43207, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7622 - accuracy: 0.7288 - val_loss: 1.4321 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2345/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7427 - accuracy: 0.7417\n",
      "Epoch 2345: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7427 - accuracy: 0.7417 - val_loss: 1.4370 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2346/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7444 - accuracy: 0.7465\n",
      "Epoch 2346: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7444 - accuracy: 0.7465 - val_loss: 1.4518 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2347/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7294 - accuracy: 0.7441\n",
      "Epoch 2347: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7294 - accuracy: 0.7441 - val_loss: 1.4540 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2348/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7225 - accuracy: 0.7476\n",
      "Epoch 2348: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7225 - accuracy: 0.7476 - val_loss: 1.4592 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2349/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7129 - accuracy: 0.7461\n",
      "Epoch 2349: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7129 - accuracy: 0.7461 - val_loss: 1.4626 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2350/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7311 - accuracy: 0.7382\n",
      "Epoch 2350: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7311 - accuracy: 0.7382 - val_loss: 1.4599 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2351/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7393 - accuracy: 0.7441\n",
      "Epoch 2351: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7393 - accuracy: 0.7441 - val_loss: 1.4538 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2352/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7285 - accuracy: 0.7241\n",
      "Epoch 2352: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7285 - accuracy: 0.7241 - val_loss: 1.4471 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2353/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7210 - accuracy: 0.7583\n",
      "Epoch 2353: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.7210 - accuracy: 0.7583 - val_loss: 1.4485 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2354/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7372 - accuracy: 0.7524\n",
      "Epoch 2354: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7372 - accuracy: 0.7524 - val_loss: 1.4496 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2355/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7021 - accuracy: 0.7512\n",
      "Epoch 2355: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7021 - accuracy: 0.7512 - val_loss: 1.4488 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2356/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7467 - accuracy: 0.7394\n",
      "Epoch 2356: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7467 - accuracy: 0.7394 - val_loss: 1.4484 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2357/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7251 - accuracy: 0.7490\n",
      "Epoch 2357: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.7251 - accuracy: 0.7490 - val_loss: 1.4504 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2358/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7049 - accuracy: 0.7630\n",
      "Epoch 2358: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7049 - accuracy: 0.7630 - val_loss: 1.4624 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2359/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.7465\n",
      "Epoch 2359: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7302 - accuracy: 0.7465 - val_loss: 1.4860 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2360/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7297 - accuracy: 0.7347\n",
      "Epoch 2360: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7297 - accuracy: 0.7347 - val_loss: 1.5019 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2361/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.7393\n",
      "Epoch 2361: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7218 - accuracy: 0.7393 - val_loss: 1.5147 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2362/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7423 - accuracy: 0.7288\n",
      "Epoch 2362: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7423 - accuracy: 0.7288 - val_loss: 1.5270 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2363/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7606 - accuracy: 0.7323\n",
      "Epoch 2363: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7606 - accuracy: 0.7323 - val_loss: 1.5374 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2364/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.7394\n",
      "Epoch 2364: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7137 - accuracy: 0.7394 - val_loss: 1.5499 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2365/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7384 - accuracy: 0.7393\n",
      "Epoch 2365: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7384 - accuracy: 0.7393 - val_loss: 1.5640 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2366/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7258 - accuracy: 0.7370\n",
      "Epoch 2366: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7258 - accuracy: 0.7370 - val_loss: 1.5608 - val_accuracy: 0.5126 - lr: 1.0000e-05\n",
      "Epoch 2367/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7420 - accuracy: 0.7382\n",
      "Epoch 2367: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.7420 - accuracy: 0.7382 - val_loss: 1.5506 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2368/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7560 - accuracy: 0.7217\n",
      "Epoch 2368: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7560 - accuracy: 0.7217 - val_loss: 1.5379 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2369/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7388 - accuracy: 0.7335\n",
      "Epoch 2369: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7388 - accuracy: 0.7335 - val_loss: 1.5296 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2370/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7687 - accuracy: 0.7288\n",
      "Epoch 2370: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7687 - accuracy: 0.7288 - val_loss: 1.5261 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2371/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7328 - accuracy: 0.7500\n",
      "Epoch 2371: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7328 - accuracy: 0.7500 - val_loss: 1.5273 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2372/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7018 - accuracy: 0.7512\n",
      "Epoch 2372: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7018 - accuracy: 0.7512 - val_loss: 1.5350 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2373/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7708 - accuracy: 0.7305\n",
      "Epoch 2373: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7708 - accuracy: 0.7305 - val_loss: 1.5366 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2374/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.7488\n",
      "Epoch 2374: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7428 - accuracy: 0.7488 - val_loss: 1.5360 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2375/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7861 - accuracy: 0.7146\n",
      "Epoch 2375: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7861 - accuracy: 0.7146 - val_loss: 1.5259 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2376/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7455 - accuracy: 0.7441\n",
      "Epoch 2376: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7455 - accuracy: 0.7441 - val_loss: 1.5068 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2377/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.7429\n",
      "Epoch 2377: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7288 - accuracy: 0.7429 - val_loss: 1.4933 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2378/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7821 - accuracy: 0.7182\n",
      "Epoch 2378: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.7821 - accuracy: 0.7182 - val_loss: 1.4822 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2379/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.7363\n",
      "Epoch 2379: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.7448 - accuracy: 0.7363 - val_loss: 1.4705 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2380/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.7500\n",
      "Epoch 2380: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6992 - accuracy: 0.7500 - val_loss: 1.4645 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2381/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7449 - accuracy: 0.7205\n",
      "Epoch 2381: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.7449 - accuracy: 0.7205 - val_loss: 1.4586 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2382/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7418 - accuracy: 0.7453\n",
      "Epoch 2382: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7418 - accuracy: 0.7453 - val_loss: 1.4442 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2383/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7412 - accuracy: 0.7500\n",
      "Epoch 2383: val_loss did not improve from 1.43207\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.7412 - accuracy: 0.7500 - val_loss: 1.4327 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2384/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.7393\n",
      "Epoch 2384: val_loss improved from 1.43207 to 1.42150, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7357 - accuracy: 0.7393 - val_loss: 1.4215 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2385/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.7630\n",
      "Epoch 2385: val_loss improved from 1.42150 to 1.41353, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.6849 - accuracy: 0.7630 - val_loss: 1.4135 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2386/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7579 - accuracy: 0.7441\n",
      "Epoch 2386: val_loss improved from 1.41353 to 1.41069, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7579 - accuracy: 0.7441 - val_loss: 1.4107 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2387/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7136 - accuracy: 0.7394\n",
      "Epoch 2387: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7136 - accuracy: 0.7394 - val_loss: 1.4114 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2388/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.7182\n",
      "Epoch 2388: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7779 - accuracy: 0.7182 - val_loss: 1.4155 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2389/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.7347\n",
      "Epoch 2389: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.7584 - accuracy: 0.7347 - val_loss: 1.4210 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2390/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7049 - accuracy: 0.7382\n",
      "Epoch 2390: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7049 - accuracy: 0.7382 - val_loss: 1.4196 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2391/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7404 - accuracy: 0.7394\n",
      "Epoch 2391: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7404 - accuracy: 0.7394 - val_loss: 1.4304 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2392/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7269 - accuracy: 0.7370\n",
      "Epoch 2392: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7269 - accuracy: 0.7370 - val_loss: 1.4480 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2393/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.7323\n",
      "Epoch 2393: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7232 - accuracy: 0.7323 - val_loss: 1.4646 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2394/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7406 - accuracy: 0.7370\n",
      "Epoch 2394: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7406 - accuracy: 0.7370 - val_loss: 1.4661 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2395/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7151 - accuracy: 0.7422\n",
      "Epoch 2395: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7151 - accuracy: 0.7422 - val_loss: 1.4669 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2396/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6797 - accuracy: 0.7618\n",
      "Epoch 2396: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.6797 - accuracy: 0.7618 - val_loss: 1.4598 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2397/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7259 - accuracy: 0.7394\n",
      "Epoch 2397: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7259 - accuracy: 0.7394 - val_loss: 1.4577 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2398/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7103 - accuracy: 0.7618\n",
      "Epoch 2398: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7103 - accuracy: 0.7618 - val_loss: 1.4611 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2399/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7440 - accuracy: 0.7417\n",
      "Epoch 2399: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7440 - accuracy: 0.7417 - val_loss: 1.4739 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2400/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7155 - accuracy: 0.7618\n",
      "Epoch 2400: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7155 - accuracy: 0.7618 - val_loss: 1.4849 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2401/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7671 - accuracy: 0.7123\n",
      "Epoch 2401: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.7671 - accuracy: 0.7123 - val_loss: 1.4893 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2402/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.7370\n",
      "Epoch 2402: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7323 - accuracy: 0.7370 - val_loss: 1.4901 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2403/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7174 - accuracy: 0.7347\n",
      "Epoch 2403: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.7174 - accuracy: 0.7347 - val_loss: 1.5109 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2404/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7147 - accuracy: 0.7441\n",
      "Epoch 2404: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7147 - accuracy: 0.7441 - val_loss: 1.5209 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2405/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7296 - accuracy: 0.7335\n",
      "Epoch 2405: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7296 - accuracy: 0.7335 - val_loss: 1.5403 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2406/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.7500\n",
      "Epoch 2406: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.7307 - accuracy: 0.7500 - val_loss: 1.5544 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2407/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7398 - accuracy: 0.7471\n",
      "Epoch 2407: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7398 - accuracy: 0.7471 - val_loss: 1.5533 - val_accuracy: 0.5162 - lr: 1.0000e-05\n",
      "Epoch 2408/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.7335\n",
      "Epoch 2408: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7335 - accuracy: 0.7335 - val_loss: 1.5471 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2409/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6685 - accuracy: 0.7606\n",
      "Epoch 2409: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6685 - accuracy: 0.7606 - val_loss: 1.5377 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2410/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7466 - accuracy: 0.7406\n",
      "Epoch 2410: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.7466 - accuracy: 0.7406 - val_loss: 1.5203 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2411/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7225 - accuracy: 0.7285\n",
      "Epoch 2411: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7225 - accuracy: 0.7285 - val_loss: 1.5032 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2412/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.7264\n",
      "Epoch 2412: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7342 - accuracy: 0.7264 - val_loss: 1.4953 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2413/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7189 - accuracy: 0.7453\n",
      "Epoch 2413: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7189 - accuracy: 0.7453 - val_loss: 1.4827 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2414/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7283 - accuracy: 0.7465\n",
      "Epoch 2414: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7283 - accuracy: 0.7465 - val_loss: 1.4817 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2415/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.7323\n",
      "Epoch 2415: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7245 - accuracy: 0.7323 - val_loss: 1.4693 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2416/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7186 - accuracy: 0.7571\n",
      "Epoch 2416: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7186 - accuracy: 0.7571 - val_loss: 1.4569 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2417/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7420 - accuracy: 0.7417\n",
      "Epoch 2417: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.7420 - accuracy: 0.7417 - val_loss: 1.4539 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2418/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7513 - accuracy: 0.7370\n",
      "Epoch 2418: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7513 - accuracy: 0.7370 - val_loss: 1.4449 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2419/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7289 - accuracy: 0.7500\n",
      "Epoch 2419: val_loss did not improve from 1.41069\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7289 - accuracy: 0.7500 - val_loss: 1.4170 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2420/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7243 - accuracy: 0.7441\n",
      "Epoch 2420: val_loss improved from 1.41069 to 1.39366, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7243 - accuracy: 0.7441 - val_loss: 1.3937 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2421/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7253 - accuracy: 0.7394\n",
      "Epoch 2421: val_loss improved from 1.39366 to 1.38367, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.7253 - accuracy: 0.7394 - val_loss: 1.3837 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2422/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.7524\n",
      "Epoch 2422: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7175 - accuracy: 0.7524 - val_loss: 1.3842 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2423/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7314 - accuracy: 0.7417\n",
      "Epoch 2423: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7314 - accuracy: 0.7417 - val_loss: 1.3952 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2424/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7361 - accuracy: 0.7441\n",
      "Epoch 2424: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7361 - accuracy: 0.7441 - val_loss: 1.4026 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2425/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7202 - accuracy: 0.7453\n",
      "Epoch 2425: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7202 - accuracy: 0.7453 - val_loss: 1.4189 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2426/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7178 - accuracy: 0.7568\n",
      "Epoch 2426: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.7178 - accuracy: 0.7568 - val_loss: 1.4274 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2427/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7329 - accuracy: 0.7512\n",
      "Epoch 2427: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7329 - accuracy: 0.7512 - val_loss: 1.4293 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2428/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7461 - accuracy: 0.7441\n",
      "Epoch 2428: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7461 - accuracy: 0.7441 - val_loss: 1.4236 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2429/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7214 - accuracy: 0.7453\n",
      "Epoch 2429: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7214 - accuracy: 0.7453 - val_loss: 1.4097 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2430/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7380 - accuracy: 0.7412\n",
      "Epoch 2430: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7380 - accuracy: 0.7412 - val_loss: 1.4031 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2431/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7491 - accuracy: 0.7358\n",
      "Epoch 2431: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7491 - accuracy: 0.7358 - val_loss: 1.3989 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2432/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.7453\n",
      "Epoch 2432: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7216 - accuracy: 0.7453 - val_loss: 1.4005 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2433/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7434 - accuracy: 0.7252\n",
      "Epoch 2433: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7434 - accuracy: 0.7252 - val_loss: 1.4036 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2434/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7507 - accuracy: 0.7453\n",
      "Epoch 2434: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7507 - accuracy: 0.7453 - val_loss: 1.4207 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2435/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7183 - accuracy: 0.7295\n",
      "Epoch 2435: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.7183 - accuracy: 0.7295 - val_loss: 1.4339 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2436/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.7559\n",
      "Epoch 2436: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7044 - accuracy: 0.7559 - val_loss: 1.4380 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2437/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7196 - accuracy: 0.7461\n",
      "Epoch 2437: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7196 - accuracy: 0.7461 - val_loss: 1.4385 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2438/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7512\n",
      "Epoch 2438: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.7395 - accuracy: 0.7512 - val_loss: 1.4343 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2439/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7157 - accuracy: 0.7471\n",
      "Epoch 2439: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7157 - accuracy: 0.7471 - val_loss: 1.4398 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2440/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.7594\n",
      "Epoch 2440: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.7064 - accuracy: 0.7594 - val_loss: 1.4454 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2441/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7628 - accuracy: 0.7300\n",
      "Epoch 2441: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7628 - accuracy: 0.7300 - val_loss: 1.4425 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2442/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7586 - accuracy: 0.7323\n",
      "Epoch 2442: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.7586 - accuracy: 0.7323 - val_loss: 1.4362 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2443/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7223 - accuracy: 0.7370\n",
      "Epoch 2443: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7223 - accuracy: 0.7370 - val_loss: 1.4469 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2444/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7151 - accuracy: 0.7323\n",
      "Epoch 2444: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7151 - accuracy: 0.7323 - val_loss: 1.4642 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2445/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7260 - accuracy: 0.7422\n",
      "Epoch 2445: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7260 - accuracy: 0.7422 - val_loss: 1.4759 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2446/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7336 - accuracy: 0.7373\n",
      "Epoch 2446: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7336 - accuracy: 0.7373 - val_loss: 1.4850 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2447/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7321 - accuracy: 0.7370\n",
      "Epoch 2447: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7321 - accuracy: 0.7370 - val_loss: 1.5019 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2448/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.7453\n",
      "Epoch 2448: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.7335 - accuracy: 0.7453 - val_loss: 1.5127 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2449/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.7335\n",
      "Epoch 2449: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.7319 - accuracy: 0.7335 - val_loss: 1.5186 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2450/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7123 - accuracy: 0.7559\n",
      "Epoch 2450: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7123 - accuracy: 0.7559 - val_loss: 1.5188 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2451/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.7535\n",
      "Epoch 2451: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6901 - accuracy: 0.7535 - val_loss: 1.5232 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2452/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.7441\n",
      "Epoch 2452: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7203 - accuracy: 0.7441 - val_loss: 1.5201 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2453/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7328 - accuracy: 0.7358\n",
      "Epoch 2453: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7328 - accuracy: 0.7358 - val_loss: 1.5104 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2454/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7349 - accuracy: 0.7335\n",
      "Epoch 2454: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7349 - accuracy: 0.7335 - val_loss: 1.4937 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2455/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7103 - accuracy: 0.7370\n",
      "Epoch 2455: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7103 - accuracy: 0.7370 - val_loss: 1.4779 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2456/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7477 - accuracy: 0.7402\n",
      "Epoch 2456: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7477 - accuracy: 0.7402 - val_loss: 1.4686 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2457/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7157 - accuracy: 0.7406\n",
      "Epoch 2457: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7157 - accuracy: 0.7406 - val_loss: 1.4774 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2458/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7138 - accuracy: 0.7370\n",
      "Epoch 2458: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7138 - accuracy: 0.7370 - val_loss: 1.4867 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2459/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7484 - accuracy: 0.7276\n",
      "Epoch 2459: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7484 - accuracy: 0.7276 - val_loss: 1.4931 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2460/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7172 - accuracy: 0.7583\n",
      "Epoch 2460: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7172 - accuracy: 0.7583 - val_loss: 1.5002 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2461/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7345 - accuracy: 0.7358\n",
      "Epoch 2461: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7345 - accuracy: 0.7358 - val_loss: 1.4987 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2462/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.7453\n",
      "Epoch 2462: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.7125 - accuracy: 0.7453 - val_loss: 1.4999 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2463/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.7736\n",
      "Epoch 2463: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6952 - accuracy: 0.7736 - val_loss: 1.5147 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2464/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7429 - accuracy: 0.7229\n",
      "Epoch 2464: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7429 - accuracy: 0.7229 - val_loss: 1.5373 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2465/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.7700\n",
      "Epoch 2465: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6902 - accuracy: 0.7700 - val_loss: 1.5438 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2466/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.7422\n",
      "Epoch 2466: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.7279 - accuracy: 0.7422 - val_loss: 1.5399 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2467/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7146 - accuracy: 0.7406\n",
      "Epoch 2467: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.7146 - accuracy: 0.7406 - val_loss: 1.5405 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2468/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.7422\n",
      "Epoch 2468: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.7216 - accuracy: 0.7422 - val_loss: 1.5326 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2469/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.7500\n",
      "Epoch 2469: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.6997 - accuracy: 0.7500 - val_loss: 1.5259 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2470/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7447 - accuracy: 0.7335\n",
      "Epoch 2470: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.7447 - accuracy: 0.7335 - val_loss: 1.5144 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2471/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7249 - accuracy: 0.7432\n",
      "Epoch 2471: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7249 - accuracy: 0.7432 - val_loss: 1.4979 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2472/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.7571\n",
      "Epoch 2472: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6868 - accuracy: 0.7571 - val_loss: 1.4785 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2473/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.7441\n",
      "Epoch 2473: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7052 - accuracy: 0.7441 - val_loss: 1.4606 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2474/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6785 - accuracy: 0.7689\n",
      "Epoch 2474: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6785 - accuracy: 0.7689 - val_loss: 1.4466 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2475/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6984 - accuracy: 0.7618\n",
      "Epoch 2475: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6984 - accuracy: 0.7618 - val_loss: 1.4322 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2476/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.7524\n",
      "Epoch 2476: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6970 - accuracy: 0.7524 - val_loss: 1.4137 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2477/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.7500\n",
      "Epoch 2477: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6979 - accuracy: 0.7500 - val_loss: 1.4071 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2478/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7093 - accuracy: 0.7335\n",
      "Epoch 2478: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7093 - accuracy: 0.7335 - val_loss: 1.4119 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2479/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.7465\n",
      "Epoch 2479: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.7006 - accuracy: 0.7465 - val_loss: 1.4148 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2480/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.7617\n",
      "Epoch 2480: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.7014 - accuracy: 0.7617 - val_loss: 1.4211 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2481/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7290 - accuracy: 0.7394\n",
      "Epoch 2481: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7290 - accuracy: 0.7394 - val_loss: 1.4166 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2482/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.7520\n",
      "Epoch 2482: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.6995 - accuracy: 0.7520 - val_loss: 1.4133 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2483/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.7335\n",
      "Epoch 2483: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7280 - accuracy: 0.7335 - val_loss: 1.4105 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2484/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7005 - accuracy: 0.7695\n",
      "Epoch 2484: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7005 - accuracy: 0.7695 - val_loss: 1.4099 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2485/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.7370\n",
      "Epoch 2485: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7438 - accuracy: 0.7370 - val_loss: 1.4146 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2486/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.7700\n",
      "Epoch 2486: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6970 - accuracy: 0.7700 - val_loss: 1.4109 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2487/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6867 - accuracy: 0.7535\n",
      "Epoch 2487: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6867 - accuracy: 0.7535 - val_loss: 1.4055 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2488/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7070 - accuracy: 0.7524\n",
      "Epoch 2488: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.7070 - accuracy: 0.7524 - val_loss: 1.4002 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2489/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6984 - accuracy: 0.7512\n",
      "Epoch 2489: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6984 - accuracy: 0.7512 - val_loss: 1.3928 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2490/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.7490\n",
      "Epoch 2490: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7232 - accuracy: 0.7490 - val_loss: 1.3912 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2491/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7431 - accuracy: 0.7394\n",
      "Epoch 2491: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7431 - accuracy: 0.7394 - val_loss: 1.3975 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2492/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.7394\n",
      "Epoch 2492: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7397 - accuracy: 0.7394 - val_loss: 1.4080 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2493/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7080 - accuracy: 0.7512\n",
      "Epoch 2493: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7080 - accuracy: 0.7512 - val_loss: 1.4073 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2494/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7372 - accuracy: 0.7441\n",
      "Epoch 2494: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.7372 - accuracy: 0.7441 - val_loss: 1.4095 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2495/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7112 - accuracy: 0.7547\n",
      "Epoch 2495: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.7112 - accuracy: 0.7547 - val_loss: 1.4090 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2496/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7166 - accuracy: 0.7535\n",
      "Epoch 2496: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7166 - accuracy: 0.7535 - val_loss: 1.4141 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2497/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7162 - accuracy: 0.7406\n",
      "Epoch 2497: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7162 - accuracy: 0.7406 - val_loss: 1.4291 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2498/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.7559\n",
      "Epoch 2498: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.6746 - accuracy: 0.7559 - val_loss: 1.4403 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2499/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7161 - accuracy: 0.7490\n",
      "Epoch 2499: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.7161 - accuracy: 0.7490 - val_loss: 1.4526 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2500/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.7429\n",
      "Epoch 2500: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.7087 - accuracy: 0.7429 - val_loss: 1.4578 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2501/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.7406\n",
      "Epoch 2501: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.7105 - accuracy: 0.7406 - val_loss: 1.4572 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2502/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6835 - accuracy: 0.7618\n",
      "Epoch 2502: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6835 - accuracy: 0.7618 - val_loss: 1.4598 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2503/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7455 - accuracy: 0.7300\n",
      "Epoch 2503: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7455 - accuracy: 0.7300 - val_loss: 1.4696 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2504/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.7524\n",
      "Epoch 2504: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6828 - accuracy: 0.7524 - val_loss: 1.4676 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2505/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6715 - accuracy: 0.7677\n",
      "Epoch 2505: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.6715 - accuracy: 0.7677 - val_loss: 1.4554 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2506/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.7653\n",
      "Epoch 2506: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6803 - accuracy: 0.7653 - val_loss: 1.4432 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2507/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.7594\n",
      "Epoch 2507: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6780 - accuracy: 0.7594 - val_loss: 1.4270 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2508/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7257 - accuracy: 0.7373\n",
      "Epoch 2508: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.7257 - accuracy: 0.7373 - val_loss: 1.4240 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2509/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.7266\n",
      "Epoch 2509: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.7233 - accuracy: 0.7266 - val_loss: 1.4257 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2510/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.7646\n",
      "Epoch 2510: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6860 - accuracy: 0.7646 - val_loss: 1.4289 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2511/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.7490\n",
      "Epoch 2511: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7060 - accuracy: 0.7490 - val_loss: 1.4333 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2512/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7212 - accuracy: 0.7500\n",
      "Epoch 2512: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.7212 - accuracy: 0.7500 - val_loss: 1.4417 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2513/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7575 - accuracy: 0.7241\n",
      "Epoch 2513: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.7575 - accuracy: 0.7241 - val_loss: 1.4605 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2514/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7166 - accuracy: 0.7490\n",
      "Epoch 2514: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.7166 - accuracy: 0.7490 - val_loss: 1.4741 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2515/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.7571\n",
      "Epoch 2515: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6972 - accuracy: 0.7571 - val_loss: 1.4787 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2516/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7205 - accuracy: 0.7594\n",
      "Epoch 2516: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.7205 - accuracy: 0.7594 - val_loss: 1.4895 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2517/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7896 - accuracy: 0.7099\n",
      "Epoch 2517: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7896 - accuracy: 0.7099 - val_loss: 1.4898 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2518/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7159 - accuracy: 0.7700\n",
      "Epoch 2518: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7159 - accuracy: 0.7700 - val_loss: 1.4925 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2519/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.7524\n",
      "Epoch 2519: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6995 - accuracy: 0.7524 - val_loss: 1.4994 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2520/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.7583\n",
      "Epoch 2520: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6910 - accuracy: 0.7583 - val_loss: 1.5105 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
      "Epoch 2521/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7159 - accuracy: 0.7406\n",
      "Epoch 2521: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7159 - accuracy: 0.7406 - val_loss: 1.5303 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2522/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.7465\n",
      "Epoch 2522: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7233 - accuracy: 0.7465 - val_loss: 1.5284 - val_accuracy: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 2523/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.7461\n",
      "Epoch 2523: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6930 - accuracy: 0.7461 - val_loss: 1.5119 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2524/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.7488\n",
      "Epoch 2524: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6836 - accuracy: 0.7488 - val_loss: 1.4886 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2525/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.7700\n",
      "Epoch 2525: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7024 - accuracy: 0.7700 - val_loss: 1.4608 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2526/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7208 - accuracy: 0.7300\n",
      "Epoch 2526: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7208 - accuracy: 0.7300 - val_loss: 1.4392 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2527/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.7476\n",
      "Epoch 2527: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7031 - accuracy: 0.7476 - val_loss: 1.4352 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2528/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7343 - accuracy: 0.7432\n",
      "Epoch 2528: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7343 - accuracy: 0.7432 - val_loss: 1.4393 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2529/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.7488\n",
      "Epoch 2529: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7105 - accuracy: 0.7488 - val_loss: 1.4427 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2530/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.7705\n",
      "Epoch 2530: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6869 - accuracy: 0.7705 - val_loss: 1.4439 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2531/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.7676\n",
      "Epoch 2531: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6928 - accuracy: 0.7676 - val_loss: 1.4459 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2532/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7068 - accuracy: 0.7594\n",
      "Epoch 2532: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.7068 - accuracy: 0.7594 - val_loss: 1.4361 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2533/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7356 - accuracy: 0.7512\n",
      "Epoch 2533: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7356 - accuracy: 0.7512 - val_loss: 1.4451 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2534/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.7453\n",
      "Epoch 2534: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6942 - accuracy: 0.7453 - val_loss: 1.4463 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2535/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.7524\n",
      "Epoch 2535: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.7175 - accuracy: 0.7524 - val_loss: 1.4376 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2536/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.7335\n",
      "Epoch 2536: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7231 - accuracy: 0.7335 - val_loss: 1.4341 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2537/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7277 - accuracy: 0.7451\n",
      "Epoch 2537: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.7277 - accuracy: 0.7451 - val_loss: 1.4224 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2538/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6785 - accuracy: 0.7656\n",
      "Epoch 2538: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6785 - accuracy: 0.7656 - val_loss: 1.4185 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2539/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7239 - accuracy: 0.7441\n",
      "Epoch 2539: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.7239 - accuracy: 0.7441 - val_loss: 1.4255 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2540/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.7547\n",
      "Epoch 2540: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7023 - accuracy: 0.7547 - val_loss: 1.4390 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2541/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.7529\n",
      "Epoch 2541: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6907 - accuracy: 0.7529 - val_loss: 1.4452 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2542/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.7594\n",
      "Epoch 2542: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6932 - accuracy: 0.7594 - val_loss: 1.4386 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2543/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.7618\n",
      "Epoch 2543: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6992 - accuracy: 0.7618 - val_loss: 1.4347 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2544/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.7358\n",
      "Epoch 2544: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7020 - accuracy: 0.7358 - val_loss: 1.4280 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2545/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7283 - accuracy: 0.7488\n",
      "Epoch 2545: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7283 - accuracy: 0.7488 - val_loss: 1.4273 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2546/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7217 - accuracy: 0.7311\n",
      "Epoch 2546: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7217 - accuracy: 0.7311 - val_loss: 1.4188 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2547/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7127 - accuracy: 0.7441\n",
      "Epoch 2547: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.7127 - accuracy: 0.7441 - val_loss: 1.4217 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2548/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.7488\n",
      "Epoch 2548: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6808 - accuracy: 0.7488 - val_loss: 1.4128 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2549/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7090 - accuracy: 0.7559\n",
      "Epoch 2549: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.7090 - accuracy: 0.7559 - val_loss: 1.4095 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2550/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6659 - accuracy: 0.7734\n",
      "Epoch 2550: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6659 - accuracy: 0.7734 - val_loss: 1.4025 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2551/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7107 - accuracy: 0.7429\n",
      "Epoch 2551: val_loss did not improve from 1.38367\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7107 - accuracy: 0.7429 - val_loss: 1.3914 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2552/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.7559\n",
      "Epoch 2552: val_loss improved from 1.38367 to 1.38036, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6975 - accuracy: 0.7559 - val_loss: 1.3804 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2553/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.7324\n",
      "Epoch 2553: val_loss improved from 1.38036 to 1.37451, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.7203 - accuracy: 0.7324 - val_loss: 1.3745 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2554/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.7607\n",
      "Epoch 2554: val_loss improved from 1.37451 to 1.36763, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.6828 - accuracy: 0.7607 - val_loss: 1.3676 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2555/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.7512\n",
      "Epoch 2555: val_loss improved from 1.36763 to 1.35944, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7060 - accuracy: 0.7512 - val_loss: 1.3594 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2556/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.7311\n",
      "Epoch 2556: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6800 - accuracy: 0.7311 - val_loss: 1.3604 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2557/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.7618\n",
      "Epoch 2557: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6912 - accuracy: 0.7618 - val_loss: 1.3625 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2558/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7108 - accuracy: 0.7323\n",
      "Epoch 2558: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.7108 - accuracy: 0.7323 - val_loss: 1.3694 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2559/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7201 - accuracy: 0.7323\n",
      "Epoch 2559: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7201 - accuracy: 0.7323 - val_loss: 1.3797 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2560/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7151 - accuracy: 0.7441\n",
      "Epoch 2560: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.7151 - accuracy: 0.7441 - val_loss: 1.3886 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2561/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7228 - accuracy: 0.7465\n",
      "Epoch 2561: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7228 - accuracy: 0.7465 - val_loss: 1.3965 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2562/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7427 - accuracy: 0.7276\n",
      "Epoch 2562: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7427 - accuracy: 0.7276 - val_loss: 1.4141 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2563/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7116 - accuracy: 0.7417\n",
      "Epoch 2563: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7116 - accuracy: 0.7417 - val_loss: 1.4263 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2564/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.7512\n",
      "Epoch 2564: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6931 - accuracy: 0.7512 - val_loss: 1.4363 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2565/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7010 - accuracy: 0.7300\n",
      "Epoch 2565: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7010 - accuracy: 0.7300 - val_loss: 1.4413 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2566/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7404 - accuracy: 0.7370\n",
      "Epoch 2566: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7404 - accuracy: 0.7370 - val_loss: 1.4401 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2567/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.7559\n",
      "Epoch 2567: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6817 - accuracy: 0.7559 - val_loss: 1.4424 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2568/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7303 - accuracy: 0.7412\n",
      "Epoch 2568: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.7303 - accuracy: 0.7412 - val_loss: 1.4415 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2569/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7055 - accuracy: 0.7453\n",
      "Epoch 2569: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7055 - accuracy: 0.7453 - val_loss: 1.4463 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2570/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.7666\n",
      "Epoch 2570: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6922 - accuracy: 0.7666 - val_loss: 1.4505 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2571/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7037 - accuracy: 0.7535\n",
      "Epoch 2571: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.7037 - accuracy: 0.7535 - val_loss: 1.4532 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2572/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.7432\n",
      "Epoch 2572: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7218 - accuracy: 0.7432 - val_loss: 1.4441 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2573/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6976 - accuracy: 0.7559\n",
      "Epoch 2573: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6976 - accuracy: 0.7559 - val_loss: 1.4401 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2574/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7250 - accuracy: 0.7394\n",
      "Epoch 2574: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7250 - accuracy: 0.7394 - val_loss: 1.4317 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2575/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7095 - accuracy: 0.7653\n",
      "Epoch 2575: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.7095 - accuracy: 0.7653 - val_loss: 1.4221 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2576/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.7583\n",
      "Epoch 2576: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6787 - accuracy: 0.7583 - val_loss: 1.4159 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2577/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7061 - accuracy: 0.7451\n",
      "Epoch 2577: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7061 - accuracy: 0.7451 - val_loss: 1.4188 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2578/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.7617\n",
      "Epoch 2578: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.6783 - accuracy: 0.7617 - val_loss: 1.4225 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2579/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7351 - accuracy: 0.7382\n",
      "Epoch 2579: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7351 - accuracy: 0.7382 - val_loss: 1.4280 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2580/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.7748\n",
      "Epoch 2580: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6575 - accuracy: 0.7748 - val_loss: 1.4372 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2581/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.7476\n",
      "Epoch 2581: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6978 - accuracy: 0.7476 - val_loss: 1.4518 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2582/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.7676\n",
      "Epoch 2582: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6852 - accuracy: 0.7676 - val_loss: 1.4680 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2583/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7046 - accuracy: 0.7547\n",
      "Epoch 2583: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.7046 - accuracy: 0.7547 - val_loss: 1.4798 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2584/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7379 - accuracy: 0.7323\n",
      "Epoch 2584: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7379 - accuracy: 0.7323 - val_loss: 1.4871 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2585/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7077 - accuracy: 0.7347\n",
      "Epoch 2585: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7077 - accuracy: 0.7347 - val_loss: 1.4954 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2586/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.7520\n",
      "Epoch 2586: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7050 - accuracy: 0.7520 - val_loss: 1.4995 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2587/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.7736\n",
      "Epoch 2587: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6919 - accuracy: 0.7736 - val_loss: 1.4944 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2588/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7191 - accuracy: 0.7394\n",
      "Epoch 2588: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7191 - accuracy: 0.7394 - val_loss: 1.4919 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2589/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7228 - accuracy: 0.7500\n",
      "Epoch 2589: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.7228 - accuracy: 0.7500 - val_loss: 1.4894 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2590/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6966 - accuracy: 0.7547\n",
      "Epoch 2590: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6966 - accuracy: 0.7547 - val_loss: 1.4881 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2591/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.7677\n",
      "Epoch 2591: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6614 - accuracy: 0.7677 - val_loss: 1.4931 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2592/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.7642\n",
      "Epoch 2592: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6783 - accuracy: 0.7642 - val_loss: 1.4904 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2593/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.7642\n",
      "Epoch 2593: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6699 - accuracy: 0.7642 - val_loss: 1.4882 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2594/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.7547\n",
      "Epoch 2594: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7182 - accuracy: 0.7547 - val_loss: 1.4755 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2595/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7117 - accuracy: 0.7524\n",
      "Epoch 2595: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7117 - accuracy: 0.7524 - val_loss: 1.4570 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2596/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.7583\n",
      "Epoch 2596: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6830 - accuracy: 0.7583 - val_loss: 1.4443 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2597/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.7547\n",
      "Epoch 2597: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6858 - accuracy: 0.7547 - val_loss: 1.4351 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2598/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.7465\n",
      "Epoch 2598: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6841 - accuracy: 0.7465 - val_loss: 1.4209 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2599/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.7480\n",
      "Epoch 2599: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6938 - accuracy: 0.7480 - val_loss: 1.4067 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2600/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7042 - accuracy: 0.7642\n",
      "Epoch 2600: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.7042 - accuracy: 0.7642 - val_loss: 1.4033 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2601/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.7476\n",
      "Epoch 2601: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7082 - accuracy: 0.7476 - val_loss: 1.4006 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2602/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7341 - accuracy: 0.7354\n",
      "Epoch 2602: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.7341 - accuracy: 0.7354 - val_loss: 1.4011 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2603/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7126 - accuracy: 0.7402\n",
      "Epoch 2603: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.7126 - accuracy: 0.7402 - val_loss: 1.4113 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2604/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.7512\n",
      "Epoch 2604: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6972 - accuracy: 0.7512 - val_loss: 1.4257 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2605/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.7618\n",
      "Epoch 2605: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.6608 - accuracy: 0.7618 - val_loss: 1.4459 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2606/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.7642\n",
      "Epoch 2606: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.6925 - accuracy: 0.7642 - val_loss: 1.4672 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2607/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7199 - accuracy: 0.7432\n",
      "Epoch 2607: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.7199 - accuracy: 0.7432 - val_loss: 1.4711 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2608/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.7500\n",
      "Epoch 2608: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6951 - accuracy: 0.7500 - val_loss: 1.4795 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2609/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7385 - accuracy: 0.7471\n",
      "Epoch 2609: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.7385 - accuracy: 0.7471 - val_loss: 1.4850 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2610/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.7488\n",
      "Epoch 2610: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6997 - accuracy: 0.7488 - val_loss: 1.4932 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2611/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7074 - accuracy: 0.7429\n",
      "Epoch 2611: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7074 - accuracy: 0.7429 - val_loss: 1.5021 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2612/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7328 - accuracy: 0.7382\n",
      "Epoch 2612: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7328 - accuracy: 0.7382 - val_loss: 1.5072 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2613/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.7358\n",
      "Epoch 2613: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.7153 - accuracy: 0.7358 - val_loss: 1.5047 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2614/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7103 - accuracy: 0.7429\n",
      "Epoch 2614: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7103 - accuracy: 0.7429 - val_loss: 1.5015 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2615/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.7451\n",
      "Epoch 2615: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7135 - accuracy: 0.7451 - val_loss: 1.4927 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2616/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.7383\n",
      "Epoch 2616: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7125 - accuracy: 0.7383 - val_loss: 1.4865 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2617/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.7535\n",
      "Epoch 2617: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6612 - accuracy: 0.7535 - val_loss: 1.4774 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2618/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.7500\n",
      "Epoch 2618: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7357 - accuracy: 0.7500 - val_loss: 1.4880 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2619/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7311 - accuracy: 0.7500\n",
      "Epoch 2619: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7311 - accuracy: 0.7500 - val_loss: 1.5019 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2620/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.7606\n",
      "Epoch 2620: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6642 - accuracy: 0.7606 - val_loss: 1.5069 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2621/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.7724\n",
      "Epoch 2621: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6893 - accuracy: 0.7724 - val_loss: 1.5054 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2622/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7070 - accuracy: 0.7512\n",
      "Epoch 2622: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7070 - accuracy: 0.7512 - val_loss: 1.4976 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2623/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.7594\n",
      "Epoch 2623: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6826 - accuracy: 0.7594 - val_loss: 1.4926 - val_accuracy: 0.5271 - lr: 1.0000e-05\n",
      "Epoch 2624/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7128 - accuracy: 0.7471\n",
      "Epoch 2624: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.7128 - accuracy: 0.7471 - val_loss: 1.4783 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2625/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.7453\n",
      "Epoch 2625: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6878 - accuracy: 0.7453 - val_loss: 1.4741 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2626/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.7547\n",
      "Epoch 2626: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6996 - accuracy: 0.7547 - val_loss: 1.4716 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2627/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7035 - accuracy: 0.7535\n",
      "Epoch 2627: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7035 - accuracy: 0.7535 - val_loss: 1.4791 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2628/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7084 - accuracy: 0.7417\n",
      "Epoch 2628: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.7084 - accuracy: 0.7417 - val_loss: 1.4902 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2629/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.7677\n",
      "Epoch 2629: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6494 - accuracy: 0.7677 - val_loss: 1.4902 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2630/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.7510\n",
      "Epoch 2630: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6894 - accuracy: 0.7510 - val_loss: 1.4843 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2631/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.7547\n",
      "Epoch 2631: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6903 - accuracy: 0.7547 - val_loss: 1.4732 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2632/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6747 - accuracy: 0.7795\n",
      "Epoch 2632: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6747 - accuracy: 0.7795 - val_loss: 1.4668 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2633/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6839 - accuracy: 0.7524\n",
      "Epoch 2633: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6839 - accuracy: 0.7524 - val_loss: 1.4716 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2634/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7223 - accuracy: 0.7547\n",
      "Epoch 2634: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7223 - accuracy: 0.7547 - val_loss: 1.4732 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2635/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.7559\n",
      "Epoch 2635: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6660 - accuracy: 0.7559 - val_loss: 1.4734 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2636/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.7547\n",
      "Epoch 2636: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6868 - accuracy: 0.7547 - val_loss: 1.4692 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2637/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.7323\n",
      "Epoch 2637: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7169 - accuracy: 0.7323 - val_loss: 1.4547 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2638/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6814 - accuracy: 0.7524\n",
      "Epoch 2638: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6814 - accuracy: 0.7524 - val_loss: 1.4464 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2639/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.7512\n",
      "Epoch 2639: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.6781 - accuracy: 0.7512 - val_loss: 1.4341 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2640/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7028 - accuracy: 0.7559\n",
      "Epoch 2640: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7028 - accuracy: 0.7559 - val_loss: 1.4184 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2641/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6806 - accuracy: 0.7630\n",
      "Epoch 2641: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6806 - accuracy: 0.7630 - val_loss: 1.4065 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2642/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.7578\n",
      "Epoch 2642: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.7052 - accuracy: 0.7578 - val_loss: 1.3956 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2643/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.7677\n",
      "Epoch 2643: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6869 - accuracy: 0.7677 - val_loss: 1.3898 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2644/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.7500\n",
      "Epoch 2644: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.7238 - accuracy: 0.7500 - val_loss: 1.3912 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2645/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7058 - accuracy: 0.7559\n",
      "Epoch 2645: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.7058 - accuracy: 0.7559 - val_loss: 1.3808 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2646/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6792 - accuracy: 0.7578\n",
      "Epoch 2646: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6792 - accuracy: 0.7578 - val_loss: 1.3774 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2647/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.7535\n",
      "Epoch 2647: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7072 - accuracy: 0.7535 - val_loss: 1.3814 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2648/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.7724\n",
      "Epoch 2648: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6799 - accuracy: 0.7724 - val_loss: 1.3814 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2649/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.7653\n",
      "Epoch 2649: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6801 - accuracy: 0.7653 - val_loss: 1.3831 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2650/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.7417\n",
      "Epoch 2650: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6912 - accuracy: 0.7417 - val_loss: 1.3815 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2651/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6987 - accuracy: 0.7500\n",
      "Epoch 2651: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6987 - accuracy: 0.7500 - val_loss: 1.3814 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2652/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.7665\n",
      "Epoch 2652: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.6552 - accuracy: 0.7665 - val_loss: 1.3773 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2653/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.7488\n",
      "Epoch 2653: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.7014 - accuracy: 0.7488 - val_loss: 1.3872 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2654/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.7606\n",
      "Epoch 2654: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6788 - accuracy: 0.7606 - val_loss: 1.3859 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2655/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.7594\n",
      "Epoch 2655: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6794 - accuracy: 0.7594 - val_loss: 1.3757 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2656/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7099 - accuracy: 0.7535\n",
      "Epoch 2656: val_loss did not improve from 1.35944\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7099 - accuracy: 0.7535 - val_loss: 1.3673 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2657/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.7594\n",
      "Epoch 2657: val_loss improved from 1.35944 to 1.35724, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6777 - accuracy: 0.7594 - val_loss: 1.3572 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2658/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7040 - accuracy: 0.7476\n",
      "Epoch 2658: val_loss improved from 1.35724 to 1.34577, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.7040 - accuracy: 0.7476 - val_loss: 1.3458 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2659/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.7524\n",
      "Epoch 2659: val_loss improved from 1.34577 to 1.34419, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6709 - accuracy: 0.7524 - val_loss: 1.3442 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2660/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.7700\n",
      "Epoch 2660: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6811 - accuracy: 0.7700 - val_loss: 1.3486 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2661/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.7583\n",
      "Epoch 2661: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.6906 - accuracy: 0.7583 - val_loss: 1.3563 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2662/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7071 - accuracy: 0.7354\n",
      "Epoch 2662: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.7071 - accuracy: 0.7354 - val_loss: 1.3623 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2663/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6810 - accuracy: 0.7795\n",
      "Epoch 2663: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6810 - accuracy: 0.7795 - val_loss: 1.3763 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2664/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.7583\n",
      "Epoch 2664: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6781 - accuracy: 0.7583 - val_loss: 1.3786 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2665/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.7559\n",
      "Epoch 2665: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6894 - accuracy: 0.7559 - val_loss: 1.3856 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2666/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.7588\n",
      "Epoch 2666: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6831 - accuracy: 0.7588 - val_loss: 1.3912 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2667/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.7583\n",
      "Epoch 2667: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6811 - accuracy: 0.7583 - val_loss: 1.3926 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2668/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.7646\n",
      "Epoch 2668: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6767 - accuracy: 0.7646 - val_loss: 1.3930 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2669/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.7571\n",
      "Epoch 2669: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6939 - accuracy: 0.7571 - val_loss: 1.4083 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2670/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6822 - accuracy: 0.7594\n",
      "Epoch 2670: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6822 - accuracy: 0.7594 - val_loss: 1.4192 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2671/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.7646\n",
      "Epoch 2671: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6901 - accuracy: 0.7646 - val_loss: 1.4419 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2672/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.7653\n",
      "Epoch 2672: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6736 - accuracy: 0.7653 - val_loss: 1.4679 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2673/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7053 - accuracy: 0.7547\n",
      "Epoch 2673: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.7053 - accuracy: 0.7547 - val_loss: 1.4742 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2674/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7151 - accuracy: 0.7370\n",
      "Epoch 2674: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.7151 - accuracy: 0.7370 - val_loss: 1.4694 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2675/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.7476\n",
      "Epoch 2675: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6876 - accuracy: 0.7476 - val_loss: 1.4632 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2676/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6548 - accuracy: 0.7744\n",
      "Epoch 2676: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6548 - accuracy: 0.7744 - val_loss: 1.4732 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2677/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.7630\n",
      "Epoch 2677: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6850 - accuracy: 0.7630 - val_loss: 1.4846 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2678/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.7335\n",
      "Epoch 2678: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.7213 - accuracy: 0.7335 - val_loss: 1.4944 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2679/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7079 - accuracy: 0.7700\n",
      "Epoch 2679: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.7079 - accuracy: 0.7700 - val_loss: 1.5003 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2680/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.7480\n",
      "Epoch 2680: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.6996 - accuracy: 0.7480 - val_loss: 1.5017 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2681/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.7642\n",
      "Epoch 2681: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6882 - accuracy: 0.7642 - val_loss: 1.4945 - val_accuracy: 0.5343 - lr: 1.0000e-05\n",
      "Epoch 2682/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6619 - accuracy: 0.7588\n",
      "Epoch 2682: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.6619 - accuracy: 0.7588 - val_loss: 1.4741 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 2683/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6839 - accuracy: 0.7441\n",
      "Epoch 2683: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.6839 - accuracy: 0.7441 - val_loss: 1.4524 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2684/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.7559\n",
      "Epoch 2684: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6998 - accuracy: 0.7559 - val_loss: 1.4341 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2685/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.7677\n",
      "Epoch 2685: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6849 - accuracy: 0.7677 - val_loss: 1.4098 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2686/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7042 - accuracy: 0.7665\n",
      "Epoch 2686: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7042 - accuracy: 0.7665 - val_loss: 1.3853 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2687/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.7642\n",
      "Epoch 2687: val_loss did not improve from 1.34419\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6947 - accuracy: 0.7642 - val_loss: 1.3621 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2688/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.7535\n",
      "Epoch 2688: val_loss improved from 1.34419 to 1.34115, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6978 - accuracy: 0.7535 - val_loss: 1.3411 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2689/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.7406\n",
      "Epoch 2689: val_loss improved from 1.34115 to 1.32366, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.7142 - accuracy: 0.7406 - val_loss: 1.3237 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2690/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7080 - accuracy: 0.7406\n",
      "Epoch 2690: val_loss improved from 1.32366 to 1.31944, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.7080 - accuracy: 0.7406 - val_loss: 1.3194 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2691/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.7559\n",
      "Epoch 2691: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6903 - accuracy: 0.7559 - val_loss: 1.3224 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2692/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7235 - accuracy: 0.7370\n",
      "Epoch 2692: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7235 - accuracy: 0.7370 - val_loss: 1.3397 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2693/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6648 - accuracy: 0.7712\n",
      "Epoch 2693: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6648 - accuracy: 0.7712 - val_loss: 1.3579 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2694/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7074 - accuracy: 0.7394\n",
      "Epoch 2694: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.7074 - accuracy: 0.7394 - val_loss: 1.3696 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2695/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.7598\n",
      "Epoch 2695: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6652 - accuracy: 0.7598 - val_loss: 1.3773 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2696/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.7618\n",
      "Epoch 2696: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6740 - accuracy: 0.7618 - val_loss: 1.3960 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2697/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6859 - accuracy: 0.7500\n",
      "Epoch 2697: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.6859 - accuracy: 0.7500 - val_loss: 1.4091 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2698/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.7607\n",
      "Epoch 2698: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6843 - accuracy: 0.7607 - val_loss: 1.4195 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2699/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.7547\n",
      "Epoch 2699: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6896 - accuracy: 0.7547 - val_loss: 1.4369 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2700/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.7583\n",
      "Epoch 2700: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6979 - accuracy: 0.7583 - val_loss: 1.4404 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 2701/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.7689\n",
      "Epoch 2701: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6794 - accuracy: 0.7689 - val_loss: 1.4382 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2702/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6713 - accuracy: 0.7642\n",
      "Epoch 2702: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.6713 - accuracy: 0.7642 - val_loss: 1.4362 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2703/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7100 - accuracy: 0.7465\n",
      "Epoch 2703: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7100 - accuracy: 0.7465 - val_loss: 1.4370 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2704/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.7665\n",
      "Epoch 2704: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6773 - accuracy: 0.7665 - val_loss: 1.4399 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2705/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.7524\n",
      "Epoch 2705: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6823 - accuracy: 0.7524 - val_loss: 1.4405 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2706/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.7451\n",
      "Epoch 2706: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.7059 - accuracy: 0.7451 - val_loss: 1.4438 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2707/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.7347\n",
      "Epoch 2707: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.7405 - accuracy: 0.7347 - val_loss: 1.4437 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2708/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.7394\n",
      "Epoch 2708: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7176 - accuracy: 0.7394 - val_loss: 1.4376 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2709/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.7524\n",
      "Epoch 2709: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6642 - accuracy: 0.7524 - val_loss: 1.4248 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2710/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7559\n",
      "Epoch 2710: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6764 - accuracy: 0.7559 - val_loss: 1.4217 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2711/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.7588\n",
      "Epoch 2711: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.6625 - accuracy: 0.7588 - val_loss: 1.4184 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2712/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6544 - accuracy: 0.7677\n",
      "Epoch 2712: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6544 - accuracy: 0.7677 - val_loss: 1.4178 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2713/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6269 - accuracy: 0.7725\n",
      "Epoch 2713: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6269 - accuracy: 0.7725 - val_loss: 1.4182 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2714/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.7606\n",
      "Epoch 2714: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6701 - accuracy: 0.7606 - val_loss: 1.4125 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2715/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6663 - accuracy: 0.7568\n",
      "Epoch 2715: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6663 - accuracy: 0.7568 - val_loss: 1.4106 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2716/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6734 - accuracy: 0.7656\n",
      "Epoch 2716: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6734 - accuracy: 0.7656 - val_loss: 1.4134 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2717/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.7335\n",
      "Epoch 2717: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7170 - accuracy: 0.7335 - val_loss: 1.4139 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2718/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.7665\n",
      "Epoch 2718: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6837 - accuracy: 0.7665 - val_loss: 1.4083 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2719/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.7512\n",
      "Epoch 2719: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7060 - accuracy: 0.7512 - val_loss: 1.3992 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2720/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.7630\n",
      "Epoch 2720: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6579 - accuracy: 0.7630 - val_loss: 1.4030 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2721/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.7422\n",
      "Epoch 2721: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.6979 - accuracy: 0.7422 - val_loss: 1.4046 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2722/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.7630\n",
      "Epoch 2722: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6688 - accuracy: 0.7630 - val_loss: 1.4070 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2723/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7127 - accuracy: 0.7476\n",
      "Epoch 2723: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7127 - accuracy: 0.7476 - val_loss: 1.4041 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2724/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7239 - accuracy: 0.7394\n",
      "Epoch 2724: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.7239 - accuracy: 0.7394 - val_loss: 1.4058 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2725/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.7571\n",
      "Epoch 2725: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6883 - accuracy: 0.7571 - val_loss: 1.4077 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2726/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.7637\n",
      "Epoch 2726: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.6870 - accuracy: 0.7637 - val_loss: 1.3998 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2727/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7488\n",
      "Epoch 2727: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6923 - accuracy: 0.7488 - val_loss: 1.3893 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2728/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7748\n",
      "Epoch 2728: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6352 - accuracy: 0.7748 - val_loss: 1.3831 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2729/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.7453\n",
      "Epoch 2729: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6903 - accuracy: 0.7453 - val_loss: 1.3850 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2730/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7009 - accuracy: 0.7547\n",
      "Epoch 2730: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7009 - accuracy: 0.7547 - val_loss: 1.3812 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2731/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.7524\n",
      "Epoch 2731: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6942 - accuracy: 0.7524 - val_loss: 1.3736 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2732/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6966 - accuracy: 0.7476\n",
      "Epoch 2732: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6966 - accuracy: 0.7476 - val_loss: 1.3741 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2733/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6741 - accuracy: 0.7630\n",
      "Epoch 2733: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6741 - accuracy: 0.7630 - val_loss: 1.3734 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2734/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.7653\n",
      "Epoch 2734: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6808 - accuracy: 0.7653 - val_loss: 1.3840 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2735/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7795\n",
      "Epoch 2735: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6375 - accuracy: 0.7795 - val_loss: 1.3793 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2736/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6770 - accuracy: 0.7547\n",
      "Epoch 2736: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6770 - accuracy: 0.7547 - val_loss: 1.3855 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2737/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6819 - accuracy: 0.7347\n",
      "Epoch 2737: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6819 - accuracy: 0.7347 - val_loss: 1.3928 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2738/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.7606\n",
      "Epoch 2738: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6705 - accuracy: 0.7606 - val_loss: 1.4022 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2739/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.7677\n",
      "Epoch 2739: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6624 - accuracy: 0.7677 - val_loss: 1.4039 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2740/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.7465\n",
      "Epoch 2740: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6791 - accuracy: 0.7465 - val_loss: 1.3970 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2741/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6730 - accuracy: 0.7559\n",
      "Epoch 2741: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6730 - accuracy: 0.7559 - val_loss: 1.3821 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2742/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6534 - accuracy: 0.7653\n",
      "Epoch 2742: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6534 - accuracy: 0.7653 - val_loss: 1.3699 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2743/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7092 - accuracy: 0.7323\n",
      "Epoch 2743: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.7092 - accuracy: 0.7323 - val_loss: 1.3490 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2744/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.7358\n",
      "Epoch 2744: val_loss did not improve from 1.31944\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6883 - accuracy: 0.7358 - val_loss: 1.3268 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2745/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6664 - accuracy: 0.7771\n",
      "Epoch 2745: val_loss improved from 1.31944 to 1.31140, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6664 - accuracy: 0.7771 - val_loss: 1.3114 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2746/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6599 - accuracy: 0.7617\n",
      "Epoch 2746: val_loss improved from 1.31140 to 1.30709, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.6599 - accuracy: 0.7617 - val_loss: 1.3071 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2747/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.7830\n",
      "Epoch 2747: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.6331 - accuracy: 0.7830 - val_loss: 1.3077 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2748/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7112 - accuracy: 0.7441\n",
      "Epoch 2748: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7112 - accuracy: 0.7441 - val_loss: 1.3114 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2749/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6807 - accuracy: 0.7653\n",
      "Epoch 2749: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6807 - accuracy: 0.7653 - val_loss: 1.3116 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2750/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.7559\n",
      "Epoch 2750: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6796 - accuracy: 0.7559 - val_loss: 1.3166 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2751/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.7535\n",
      "Epoch 2751: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6705 - accuracy: 0.7535 - val_loss: 1.3286 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2752/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7092 - accuracy: 0.7347\n",
      "Epoch 2752: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7092 - accuracy: 0.7347 - val_loss: 1.3400 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2753/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6977 - accuracy: 0.7571\n",
      "Epoch 2753: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6977 - accuracy: 0.7571 - val_loss: 1.3533 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2754/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.7689\n",
      "Epoch 2754: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6360 - accuracy: 0.7689 - val_loss: 1.3633 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2755/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.7549\n",
      "Epoch 2755: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6799 - accuracy: 0.7549 - val_loss: 1.3649 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2756/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.7583\n",
      "Epoch 2756: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6800 - accuracy: 0.7583 - val_loss: 1.3847 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2757/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.7666\n",
      "Epoch 2757: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6643 - accuracy: 0.7666 - val_loss: 1.4066 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2758/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.7347\n",
      "Epoch 2758: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.6993 - accuracy: 0.7347 - val_loss: 1.4166 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2759/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.7665\n",
      "Epoch 2759: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 1.4225 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2760/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.7606\n",
      "Epoch 2760: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6774 - accuracy: 0.7606 - val_loss: 1.4307 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2761/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.7488\n",
      "Epoch 2761: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6978 - accuracy: 0.7488 - val_loss: 1.4333 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2762/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.7854\n",
      "Epoch 2762: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6343 - accuracy: 0.7854 - val_loss: 1.4320 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2763/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.7594\n",
      "Epoch 2763: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6860 - accuracy: 0.7594 - val_loss: 1.4379 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2764/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.7524\n",
      "Epoch 2764: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6878 - accuracy: 0.7524 - val_loss: 1.4468 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2765/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.7606\n",
      "Epoch 2765: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6957 - accuracy: 0.7606 - val_loss: 1.4509 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2766/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.7524\n",
      "Epoch 2766: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6841 - accuracy: 0.7524 - val_loss: 1.4459 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2767/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.7759\n",
      "Epoch 2767: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6300 - accuracy: 0.7759 - val_loss: 1.4384 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2768/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.7417\n",
      "Epoch 2768: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6945 - accuracy: 0.7417 - val_loss: 1.4281 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2769/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7017 - accuracy: 0.7535\n",
      "Epoch 2769: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.7017 - accuracy: 0.7535 - val_loss: 1.4203 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2770/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6785 - accuracy: 0.7618\n",
      "Epoch 2770: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6785 - accuracy: 0.7618 - val_loss: 1.4116 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2771/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.7571\n",
      "Epoch 2771: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6789 - accuracy: 0.7571 - val_loss: 1.4028 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2772/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.7422\n",
      "Epoch 2772: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6989 - accuracy: 0.7422 - val_loss: 1.4011 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2773/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6977 - accuracy: 0.7618\n",
      "Epoch 2773: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6977 - accuracy: 0.7618 - val_loss: 1.4136 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2774/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.7547\n",
      "Epoch 2774: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6808 - accuracy: 0.7547 - val_loss: 1.3999 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2775/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.7559\n",
      "Epoch 2775: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.6907 - accuracy: 0.7559 - val_loss: 1.3893 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2776/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.7889\n",
      "Epoch 2776: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6419 - accuracy: 0.7889 - val_loss: 1.3627 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2777/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.7606\n",
      "Epoch 2777: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.6653 - accuracy: 0.7606 - val_loss: 1.3369 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2778/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.7630\n",
      "Epoch 2778: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6805 - accuracy: 0.7630 - val_loss: 1.3205 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2779/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.7453\n",
      "Epoch 2779: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6952 - accuracy: 0.7453 - val_loss: 1.3187 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2780/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.7559\n",
      "Epoch 2780: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6961 - accuracy: 0.7559 - val_loss: 1.3207 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2781/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.7539\n",
      "Epoch 2781: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6862 - accuracy: 0.7539 - val_loss: 1.3237 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2782/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.7606\n",
      "Epoch 2782: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6597 - accuracy: 0.7606 - val_loss: 1.3280 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2783/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.7606\n",
      "Epoch 2783: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6936 - accuracy: 0.7606 - val_loss: 1.3253 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2784/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.7606\n",
      "Epoch 2784: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6780 - accuracy: 0.7606 - val_loss: 1.3284 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2785/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.7676\n",
      "Epoch 2785: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6718 - accuracy: 0.7676 - val_loss: 1.3275 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2786/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.7712\n",
      "Epoch 2786: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6425 - accuracy: 0.7712 - val_loss: 1.3223 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2787/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.7559\n",
      "Epoch 2787: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6880 - accuracy: 0.7559 - val_loss: 1.3157 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2788/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.7432\n",
      "Epoch 2788: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.6857 - accuracy: 0.7432 - val_loss: 1.3142 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2789/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.7712\n",
      "Epoch 2789: val_loss did not improve from 1.30709\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6866 - accuracy: 0.7712 - val_loss: 1.3099 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2790/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.7465\n",
      "Epoch 2790: val_loss improved from 1.30709 to 1.30549, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6681 - accuracy: 0.7465 - val_loss: 1.3055 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2791/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.7571\n",
      "Epoch 2791: val_loss improved from 1.30549 to 1.30421, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6972 - accuracy: 0.7571 - val_loss: 1.3042 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2792/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.7606\n",
      "Epoch 2792: val_loss improved from 1.30421 to 1.29843, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6780 - accuracy: 0.7606 - val_loss: 1.2984 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2793/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.7642\n",
      "Epoch 2793: val_loss did not improve from 1.29843\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6606 - accuracy: 0.7642 - val_loss: 1.2995 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2794/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.7736\n",
      "Epoch 2794: val_loss improved from 1.29843 to 1.29668, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.6746 - accuracy: 0.7736 - val_loss: 1.2967 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2795/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.7539\n",
      "Epoch 2795: val_loss improved from 1.29668 to 1.29061, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6837 - accuracy: 0.7539 - val_loss: 1.2906 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2796/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.7598\n",
      "Epoch 2796: val_loss improved from 1.29061 to 1.28995, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.6902 - accuracy: 0.7598 - val_loss: 1.2900 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2797/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.7712\n",
      "Epoch 2797: val_loss improved from 1.28995 to 1.28694, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.6787 - accuracy: 0.7712 - val_loss: 1.2869 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2798/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.7594\n",
      "Epoch 2798: val_loss improved from 1.28694 to 1.28237, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6841 - accuracy: 0.7594 - val_loss: 1.2824 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2799/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6689 - accuracy: 0.7642\n",
      "Epoch 2799: val_loss improved from 1.28237 to 1.28118, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6689 - accuracy: 0.7642 - val_loss: 1.2812 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2800/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.7549\n",
      "Epoch 2800: val_loss improved from 1.28118 to 1.27963, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6611 - accuracy: 0.7549 - val_loss: 1.2796 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2801/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.7736\n",
      "Epoch 2801: val_loss improved from 1.27963 to 1.27789, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6443 - accuracy: 0.7736 - val_loss: 1.2779 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2802/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6680 - accuracy: 0.7700\n",
      "Epoch 2802: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6680 - accuracy: 0.7700 - val_loss: 1.2798 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2803/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6954 - accuracy: 0.7547\n",
      "Epoch 2803: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6954 - accuracy: 0.7547 - val_loss: 1.2937 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2804/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.7700\n",
      "Epoch 2804: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6772 - accuracy: 0.7700 - val_loss: 1.3128 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2805/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.7642\n",
      "Epoch 2805: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6906 - accuracy: 0.7642 - val_loss: 1.3190 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2806/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.7588\n",
      "Epoch 2806: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6774 - accuracy: 0.7588 - val_loss: 1.3290 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2807/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6582 - accuracy: 0.7618\n",
      "Epoch 2807: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6582 - accuracy: 0.7618 - val_loss: 1.3263 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2808/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.7559\n",
      "Epoch 2808: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6939 - accuracy: 0.7559 - val_loss: 1.3215 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2809/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7009 - accuracy: 0.7535\n",
      "Epoch 2809: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.7009 - accuracy: 0.7535 - val_loss: 1.3326 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2810/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.7712\n",
      "Epoch 2810: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6633 - accuracy: 0.7712 - val_loss: 1.3513 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2811/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.7510\n",
      "Epoch 2811: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6707 - accuracy: 0.7510 - val_loss: 1.3733 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2812/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6519 - accuracy: 0.7578\n",
      "Epoch 2812: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6519 - accuracy: 0.7578 - val_loss: 1.3958 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2813/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.7642\n",
      "Epoch 2813: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.6543 - accuracy: 0.7642 - val_loss: 1.4173 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2814/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.7571\n",
      "Epoch 2814: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6767 - accuracy: 0.7571 - val_loss: 1.4352 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2815/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6180 - accuracy: 0.7630\n",
      "Epoch 2815: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6180 - accuracy: 0.7630 - val_loss: 1.4439 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2816/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.7588\n",
      "Epoch 2816: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.6611 - accuracy: 0.7588 - val_loss: 1.4380 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2817/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.7618\n",
      "Epoch 2817: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6777 - accuracy: 0.7618 - val_loss: 1.4333 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2818/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.7653\n",
      "Epoch 2818: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6762 - accuracy: 0.7653 - val_loss: 1.4315 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2819/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7038 - accuracy: 0.7335\n",
      "Epoch 2819: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.7038 - accuracy: 0.7335 - val_loss: 1.4258 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2820/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.7736\n",
      "Epoch 2820: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6736 - accuracy: 0.7736 - val_loss: 1.4150 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2821/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.7736\n",
      "Epoch 2821: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6758 - accuracy: 0.7736 - val_loss: 1.4091 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2822/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6720 - accuracy: 0.7583\n",
      "Epoch 2822: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6720 - accuracy: 0.7583 - val_loss: 1.3993 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2823/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.7441\n",
      "Epoch 2823: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7221 - accuracy: 0.7441 - val_loss: 1.3969 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2824/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.7724\n",
      "Epoch 2824: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.6531 - accuracy: 0.7724 - val_loss: 1.4029 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2825/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.7547\n",
      "Epoch 2825: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6921 - accuracy: 0.7547 - val_loss: 1.4099 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2826/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.7618\n",
      "Epoch 2826: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.6949 - accuracy: 0.7618 - val_loss: 1.4098 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2827/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6562 - accuracy: 0.7594\n",
      "Epoch 2827: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6562 - accuracy: 0.7594 - val_loss: 1.3918 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2828/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.7676\n",
      "Epoch 2828: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6782 - accuracy: 0.7676 - val_loss: 1.3795 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2829/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.7617\n",
      "Epoch 2829: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6397 - accuracy: 0.7617 - val_loss: 1.3678 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2830/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6822 - accuracy: 0.7559\n",
      "Epoch 2830: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6822 - accuracy: 0.7559 - val_loss: 1.3559 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2831/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.7422\n",
      "Epoch 2831: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6860 - accuracy: 0.7422 - val_loss: 1.3443 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2832/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7156 - accuracy: 0.7453\n",
      "Epoch 2832: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.7156 - accuracy: 0.7453 - val_loss: 1.3467 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2833/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.7429\n",
      "Epoch 2833: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7072 - accuracy: 0.7429 - val_loss: 1.3605 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2834/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.7559\n",
      "Epoch 2834: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6853 - accuracy: 0.7559 - val_loss: 1.3745 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2835/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.7748\n",
      "Epoch 2835: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6606 - accuracy: 0.7748 - val_loss: 1.3900 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2836/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.7795\n",
      "Epoch 2836: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6517 - accuracy: 0.7795 - val_loss: 1.3972 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2837/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.7665\n",
      "Epoch 2837: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6740 - accuracy: 0.7665 - val_loss: 1.4109 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2838/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.7453\n",
      "Epoch 2838: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6969 - accuracy: 0.7453 - val_loss: 1.4256 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2839/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.7712\n",
      "Epoch 2839: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6745 - accuracy: 0.7712 - val_loss: 1.4334 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2840/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6404 - accuracy: 0.7807\n",
      "Epoch 2840: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6404 - accuracy: 0.7807 - val_loss: 1.4300 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2841/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6586 - accuracy: 0.7642\n",
      "Epoch 2841: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6586 - accuracy: 0.7642 - val_loss: 1.4135 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2842/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.7547\n",
      "Epoch 2842: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6900 - accuracy: 0.7547 - val_loss: 1.4117 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2843/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.7630\n",
      "Epoch 2843: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6772 - accuracy: 0.7630 - val_loss: 1.4178 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2844/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.7617\n",
      "Epoch 2844: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6673 - accuracy: 0.7617 - val_loss: 1.4270 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2845/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.7441\n",
      "Epoch 2845: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6919 - accuracy: 0.7441 - val_loss: 1.4298 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2846/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.7432\n",
      "Epoch 2846: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6885 - accuracy: 0.7432 - val_loss: 1.4293 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 2847/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6519 - accuracy: 0.7653\n",
      "Epoch 2847: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6519 - accuracy: 0.7653 - val_loss: 1.4133 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2848/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6663 - accuracy: 0.7488\n",
      "Epoch 2848: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6663 - accuracy: 0.7488 - val_loss: 1.3935 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2849/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.7441\n",
      "Epoch 2849: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6951 - accuracy: 0.7441 - val_loss: 1.3814 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2850/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.7547\n",
      "Epoch 2850: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6777 - accuracy: 0.7547 - val_loss: 1.3710 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2851/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.7712\n",
      "Epoch 2851: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.6672 - accuracy: 0.7712 - val_loss: 1.3714 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2852/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6601 - accuracy: 0.7618\n",
      "Epoch 2852: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6601 - accuracy: 0.7618 - val_loss: 1.3696 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2853/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.7925\n",
      "Epoch 2853: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6495 - accuracy: 0.7925 - val_loss: 1.3695 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2854/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.7559\n",
      "Epoch 2854: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6947 - accuracy: 0.7559 - val_loss: 1.3726 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2855/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6697 - accuracy: 0.7559\n",
      "Epoch 2855: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6697 - accuracy: 0.7559 - val_loss: 1.3701 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2856/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.7606\n",
      "Epoch 2856: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6721 - accuracy: 0.7606 - val_loss: 1.3610 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2857/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.7453\n",
      "Epoch 2857: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.7044 - accuracy: 0.7453 - val_loss: 1.3465 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2858/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.7646\n",
      "Epoch 2858: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6789 - accuracy: 0.7646 - val_loss: 1.3442 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2859/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6976 - accuracy: 0.7476\n",
      "Epoch 2859: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6976 - accuracy: 0.7476 - val_loss: 1.3417 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2860/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6744 - accuracy: 0.7571\n",
      "Epoch 2860: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6744 - accuracy: 0.7571 - val_loss: 1.3368 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2861/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.7771\n",
      "Epoch 2861: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6474 - accuracy: 0.7771 - val_loss: 1.3457 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2862/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.7773\n",
      "Epoch 2862: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6622 - accuracy: 0.7773 - val_loss: 1.3507 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2863/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.7347\n",
      "Epoch 2863: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6907 - accuracy: 0.7347 - val_loss: 1.3557 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2864/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6572 - accuracy: 0.7559\n",
      "Epoch 2864: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6572 - accuracy: 0.7559 - val_loss: 1.3632 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2865/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.7594\n",
      "Epoch 2865: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6580 - accuracy: 0.7594 - val_loss: 1.3665 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2866/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.7646\n",
      "Epoch 2866: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6571 - accuracy: 0.7646 - val_loss: 1.3625 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2867/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7186 - accuracy: 0.7453\n",
      "Epoch 2867: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.7186 - accuracy: 0.7453 - val_loss: 1.3589 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2868/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.7736\n",
      "Epoch 2868: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6495 - accuracy: 0.7736 - val_loss: 1.3527 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2869/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.7700\n",
      "Epoch 2869: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6661 - accuracy: 0.7700 - val_loss: 1.3515 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2870/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.7665\n",
      "Epoch 2870: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6594 - accuracy: 0.7665 - val_loss: 1.3506 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2871/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7581 - accuracy: 0.7370\n",
      "Epoch 2871: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7581 - accuracy: 0.7370 - val_loss: 1.3594 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2872/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.7618\n",
      "Epoch 2872: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6756 - accuracy: 0.7618 - val_loss: 1.3682 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2873/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.7618\n",
      "Epoch 2873: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6620 - accuracy: 0.7618 - val_loss: 1.3806 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2874/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6615 - accuracy: 0.7665\n",
      "Epoch 2874: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6615 - accuracy: 0.7665 - val_loss: 1.3991 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2875/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6719 - accuracy: 0.7642\n",
      "Epoch 2875: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6719 - accuracy: 0.7642 - val_loss: 1.4072 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2876/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6729 - accuracy: 0.7512\n",
      "Epoch 2876: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6729 - accuracy: 0.7512 - val_loss: 1.4089 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2877/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6578 - accuracy: 0.7642\n",
      "Epoch 2877: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6578 - accuracy: 0.7642 - val_loss: 1.4121 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2878/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6697 - accuracy: 0.7571\n",
      "Epoch 2878: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6697 - accuracy: 0.7571 - val_loss: 1.4088 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2879/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.7465\n",
      "Epoch 2879: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6932 - accuracy: 0.7465 - val_loss: 1.3931 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2880/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.7748\n",
      "Epoch 2880: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6236 - accuracy: 0.7748 - val_loss: 1.3798 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2881/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6502 - accuracy: 0.7665\n",
      "Epoch 2881: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6502 - accuracy: 0.7665 - val_loss: 1.3609 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2882/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6665 - accuracy: 0.7606\n",
      "Epoch 2882: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.6665 - accuracy: 0.7606 - val_loss: 1.3530 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2883/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6684 - accuracy: 0.7666\n",
      "Epoch 2883: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.6684 - accuracy: 0.7666 - val_loss: 1.3547 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2884/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7053 - accuracy: 0.7417\n",
      "Epoch 2884: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7053 - accuracy: 0.7417 - val_loss: 1.3524 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2885/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.7512\n",
      "Epoch 2885: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6896 - accuracy: 0.7512 - val_loss: 1.3485 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2886/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.7606\n",
      "Epoch 2886: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6457 - accuracy: 0.7606 - val_loss: 1.3585 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2887/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.7759\n",
      "Epoch 2887: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6463 - accuracy: 0.7759 - val_loss: 1.3696 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2888/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.7689\n",
      "Epoch 2888: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6699 - accuracy: 0.7689 - val_loss: 1.3711 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2889/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6770 - accuracy: 0.7642\n",
      "Epoch 2889: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6770 - accuracy: 0.7642 - val_loss: 1.3583 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2890/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6634 - accuracy: 0.7535\n",
      "Epoch 2890: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6634 - accuracy: 0.7535 - val_loss: 1.3382 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2891/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.7583\n",
      "Epoch 2891: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6756 - accuracy: 0.7583 - val_loss: 1.3264 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2892/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.7571\n",
      "Epoch 2892: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6667 - accuracy: 0.7571 - val_loss: 1.3339 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2893/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.7598\n",
      "Epoch 2893: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6650 - accuracy: 0.7598 - val_loss: 1.3440 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2894/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.7606\n",
      "Epoch 2894: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6565 - accuracy: 0.7606 - val_loss: 1.3542 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2895/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.7642\n",
      "Epoch 2895: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6594 - accuracy: 0.7642 - val_loss: 1.3656 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2896/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.7771\n",
      "Epoch 2896: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6299 - accuracy: 0.7771 - val_loss: 1.3802 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2897/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.7642\n",
      "Epoch 2897: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7019 - accuracy: 0.7642 - val_loss: 1.3889 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2898/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.7311\n",
      "Epoch 2898: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.7213 - accuracy: 0.7311 - val_loss: 1.3944 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2899/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6810 - accuracy: 0.7583\n",
      "Epoch 2899: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.6810 - accuracy: 0.7583 - val_loss: 1.3923 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2900/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.7734\n",
      "Epoch 2900: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6387 - accuracy: 0.7734 - val_loss: 1.3956 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2901/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.7759\n",
      "Epoch 2901: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6440 - accuracy: 0.7759 - val_loss: 1.3909 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2902/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 0.7476\n",
      "Epoch 2902: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6990 - accuracy: 0.7476 - val_loss: 1.3955 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2903/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6723 - accuracy: 0.7594\n",
      "Epoch 2903: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6723 - accuracy: 0.7594 - val_loss: 1.4028 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2904/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.7665\n",
      "Epoch 2904: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6580 - accuracy: 0.7665 - val_loss: 1.4049 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2905/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.7630\n",
      "Epoch 2905: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6439 - accuracy: 0.7630 - val_loss: 1.4139 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2906/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.7724\n",
      "Epoch 2906: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6313 - accuracy: 0.7724 - val_loss: 1.4171 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2907/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.7453\n",
      "Epoch 2907: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.7023 - accuracy: 0.7453 - val_loss: 1.4270 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2908/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.7646\n",
      "Epoch 2908: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6848 - accuracy: 0.7646 - val_loss: 1.4325 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2909/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6567 - accuracy: 0.7724\n",
      "Epoch 2909: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6567 - accuracy: 0.7724 - val_loss: 1.4263 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2910/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.7547\n",
      "Epoch 2910: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6602 - accuracy: 0.7547 - val_loss: 1.4218 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2911/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6256 - accuracy: 0.7715\n",
      "Epoch 2911: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6256 - accuracy: 0.7715 - val_loss: 1.4176 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2912/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7571\n",
      "Epoch 2912: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6764 - accuracy: 0.7571 - val_loss: 1.4140 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2913/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6315 - accuracy: 0.7795\n",
      "Epoch 2913: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6315 - accuracy: 0.7795 - val_loss: 1.3974 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2914/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.7724\n",
      "Epoch 2914: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.6485 - accuracy: 0.7724 - val_loss: 1.3815 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2915/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6739 - accuracy: 0.7535\n",
      "Epoch 2915: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6739 - accuracy: 0.7535 - val_loss: 1.3746 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2916/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6459 - accuracy: 0.7695\n",
      "Epoch 2916: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6459 - accuracy: 0.7695 - val_loss: 1.3701 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2917/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6478 - accuracy: 0.7724\n",
      "Epoch 2917: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6478 - accuracy: 0.7724 - val_loss: 1.3666 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2918/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.7642\n",
      "Epoch 2918: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6652 - accuracy: 0.7642 - val_loss: 1.3612 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2919/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.7677\n",
      "Epoch 2919: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6569 - accuracy: 0.7677 - val_loss: 1.3624 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2920/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.7571\n",
      "Epoch 2920: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6967 - accuracy: 0.7571 - val_loss: 1.3641 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2921/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.7700\n",
      "Epoch 2921: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.6610 - accuracy: 0.7700 - val_loss: 1.3644 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2922/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6648 - accuracy: 0.7665\n",
      "Epoch 2922: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6648 - accuracy: 0.7665 - val_loss: 1.3556 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2923/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6640 - accuracy: 0.7665\n",
      "Epoch 2923: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6640 - accuracy: 0.7665 - val_loss: 1.3503 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2924/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.7712\n",
      "Epoch 2924: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6414 - accuracy: 0.7712 - val_loss: 1.3485 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2925/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.7666\n",
      "Epoch 2925: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6686 - accuracy: 0.7666 - val_loss: 1.3574 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2926/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.7759\n",
      "Epoch 2926: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6346 - accuracy: 0.7759 - val_loss: 1.3597 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2927/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.7571\n",
      "Epoch 2927: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6758 - accuracy: 0.7571 - val_loss: 1.3629 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2928/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6793 - accuracy: 0.7630\n",
      "Epoch 2928: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6793 - accuracy: 0.7630 - val_loss: 1.3629 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2929/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.7822\n",
      "Epoch 2929: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.6243 - accuracy: 0.7822 - val_loss: 1.3634 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2930/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6601 - accuracy: 0.7795\n",
      "Epoch 2930: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6601 - accuracy: 0.7795 - val_loss: 1.3725 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2931/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.7535\n",
      "Epoch 2931: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6799 - accuracy: 0.7535 - val_loss: 1.3808 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2932/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6675 - accuracy: 0.7677\n",
      "Epoch 2932: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6675 - accuracy: 0.7677 - val_loss: 1.3820 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2933/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.7465\n",
      "Epoch 2933: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6888 - accuracy: 0.7465 - val_loss: 1.3988 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2934/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.7744\n",
      "Epoch 2934: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6345 - accuracy: 0.7744 - val_loss: 1.4095 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2935/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6398 - accuracy: 0.7686\n",
      "Epoch 2935: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6398 - accuracy: 0.7686 - val_loss: 1.4157 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2936/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.7771\n",
      "Epoch 2936: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6411 - accuracy: 0.7771 - val_loss: 1.4180 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2937/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6480 - accuracy: 0.7571\n",
      "Epoch 2937: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6480 - accuracy: 0.7571 - val_loss: 1.4133 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 2938/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7653\n",
      "Epoch 2938: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6445 - accuracy: 0.7653 - val_loss: 1.4080 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2939/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.7642\n",
      "Epoch 2939: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6471 - accuracy: 0.7642 - val_loss: 1.3906 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2940/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.7559\n",
      "Epoch 2940: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6681 - accuracy: 0.7559 - val_loss: 1.3716 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 2941/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6568 - accuracy: 0.7653\n",
      "Epoch 2941: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6568 - accuracy: 0.7653 - val_loss: 1.3505 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2942/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.7583\n",
      "Epoch 2942: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.6479 - accuracy: 0.7583 - val_loss: 1.3419 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2943/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.7724\n",
      "Epoch 2943: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6737 - accuracy: 0.7724 - val_loss: 1.3200 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2944/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6548 - accuracy: 0.7606\n",
      "Epoch 2944: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.6548 - accuracy: 0.7606 - val_loss: 1.3161 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2945/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.7559\n",
      "Epoch 2945: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6745 - accuracy: 0.7559 - val_loss: 1.3041 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2946/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.7606\n",
      "Epoch 2946: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6906 - accuracy: 0.7606 - val_loss: 1.3076 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2947/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.7724\n",
      "Epoch 2947: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6411 - accuracy: 0.7724 - val_loss: 1.3162 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2948/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6548 - accuracy: 0.7627\n",
      "Epoch 2948: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6548 - accuracy: 0.7627 - val_loss: 1.3227 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2949/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6502 - accuracy: 0.7736\n",
      "Epoch 2949: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6502 - accuracy: 0.7736 - val_loss: 1.3300 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2950/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.7606\n",
      "Epoch 2950: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6560 - accuracy: 0.7606 - val_loss: 1.3383 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2951/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.7689\n",
      "Epoch 2951: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6594 - accuracy: 0.7689 - val_loss: 1.3425 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2952/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.7606\n",
      "Epoch 2952: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6776 - accuracy: 0.7606 - val_loss: 1.3409 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2953/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6731 - accuracy: 0.7715\n",
      "Epoch 2953: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6731 - accuracy: 0.7715 - val_loss: 1.3416 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2954/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6657 - accuracy: 0.7512\n",
      "Epoch 2954: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.6657 - accuracy: 0.7512 - val_loss: 1.3506 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2955/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.7606\n",
      "Epoch 2955: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6614 - accuracy: 0.7606 - val_loss: 1.3540 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2956/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.7500\n",
      "Epoch 2956: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6736 - accuracy: 0.7500 - val_loss: 1.3589 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2957/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.7618\n",
      "Epoch 2957: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6635 - accuracy: 0.7618 - val_loss: 1.3721 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2958/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6786 - accuracy: 0.7510\n",
      "Epoch 2958: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6786 - accuracy: 0.7510 - val_loss: 1.3855 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2959/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.7653\n",
      "Epoch 2959: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6613 - accuracy: 0.7653 - val_loss: 1.3895 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2960/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.7724\n",
      "Epoch 2960: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6249 - accuracy: 0.7724 - val_loss: 1.4026 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2961/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6675 - accuracy: 0.7618\n",
      "Epoch 2961: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6675 - accuracy: 0.7618 - val_loss: 1.4115 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2962/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.7653\n",
      "Epoch 2962: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6900 - accuracy: 0.7653 - val_loss: 1.4178 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2963/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.7677\n",
      "Epoch 2963: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6667 - accuracy: 0.7677 - val_loss: 1.4232 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2964/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6626 - accuracy: 0.7529\n",
      "Epoch 2964: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.6626 - accuracy: 0.7529 - val_loss: 1.4325 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2965/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.7748\n",
      "Epoch 2965: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6635 - accuracy: 0.7748 - val_loss: 1.4355 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2966/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.7686\n",
      "Epoch 2966: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6517 - accuracy: 0.7686 - val_loss: 1.4367 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2967/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6630 - accuracy: 0.7795\n",
      "Epoch 2967: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6630 - accuracy: 0.7795 - val_loss: 1.4331 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2968/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.7783\n",
      "Epoch 2968: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6299 - accuracy: 0.7783 - val_loss: 1.4387 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2969/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6739 - accuracy: 0.7642\n",
      "Epoch 2969: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6739 - accuracy: 0.7642 - val_loss: 1.4431 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2970/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.7630\n",
      "Epoch 2970: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6580 - accuracy: 0.7630 - val_loss: 1.4467 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 2971/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.7665\n",
      "Epoch 2971: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6414 - accuracy: 0.7665 - val_loss: 1.4385 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2972/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.7724\n",
      "Epoch 2972: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6576 - accuracy: 0.7724 - val_loss: 1.4215 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 2973/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.7689\n",
      "Epoch 2973: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6447 - accuracy: 0.7689 - val_loss: 1.3950 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 2974/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6644 - accuracy: 0.7748\n",
      "Epoch 2974: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.6644 - accuracy: 0.7748 - val_loss: 1.3705 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2975/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.7653\n",
      "Epoch 2975: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6538 - accuracy: 0.7653 - val_loss: 1.3432 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2976/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.7653\n",
      "Epoch 2976: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6560 - accuracy: 0.7653 - val_loss: 1.3222 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2977/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6689 - accuracy: 0.7524\n",
      "Epoch 2977: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6689 - accuracy: 0.7524 - val_loss: 1.3135 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2978/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6530 - accuracy: 0.7666\n",
      "Epoch 2978: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6530 - accuracy: 0.7666 - val_loss: 1.3138 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2979/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.7524\n",
      "Epoch 2979: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6442 - accuracy: 0.7524 - val_loss: 1.3147 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2980/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.7748\n",
      "Epoch 2980: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6446 - accuracy: 0.7748 - val_loss: 1.3098 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2981/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.7500\n",
      "Epoch 2981: val_loss did not improve from 1.27789\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.6874 - accuracy: 0.7500 - val_loss: 1.2936 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2982/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6486 - accuracy: 0.7736\n",
      "Epoch 2982: val_loss improved from 1.27789 to 1.27779, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.6486 - accuracy: 0.7736 - val_loss: 1.2778 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2983/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.7432\n",
      "Epoch 2983: val_loss improved from 1.27779 to 1.27591, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.6842 - accuracy: 0.7432 - val_loss: 1.2759 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2984/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.7568\n",
      "Epoch 2984: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6666 - accuracy: 0.7568 - val_loss: 1.2803 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2985/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.7594\n",
      "Epoch 2985: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6501 - accuracy: 0.7594 - val_loss: 1.2940 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 2986/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6451 - accuracy: 0.7736\n",
      "Epoch 2986: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6451 - accuracy: 0.7736 - val_loss: 1.3147 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 2987/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.7771\n",
      "Epoch 2987: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6552 - accuracy: 0.7771 - val_loss: 1.3309 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2988/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.7524\n",
      "Epoch 2988: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6676 - accuracy: 0.7524 - val_loss: 1.3375 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2989/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.7866\n",
      "Epoch 2989: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6379 - accuracy: 0.7866 - val_loss: 1.3386 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2990/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.7606\n",
      "Epoch 2990: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.6324 - accuracy: 0.7606 - val_loss: 1.3327 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2991/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.7807\n",
      "Epoch 2991: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6130 - accuracy: 0.7807 - val_loss: 1.3294 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 2992/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6374 - accuracy: 0.7653\n",
      "Epoch 2992: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6374 - accuracy: 0.7653 - val_loss: 1.3372 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2993/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.7594\n",
      "Epoch 2993: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6705 - accuracy: 0.7594 - val_loss: 1.3390 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2994/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.7783\n",
      "Epoch 2994: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6237 - accuracy: 0.7783 - val_loss: 1.3341 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 2995/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.7370\n",
      "Epoch 2995: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6925 - accuracy: 0.7370 - val_loss: 1.3280 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2996/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.7724\n",
      "Epoch 2996: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.6492 - accuracy: 0.7724 - val_loss: 1.3208 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2997/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.7630\n",
      "Epoch 2997: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.6758 - accuracy: 0.7630 - val_loss: 1.3222 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2998/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6634 - accuracy: 0.7606\n",
      "Epoch 2998: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6634 - accuracy: 0.7606 - val_loss: 1.3200 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 2999/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6585 - accuracy: 0.7666\n",
      "Epoch 2999: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6585 - accuracy: 0.7666 - val_loss: 1.3249 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3000/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.7700\n",
      "Epoch 3000: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6637 - accuracy: 0.7700 - val_loss: 1.3429 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3001/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6408 - accuracy: 0.7818\n",
      "Epoch 3001: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6408 - accuracy: 0.7818 - val_loss: 1.3657 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3002/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.7630\n",
      "Epoch 3002: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6472 - accuracy: 0.7630 - val_loss: 1.3740 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3003/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6628 - accuracy: 0.7606\n",
      "Epoch 3003: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6628 - accuracy: 0.7606 - val_loss: 1.3838 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3004/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.7700\n",
      "Epoch 3004: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6540 - accuracy: 0.7700 - val_loss: 1.3934 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3005/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6478 - accuracy: 0.7736\n",
      "Epoch 3005: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6478 - accuracy: 0.7736 - val_loss: 1.3992 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3006/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6693 - accuracy: 0.7547\n",
      "Epoch 3006: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6693 - accuracy: 0.7547 - val_loss: 1.4097 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3007/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6599 - accuracy: 0.7676\n",
      "Epoch 3007: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6599 - accuracy: 0.7676 - val_loss: 1.4270 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3008/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.7520\n",
      "Epoch 3008: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.6576 - accuracy: 0.7520 - val_loss: 1.4379 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 3009/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.7724\n",
      "Epoch 3009: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6316 - accuracy: 0.7724 - val_loss: 1.4547 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 3010/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.7665\n",
      "Epoch 3010: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6455 - accuracy: 0.7665 - val_loss: 1.4587 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3011/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6394 - accuracy: 0.7866\n",
      "Epoch 3011: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6394 - accuracy: 0.7866 - val_loss: 1.4548 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 3012/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.7406\n",
      "Epoch 3012: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6991 - accuracy: 0.7406 - val_loss: 1.4611 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3013/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.7771\n",
      "Epoch 3013: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6275 - accuracy: 0.7771 - val_loss: 1.4602 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 3014/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.7630\n",
      "Epoch 3014: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6511 - accuracy: 0.7630 - val_loss: 1.4558 - val_accuracy: 0.5415 - lr: 1.0000e-05\n",
      "Epoch 3015/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.7465\n",
      "Epoch 3015: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6645 - accuracy: 0.7465 - val_loss: 1.4343 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3016/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.7559\n",
      "Epoch 3016: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6757 - accuracy: 0.7559 - val_loss: 1.4279 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3017/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.7583\n",
      "Epoch 3017: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6782 - accuracy: 0.7583 - val_loss: 1.4315 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3018/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.7583\n",
      "Epoch 3018: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7007 - accuracy: 0.7583 - val_loss: 1.4300 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3019/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6488 - accuracy: 0.7748\n",
      "Epoch 3019: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6488 - accuracy: 0.7748 - val_loss: 1.4367 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3020/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.7677\n",
      "Epoch 3020: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6703 - accuracy: 0.7677 - val_loss: 1.4352 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3021/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.7571\n",
      "Epoch 3021: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6750 - accuracy: 0.7571 - val_loss: 1.4229 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3022/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.7764\n",
      "Epoch 3022: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6440 - accuracy: 0.7764 - val_loss: 1.4040 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3023/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.7712\n",
      "Epoch 3023: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6436 - accuracy: 0.7712 - val_loss: 1.3923 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3024/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.7441\n",
      "Epoch 3024: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.6843 - accuracy: 0.7441 - val_loss: 1.3914 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3025/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.7594\n",
      "Epoch 3025: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6654 - accuracy: 0.7594 - val_loss: 1.3829 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3026/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.7913\n",
      "Epoch 3026: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.6413 - accuracy: 0.7913 - val_loss: 1.3733 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3027/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.7854\n",
      "Epoch 3027: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6238 - accuracy: 0.7854 - val_loss: 1.3580 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3028/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.7500\n",
      "Epoch 3028: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6882 - accuracy: 0.7500 - val_loss: 1.3453 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3029/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.7583\n",
      "Epoch 3029: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6654 - accuracy: 0.7583 - val_loss: 1.3317 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3030/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.7724\n",
      "Epoch 3030: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6322 - accuracy: 0.7724 - val_loss: 1.3260 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3031/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6504 - accuracy: 0.7748\n",
      "Epoch 3031: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6504 - accuracy: 0.7748 - val_loss: 1.3265 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3032/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6409 - accuracy: 0.7736\n",
      "Epoch 3032: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.6409 - accuracy: 0.7736 - val_loss: 1.3338 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3033/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6640 - accuracy: 0.7594\n",
      "Epoch 3033: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6640 - accuracy: 0.7594 - val_loss: 1.3440 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3034/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6470 - accuracy: 0.7677\n",
      "Epoch 3034: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6470 - accuracy: 0.7677 - val_loss: 1.3450 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3035/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6537 - accuracy: 0.7618\n",
      "Epoch 3035: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6537 - accuracy: 0.7618 - val_loss: 1.3366 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3036/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.7771\n",
      "Epoch 3036: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6517 - accuracy: 0.7771 - val_loss: 1.3222 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3037/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6640 - accuracy: 0.7642\n",
      "Epoch 3037: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6640 - accuracy: 0.7642 - val_loss: 1.3140 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3038/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.7656\n",
      "Epoch 3038: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6367 - accuracy: 0.7656 - val_loss: 1.3089 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3039/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.7583\n",
      "Epoch 3039: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6691 - accuracy: 0.7583 - val_loss: 1.2988 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3040/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.7783\n",
      "Epoch 3040: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6463 - accuracy: 0.7783 - val_loss: 1.3011 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3041/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6879 - accuracy: 0.7512\n",
      "Epoch 3041: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6879 - accuracy: 0.7512 - val_loss: 1.3070 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3042/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6743 - accuracy: 0.7535\n",
      "Epoch 3042: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6743 - accuracy: 0.7535 - val_loss: 1.3202 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3043/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.7783\n",
      "Epoch 3043: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6182 - accuracy: 0.7783 - val_loss: 1.3313 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3044/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.7736\n",
      "Epoch 3044: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6411 - accuracy: 0.7736 - val_loss: 1.3379 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3045/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.7642\n",
      "Epoch 3045: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6402 - accuracy: 0.7642 - val_loss: 1.3391 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3046/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.7529\n",
      "Epoch 3046: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6661 - accuracy: 0.7529 - val_loss: 1.3448 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3047/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.7700\n",
      "Epoch 3047: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6707 - accuracy: 0.7700 - val_loss: 1.3490 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3048/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.7724\n",
      "Epoch 3048: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6360 - accuracy: 0.7724 - val_loss: 1.3498 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3049/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.7642\n",
      "Epoch 3049: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6926 - accuracy: 0.7642 - val_loss: 1.3530 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3050/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.7754\n",
      "Epoch 3050: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.6262 - accuracy: 0.7754 - val_loss: 1.3534 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3051/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.7866\n",
      "Epoch 3051: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6217 - accuracy: 0.7866 - val_loss: 1.3701 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3052/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.7677\n",
      "Epoch 3052: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6365 - accuracy: 0.7677 - val_loss: 1.3761 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3053/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.7830\n",
      "Epoch 3053: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6139 - accuracy: 0.7830 - val_loss: 1.3759 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3054/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.7712\n",
      "Epoch 3054: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6495 - accuracy: 0.7712 - val_loss: 1.3747 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3055/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6573 - accuracy: 0.7676\n",
      "Epoch 3055: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6573 - accuracy: 0.7676 - val_loss: 1.3787 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3056/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.7441\n",
      "Epoch 3056: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6781 - accuracy: 0.7441 - val_loss: 1.3770 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3057/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.7795\n",
      "Epoch 3057: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6507 - accuracy: 0.7795 - val_loss: 1.3747 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3058/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6793 - accuracy: 0.7607\n",
      "Epoch 3058: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6793 - accuracy: 0.7607 - val_loss: 1.3666 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3059/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6399 - accuracy: 0.7627\n",
      "Epoch 3059: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6399 - accuracy: 0.7627 - val_loss: 1.3569 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3060/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6615 - accuracy: 0.7653\n",
      "Epoch 3060: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6615 - accuracy: 0.7653 - val_loss: 1.3462 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3061/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6480 - accuracy: 0.7642\n",
      "Epoch 3061: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6480 - accuracy: 0.7642 - val_loss: 1.3440 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3062/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.7656\n",
      "Epoch 3062: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.6673 - accuracy: 0.7656 - val_loss: 1.3465 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3063/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.7695\n",
      "Epoch 3063: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6464 - accuracy: 0.7695 - val_loss: 1.3504 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3064/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.7759\n",
      "Epoch 3064: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6472 - accuracy: 0.7759 - val_loss: 1.3547 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3065/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.7547\n",
      "Epoch 3065: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.6908 - accuracy: 0.7547 - val_loss: 1.3588 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3066/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6371 - accuracy: 0.7689\n",
      "Epoch 3066: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6371 - accuracy: 0.7689 - val_loss: 1.3624 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3067/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.7606\n",
      "Epoch 3067: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6736 - accuracy: 0.7606 - val_loss: 1.3787 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3068/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.7689\n",
      "Epoch 3068: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6285 - accuracy: 0.7689 - val_loss: 1.3866 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3069/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.7606\n",
      "Epoch 3069: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6422 - accuracy: 0.7606 - val_loss: 1.3797 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3070/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.7764\n",
      "Epoch 3070: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6317 - accuracy: 0.7764 - val_loss: 1.3713 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3071/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.7712\n",
      "Epoch 3071: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6674 - accuracy: 0.7712 - val_loss: 1.3750 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3072/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.7712\n",
      "Epoch 3072: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6411 - accuracy: 0.7712 - val_loss: 1.3753 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3073/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6519 - accuracy: 0.7689\n",
      "Epoch 3073: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6519 - accuracy: 0.7689 - val_loss: 1.3687 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3074/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6366 - accuracy: 0.7871\n",
      "Epoch 3074: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6366 - accuracy: 0.7871 - val_loss: 1.3631 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3075/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6326 - accuracy: 0.7736\n",
      "Epoch 3075: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6326 - accuracy: 0.7736 - val_loss: 1.3600 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3076/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6693 - accuracy: 0.7689\n",
      "Epoch 3076: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6693 - accuracy: 0.7689 - val_loss: 1.3553 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3077/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.7712\n",
      "Epoch 3077: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6539 - accuracy: 0.7712 - val_loss: 1.3578 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3078/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.7807\n",
      "Epoch 3078: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6151 - accuracy: 0.7807 - val_loss: 1.3635 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3079/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.7630\n",
      "Epoch 3079: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6358 - accuracy: 0.7630 - val_loss: 1.3537 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3080/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.7866\n",
      "Epoch 3080: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6064 - accuracy: 0.7866 - val_loss: 1.3359 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3081/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.7594\n",
      "Epoch 3081: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6809 - accuracy: 0.7594 - val_loss: 1.3388 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3082/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.7653\n",
      "Epoch 3082: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6314 - accuracy: 0.7653 - val_loss: 1.3296 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3083/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6459 - accuracy: 0.7583\n",
      "Epoch 3083: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6459 - accuracy: 0.7583 - val_loss: 1.3207 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3084/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.7676\n",
      "Epoch 3084: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6351 - accuracy: 0.7676 - val_loss: 1.3268 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3085/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.7807\n",
      "Epoch 3085: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6240 - accuracy: 0.7807 - val_loss: 1.3306 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3086/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.7677\n",
      "Epoch 3086: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6545 - accuracy: 0.7677 - val_loss: 1.3359 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3087/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.7748\n",
      "Epoch 3087: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6596 - accuracy: 0.7748 - val_loss: 1.3521 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3088/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.7559\n",
      "Epoch 3088: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6687 - accuracy: 0.7559 - val_loss: 1.3674 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3089/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.7773\n",
      "Epoch 3089: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6382 - accuracy: 0.7773 - val_loss: 1.3837 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3090/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.7736\n",
      "Epoch 3090: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6554 - accuracy: 0.7736 - val_loss: 1.4005 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3091/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6293 - accuracy: 0.7759\n",
      "Epoch 3091: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6293 - accuracy: 0.7759 - val_loss: 1.4068 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3092/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.7700\n",
      "Epoch 3092: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6241 - accuracy: 0.7700 - val_loss: 1.4152 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3093/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6384 - accuracy: 0.7803\n",
      "Epoch 3093: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6384 - accuracy: 0.7803 - val_loss: 1.4134 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3094/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6293 - accuracy: 0.7830\n",
      "Epoch 3094: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6293 - accuracy: 0.7830 - val_loss: 1.3942 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3095/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.7771\n",
      "Epoch 3095: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6099 - accuracy: 0.7771 - val_loss: 1.3778 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3096/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.7724\n",
      "Epoch 3096: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6746 - accuracy: 0.7724 - val_loss: 1.3646 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3097/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.7866\n",
      "Epoch 3097: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6155 - accuracy: 0.7866 - val_loss: 1.3647 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3098/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.7771\n",
      "Epoch 3098: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6489 - accuracy: 0.7771 - val_loss: 1.3701 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3099/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6573 - accuracy: 0.7686\n",
      "Epoch 3099: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6573 - accuracy: 0.7686 - val_loss: 1.3739 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3100/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6340 - accuracy: 0.7725\n",
      "Epoch 3100: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.6340 - accuracy: 0.7725 - val_loss: 1.3804 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3101/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6795 - accuracy: 0.7594\n",
      "Epoch 3101: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6795 - accuracy: 0.7594 - val_loss: 1.3914 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3102/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6714 - accuracy: 0.7618\n",
      "Epoch 3102: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.6714 - accuracy: 0.7618 - val_loss: 1.3973 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3103/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.7920\n",
      "Epoch 3103: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6434 - accuracy: 0.7920 - val_loss: 1.3993 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3104/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.7594\n",
      "Epoch 3104: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6624 - accuracy: 0.7594 - val_loss: 1.4035 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3105/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6765 - accuracy: 0.7594\n",
      "Epoch 3105: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6765 - accuracy: 0.7594 - val_loss: 1.3949 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3106/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6751 - accuracy: 0.7653\n",
      "Epoch 3106: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6751 - accuracy: 0.7653 - val_loss: 1.4003 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3107/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5996 - accuracy: 0.7818\n",
      "Epoch 3107: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.5996 - accuracy: 0.7818 - val_loss: 1.3994 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3108/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.7736\n",
      "Epoch 3108: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6364 - accuracy: 0.7736 - val_loss: 1.3982 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3109/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6550 - accuracy: 0.7606\n",
      "Epoch 3109: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6550 - accuracy: 0.7606 - val_loss: 1.4005 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3110/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.7689\n",
      "Epoch 3110: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6543 - accuracy: 0.7689 - val_loss: 1.3963 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3111/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6546 - accuracy: 0.7665\n",
      "Epoch 3111: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6546 - accuracy: 0.7665 - val_loss: 1.3888 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3112/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.7630\n",
      "Epoch 3112: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6660 - accuracy: 0.7630 - val_loss: 1.3883 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3113/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6677 - accuracy: 0.7524\n",
      "Epoch 3113: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6677 - accuracy: 0.7524 - val_loss: 1.4007 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3114/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.7588\n",
      "Epoch 3114: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6452 - accuracy: 0.7588 - val_loss: 1.4211 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3115/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6656 - accuracy: 0.7594\n",
      "Epoch 3115: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6656 - accuracy: 0.7594 - val_loss: 1.4258 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3116/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6337 - accuracy: 0.7783\n",
      "Epoch 3116: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6337 - accuracy: 0.7783 - val_loss: 1.4372 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3117/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6230 - accuracy: 0.7783\n",
      "Epoch 3117: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.6230 - accuracy: 0.7783 - val_loss: 1.4434 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3118/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6269 - accuracy: 0.7852\n",
      "Epoch 3118: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6269 - accuracy: 0.7852 - val_loss: 1.4378 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3119/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7948\n",
      "Epoch 3119: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.6129 - accuracy: 0.7948 - val_loss: 1.4418 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3120/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.7783\n",
      "Epoch 3120: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6147 - accuracy: 0.7783 - val_loss: 1.4379 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3121/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6308 - accuracy: 0.7807\n",
      "Epoch 3121: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6308 - accuracy: 0.7807 - val_loss: 1.4221 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3122/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.7736\n",
      "Epoch 3122: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6419 - accuracy: 0.7736 - val_loss: 1.4091 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3123/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.7830\n",
      "Epoch 3123: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6349 - accuracy: 0.7830 - val_loss: 1.4114 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3124/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6487 - accuracy: 0.7559\n",
      "Epoch 3124: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6487 - accuracy: 0.7559 - val_loss: 1.4224 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3125/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6395 - accuracy: 0.7744\n",
      "Epoch 3125: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6395 - accuracy: 0.7744 - val_loss: 1.4336 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3126/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7712\n",
      "Epoch 3126: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6462 - accuracy: 0.7712 - val_loss: 1.4439 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3127/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6053 - accuracy: 0.7972\n",
      "Epoch 3127: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6053 - accuracy: 0.7972 - val_loss: 1.4492 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3128/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.7736\n",
      "Epoch 3128: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6736 - accuracy: 0.7736 - val_loss: 1.4491 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3129/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.7771\n",
      "Epoch 3129: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6276 - accuracy: 0.7771 - val_loss: 1.4416 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3130/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6723 - accuracy: 0.7642\n",
      "Epoch 3130: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6723 - accuracy: 0.7642 - val_loss: 1.4306 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3131/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.7759\n",
      "Epoch 3131: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6322 - accuracy: 0.7759 - val_loss: 1.4136 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3132/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5816 - accuracy: 0.8054\n",
      "Epoch 3132: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5816 - accuracy: 0.8054 - val_loss: 1.3879 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3133/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.7559\n",
      "Epoch 3133: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6503 - accuracy: 0.7559 - val_loss: 1.3846 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3134/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.7488\n",
      "Epoch 3134: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6930 - accuracy: 0.7488 - val_loss: 1.3788 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3135/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.7830\n",
      "Epoch 3135: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.6231 - accuracy: 0.7830 - val_loss: 1.3760 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3136/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.7653\n",
      "Epoch 3136: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6410 - accuracy: 0.7653 - val_loss: 1.3805 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3137/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.7832\n",
      "Epoch 3137: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6328 - accuracy: 0.7832 - val_loss: 1.3883 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3138/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.7712\n",
      "Epoch 3138: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6341 - accuracy: 0.7712 - val_loss: 1.3827 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3139/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.7630\n",
      "Epoch 3139: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6471 - accuracy: 0.7630 - val_loss: 1.3774 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3140/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.7700\n",
      "Epoch 3140: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6612 - accuracy: 0.7700 - val_loss: 1.3628 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3141/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.7712\n",
      "Epoch 3141: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6246 - accuracy: 0.7712 - val_loss: 1.3490 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3142/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.7795\n",
      "Epoch 3142: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6367 - accuracy: 0.7795 - val_loss: 1.3507 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3143/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6832 - accuracy: 0.7461\n",
      "Epoch 3143: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6832 - accuracy: 0.7461 - val_loss: 1.3454 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3144/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.7583\n",
      "Epoch 3144: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6413 - accuracy: 0.7583 - val_loss: 1.3557 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3145/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.7630\n",
      "Epoch 3145: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6357 - accuracy: 0.7630 - val_loss: 1.3740 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3146/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.7488\n",
      "Epoch 3146: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6968 - accuracy: 0.7488 - val_loss: 1.4003 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3147/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.7748\n",
      "Epoch 3147: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6397 - accuracy: 0.7748 - val_loss: 1.4338 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3148/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.7689\n",
      "Epoch 3148: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6449 - accuracy: 0.7689 - val_loss: 1.4568 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3149/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6420 - accuracy: 0.7818\n",
      "Epoch 3149: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6420 - accuracy: 0.7818 - val_loss: 1.4710 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 3150/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6581 - accuracy: 0.7771\n",
      "Epoch 3150: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6581 - accuracy: 0.7771 - val_loss: 1.5001 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 3151/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.7535\n",
      "Epoch 3151: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.6440 - accuracy: 0.7535 - val_loss: 1.5052 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 3152/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.7653\n",
      "Epoch 3152: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6188 - accuracy: 0.7653 - val_loss: 1.5070 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 3153/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.7571\n",
      "Epoch 3153: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6512 - accuracy: 0.7571 - val_loss: 1.5047 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 3154/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.7712\n",
      "Epoch 3154: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6156 - accuracy: 0.7712 - val_loss: 1.5081 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 3155/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6722 - accuracy: 0.7559\n",
      "Epoch 3155: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6722 - accuracy: 0.7559 - val_loss: 1.5078 - val_accuracy: 0.5307 - lr: 1.0000e-05\n",
      "Epoch 3156/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.7866\n",
      "Epoch 3156: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6098 - accuracy: 0.7866 - val_loss: 1.5090 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 3157/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.7429\n",
      "Epoch 3157: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6651 - accuracy: 0.7429 - val_loss: 1.5034 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 3158/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.7539\n",
      "Epoch 3158: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6782 - accuracy: 0.7539 - val_loss: 1.4854 - val_accuracy: 0.5379 - lr: 1.0000e-05\n",
      "Epoch 3159/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.7736\n",
      "Epoch 3159: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6324 - accuracy: 0.7736 - val_loss: 1.4563 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3160/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.7653\n",
      "Epoch 3160: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6364 - accuracy: 0.7653 - val_loss: 1.4336 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3161/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6629 - accuracy: 0.7594\n",
      "Epoch 3161: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6629 - accuracy: 0.7594 - val_loss: 1.4206 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3162/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7866\n",
      "Epoch 3162: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6042 - accuracy: 0.7866 - val_loss: 1.4188 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3163/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.7689\n",
      "Epoch 3163: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6603 - accuracy: 0.7689 - val_loss: 1.4439 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3164/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6604 - accuracy: 0.7512\n",
      "Epoch 3164: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6604 - accuracy: 0.7512 - val_loss: 1.4625 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3165/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.7559\n",
      "Epoch 3165: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6837 - accuracy: 0.7559 - val_loss: 1.4608 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3166/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6424 - accuracy: 0.7689\n",
      "Epoch 3166: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6424 - accuracy: 0.7689 - val_loss: 1.4508 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3167/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.7818\n",
      "Epoch 3167: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6262 - accuracy: 0.7818 - val_loss: 1.4303 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3168/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.7677\n",
      "Epoch 3168: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6239 - accuracy: 0.7677 - val_loss: 1.4204 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3169/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6708 - accuracy: 0.7606\n",
      "Epoch 3169: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6708 - accuracy: 0.7606 - val_loss: 1.4043 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3170/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.7571\n",
      "Epoch 3170: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6309 - accuracy: 0.7571 - val_loss: 1.4007 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3171/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7783\n",
      "Epoch 3171: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6375 - accuracy: 0.7783 - val_loss: 1.3910 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3172/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.7748\n",
      "Epoch 3172: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6419 - accuracy: 0.7748 - val_loss: 1.3930 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3173/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.7665\n",
      "Epoch 3173: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6511 - accuracy: 0.7665 - val_loss: 1.4015 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3174/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6729 - accuracy: 0.7559\n",
      "Epoch 3174: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6729 - accuracy: 0.7559 - val_loss: 1.3970 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3175/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.7646\n",
      "Epoch 3175: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6355 - accuracy: 0.7646 - val_loss: 1.3833 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3176/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.7724\n",
      "Epoch 3176: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6400 - accuracy: 0.7724 - val_loss: 1.3687 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3177/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6295 - accuracy: 0.7807\n",
      "Epoch 3177: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.6295 - accuracy: 0.7807 - val_loss: 1.3400 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3178/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7783\n",
      "Epoch 3178: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6375 - accuracy: 0.7783 - val_loss: 1.3199 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3179/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7972\n",
      "Epoch 3179: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.6129 - accuracy: 0.7972 - val_loss: 1.3083 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3180/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.7783\n",
      "Epoch 3180: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6276 - accuracy: 0.7783 - val_loss: 1.3059 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3181/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6621 - accuracy: 0.7630\n",
      "Epoch 3181: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6621 - accuracy: 0.7630 - val_loss: 1.3097 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3182/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.7948\n",
      "Epoch 3182: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.6081 - accuracy: 0.7948 - val_loss: 1.3062 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3183/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7676\n",
      "Epoch 3183: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6445 - accuracy: 0.7676 - val_loss: 1.2979 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3184/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.7807\n",
      "Epoch 3184: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6455 - accuracy: 0.7807 - val_loss: 1.3024 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3185/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.7795\n",
      "Epoch 3185: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.6272 - accuracy: 0.7795 - val_loss: 1.3083 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3186/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.7724\n",
      "Epoch 3186: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6322 - accuracy: 0.7724 - val_loss: 1.3083 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3187/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.7656\n",
      "Epoch 3187: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6401 - accuracy: 0.7656 - val_loss: 1.3058 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3188/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.7689\n",
      "Epoch 3188: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6466 - accuracy: 0.7689 - val_loss: 1.3121 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3189/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6484 - accuracy: 0.7715\n",
      "Epoch 3189: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6484 - accuracy: 0.7715 - val_loss: 1.3171 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3190/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.7889\n",
      "Epoch 3190: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6169 - accuracy: 0.7889 - val_loss: 1.3228 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3191/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6398 - accuracy: 0.7807\n",
      "Epoch 3191: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6398 - accuracy: 0.7807 - val_loss: 1.3301 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3192/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6008 - accuracy: 0.7854\n",
      "Epoch 3192: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6008 - accuracy: 0.7854 - val_loss: 1.3390 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3193/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6393 - accuracy: 0.7715\n",
      "Epoch 3193: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6393 - accuracy: 0.7715 - val_loss: 1.3462 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3194/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.7771\n",
      "Epoch 3194: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6194 - accuracy: 0.7771 - val_loss: 1.3392 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3195/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.7771\n",
      "Epoch 3195: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6589 - accuracy: 0.7771 - val_loss: 1.3476 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3196/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6493 - accuracy: 0.7795\n",
      "Epoch 3196: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6493 - accuracy: 0.7795 - val_loss: 1.3469 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3197/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.7795\n",
      "Epoch 3197: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6222 - accuracy: 0.7795 - val_loss: 1.3262 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3198/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6392 - accuracy: 0.7594\n",
      "Epoch 3198: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6392 - accuracy: 0.7594 - val_loss: 1.3185 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3199/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.7795\n",
      "Epoch 3199: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6241 - accuracy: 0.7795 - val_loss: 1.3033 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3200/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.7901\n",
      "Epoch 3200: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6159 - accuracy: 0.7901 - val_loss: 1.2862 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3201/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6417 - accuracy: 0.7500\n",
      "Epoch 3201: val_loss did not improve from 1.27591\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6417 - accuracy: 0.7500 - val_loss: 1.2774 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3202/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.7689\n",
      "Epoch 3202: val_loss improved from 1.27591 to 1.26413, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6436 - accuracy: 0.7689 - val_loss: 1.2641 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3203/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.7512\n",
      "Epoch 3203: val_loss improved from 1.26413 to 1.25580, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6540 - accuracy: 0.7512 - val_loss: 1.2558 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3204/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.7630\n",
      "Epoch 3204: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.6610 - accuracy: 0.7630 - val_loss: 1.2599 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3205/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6632 - accuracy: 0.7568\n",
      "Epoch 3205: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6632 - accuracy: 0.7568 - val_loss: 1.2638 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3206/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.7759\n",
      "Epoch 3206: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.6365 - accuracy: 0.7759 - val_loss: 1.2734 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3207/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.7842\n",
      "Epoch 3207: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6203 - accuracy: 0.7842 - val_loss: 1.2874 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3208/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.7866\n",
      "Epoch 3208: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6416 - accuracy: 0.7866 - val_loss: 1.2901 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3209/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.7606\n",
      "Epoch 3209: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6479 - accuracy: 0.7606 - val_loss: 1.2839 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3210/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.7700\n",
      "Epoch 3210: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.6505 - accuracy: 0.7700 - val_loss: 1.2798 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3211/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6113 - accuracy: 0.7913\n",
      "Epoch 3211: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6113 - accuracy: 0.7913 - val_loss: 1.2743 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3212/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.7725\n",
      "Epoch 3212: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6198 - accuracy: 0.7725 - val_loss: 1.2728 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3213/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6226 - accuracy: 0.7866\n",
      "Epoch 3213: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6226 - accuracy: 0.7866 - val_loss: 1.2757 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3214/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.7830\n",
      "Epoch 3214: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6138 - accuracy: 0.7830 - val_loss: 1.2806 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3215/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.7842\n",
      "Epoch 3215: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6169 - accuracy: 0.7842 - val_loss: 1.2885 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3216/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.7803\n",
      "Epoch 3216: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6466 - accuracy: 0.7803 - val_loss: 1.2944 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3217/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.7783\n",
      "Epoch 3217: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6002 - accuracy: 0.7783 - val_loss: 1.3081 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3218/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.7689\n",
      "Epoch 3218: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6367 - accuracy: 0.7689 - val_loss: 1.3115 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3219/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.7630\n",
      "Epoch 3219: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6411 - accuracy: 0.7630 - val_loss: 1.3129 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3220/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.7606\n",
      "Epoch 3220: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6443 - accuracy: 0.7606 - val_loss: 1.3105 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3221/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.7724\n",
      "Epoch 3221: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6185 - accuracy: 0.7724 - val_loss: 1.2936 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3222/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.7803\n",
      "Epoch 3222: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6171 - accuracy: 0.7803 - val_loss: 1.2829 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3223/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.7877\n",
      "Epoch 3223: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6122 - accuracy: 0.7877 - val_loss: 1.2786 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3224/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.7676\n",
      "Epoch 3224: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.6517 - accuracy: 0.7676 - val_loss: 1.2916 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3225/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.7889\n",
      "Epoch 3225: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6198 - accuracy: 0.7889 - val_loss: 1.2998 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3226/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.7712\n",
      "Epoch 3226: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6543 - accuracy: 0.7712 - val_loss: 1.3185 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3227/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6806 - accuracy: 0.7618\n",
      "Epoch 3227: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6806 - accuracy: 0.7618 - val_loss: 1.3389 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3228/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6308 - accuracy: 0.7736\n",
      "Epoch 3228: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6308 - accuracy: 0.7736 - val_loss: 1.3626 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3229/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6244 - accuracy: 0.7803\n",
      "Epoch 3229: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6244 - accuracy: 0.7803 - val_loss: 1.3719 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3230/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.7559\n",
      "Epoch 3230: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6580 - accuracy: 0.7559 - val_loss: 1.3828 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3231/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.7842\n",
      "Epoch 3231: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6225 - accuracy: 0.7842 - val_loss: 1.4001 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3232/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.7520\n",
      "Epoch 3232: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.6700 - accuracy: 0.7520 - val_loss: 1.4045 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3233/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.7712\n",
      "Epoch 3233: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6227 - accuracy: 0.7712 - val_loss: 1.4132 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3234/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7807\n",
      "Epoch 3234: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6352 - accuracy: 0.7807 - val_loss: 1.4156 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3235/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.7783\n",
      "Epoch 3235: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6250 - accuracy: 0.7783 - val_loss: 1.4252 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3236/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.7793\n",
      "Epoch 3236: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6305 - accuracy: 0.7793 - val_loss: 1.4240 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3237/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.7594\n",
      "Epoch 3237: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6545 - accuracy: 0.7594 - val_loss: 1.4283 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3238/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.7754\n",
      "Epoch 3238: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.6362 - accuracy: 0.7754 - val_loss: 1.4379 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3239/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5982 - accuracy: 0.7936\n",
      "Epoch 3239: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5982 - accuracy: 0.7936 - val_loss: 1.4576 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3240/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.7983\n",
      "Epoch 3240: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6286 - accuracy: 0.7983 - val_loss: 1.4568 - val_accuracy: 0.5451 - lr: 1.0000e-05\n",
      "Epoch 3241/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.7783\n",
      "Epoch 3241: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6303 - accuracy: 0.7783 - val_loss: 1.4446 - val_accuracy: 0.5487 - lr: 1.0000e-05\n",
      "Epoch 3242/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6293 - accuracy: 0.7736\n",
      "Epoch 3242: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6293 - accuracy: 0.7736 - val_loss: 1.4237 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 3243/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.7606\n",
      "Epoch 3243: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6460 - accuracy: 0.7606 - val_loss: 1.4092 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3244/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.7854\n",
      "Epoch 3244: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6144 - accuracy: 0.7854 - val_loss: 1.3908 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3245/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.7618\n",
      "Epoch 3245: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6511 - accuracy: 0.7618 - val_loss: 1.3785 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3246/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.7700\n",
      "Epoch 3246: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6354 - accuracy: 0.7700 - val_loss: 1.3695 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3247/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.7812\n",
      "Epoch 3247: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.6091 - accuracy: 0.7812 - val_loss: 1.3511 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3248/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.7700\n",
      "Epoch 3248: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6372 - accuracy: 0.7700 - val_loss: 1.3417 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3249/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.7854\n",
      "Epoch 3249: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6098 - accuracy: 0.7854 - val_loss: 1.3360 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3250/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.7818\n",
      "Epoch 3250: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6377 - accuracy: 0.7818 - val_loss: 1.3387 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3251/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.7606\n",
      "Epoch 3251: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6696 - accuracy: 0.7606 - val_loss: 1.3438 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3252/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6532 - accuracy: 0.7618\n",
      "Epoch 3252: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6532 - accuracy: 0.7618 - val_loss: 1.3399 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3253/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.7529\n",
      "Epoch 3253: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.6372 - accuracy: 0.7529 - val_loss: 1.3316 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3254/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.7642\n",
      "Epoch 3254: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6494 - accuracy: 0.7642 - val_loss: 1.3406 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3255/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6097 - accuracy: 0.7900\n",
      "Epoch 3255: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.6097 - accuracy: 0.7900 - val_loss: 1.3465 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3256/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.7646\n",
      "Epoch 3256: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6597 - accuracy: 0.7646 - val_loss: 1.3458 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3257/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.7783\n",
      "Epoch 3257: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6046 - accuracy: 0.7783 - val_loss: 1.3415 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3258/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.7983\n",
      "Epoch 3258: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6037 - accuracy: 0.7983 - val_loss: 1.3277 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3259/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.7842\n",
      "Epoch 3259: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6422 - accuracy: 0.7842 - val_loss: 1.3281 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3260/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6278 - accuracy: 0.7783\n",
      "Epoch 3260: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6278 - accuracy: 0.7783 - val_loss: 1.3301 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3261/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.7724\n",
      "Epoch 3261: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6441 - accuracy: 0.7724 - val_loss: 1.3446 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3262/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.7995\n",
      "Epoch 3262: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6182 - accuracy: 0.7995 - val_loss: 1.3540 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3263/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7666\n",
      "Epoch 3263: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6129 - accuracy: 0.7666 - val_loss: 1.3635 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3264/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6287 - accuracy: 0.7759\n",
      "Epoch 3264: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6287 - accuracy: 0.7759 - val_loss: 1.3642 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3265/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.7854\n",
      "Epoch 3265: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6414 - accuracy: 0.7854 - val_loss: 1.3451 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3266/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6263 - accuracy: 0.7830\n",
      "Epoch 3266: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6263 - accuracy: 0.7830 - val_loss: 1.3267 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3267/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.7842\n",
      "Epoch 3267: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6239 - accuracy: 0.7842 - val_loss: 1.3109 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3268/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6451 - accuracy: 0.7748\n",
      "Epoch 3268: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6451 - accuracy: 0.7748 - val_loss: 1.3002 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3269/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.7736\n",
      "Epoch 3269: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6324 - accuracy: 0.7736 - val_loss: 1.2881 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3270/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.7925\n",
      "Epoch 3270: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6419 - accuracy: 0.7925 - val_loss: 1.2799 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3271/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.7773\n",
      "Epoch 3271: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6283 - accuracy: 0.7773 - val_loss: 1.2713 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3272/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6308 - accuracy: 0.7736\n",
      "Epoch 3272: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6308 - accuracy: 0.7736 - val_loss: 1.2648 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3273/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.7583\n",
      "Epoch 3273: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6654 - accuracy: 0.7583 - val_loss: 1.2704 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3274/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.7606\n",
      "Epoch 3274: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6250 - accuracy: 0.7606 - val_loss: 1.2701 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3275/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.7500\n",
      "Epoch 3275: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.6994 - accuracy: 0.7500 - val_loss: 1.2738 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3276/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6592 - accuracy: 0.7677\n",
      "Epoch 3276: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6592 - accuracy: 0.7677 - val_loss: 1.2690 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3277/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7441\n",
      "Epoch 3277: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6764 - accuracy: 0.7441 - val_loss: 1.2602 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3278/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7705\n",
      "Epoch 3278: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6462 - accuracy: 0.7705 - val_loss: 1.2563 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3279/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.7795\n",
      "Epoch 3279: val_loss did not improve from 1.25580\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6184 - accuracy: 0.7795 - val_loss: 1.2559 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3280/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.7842\n",
      "Epoch 3280: val_loss improved from 1.25580 to 1.25402, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.6439 - accuracy: 0.7842 - val_loss: 1.2540 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3281/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.7759\n",
      "Epoch 3281: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5943 - accuracy: 0.7759 - val_loss: 1.2696 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3282/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6103 - accuracy: 0.7866\n",
      "Epoch 3282: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6103 - accuracy: 0.7866 - val_loss: 1.2821 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3283/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.7606\n",
      "Epoch 3283: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6346 - accuracy: 0.7606 - val_loss: 1.2905 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3284/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6256 - accuracy: 0.7748\n",
      "Epoch 3284: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6256 - accuracy: 0.7748 - val_loss: 1.2947 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3285/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6116 - accuracy: 0.7807\n",
      "Epoch 3285: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6116 - accuracy: 0.7807 - val_loss: 1.2995 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3286/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6408 - accuracy: 0.7715\n",
      "Epoch 3286: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.6408 - accuracy: 0.7715 - val_loss: 1.3008 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3287/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6117 - accuracy: 0.7712\n",
      "Epoch 3287: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6117 - accuracy: 0.7712 - val_loss: 1.2915 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3288/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.7936\n",
      "Epoch 3288: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6134 - accuracy: 0.7936 - val_loss: 1.2767 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3289/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.7724\n",
      "Epoch 3289: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6339 - accuracy: 0.7724 - val_loss: 1.2742 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3290/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.7822\n",
      "Epoch 3290: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5852 - accuracy: 0.7822 - val_loss: 1.2856 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3291/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.7771\n",
      "Epoch 3291: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6276 - accuracy: 0.7771 - val_loss: 1.3000 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3292/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.7842\n",
      "Epoch 3292: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6228 - accuracy: 0.7842 - val_loss: 1.3168 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3293/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.7630\n",
      "Epoch 3293: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6357 - accuracy: 0.7630 - val_loss: 1.3221 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3294/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.7842\n",
      "Epoch 3294: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6096 - accuracy: 0.7842 - val_loss: 1.3271 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3295/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.7877\n",
      "Epoch 3295: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6211 - accuracy: 0.7877 - val_loss: 1.3368 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3296/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.7948\n",
      "Epoch 3296: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5818 - accuracy: 0.7948 - val_loss: 1.3469 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3297/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7476\n",
      "Epoch 3297: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6462 - accuracy: 0.7476 - val_loss: 1.3596 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3298/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.7866\n",
      "Epoch 3298: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6195 - accuracy: 0.7866 - val_loss: 1.3692 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3299/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.7665\n",
      "Epoch 3299: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6900 - accuracy: 0.7665 - val_loss: 1.3719 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3300/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6295 - accuracy: 0.7822\n",
      "Epoch 3300: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.6295 - accuracy: 0.7822 - val_loss: 1.3739 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3301/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.7677\n",
      "Epoch 3301: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6330 - accuracy: 0.7677 - val_loss: 1.3752 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3302/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6795 - accuracy: 0.7676\n",
      "Epoch 3302: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.6795 - accuracy: 0.7676 - val_loss: 1.3748 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3303/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.8042\n",
      "Epoch 3303: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.5847 - accuracy: 0.8042 - val_loss: 1.3791 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3304/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.7606\n",
      "Epoch 3304: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6338 - accuracy: 0.7606 - val_loss: 1.3788 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3305/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.7712\n",
      "Epoch 3305: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6251 - accuracy: 0.7712 - val_loss: 1.3749 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3306/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6092 - accuracy: 0.7866\n",
      "Epoch 3306: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6092 - accuracy: 0.7866 - val_loss: 1.3834 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3307/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.7842\n",
      "Epoch 3307: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6120 - accuracy: 0.7842 - val_loss: 1.3844 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3308/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.7712\n",
      "Epoch 3308: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6185 - accuracy: 0.7712 - val_loss: 1.3983 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3309/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6103 - accuracy: 0.7925\n",
      "Epoch 3309: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6103 - accuracy: 0.7925 - val_loss: 1.4033 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3310/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.7666\n",
      "Epoch 3310: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6402 - accuracy: 0.7666 - val_loss: 1.3980 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3311/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6069 - accuracy: 0.7960\n",
      "Epoch 3311: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6069 - accuracy: 0.7960 - val_loss: 1.3848 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3312/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.7736\n",
      "Epoch 3312: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6215 - accuracy: 0.7736 - val_loss: 1.3666 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3313/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.7925\n",
      "Epoch 3313: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5990 - accuracy: 0.7925 - val_loss: 1.3595 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3314/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.7724\n",
      "Epoch 3314: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6101 - accuracy: 0.7724 - val_loss: 1.3587 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3315/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.7771\n",
      "Epoch 3315: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6343 - accuracy: 0.7771 - val_loss: 1.3580 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3316/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6477 - accuracy: 0.7783\n",
      "Epoch 3316: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6477 - accuracy: 0.7783 - val_loss: 1.3651 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3317/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6646 - accuracy: 0.7535\n",
      "Epoch 3317: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6646 - accuracy: 0.7535 - val_loss: 1.3717 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3318/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.7715\n",
      "Epoch 3318: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6349 - accuracy: 0.7715 - val_loss: 1.3820 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3319/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7783\n",
      "Epoch 3319: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6352 - accuracy: 0.7783 - val_loss: 1.3959 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3320/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.7759\n",
      "Epoch 3320: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6112 - accuracy: 0.7759 - val_loss: 1.3993 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3321/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6148 - accuracy: 0.8031\n",
      "Epoch 3321: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6148 - accuracy: 0.8031 - val_loss: 1.3904 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3322/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.7700\n",
      "Epoch 3322: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6302 - accuracy: 0.7700 - val_loss: 1.3706 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3323/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.7783\n",
      "Epoch 3323: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6169 - accuracy: 0.7783 - val_loss: 1.3681 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3324/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.7832\n",
      "Epoch 3324: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6028 - accuracy: 0.7832 - val_loss: 1.3542 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3325/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6433 - accuracy: 0.7842\n",
      "Epoch 3325: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6433 - accuracy: 0.7842 - val_loss: 1.3498 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3326/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.7734\n",
      "Epoch 3326: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.6342 - accuracy: 0.7734 - val_loss: 1.3406 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3327/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.7759\n",
      "Epoch 3327: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6344 - accuracy: 0.7759 - val_loss: 1.3352 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3328/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.7653\n",
      "Epoch 3328: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6372 - accuracy: 0.7653 - val_loss: 1.3352 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3329/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.7736\n",
      "Epoch 3329: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6268 - accuracy: 0.7736 - val_loss: 1.3396 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3330/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.7736\n",
      "Epoch 3330: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6022 - accuracy: 0.7736 - val_loss: 1.3406 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3331/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.7700\n",
      "Epoch 3331: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6236 - accuracy: 0.7700 - val_loss: 1.3430 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3332/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6245 - accuracy: 0.7689\n",
      "Epoch 3332: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6245 - accuracy: 0.7689 - val_loss: 1.3497 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3333/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.7861\n",
      "Epoch 3333: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6193 - accuracy: 0.7861 - val_loss: 1.3456 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3334/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.7700\n",
      "Epoch 3334: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6070 - accuracy: 0.7700 - val_loss: 1.3570 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3335/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.7748\n",
      "Epoch 3335: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6334 - accuracy: 0.7748 - val_loss: 1.3710 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3336/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.7818\n",
      "Epoch 3336: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6061 - accuracy: 0.7818 - val_loss: 1.3741 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3337/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.7901\n",
      "Epoch 3337: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6387 - accuracy: 0.7901 - val_loss: 1.3727 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3338/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.7866\n",
      "Epoch 3338: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6023 - accuracy: 0.7866 - val_loss: 1.3759 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3339/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.7783\n",
      "Epoch 3339: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6241 - accuracy: 0.7783 - val_loss: 1.3748 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3340/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.7871\n",
      "Epoch 3340: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.6330 - accuracy: 0.7871 - val_loss: 1.3698 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3341/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6048 - accuracy: 0.7960\n",
      "Epoch 3341: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6048 - accuracy: 0.7960 - val_loss: 1.3630 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3342/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.7795\n",
      "Epoch 3342: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6355 - accuracy: 0.7795 - val_loss: 1.3653 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3343/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.8042\n",
      "Epoch 3343: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5998 - accuracy: 0.8042 - val_loss: 1.3608 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3344/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.7783\n",
      "Epoch 3344: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5926 - accuracy: 0.7783 - val_loss: 1.3584 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3345/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.7877\n",
      "Epoch 3345: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.6179 - accuracy: 0.7877 - val_loss: 1.3544 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3346/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.7594\n",
      "Epoch 3346: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6435 - accuracy: 0.7594 - val_loss: 1.3503 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3347/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.7822\n",
      "Epoch 3347: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.6482 - accuracy: 0.7822 - val_loss: 1.3422 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3348/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6017 - accuracy: 0.7948\n",
      "Epoch 3348: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6017 - accuracy: 0.7948 - val_loss: 1.3400 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3349/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6009 - accuracy: 0.7783\n",
      "Epoch 3349: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6009 - accuracy: 0.7783 - val_loss: 1.3254 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3350/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.7830\n",
      "Epoch 3350: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6073 - accuracy: 0.7830 - val_loss: 1.3197 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3351/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.7606\n",
      "Epoch 3351: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6446 - accuracy: 0.7606 - val_loss: 1.3188 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3352/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6006 - accuracy: 0.7866\n",
      "Epoch 3352: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6006 - accuracy: 0.7866 - val_loss: 1.3226 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3353/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.7594\n",
      "Epoch 3353: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6372 - accuracy: 0.7594 - val_loss: 1.3100 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3354/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.7748\n",
      "Epoch 3354: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6321 - accuracy: 0.7748 - val_loss: 1.2904 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3355/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.7736\n",
      "Epoch 3355: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6281 - accuracy: 0.7736 - val_loss: 1.2939 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3356/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.7653\n",
      "Epoch 3356: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6517 - accuracy: 0.7653 - val_loss: 1.3139 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3357/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.7512\n",
      "Epoch 3357: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6709 - accuracy: 0.7512 - val_loss: 1.3189 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3358/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.7983\n",
      "Epoch 3358: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5756 - accuracy: 0.7983 - val_loss: 1.3231 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3359/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.7606\n",
      "Epoch 3359: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6435 - accuracy: 0.7606 - val_loss: 1.3176 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3360/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.7653\n",
      "Epoch 3360: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6436 - accuracy: 0.7653 - val_loss: 1.3126 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3361/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.7822\n",
      "Epoch 3361: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.6123 - accuracy: 0.7822 - val_loss: 1.3064 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3362/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6087 - accuracy: 0.8019\n",
      "Epoch 3362: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6087 - accuracy: 0.8019 - val_loss: 1.3061 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3363/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.7795\n",
      "Epoch 3363: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6165 - accuracy: 0.7795 - val_loss: 1.3089 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3364/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.7830\n",
      "Epoch 3364: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.5913 - accuracy: 0.7830 - val_loss: 1.3041 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3365/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5977 - accuracy: 0.7807\n",
      "Epoch 3365: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5977 - accuracy: 0.7807 - val_loss: 1.2872 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3366/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.7925\n",
      "Epoch 3366: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6098 - accuracy: 0.7925 - val_loss: 1.2756 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3367/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7842\n",
      "Epoch 3367: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6127 - accuracy: 0.7842 - val_loss: 1.2651 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3368/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6526 - accuracy: 0.7689\n",
      "Epoch 3368: val_loss did not improve from 1.25402\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6526 - accuracy: 0.7689 - val_loss: 1.2563 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3369/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.7795\n",
      "Epoch 3369: val_loss improved from 1.25402 to 1.24533, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6061 - accuracy: 0.7795 - val_loss: 1.2453 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3370/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.7695\n",
      "Epoch 3370: val_loss improved from 1.24533 to 1.24074, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.6333 - accuracy: 0.7695 - val_loss: 1.2407 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3371/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.7889\n",
      "Epoch 3371: val_loss did not improve from 1.24074\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5969 - accuracy: 0.7889 - val_loss: 1.2425 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3372/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.7832\n",
      "Epoch 3372: val_loss did not improve from 1.24074\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.5981 - accuracy: 0.7832 - val_loss: 1.2453 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3373/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6051 - accuracy: 0.7771\n",
      "Epoch 3373: val_loss improved from 1.24074 to 1.24062, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6051 - accuracy: 0.7771 - val_loss: 1.2406 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3374/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.7594\n",
      "Epoch 3374: val_loss did not improve from 1.24062\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6503 - accuracy: 0.7594 - val_loss: 1.2416 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3375/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.7818\n",
      "Epoch 3375: val_loss improved from 1.24062 to 1.22758, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6080 - accuracy: 0.7818 - val_loss: 1.2276 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3376/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.7995\n",
      "Epoch 3376: val_loss improved from 1.22758 to 1.20414, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5907 - accuracy: 0.7995 - val_loss: 1.2041 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3377/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.7983\n",
      "Epoch 3377: val_loss improved from 1.20414 to 1.19180, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6003 - accuracy: 0.7983 - val_loss: 1.1918 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3378/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.7818\n",
      "Epoch 3378: val_loss improved from 1.19180 to 1.18750, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6136 - accuracy: 0.7818 - val_loss: 1.1875 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 3379/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5828 - accuracy: 0.7854\n",
      "Epoch 3379: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5828 - accuracy: 0.7854 - val_loss: 1.1886 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3380/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7689\n",
      "Epoch 3380: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6127 - accuracy: 0.7689 - val_loss: 1.1959 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3381/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.7866\n",
      "Epoch 3381: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.5959 - accuracy: 0.7866 - val_loss: 1.2139 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3382/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.7724\n",
      "Epoch 3382: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6388 - accuracy: 0.7724 - val_loss: 1.2383 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3383/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.7901\n",
      "Epoch 3383: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5968 - accuracy: 0.7901 - val_loss: 1.2607 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3384/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.7700\n",
      "Epoch 3384: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6161 - accuracy: 0.7700 - val_loss: 1.2822 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3385/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.7771\n",
      "Epoch 3385: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6258 - accuracy: 0.7771 - val_loss: 1.2989 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3386/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.7642\n",
      "Epoch 3386: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6155 - accuracy: 0.7642 - val_loss: 1.3145 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3387/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.7712\n",
      "Epoch 3387: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6463 - accuracy: 0.7712 - val_loss: 1.3199 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3388/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.7795\n",
      "Epoch 3388: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6238 - accuracy: 0.7795 - val_loss: 1.3218 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3389/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.8007\n",
      "Epoch 3389: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.5970 - accuracy: 0.8007 - val_loss: 1.3124 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3390/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6444 - accuracy: 0.7630\n",
      "Epoch 3390: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6444 - accuracy: 0.7630 - val_loss: 1.3135 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3391/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.7891\n",
      "Epoch 3391: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6207 - accuracy: 0.7891 - val_loss: 1.3113 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3392/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.7803\n",
      "Epoch 3392: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.6131 - accuracy: 0.7803 - val_loss: 1.3008 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3393/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.7871\n",
      "Epoch 3393: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.6225 - accuracy: 0.7871 - val_loss: 1.2978 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3394/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6058 - accuracy: 0.7877\n",
      "Epoch 3394: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6058 - accuracy: 0.7877 - val_loss: 1.3038 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3395/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.7736\n",
      "Epoch 3395: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6302 - accuracy: 0.7736 - val_loss: 1.3165 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3396/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6278 - accuracy: 0.7695\n",
      "Epoch 3396: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6278 - accuracy: 0.7695 - val_loss: 1.3295 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3397/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.7754\n",
      "Epoch 3397: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6177 - accuracy: 0.7754 - val_loss: 1.3248 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3398/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6053 - accuracy: 0.7901\n",
      "Epoch 3398: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6053 - accuracy: 0.7901 - val_loss: 1.3112 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3399/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.7748\n",
      "Epoch 3399: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6280 - accuracy: 0.7748 - val_loss: 1.3093 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3400/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.7936\n",
      "Epoch 3400: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5960 - accuracy: 0.7936 - val_loss: 1.3090 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3401/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.7665\n",
      "Epoch 3401: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6013 - accuracy: 0.7665 - val_loss: 1.3122 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3402/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.7759\n",
      "Epoch 3402: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6348 - accuracy: 0.7759 - val_loss: 1.3268 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3403/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.7759\n",
      "Epoch 3403: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.5928 - accuracy: 0.7759 - val_loss: 1.3556 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3404/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.7854\n",
      "Epoch 3404: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.5939 - accuracy: 0.7854 - val_loss: 1.3830 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3405/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.7910\n",
      "Epoch 3405: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6064 - accuracy: 0.7910 - val_loss: 1.4003 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3406/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5997 - accuracy: 0.7854\n",
      "Epoch 3406: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.5997 - accuracy: 0.7854 - val_loss: 1.3916 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3407/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5872 - accuracy: 0.7948\n",
      "Epoch 3407: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.5872 - accuracy: 0.7948 - val_loss: 1.3842 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3408/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.7807\n",
      "Epoch 3408: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6013 - accuracy: 0.7807 - val_loss: 1.3900 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3409/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.7803\n",
      "Epoch 3409: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6090 - accuracy: 0.7803 - val_loss: 1.4005 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3410/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.7877\n",
      "Epoch 3410: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.5956 - accuracy: 0.7877 - val_loss: 1.3968 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3411/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.7488\n",
      "Epoch 3411: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6449 - accuracy: 0.7488 - val_loss: 1.3828 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3412/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5905 - accuracy: 0.7900\n",
      "Epoch 3412: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5905 - accuracy: 0.7900 - val_loss: 1.3682 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3413/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.7830\n",
      "Epoch 3413: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6121 - accuracy: 0.7830 - val_loss: 1.3624 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3414/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.7877\n",
      "Epoch 3414: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6163 - accuracy: 0.7877 - val_loss: 1.3625 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3415/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5888 - accuracy: 0.8090\n",
      "Epoch 3415: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5888 - accuracy: 0.8090 - val_loss: 1.3563 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3416/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.7822\n",
      "Epoch 3416: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.5994 - accuracy: 0.7822 - val_loss: 1.3588 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3417/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.7900\n",
      "Epoch 3417: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.5857 - accuracy: 0.7900 - val_loss: 1.3666 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3418/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.7842\n",
      "Epoch 3418: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6061 - accuracy: 0.7842 - val_loss: 1.3822 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3419/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.7925\n",
      "Epoch 3419: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.5909 - accuracy: 0.7925 - val_loss: 1.4029 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3420/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.7724\n",
      "Epoch 3420: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6338 - accuracy: 0.7724 - val_loss: 1.4150 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3421/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.7842\n",
      "Epoch 3421: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.6118 - accuracy: 0.7842 - val_loss: 1.4184 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3422/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6288 - accuracy: 0.7712\n",
      "Epoch 3422: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6288 - accuracy: 0.7712 - val_loss: 1.4159 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3423/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6210 - accuracy: 0.7759\n",
      "Epoch 3423: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6210 - accuracy: 0.7759 - val_loss: 1.4164 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3424/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.7744\n",
      "Epoch 3424: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.6161 - accuracy: 0.7744 - val_loss: 1.4113 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3425/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6404 - accuracy: 0.7830\n",
      "Epoch 3425: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6404 - accuracy: 0.7830 - val_loss: 1.4063 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3426/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.7771\n",
      "Epoch 3426: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6175 - accuracy: 0.7771 - val_loss: 1.3966 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3427/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6444 - accuracy: 0.7656\n",
      "Epoch 3427: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.6444 - accuracy: 0.7656 - val_loss: 1.3880 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3428/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.7900\n",
      "Epoch 3428: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.6121 - accuracy: 0.7900 - val_loss: 1.3899 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3429/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.8007\n",
      "Epoch 3429: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6130 - accuracy: 0.8007 - val_loss: 1.3825 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3430/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5789 - accuracy: 0.8078\n",
      "Epoch 3430: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.5789 - accuracy: 0.8078 - val_loss: 1.3756 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3431/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.7866\n",
      "Epoch 3431: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6339 - accuracy: 0.7866 - val_loss: 1.3682 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3432/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5874 - accuracy: 0.7972\n",
      "Epoch 3432: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5874 - accuracy: 0.7972 - val_loss: 1.3580 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3433/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.7700\n",
      "Epoch 3433: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6305 - accuracy: 0.7700 - val_loss: 1.3474 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3434/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.7889\n",
      "Epoch 3434: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.5922 - accuracy: 0.7889 - val_loss: 1.3381 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3435/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6216 - accuracy: 0.7854\n",
      "Epoch 3435: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.6216 - accuracy: 0.7854 - val_loss: 1.3327 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3436/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6032 - accuracy: 0.7901\n",
      "Epoch 3436: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6032 - accuracy: 0.7901 - val_loss: 1.3282 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3437/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.7830\n",
      "Epoch 3437: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.5841 - accuracy: 0.7830 - val_loss: 1.3158 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3438/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.7842\n",
      "Epoch 3438: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6112 - accuracy: 0.7842 - val_loss: 1.3109 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3439/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7783\n",
      "Epoch 3439: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6088 - accuracy: 0.7783 - val_loss: 1.3057 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3440/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.7822\n",
      "Epoch 3440: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6101 - accuracy: 0.7822 - val_loss: 1.2906 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3441/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.7852\n",
      "Epoch 3441: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.5893 - accuracy: 0.7852 - val_loss: 1.2825 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3442/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5993 - accuracy: 0.7948\n",
      "Epoch 3442: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.5993 - accuracy: 0.7948 - val_loss: 1.2724 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3443/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.7818\n",
      "Epoch 3443: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6144 - accuracy: 0.7818 - val_loss: 1.2678 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3444/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6389 - accuracy: 0.7630\n",
      "Epoch 3444: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6389 - accuracy: 0.7630 - val_loss: 1.2623 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3445/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6100 - accuracy: 0.7818\n",
      "Epoch 3445: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6100 - accuracy: 0.7818 - val_loss: 1.2670 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3446/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.7783\n",
      "Epoch 3446: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6387 - accuracy: 0.7783 - val_loss: 1.2672 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3447/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.7715\n",
      "Epoch 3447: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6078 - accuracy: 0.7715 - val_loss: 1.2669 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3448/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6190 - accuracy: 0.7724\n",
      "Epoch 3448: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6190 - accuracy: 0.7724 - val_loss: 1.2693 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3449/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.7925\n",
      "Epoch 3449: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.5991 - accuracy: 0.7925 - val_loss: 1.2751 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3450/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.7700\n",
      "Epoch 3450: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.6307 - accuracy: 0.7700 - val_loss: 1.2820 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3451/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.7700\n",
      "Epoch 3451: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6436 - accuracy: 0.7700 - val_loss: 1.2884 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3452/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7665\n",
      "Epoch 3452: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6462 - accuracy: 0.7665 - val_loss: 1.2788 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3453/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.7995\n",
      "Epoch 3453: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6028 - accuracy: 0.7995 - val_loss: 1.2752 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3454/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.7913\n",
      "Epoch 3454: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.5792 - accuracy: 0.7913 - val_loss: 1.2640 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3455/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.7744\n",
      "Epoch 3455: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.6338 - accuracy: 0.7744 - val_loss: 1.2568 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3456/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6369 - accuracy: 0.7830\n",
      "Epoch 3456: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6369 - accuracy: 0.7830 - val_loss: 1.2448 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3457/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.7653\n",
      "Epoch 3457: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6357 - accuracy: 0.7653 - val_loss: 1.2272 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3458/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5952 - accuracy: 0.7818\n",
      "Epoch 3458: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.5952 - accuracy: 0.7818 - val_loss: 1.2166 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3459/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.7901\n",
      "Epoch 3459: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5929 - accuracy: 0.7901 - val_loss: 1.2184 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3460/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.7842\n",
      "Epoch 3460: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6264 - accuracy: 0.7842 - val_loss: 1.2196 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3461/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.7700\n",
      "Epoch 3461: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6106 - accuracy: 0.7700 - val_loss: 1.2284 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3462/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.8031\n",
      "Epoch 3462: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.5866 - accuracy: 0.8031 - val_loss: 1.2516 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3463/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.7642\n",
      "Epoch 3463: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6316 - accuracy: 0.7642 - val_loss: 1.2728 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3464/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.7842\n",
      "Epoch 3464: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6055 - accuracy: 0.7842 - val_loss: 1.2888 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3465/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6527 - accuracy: 0.7627\n",
      "Epoch 3465: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.6527 - accuracy: 0.7627 - val_loss: 1.2945 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3466/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.7689\n",
      "Epoch 3466: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.6377 - accuracy: 0.7689 - val_loss: 1.2917 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3467/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.7771\n",
      "Epoch 3467: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6236 - accuracy: 0.7771 - val_loss: 1.2779 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3468/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.7830\n",
      "Epoch 3468: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6123 - accuracy: 0.7830 - val_loss: 1.2613 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3469/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6004 - accuracy: 0.7910\n",
      "Epoch 3469: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.6004 - accuracy: 0.7910 - val_loss: 1.2612 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3470/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6145 - accuracy: 0.7830\n",
      "Epoch 3470: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6145 - accuracy: 0.7830 - val_loss: 1.2624 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3471/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6140 - accuracy: 0.7830\n",
      "Epoch 3471: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6140 - accuracy: 0.7830 - val_loss: 1.2677 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3472/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.7842\n",
      "Epoch 3472: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6185 - accuracy: 0.7842 - val_loss: 1.2742 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3473/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.7759\n",
      "Epoch 3473: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.6396 - accuracy: 0.7759 - val_loss: 1.2892 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3474/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.7724\n",
      "Epoch 3474: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.6173 - accuracy: 0.7724 - val_loss: 1.2997 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3475/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5920 - accuracy: 0.7936\n",
      "Epoch 3475: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5920 - accuracy: 0.7936 - val_loss: 1.3173 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3476/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7889\n",
      "Epoch 3476: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5973 - accuracy: 0.7889 - val_loss: 1.3355 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3477/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.7795\n",
      "Epoch 3477: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6002 - accuracy: 0.7795 - val_loss: 1.3468 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3478/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.7653\n",
      "Epoch 3478: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.6341 - accuracy: 0.7653 - val_loss: 1.3472 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3479/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.7807\n",
      "Epoch 3479: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6007 - accuracy: 0.7807 - val_loss: 1.3441 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3480/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.7695\n",
      "Epoch 3480: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6174 - accuracy: 0.7695 - val_loss: 1.3429 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3481/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.7822\n",
      "Epoch 3481: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.6121 - accuracy: 0.7822 - val_loss: 1.3586 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3482/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.7783\n",
      "Epoch 3482: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.6035 - accuracy: 0.7783 - val_loss: 1.3647 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3483/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6245 - accuracy: 0.7783\n",
      "Epoch 3483: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.6245 - accuracy: 0.7783 - val_loss: 1.3582 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3484/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5804 - accuracy: 0.7818\n",
      "Epoch 3484: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.5804 - accuracy: 0.7818 - val_loss: 1.3411 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3485/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5773 - accuracy: 0.7939\n",
      "Epoch 3485: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.5773 - accuracy: 0.7939 - val_loss: 1.3284 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3486/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6392 - accuracy: 0.7724\n",
      "Epoch 3486: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6392 - accuracy: 0.7724 - val_loss: 1.3271 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3487/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.7783\n",
      "Epoch 3487: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 2s 270ms/step - loss: 0.6107 - accuracy: 0.7783 - val_loss: 1.3237 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3488/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.7677\n",
      "Epoch 3488: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.6456 - accuracy: 0.7677 - val_loss: 1.3337 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3489/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.7852\n",
      "Epoch 3489: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.6194 - accuracy: 0.7852 - val_loss: 1.3377 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3490/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.7830\n",
      "Epoch 3490: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6047 - accuracy: 0.7830 - val_loss: 1.3377 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3491/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.7771\n",
      "Epoch 3491: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6259 - accuracy: 0.7771 - val_loss: 1.3197 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3492/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.7712\n",
      "Epoch 3492: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.6102 - accuracy: 0.7712 - val_loss: 1.2905 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3493/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.7807\n",
      "Epoch 3493: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6050 - accuracy: 0.7807 - val_loss: 1.2711 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3494/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.7936\n",
      "Epoch 3494: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.5917 - accuracy: 0.7936 - val_loss: 1.2553 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3495/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5819 - accuracy: 0.8007\n",
      "Epoch 3495: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.5819 - accuracy: 0.8007 - val_loss: 1.2367 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3496/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.7930\n",
      "Epoch 3496: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6052 - accuracy: 0.7930 - val_loss: 1.2350 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3497/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.7744\n",
      "Epoch 3497: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6075 - accuracy: 0.7744 - val_loss: 1.2334 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3498/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.8007\n",
      "Epoch 3498: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5941 - accuracy: 0.8007 - val_loss: 1.2236 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3499/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.7854\n",
      "Epoch 3499: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.5869 - accuracy: 0.7854 - val_loss: 1.2277 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3500/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.7783\n",
      "Epoch 3500: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6193 - accuracy: 0.7783 - val_loss: 1.2380 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3501/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.7988\n",
      "Epoch 3501: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6215 - accuracy: 0.7988 - val_loss: 1.2476 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3502/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.8008\n",
      "Epoch 3502: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5999 - accuracy: 0.8008 - val_loss: 1.2614 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3503/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.7795\n",
      "Epoch 3503: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.6086 - accuracy: 0.7795 - val_loss: 1.2819 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3504/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.7759\n",
      "Epoch 3504: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.6159 - accuracy: 0.7759 - val_loss: 1.2890 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3505/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7822\n",
      "Epoch 3505: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6088 - accuracy: 0.7822 - val_loss: 1.2906 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3506/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5932 - accuracy: 0.7842\n",
      "Epoch 3506: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.5932 - accuracy: 0.7842 - val_loss: 1.2858 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3507/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.7771\n",
      "Epoch 3507: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.6316 - accuracy: 0.7771 - val_loss: 1.2722 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3508/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6310 - accuracy: 0.7606\n",
      "Epoch 3508: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6310 - accuracy: 0.7606 - val_loss: 1.2594 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3509/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.7842\n",
      "Epoch 3509: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.6177 - accuracy: 0.7842 - val_loss: 1.2554 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3510/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5811 - accuracy: 0.8007\n",
      "Epoch 3510: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5811 - accuracy: 0.8007 - val_loss: 1.2526 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3511/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6043 - accuracy: 0.7842\n",
      "Epoch 3511: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6043 - accuracy: 0.7842 - val_loss: 1.2478 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3512/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.8066\n",
      "Epoch 3512: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5798 - accuracy: 0.8066 - val_loss: 1.2547 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3513/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.8007\n",
      "Epoch 3513: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.5964 - accuracy: 0.8007 - val_loss: 1.2689 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3514/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.7630\n",
      "Epoch 3514: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.6260 - accuracy: 0.7630 - val_loss: 1.2704 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3515/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.7748\n",
      "Epoch 3515: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.6021 - accuracy: 0.7748 - val_loss: 1.2690 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3516/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5925 - accuracy: 0.7891\n",
      "Epoch 3516: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.5925 - accuracy: 0.7891 - val_loss: 1.2703 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3517/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.7889\n",
      "Epoch 3517: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.6156 - accuracy: 0.7889 - val_loss: 1.2748 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3518/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.7759\n",
      "Epoch 3518: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.6151 - accuracy: 0.7759 - val_loss: 1.2803 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3519/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.7854\n",
      "Epoch 3519: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5971 - accuracy: 0.7854 - val_loss: 1.2847 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3520/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5967 - accuracy: 0.7665\n",
      "Epoch 3520: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.5967 - accuracy: 0.7665 - val_loss: 1.3016 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3521/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.7948\n",
      "Epoch 3521: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6091 - accuracy: 0.7948 - val_loss: 1.3125 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3522/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.7948\n",
      "Epoch 3522: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.5792 - accuracy: 0.7948 - val_loss: 1.3270 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3523/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.7920\n",
      "Epoch 3523: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5926 - accuracy: 0.7920 - val_loss: 1.3383 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3524/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.7818\n",
      "Epoch 3524: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.6045 - accuracy: 0.7818 - val_loss: 1.3449 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3525/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.7807\n",
      "Epoch 3525: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.6046 - accuracy: 0.7807 - val_loss: 1.3358 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3526/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5912 - accuracy: 0.7901\n",
      "Epoch 3526: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.5912 - accuracy: 0.7901 - val_loss: 1.3342 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3527/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5987 - accuracy: 0.7842\n",
      "Epoch 3527: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.5987 - accuracy: 0.7842 - val_loss: 1.3272 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3528/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.7949\n",
      "Epoch 3528: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6039 - accuracy: 0.7949 - val_loss: 1.3316 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3529/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.7877\n",
      "Epoch 3529: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5917 - accuracy: 0.7877 - val_loss: 1.3310 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3530/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6057 - accuracy: 0.7712\n",
      "Epoch 3530: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6057 - accuracy: 0.7712 - val_loss: 1.3510 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3531/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7936\n",
      "Epoch 3531: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.5660 - accuracy: 0.7936 - val_loss: 1.3781 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3532/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.7795\n",
      "Epoch 3532: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.6076 - accuracy: 0.7795 - val_loss: 1.3922 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3533/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6404 - accuracy: 0.7736\n",
      "Epoch 3533: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.6404 - accuracy: 0.7736 - val_loss: 1.3945 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3534/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.7972\n",
      "Epoch 3534: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.5876 - accuracy: 0.7972 - val_loss: 1.3999 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3535/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.7901\n",
      "Epoch 3535: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6076 - accuracy: 0.7901 - val_loss: 1.4033 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3536/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6057 - accuracy: 0.7759\n",
      "Epoch 3536: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.6057 - accuracy: 0.7759 - val_loss: 1.4039 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3537/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.7891\n",
      "Epoch 3537: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5846 - accuracy: 0.7891 - val_loss: 1.4060 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 3538/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.7759\n",
      "Epoch 3538: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 9s 3s/step - loss: 0.6130 - accuracy: 0.7759 - val_loss: 1.3902 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3539/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6448 - accuracy: 0.7653\n",
      "Epoch 3539: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 2s 364ms/step - loss: 0.6448 - accuracy: 0.7653 - val_loss: 1.3809 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3540/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.7793\n",
      "Epoch 3540: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.6227 - accuracy: 0.7793 - val_loss: 1.3734 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3541/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.7936\n",
      "Epoch 3541: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.5870 - accuracy: 0.7936 - val_loss: 1.3649 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3542/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.8125\n",
      "Epoch 3542: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5913 - accuracy: 0.8125 - val_loss: 1.3482 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3543/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.7901\n",
      "Epoch 3543: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5934 - accuracy: 0.7901 - val_loss: 1.3405 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3544/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.7689\n",
      "Epoch 3544: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6070 - accuracy: 0.7689 - val_loss: 1.3428 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3545/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.7653\n",
      "Epoch 3545: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.6382 - accuracy: 0.7653 - val_loss: 1.3267 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3546/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.7795\n",
      "Epoch 3546: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6191 - accuracy: 0.7795 - val_loss: 1.3041 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3547/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.7913\n",
      "Epoch 3547: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.6179 - accuracy: 0.7913 - val_loss: 1.2853 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3548/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.7807\n",
      "Epoch 3548: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 0.6461 - accuracy: 0.7807 - val_loss: 1.2664 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3549/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.7960\n",
      "Epoch 3549: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5768 - accuracy: 0.7960 - val_loss: 1.2559 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3550/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.7736\n",
      "Epoch 3550: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6228 - accuracy: 0.7736 - val_loss: 1.2564 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3551/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.7734\n",
      "Epoch 3551: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.6138 - accuracy: 0.7734 - val_loss: 1.2599 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3552/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.7936\n",
      "Epoch 3552: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5960 - accuracy: 0.7936 - val_loss: 1.2584 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3553/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.7910\n",
      "Epoch 3553: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.5671 - accuracy: 0.7910 - val_loss: 1.2624 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3554/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.7773\n",
      "Epoch 3554: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 345ms/step - loss: 0.6130 - accuracy: 0.7773 - val_loss: 1.2739 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3555/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5721 - accuracy: 0.8078\n",
      "Epoch 3555: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.5721 - accuracy: 0.8078 - val_loss: 1.2785 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3556/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.7783\n",
      "Epoch 3556: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6091 - accuracy: 0.7783 - val_loss: 1.2794 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3557/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.7830\n",
      "Epoch 3557: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6317 - accuracy: 0.7830 - val_loss: 1.2806 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3558/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6389 - accuracy: 0.7653\n",
      "Epoch 3558: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.6389 - accuracy: 0.7653 - val_loss: 1.2785 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3559/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.7925\n",
      "Epoch 3559: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5935 - accuracy: 0.7925 - val_loss: 1.2863 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3560/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.7724\n",
      "Epoch 3560: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.6134 - accuracy: 0.7724 - val_loss: 1.3081 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3561/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.7920\n",
      "Epoch 3561: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5990 - accuracy: 0.7920 - val_loss: 1.3228 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3562/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.7830\n",
      "Epoch 3562: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.5959 - accuracy: 0.7830 - val_loss: 1.3271 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3563/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7930\n",
      "Epoch 3563: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5641 - accuracy: 0.7930 - val_loss: 1.3439 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3564/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.7783\n",
      "Epoch 3564: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.6336 - accuracy: 0.7783 - val_loss: 1.3660 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3565/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.7748\n",
      "Epoch 3565: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.6112 - accuracy: 0.7748 - val_loss: 1.3600 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3566/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.7995\n",
      "Epoch 3566: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6019 - accuracy: 0.7995 - val_loss: 1.3496 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3567/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.7866\n",
      "Epoch 3567: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.5865 - accuracy: 0.7866 - val_loss: 1.3453 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3568/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.7889\n",
      "Epoch 3568: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.6066 - accuracy: 0.7889 - val_loss: 1.3431 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3569/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.8042\n",
      "Epoch 3569: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 0.6007 - accuracy: 0.8042 - val_loss: 1.3409 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3570/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.7606\n",
      "Epoch 3570: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6381 - accuracy: 0.7606 - val_loss: 1.3396 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3571/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.7842\n",
      "Epoch 3571: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.6111 - accuracy: 0.7842 - val_loss: 1.3413 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3572/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.7818\n",
      "Epoch 3572: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.6002 - accuracy: 0.7818 - val_loss: 1.3454 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3573/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5748 - accuracy: 0.7913\n",
      "Epoch 3573: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5748 - accuracy: 0.7913 - val_loss: 1.3413 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3574/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.7677\n",
      "Epoch 3574: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6037 - accuracy: 0.7677 - val_loss: 1.3276 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3575/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.7795\n",
      "Epoch 3575: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.6206 - accuracy: 0.7795 - val_loss: 1.3118 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3576/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.8007\n",
      "Epoch 3576: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.5757 - accuracy: 0.8007 - val_loss: 1.3004 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3577/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.7925\n",
      "Epoch 3577: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.5792 - accuracy: 0.7925 - val_loss: 1.2856 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3578/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.7889\n",
      "Epoch 3578: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.5870 - accuracy: 0.7889 - val_loss: 1.2709 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3579/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.7712\n",
      "Epoch 3579: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.6325 - accuracy: 0.7712 - val_loss: 1.2655 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3580/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.7877\n",
      "Epoch 3580: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5878 - accuracy: 0.7877 - val_loss: 1.2745 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3581/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5911 - accuracy: 0.7818\n",
      "Epoch 3581: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.5911 - accuracy: 0.7818 - val_loss: 1.2990 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3582/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5773 - accuracy: 0.8007\n",
      "Epoch 3582: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.5773 - accuracy: 0.8007 - val_loss: 1.3212 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3583/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5877 - accuracy: 0.7920\n",
      "Epoch 3583: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.5877 - accuracy: 0.7920 - val_loss: 1.3359 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3584/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6230 - accuracy: 0.7803\n",
      "Epoch 3584: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6230 - accuracy: 0.7803 - val_loss: 1.3474 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3585/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.7665\n",
      "Epoch 3585: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6334 - accuracy: 0.7665 - val_loss: 1.3436 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3586/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.7807\n",
      "Epoch 3586: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6096 - accuracy: 0.7807 - val_loss: 1.3268 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3587/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.7705\n",
      "Epoch 3587: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.6138 - accuracy: 0.7705 - val_loss: 1.3132 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3588/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.7830\n",
      "Epoch 3588: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.5914 - accuracy: 0.7830 - val_loss: 1.2986 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3589/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5887 - accuracy: 0.7866\n",
      "Epoch 3589: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.5887 - accuracy: 0.7866 - val_loss: 1.2918 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3590/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.7830\n",
      "Epoch 3590: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6262 - accuracy: 0.7830 - val_loss: 1.2942 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3591/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.7807\n",
      "Epoch 3591: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.5944 - accuracy: 0.7807 - val_loss: 1.2874 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3592/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5770 - accuracy: 0.8019\n",
      "Epoch 3592: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.5770 - accuracy: 0.8019 - val_loss: 1.2811 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3593/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.7771\n",
      "Epoch 3593: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6232 - accuracy: 0.7771 - val_loss: 1.2716 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3594/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.7677\n",
      "Epoch 3594: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6284 - accuracy: 0.7677 - val_loss: 1.2627 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3595/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5811 - accuracy: 0.8066\n",
      "Epoch 3595: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5811 - accuracy: 0.8066 - val_loss: 1.2504 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3596/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.7949\n",
      "Epoch 3596: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5935 - accuracy: 0.7949 - val_loss: 1.2454 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3597/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5979 - accuracy: 0.7913\n",
      "Epoch 3597: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5979 - accuracy: 0.7913 - val_loss: 1.2223 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3598/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.7818\n",
      "Epoch 3598: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6028 - accuracy: 0.7818 - val_loss: 1.2122 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3599/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.7913\n",
      "Epoch 3599: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5941 - accuracy: 0.7913 - val_loss: 1.2045 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3600/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6060 - accuracy: 0.7736\n",
      "Epoch 3600: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6060 - accuracy: 0.7736 - val_loss: 1.2098 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3601/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.7959\n",
      "Epoch 3601: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5647 - accuracy: 0.7959 - val_loss: 1.2141 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3602/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7822\n",
      "Epoch 3602: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.6042 - accuracy: 0.7822 - val_loss: 1.2210 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3603/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.7795\n",
      "Epoch 3603: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6038 - accuracy: 0.7795 - val_loss: 1.2396 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3604/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6199 - accuracy: 0.7734\n",
      "Epoch 3604: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.6199 - accuracy: 0.7734 - val_loss: 1.2657 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3605/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.7998\n",
      "Epoch 3605: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.5893 - accuracy: 0.7998 - val_loss: 1.2895 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3606/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.7925\n",
      "Epoch 3606: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.6062 - accuracy: 0.7925 - val_loss: 1.3070 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3607/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.7900\n",
      "Epoch 3607: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.5921 - accuracy: 0.7900 - val_loss: 1.3129 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3608/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.7936\n",
      "Epoch 3608: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.5663 - accuracy: 0.7936 - val_loss: 1.3155 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3609/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.8007\n",
      "Epoch 3609: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.5788 - accuracy: 0.8007 - val_loss: 1.3253 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3610/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.8018\n",
      "Epoch 3610: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 0.5913 - accuracy: 0.8018 - val_loss: 1.3415 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3611/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7960\n",
      "Epoch 3611: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.6127 - accuracy: 0.7960 - val_loss: 1.3646 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3612/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.7866\n",
      "Epoch 3612: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.6039 - accuracy: 0.7866 - val_loss: 1.3876 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3613/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.7764\n",
      "Epoch 3613: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 330ms/step - loss: 0.5991 - accuracy: 0.7764 - val_loss: 1.4017 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3614/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5950 - accuracy: 0.7877\n",
      "Epoch 3614: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 334ms/step - loss: 0.5950 - accuracy: 0.7877 - val_loss: 1.4120 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3615/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5872 - accuracy: 0.7920\n",
      "Epoch 3615: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 331ms/step - loss: 0.5872 - accuracy: 0.7920 - val_loss: 1.4100 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3616/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5831 - accuracy: 0.7972\n",
      "Epoch 3616: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.5831 - accuracy: 0.7972 - val_loss: 1.4107 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3617/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.8054\n",
      "Epoch 3617: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 330ms/step - loss: 0.5676 - accuracy: 0.8054 - val_loss: 1.4128 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3618/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.7807\n",
      "Epoch 3618: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.5976 - accuracy: 0.7807 - val_loss: 1.4054 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3619/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.7854\n",
      "Epoch 3619: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.6200 - accuracy: 0.7854 - val_loss: 1.3983 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 3620/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7877\n",
      "Epoch 3620: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5986 - accuracy: 0.7877 - val_loss: 1.3931 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 3621/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7689\n",
      "Epoch 3621: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.6352 - accuracy: 0.7689 - val_loss: 1.3757 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3622/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5910 - accuracy: 0.7877\n",
      "Epoch 3622: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.5910 - accuracy: 0.7877 - val_loss: 1.3623 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3623/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.7948\n",
      "Epoch 3623: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.6078 - accuracy: 0.7948 - val_loss: 1.3422 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3624/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.7712\n",
      "Epoch 3624: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.6387 - accuracy: 0.7712 - val_loss: 1.3118 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3625/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5887 - accuracy: 0.7995\n",
      "Epoch 3625: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.5887 - accuracy: 0.7995 - val_loss: 1.2733 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3626/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6063 - accuracy: 0.7734\n",
      "Epoch 3626: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 327ms/step - loss: 0.6063 - accuracy: 0.7734 - val_loss: 1.2486 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3627/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5932 - accuracy: 0.7913\n",
      "Epoch 3627: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.5932 - accuracy: 0.7913 - val_loss: 1.2311 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3628/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.7830\n",
      "Epoch 3628: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.6015 - accuracy: 0.7830 - val_loss: 1.2265 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3629/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.7795\n",
      "Epoch 3629: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.6290 - accuracy: 0.7795 - val_loss: 1.2205 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3630/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7783\n",
      "Epoch 3630: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 0.5986 - accuracy: 0.7783 - val_loss: 1.2241 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3631/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.7854\n",
      "Epoch 3631: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.6013 - accuracy: 0.7854 - val_loss: 1.2277 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3632/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5720 - accuracy: 0.8066\n",
      "Epoch 3632: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.5720 - accuracy: 0.8066 - val_loss: 1.2229 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3633/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.7630\n",
      "Epoch 3633: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.6135 - accuracy: 0.7630 - val_loss: 1.2156 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3634/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.7830\n",
      "Epoch 3634: val_loss did not improve from 1.18750\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.6152 - accuracy: 0.7830 - val_loss: 1.1894 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3635/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.7948\n",
      "Epoch 3635: val_loss improved from 1.18750 to 1.18184, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.5990 - accuracy: 0.7948 - val_loss: 1.1818 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3636/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.7900\n",
      "Epoch 3636: val_loss improved from 1.18184 to 1.17986, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 0.5974 - accuracy: 0.7900 - val_loss: 1.1799 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3637/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8090\n",
      "Epoch 3637: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.5449 - accuracy: 0.8090 - val_loss: 1.1843 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3638/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.7832\n",
      "Epoch 3638: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.6131 - accuracy: 0.7832 - val_loss: 1.1845 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3639/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5821 - accuracy: 0.7854\n",
      "Epoch 3639: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.5821 - accuracy: 0.7854 - val_loss: 1.1896 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3640/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.7913\n",
      "Epoch 3640: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.6136 - accuracy: 0.7913 - val_loss: 1.1943 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3641/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.7936\n",
      "Epoch 3641: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.5700 - accuracy: 0.7936 - val_loss: 1.2044 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3642/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6311 - accuracy: 0.7877\n",
      "Epoch 3642: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.6311 - accuracy: 0.7877 - val_loss: 1.2020 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3643/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.7783\n",
      "Epoch 3643: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.5994 - accuracy: 0.7783 - val_loss: 1.2036 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3644/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.7818\n",
      "Epoch 3644: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.5902 - accuracy: 0.7818 - val_loss: 1.2088 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3645/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6069 - accuracy: 0.7653\n",
      "Epoch 3645: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.6069 - accuracy: 0.7653 - val_loss: 1.2146 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3646/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5997 - accuracy: 0.7866\n",
      "Epoch 3646: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.5997 - accuracy: 0.7866 - val_loss: 1.2191 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3647/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.7771\n",
      "Epoch 3647: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6135 - accuracy: 0.7771 - val_loss: 1.2286 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3648/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.7665\n",
      "Epoch 3648: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.6353 - accuracy: 0.7665 - val_loss: 1.2386 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3649/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.7936\n",
      "Epoch 3649: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5638 - accuracy: 0.7936 - val_loss: 1.2442 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3650/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.7852\n",
      "Epoch 3650: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.5971 - accuracy: 0.7852 - val_loss: 1.2519 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3651/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.7900\n",
      "Epoch 3651: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.5878 - accuracy: 0.7900 - val_loss: 1.2615 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3652/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5704 - accuracy: 0.8027\n",
      "Epoch 3652: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5704 - accuracy: 0.8027 - val_loss: 1.2800 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3653/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7830\n",
      "Epoch 3653: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5746 - accuracy: 0.7830 - val_loss: 1.3013 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3654/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.7807\n",
      "Epoch 3654: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6322 - accuracy: 0.7807 - val_loss: 1.3166 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3655/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.7795\n",
      "Epoch 3655: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5878 - accuracy: 0.7795 - val_loss: 1.3309 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3656/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.7901\n",
      "Epoch 3656: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5913 - accuracy: 0.7901 - val_loss: 1.3364 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3657/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5814 - accuracy: 0.7877\n",
      "Epoch 3657: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5814 - accuracy: 0.7877 - val_loss: 1.3314 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3658/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5754 - accuracy: 0.7936\n",
      "Epoch 3658: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5754 - accuracy: 0.7936 - val_loss: 1.3055 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3659/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6016 - accuracy: 0.7889\n",
      "Epoch 3659: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.6016 - accuracy: 0.7889 - val_loss: 1.2785 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3660/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.7983\n",
      "Epoch 3660: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.5726 - accuracy: 0.7983 - val_loss: 1.2749 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3661/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.7995\n",
      "Epoch 3661: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.5792 - accuracy: 0.7995 - val_loss: 1.2650 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3662/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5996 - accuracy: 0.7830\n",
      "Epoch 3662: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.5996 - accuracy: 0.7830 - val_loss: 1.2556 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3663/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5894 - accuracy: 0.7854\n",
      "Epoch 3663: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5894 - accuracy: 0.7854 - val_loss: 1.2523 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3664/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.7861\n",
      "Epoch 3664: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5882 - accuracy: 0.7861 - val_loss: 1.2569 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3665/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.7866\n",
      "Epoch 3665: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.6099 - accuracy: 0.7866 - val_loss: 1.2710 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3666/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.8160\n",
      "Epoch 3666: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.5593 - accuracy: 0.8160 - val_loss: 1.2754 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3667/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.8057\n",
      "Epoch 3667: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5797 - accuracy: 0.8057 - val_loss: 1.2739 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3668/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.7759\n",
      "Epoch 3668: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5981 - accuracy: 0.7759 - val_loss: 1.2657 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3669/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.7712\n",
      "Epoch 3669: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.6177 - accuracy: 0.7712 - val_loss: 1.2705 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3670/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.7983\n",
      "Epoch 3670: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5654 - accuracy: 0.7983 - val_loss: 1.2711 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3671/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.7524\n",
      "Epoch 3671: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6672 - accuracy: 0.7524 - val_loss: 1.2816 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3672/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.7995\n",
      "Epoch 3672: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5585 - accuracy: 0.7995 - val_loss: 1.2865 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3673/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.8037\n",
      "Epoch 3673: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5559 - accuracy: 0.8037 - val_loss: 1.2943 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3674/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.7689\n",
      "Epoch 3674: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.6196 - accuracy: 0.7689 - val_loss: 1.2992 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3675/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.7783\n",
      "Epoch 3675: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5929 - accuracy: 0.7783 - val_loss: 1.3002 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3676/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.7689\n",
      "Epoch 3676: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6102 - accuracy: 0.7689 - val_loss: 1.3056 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3677/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.7822\n",
      "Epoch 3677: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.6182 - accuracy: 0.7822 - val_loss: 1.3166 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3678/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5849 - accuracy: 0.7854\n",
      "Epoch 3678: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.5849 - accuracy: 0.7854 - val_loss: 1.3318 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3679/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5874 - accuracy: 0.7771\n",
      "Epoch 3679: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5874 - accuracy: 0.7771 - val_loss: 1.3402 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3680/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5963 - accuracy: 0.7913\n",
      "Epoch 3680: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5963 - accuracy: 0.7913 - val_loss: 1.3521 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3681/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.7724\n",
      "Epoch 3681: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6225 - accuracy: 0.7724 - val_loss: 1.3745 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3682/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6069 - accuracy: 0.7936\n",
      "Epoch 3682: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6069 - accuracy: 0.7936 - val_loss: 1.3818 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3683/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7998\n",
      "Epoch 3683: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5847 - accuracy: 0.7998 - val_loss: 1.3800 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3684/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.7930\n",
      "Epoch 3684: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5820 - accuracy: 0.7930 - val_loss: 1.3783 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3685/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.8125\n",
      "Epoch 3685: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5682 - accuracy: 0.8125 - val_loss: 1.3970 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3686/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.8101\n",
      "Epoch 3686: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.5706 - accuracy: 0.8101 - val_loss: 1.4009 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3687/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.7705\n",
      "Epoch 3687: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.6126 - accuracy: 0.7705 - val_loss: 1.3916 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3688/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5855 - accuracy: 0.7995\n",
      "Epoch 3688: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5855 - accuracy: 0.7995 - val_loss: 1.3735 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3689/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.7818\n",
      "Epoch 3689: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6134 - accuracy: 0.7818 - val_loss: 1.3624 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3690/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.7677\n",
      "Epoch 3690: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.6285 - accuracy: 0.7677 - val_loss: 1.3570 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3691/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.7995\n",
      "Epoch 3691: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5759 - accuracy: 0.7995 - val_loss: 1.3461 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3692/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.7866\n",
      "Epoch 3692: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6046 - accuracy: 0.7866 - val_loss: 1.3275 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3693/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.8042\n",
      "Epoch 3693: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5667 - accuracy: 0.8042 - val_loss: 1.3177 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3694/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5705 - accuracy: 0.8066\n",
      "Epoch 3694: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5705 - accuracy: 0.8066 - val_loss: 1.3140 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3695/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.8027\n",
      "Epoch 3695: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5697 - accuracy: 0.8027 - val_loss: 1.3117 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3696/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5827 - accuracy: 0.7803\n",
      "Epoch 3696: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5827 - accuracy: 0.7803 - val_loss: 1.3099 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3697/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5993 - accuracy: 0.7852\n",
      "Epoch 3697: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5993 - accuracy: 0.7852 - val_loss: 1.3104 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3698/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.7972\n",
      "Epoch 3698: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5772 - accuracy: 0.7972 - val_loss: 1.2861 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3699/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.8078\n",
      "Epoch 3699: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.5683 - accuracy: 0.8078 - val_loss: 1.2720 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3700/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.8135\n",
      "Epoch 3700: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 335ms/step - loss: 0.5527 - accuracy: 0.8135 - val_loss: 1.2725 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3701/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5382 - accuracy: 0.8137\n",
      "Epoch 3701: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.5382 - accuracy: 0.8137 - val_loss: 1.2851 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3702/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6049 - accuracy: 0.7795\n",
      "Epoch 3702: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.6049 - accuracy: 0.7795 - val_loss: 1.3089 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3703/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.7795\n",
      "Epoch 3703: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6300 - accuracy: 0.7795 - val_loss: 1.3271 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3704/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.8054\n",
      "Epoch 3704: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 396ms/step - loss: 0.5675 - accuracy: 0.8054 - val_loss: 1.3446 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3705/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.7712\n",
      "Epoch 3705: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.6650 - accuracy: 0.7712 - val_loss: 1.3612 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3706/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.7948\n",
      "Epoch 3706: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 330ms/step - loss: 0.5757 - accuracy: 0.7948 - val_loss: 1.3662 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3707/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.7700\n",
      "Epoch 3707: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6079 - accuracy: 0.7700 - val_loss: 1.3630 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3708/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5764 - accuracy: 0.7842\n",
      "Epoch 3708: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.5764 - accuracy: 0.7842 - val_loss: 1.3436 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3709/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.7900\n",
      "Epoch 3709: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5933 - accuracy: 0.7900 - val_loss: 1.3295 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3710/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5854 - accuracy: 0.8066\n",
      "Epoch 3710: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5854 - accuracy: 0.8066 - val_loss: 1.3215 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3711/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.7642\n",
      "Epoch 3711: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.6307 - accuracy: 0.7642 - val_loss: 1.3076 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3712/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.8018\n",
      "Epoch 3712: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.5796 - accuracy: 0.8018 - val_loss: 1.2923 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3713/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.7877\n",
      "Epoch 3713: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5830 - accuracy: 0.7877 - val_loss: 1.2864 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3714/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5895 - accuracy: 0.7866\n",
      "Epoch 3714: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.5895 - accuracy: 0.7866 - val_loss: 1.2878 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3715/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.8007\n",
      "Epoch 3715: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5742 - accuracy: 0.8007 - val_loss: 1.2875 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3716/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.7913\n",
      "Epoch 3716: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5639 - accuracy: 0.7913 - val_loss: 1.2827 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3717/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7871\n",
      "Epoch 3717: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5843 - accuracy: 0.7871 - val_loss: 1.2839 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3718/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.7972\n",
      "Epoch 3718: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5722 - accuracy: 0.7972 - val_loss: 1.2957 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3719/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.7653\n",
      "Epoch 3719: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.6081 - accuracy: 0.7653 - val_loss: 1.2964 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3720/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.7783\n",
      "Epoch 3720: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5718 - accuracy: 0.7783 - val_loss: 1.2884 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3721/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.7881\n",
      "Epoch 3721: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5628 - accuracy: 0.7881 - val_loss: 1.2839 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3722/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.8219\n",
      "Epoch 3722: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.5480 - accuracy: 0.8219 - val_loss: 1.2754 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3723/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.7818\n",
      "Epoch 3723: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6071 - accuracy: 0.7818 - val_loss: 1.2700 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3724/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.7807\n",
      "Epoch 3724: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.6229 - accuracy: 0.7807 - val_loss: 1.2734 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3725/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.7861\n",
      "Epoch 3725: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5906 - accuracy: 0.7861 - val_loss: 1.2752 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3726/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.7925\n",
      "Epoch 3726: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5738 - accuracy: 0.7925 - val_loss: 1.2792 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3727/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.7969\n",
      "Epoch 3727: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 0.5802 - accuracy: 0.7969 - val_loss: 1.2737 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3728/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.7877\n",
      "Epoch 3728: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.6052 - accuracy: 0.7877 - val_loss: 1.2707 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3729/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.7972\n",
      "Epoch 3729: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.5706 - accuracy: 0.7972 - val_loss: 1.2659 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3730/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6026 - accuracy: 0.7807\n",
      "Epoch 3730: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6026 - accuracy: 0.7807 - val_loss: 1.2568 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3731/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.8019\n",
      "Epoch 3731: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.5536 - accuracy: 0.8019 - val_loss: 1.2456 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3732/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.7910\n",
      "Epoch 3732: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.6106 - accuracy: 0.7910 - val_loss: 1.2349 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3733/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.7983\n",
      "Epoch 3733: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5631 - accuracy: 0.7983 - val_loss: 1.2198 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3734/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.8008\n",
      "Epoch 3734: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 335ms/step - loss: 0.5659 - accuracy: 0.8008 - val_loss: 1.2199 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3735/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5833 - accuracy: 0.7913\n",
      "Epoch 3735: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5833 - accuracy: 0.7913 - val_loss: 1.2256 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3736/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.7744\n",
      "Epoch 3736: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.6003 - accuracy: 0.7744 - val_loss: 1.2329 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3737/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5887 - accuracy: 0.7913\n",
      "Epoch 3737: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.5887 - accuracy: 0.7913 - val_loss: 1.2351 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3738/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5799 - accuracy: 0.7925\n",
      "Epoch 3738: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.5799 - accuracy: 0.7925 - val_loss: 1.2315 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3739/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.7939\n",
      "Epoch 3739: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 382ms/step - loss: 0.5891 - accuracy: 0.7939 - val_loss: 1.2386 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3740/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.8031\n",
      "Epoch 3740: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.5674 - accuracy: 0.8031 - val_loss: 1.2478 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3741/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5780 - accuracy: 0.7900\n",
      "Epoch 3741: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 368ms/step - loss: 0.5780 - accuracy: 0.7900 - val_loss: 1.2615 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3742/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.8027\n",
      "Epoch 3742: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 334ms/step - loss: 0.5802 - accuracy: 0.8027 - val_loss: 1.2709 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3743/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.7960\n",
      "Epoch 3743: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5759 - accuracy: 0.7960 - val_loss: 1.2804 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3744/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.8054\n",
      "Epoch 3744: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5563 - accuracy: 0.8054 - val_loss: 1.2982 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3745/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.7725\n",
      "Epoch 3745: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 358ms/step - loss: 0.6045 - accuracy: 0.7725 - val_loss: 1.3288 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3746/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.7700\n",
      "Epoch 3746: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.6139 - accuracy: 0.7700 - val_loss: 1.3631 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3747/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.7630\n",
      "Epoch 3747: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6007 - accuracy: 0.7630 - val_loss: 1.3841 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3748/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.8007\n",
      "Epoch 3748: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5795 - accuracy: 0.8007 - val_loss: 1.3870 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3749/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.7995\n",
      "Epoch 3749: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5563 - accuracy: 0.7995 - val_loss: 1.3826 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3750/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.7842\n",
      "Epoch 3750: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6039 - accuracy: 0.7842 - val_loss: 1.3672 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3751/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.7795\n",
      "Epoch 3751: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6086 - accuracy: 0.7795 - val_loss: 1.3583 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3752/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6056 - accuracy: 0.7724\n",
      "Epoch 3752: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.6056 - accuracy: 0.7724 - val_loss: 1.3514 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3753/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.7900\n",
      "Epoch 3753: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5922 - accuracy: 0.7900 - val_loss: 1.3464 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3754/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.7830\n",
      "Epoch 3754: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5927 - accuracy: 0.7830 - val_loss: 1.3449 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3755/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.7948\n",
      "Epoch 3755: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.5960 - accuracy: 0.7948 - val_loss: 1.3361 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3756/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7866\n",
      "Epoch 3756: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.5734 - accuracy: 0.7866 - val_loss: 1.3261 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3757/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.7866\n",
      "Epoch 3757: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 0.5679 - accuracy: 0.7866 - val_loss: 1.3330 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3758/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5822 - accuracy: 0.7748\n",
      "Epoch 3758: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5822 - accuracy: 0.7748 - val_loss: 1.3340 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3759/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5554 - accuracy: 0.8090\n",
      "Epoch 3759: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 390ms/step - loss: 0.5554 - accuracy: 0.8090 - val_loss: 1.3337 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3760/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7900\n",
      "Epoch 3760: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 0.6042 - accuracy: 0.7900 - val_loss: 1.3243 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3761/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.7736\n",
      "Epoch 3761: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.5875 - accuracy: 0.7736 - val_loss: 1.3115 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3762/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.7771\n",
      "Epoch 3762: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 363ms/step - loss: 0.5942 - accuracy: 0.7771 - val_loss: 1.2914 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3763/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.7866\n",
      "Epoch 3763: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5570 - accuracy: 0.7866 - val_loss: 1.2804 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3764/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.7889\n",
      "Epoch 3764: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.5839 - accuracy: 0.7889 - val_loss: 1.2808 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3765/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.7854\n",
      "Epoch 3765: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 390ms/step - loss: 0.6003 - accuracy: 0.7854 - val_loss: 1.2817 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3766/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7891\n",
      "Epoch 3766: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 0.5765 - accuracy: 0.7891 - val_loss: 1.2766 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3767/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5925 - accuracy: 0.7913\n",
      "Epoch 3767: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.5925 - accuracy: 0.7913 - val_loss: 1.2598 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3768/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.7939\n",
      "Epoch 3768: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.5883 - accuracy: 0.7939 - val_loss: 1.2456 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3769/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.7712\n",
      "Epoch 3769: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 349ms/step - loss: 0.6131 - accuracy: 0.7712 - val_loss: 1.2268 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3770/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.7960\n",
      "Epoch 3770: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 387ms/step - loss: 0.5719 - accuracy: 0.7960 - val_loss: 1.2189 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3771/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.7930\n",
      "Epoch 3771: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 351ms/step - loss: 0.5527 - accuracy: 0.7930 - val_loss: 1.2220 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3772/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5825 - accuracy: 0.8019\n",
      "Epoch 3772: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.5825 - accuracy: 0.8019 - val_loss: 1.2316 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3773/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.7901\n",
      "Epoch 3773: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 330ms/step - loss: 0.5929 - accuracy: 0.7901 - val_loss: 1.2389 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3774/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.7736\n",
      "Epoch 3774: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 375ms/step - loss: 0.5937 - accuracy: 0.7736 - val_loss: 1.2505 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3775/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.7807\n",
      "Epoch 3775: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 324ms/step - loss: 0.5901 - accuracy: 0.7807 - val_loss: 1.2612 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3776/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.7783\n",
      "Epoch 3776: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.5956 - accuracy: 0.7783 - val_loss: 1.2687 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3777/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.7803\n",
      "Epoch 3777: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 354ms/step - loss: 0.6041 - accuracy: 0.7803 - val_loss: 1.2853 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3778/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.8090\n",
      "Epoch 3778: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5550 - accuracy: 0.8090 - val_loss: 1.2912 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3779/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.7795\n",
      "Epoch 3779: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 352ms/step - loss: 0.5875 - accuracy: 0.7795 - val_loss: 1.2996 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3780/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.8054\n",
      "Epoch 3780: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.5778 - accuracy: 0.8054 - val_loss: 1.2955 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3781/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5779 - accuracy: 0.7913\n",
      "Epoch 3781: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5779 - accuracy: 0.7913 - val_loss: 1.2929 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3782/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7842\n",
      "Epoch 3782: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 0.6127 - accuracy: 0.7842 - val_loss: 1.2739 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3783/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.7861\n",
      "Epoch 3783: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6030 - accuracy: 0.7861 - val_loss: 1.2639 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3784/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.7983\n",
      "Epoch 3784: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5640 - accuracy: 0.7983 - val_loss: 1.2642 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3785/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.7960\n",
      "Epoch 3785: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5807 - accuracy: 0.7960 - val_loss: 1.2741 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3786/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.7983\n",
      "Epoch 3786: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.5681 - accuracy: 0.7983 - val_loss: 1.2817 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3787/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6072 - accuracy: 0.7889\n",
      "Epoch 3787: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6072 - accuracy: 0.7889 - val_loss: 1.2811 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3788/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5872 - accuracy: 0.7913\n",
      "Epoch 3788: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.5872 - accuracy: 0.7913 - val_loss: 1.3046 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3789/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5732 - accuracy: 0.7995\n",
      "Epoch 3789: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5732 - accuracy: 0.7995 - val_loss: 1.3110 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3790/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.8101\n",
      "Epoch 3790: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.5710 - accuracy: 0.8101 - val_loss: 1.3060 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3791/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5972 - accuracy: 0.7889\n",
      "Epoch 3791: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5972 - accuracy: 0.7889 - val_loss: 1.2988 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3792/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5717 - accuracy: 0.7979\n",
      "Epoch 3792: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 348ms/step - loss: 0.5717 - accuracy: 0.7979 - val_loss: 1.2925 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3793/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.7830\n",
      "Epoch 3793: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.5984 - accuracy: 0.7830 - val_loss: 1.2859 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3794/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.8090\n",
      "Epoch 3794: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.5719 - accuracy: 0.8090 - val_loss: 1.2881 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3795/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.7913\n",
      "Epoch 3795: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5991 - accuracy: 0.7913 - val_loss: 1.2862 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3796/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.7771\n",
      "Epoch 3796: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6046 - accuracy: 0.7771 - val_loss: 1.2921 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3797/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.7866\n",
      "Epoch 3797: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.5853 - accuracy: 0.7866 - val_loss: 1.2861 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3798/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.8086\n",
      "Epoch 3798: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5624 - accuracy: 0.8086 - val_loss: 1.2725 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3799/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.7666\n",
      "Epoch 3799: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6084 - accuracy: 0.7666 - val_loss: 1.2693 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3800/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.7877\n",
      "Epoch 3800: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5654 - accuracy: 0.7877 - val_loss: 1.2735 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3801/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5786 - accuracy: 0.8090\n",
      "Epoch 3801: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5786 - accuracy: 0.8090 - val_loss: 1.2852 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3802/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.7866\n",
      "Epoch 3802: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5917 - accuracy: 0.7866 - val_loss: 1.2901 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3803/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.7948\n",
      "Epoch 3803: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5756 - accuracy: 0.7948 - val_loss: 1.3055 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3804/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.7854\n",
      "Epoch 3804: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5778 - accuracy: 0.7854 - val_loss: 1.3128 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3805/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.7812\n",
      "Epoch 3805: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.5782 - accuracy: 0.7812 - val_loss: 1.2986 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3806/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.8019\n",
      "Epoch 3806: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.5788 - accuracy: 0.8019 - val_loss: 1.2849 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3807/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.7830\n",
      "Epoch 3807: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 0.6283 - accuracy: 0.7830 - val_loss: 1.2814 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3808/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.7877\n",
      "Epoch 3808: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.5648 - accuracy: 0.7877 - val_loss: 1.2758 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3809/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.7925\n",
      "Epoch 3809: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5661 - accuracy: 0.7925 - val_loss: 1.2694 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3810/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.8042\n",
      "Epoch 3810: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.5378 - accuracy: 0.8042 - val_loss: 1.2699 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3811/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.7936\n",
      "Epoch 3811: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5797 - accuracy: 0.7936 - val_loss: 1.2723 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3812/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5780 - accuracy: 0.7936\n",
      "Epoch 3812: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.5780 - accuracy: 0.7936 - val_loss: 1.2617 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3813/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.7969\n",
      "Epoch 3813: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 324ms/step - loss: 0.5749 - accuracy: 0.7969 - val_loss: 1.2721 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3814/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.7936\n",
      "Epoch 3814: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5614 - accuracy: 0.7936 - val_loss: 1.2910 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3815/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6014 - accuracy: 0.7822\n",
      "Epoch 3815: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 0.6014 - accuracy: 0.7822 - val_loss: 1.3170 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3816/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.8037\n",
      "Epoch 3816: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.5715 - accuracy: 0.8037 - val_loss: 1.3366 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3817/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.7925\n",
      "Epoch 3817: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5881 - accuracy: 0.7925 - val_loss: 1.3594 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3818/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.7948\n",
      "Epoch 3818: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.5744 - accuracy: 0.7948 - val_loss: 1.3668 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3819/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.7901\n",
      "Epoch 3819: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.5688 - accuracy: 0.7901 - val_loss: 1.3574 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3820/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.7795\n",
      "Epoch 3820: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 341ms/step - loss: 0.6101 - accuracy: 0.7795 - val_loss: 1.3473 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3821/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5947 - accuracy: 0.7818\n",
      "Epoch 3821: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.5947 - accuracy: 0.7818 - val_loss: 1.3343 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3822/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7783\n",
      "Epoch 3822: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5746 - accuracy: 0.7783 - val_loss: 1.3128 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3823/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5771 - accuracy: 0.7913\n",
      "Epoch 3823: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5771 - accuracy: 0.7913 - val_loss: 1.3063 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3824/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.7818\n",
      "Epoch 3824: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5788 - accuracy: 0.7818 - val_loss: 1.2831 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3825/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5318 - accuracy: 0.8078\n",
      "Epoch 3825: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.5318 - accuracy: 0.8078 - val_loss: 1.2712 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3826/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.7960\n",
      "Epoch 3826: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5836 - accuracy: 0.7960 - val_loss: 1.2623 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3827/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5754 - accuracy: 0.7871\n",
      "Epoch 3827: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 333ms/step - loss: 0.5754 - accuracy: 0.7871 - val_loss: 1.2653 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3828/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.8054\n",
      "Epoch 3828: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.5578 - accuracy: 0.8054 - val_loss: 1.2586 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3829/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5713 - accuracy: 0.8019\n",
      "Epoch 3829: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5713 - accuracy: 0.8019 - val_loss: 1.2604 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3830/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.7807\n",
      "Epoch 3830: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.5970 - accuracy: 0.7807 - val_loss: 1.2708 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3831/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8007\n",
      "Epoch 3831: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.5495 - accuracy: 0.8007 - val_loss: 1.2697 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3832/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.7866\n",
      "Epoch 3832: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 0.5866 - accuracy: 0.7866 - val_loss: 1.2812 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3833/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.7861\n",
      "Epoch 3833: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5923 - accuracy: 0.7861 - val_loss: 1.2795 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3834/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.7972\n",
      "Epoch 3834: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5711 - accuracy: 0.7972 - val_loss: 1.2784 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3835/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.7842\n",
      "Epoch 3835: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.5951 - accuracy: 0.7842 - val_loss: 1.2644 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3836/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7972\n",
      "Epoch 3836: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5588 - accuracy: 0.7972 - val_loss: 1.2427 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3837/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.7901\n",
      "Epoch 3837: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.5931 - accuracy: 0.7901 - val_loss: 1.2350 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3838/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5822 - accuracy: 0.7842\n",
      "Epoch 3838: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.5822 - accuracy: 0.7842 - val_loss: 1.2315 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3839/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.7771\n",
      "Epoch 3839: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5927 - accuracy: 0.7771 - val_loss: 1.2254 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3840/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.7983\n",
      "Epoch 3840: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5411 - accuracy: 0.7983 - val_loss: 1.2278 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3841/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.7724\n",
      "Epoch 3841: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.6207 - accuracy: 0.7724 - val_loss: 1.2471 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3842/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5696 - accuracy: 0.8066\n",
      "Epoch 3842: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.5696 - accuracy: 0.8066 - val_loss: 1.2639 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3843/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.8066\n",
      "Epoch 3843: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 0.5669 - accuracy: 0.8066 - val_loss: 1.2701 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3844/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.7913\n",
      "Epoch 3844: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.5873 - accuracy: 0.7913 - val_loss: 1.2721 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3845/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.7812\n",
      "Epoch 3845: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5881 - accuracy: 0.7812 - val_loss: 1.2679 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3846/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.8149\n",
      "Epoch 3846: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5477 - accuracy: 0.8149 - val_loss: 1.2669 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3847/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.7871\n",
      "Epoch 3847: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 0.5802 - accuracy: 0.7871 - val_loss: 1.2755 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3848/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.7972\n",
      "Epoch 3848: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.5832 - accuracy: 0.7972 - val_loss: 1.2708 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3849/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.8125\n",
      "Epoch 3849: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 337ms/step - loss: 0.5527 - accuracy: 0.8125 - val_loss: 1.2764 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3850/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.7783\n",
      "Epoch 3850: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.6094 - accuracy: 0.7783 - val_loss: 1.2831 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3851/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.8018\n",
      "Epoch 3851: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.5586 - accuracy: 0.8018 - val_loss: 1.2920 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3852/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.7925\n",
      "Epoch 3852: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.5794 - accuracy: 0.7925 - val_loss: 1.2975 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3853/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5862 - accuracy: 0.7854\n",
      "Epoch 3853: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.5862 - accuracy: 0.7854 - val_loss: 1.2900 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3854/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.7901\n",
      "Epoch 3854: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5669 - accuracy: 0.7901 - val_loss: 1.2777 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3855/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.7913\n",
      "Epoch 3855: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5817 - accuracy: 0.7913 - val_loss: 1.2714 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3856/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8042\n",
      "Epoch 3856: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5414 - accuracy: 0.8042 - val_loss: 1.2717 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3857/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.8113\n",
      "Epoch 3857: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5587 - accuracy: 0.8113 - val_loss: 1.2709 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3858/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.8018\n",
      "Epoch 3858: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.5632 - accuracy: 0.8018 - val_loss: 1.2677 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3859/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7854\n",
      "Epoch 3859: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.5588 - accuracy: 0.7854 - val_loss: 1.2581 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3860/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7930\n",
      "Epoch 3860: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5677 - accuracy: 0.7930 - val_loss: 1.2453 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3861/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5416 - accuracy: 0.8090\n",
      "Epoch 3861: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5416 - accuracy: 0.8090 - val_loss: 1.2347 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3862/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.8066\n",
      "Epoch 3862: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5992 - accuracy: 0.8066 - val_loss: 1.2347 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3863/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.7930\n",
      "Epoch 3863: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5801 - accuracy: 0.7930 - val_loss: 1.2353 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3864/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.8090\n",
      "Epoch 3864: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5641 - accuracy: 0.8090 - val_loss: 1.2330 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3865/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.7995\n",
      "Epoch 3865: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5601 - accuracy: 0.7995 - val_loss: 1.2461 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3866/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.8007\n",
      "Epoch 3866: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.5676 - accuracy: 0.8007 - val_loss: 1.2678 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3867/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.7807\n",
      "Epoch 3867: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5755 - accuracy: 0.7807 - val_loss: 1.2841 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3868/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.7949\n",
      "Epoch 3868: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5607 - accuracy: 0.7949 - val_loss: 1.2968 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3869/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.7995\n",
      "Epoch 3869: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5690 - accuracy: 0.7995 - val_loss: 1.3050 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3870/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.7948\n",
      "Epoch 3870: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5914 - accuracy: 0.7948 - val_loss: 1.3140 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3871/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.7689\n",
      "Epoch 3871: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5953 - accuracy: 0.7689 - val_loss: 1.3110 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3872/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.7948\n",
      "Epoch 3872: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5943 - accuracy: 0.7948 - val_loss: 1.3011 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3873/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.7948\n",
      "Epoch 3873: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5615 - accuracy: 0.7948 - val_loss: 1.2840 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3874/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.8008\n",
      "Epoch 3874: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.5665 - accuracy: 0.8008 - val_loss: 1.2754 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3875/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.8042\n",
      "Epoch 3875: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5435 - accuracy: 0.8042 - val_loss: 1.2650 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3876/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5898 - accuracy: 0.7881\n",
      "Epoch 3876: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5898 - accuracy: 0.7881 - val_loss: 1.2654 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3877/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.8031\n",
      "Epoch 3877: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5615 - accuracy: 0.8031 - val_loss: 1.2742 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3878/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.7960\n",
      "Epoch 3878: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5846 - accuracy: 0.7960 - val_loss: 1.2849 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3879/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.8145\n",
      "Epoch 3879: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5430 - accuracy: 0.8145 - val_loss: 1.2930 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3880/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5919 - accuracy: 0.7930\n",
      "Epoch 3880: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5919 - accuracy: 0.7930 - val_loss: 1.3013 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3881/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.7988\n",
      "Epoch 3881: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.5534 - accuracy: 0.7988 - val_loss: 1.3080 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3882/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6027 - accuracy: 0.7901\n",
      "Epoch 3882: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.6027 - accuracy: 0.7901 - val_loss: 1.3037 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3883/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5557 - accuracy: 0.7983\n",
      "Epoch 3883: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5557 - accuracy: 0.7983 - val_loss: 1.2845 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3884/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5985 - accuracy: 0.7925\n",
      "Epoch 3884: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5985 - accuracy: 0.7925 - val_loss: 1.2591 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3885/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.8008\n",
      "Epoch 3885: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5763 - accuracy: 0.8008 - val_loss: 1.2361 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3886/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.7949\n",
      "Epoch 3886: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5818 - accuracy: 0.7949 - val_loss: 1.2250 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3887/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.8078\n",
      "Epoch 3887: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5680 - accuracy: 0.8078 - val_loss: 1.2231 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3888/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.7736\n",
      "Epoch 3888: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5865 - accuracy: 0.7736 - val_loss: 1.2269 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3889/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.7925\n",
      "Epoch 3889: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5802 - accuracy: 0.7925 - val_loss: 1.2220 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3890/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.7807\n",
      "Epoch 3890: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5850 - accuracy: 0.7807 - val_loss: 1.2297 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3891/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.7998\n",
      "Epoch 3891: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5742 - accuracy: 0.7998 - val_loss: 1.2376 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3892/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.7925\n",
      "Epoch 3892: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5670 - accuracy: 0.7925 - val_loss: 1.2436 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3893/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5790 - accuracy: 0.7925\n",
      "Epoch 3893: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.5790 - accuracy: 0.7925 - val_loss: 1.2528 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3894/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.7842\n",
      "Epoch 3894: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.6002 - accuracy: 0.7842 - val_loss: 1.2563 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3895/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5619 - accuracy: 0.7930\n",
      "Epoch 3895: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.5619 - accuracy: 0.7930 - val_loss: 1.2494 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3896/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.8125\n",
      "Epoch 3896: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5506 - accuracy: 0.8125 - val_loss: 1.2492 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3897/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.7948\n",
      "Epoch 3897: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5902 - accuracy: 0.7948 - val_loss: 1.2519 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3898/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.7925\n",
      "Epoch 3898: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5451 - accuracy: 0.7925 - val_loss: 1.2532 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3899/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.7925\n",
      "Epoch 3899: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5690 - accuracy: 0.7925 - val_loss: 1.2590 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3900/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.8066\n",
      "Epoch 3900: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5575 - accuracy: 0.8066 - val_loss: 1.2672 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3901/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5827 - accuracy: 0.7830\n",
      "Epoch 3901: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.5827 - accuracy: 0.7830 - val_loss: 1.2634 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3902/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7866\n",
      "Epoch 3902: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.5746 - accuracy: 0.7866 - val_loss: 1.2581 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3903/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7988\n",
      "Epoch 3903: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5657 - accuracy: 0.7988 - val_loss: 1.2484 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3904/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.7901\n",
      "Epoch 3904: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5838 - accuracy: 0.7901 - val_loss: 1.2397 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3905/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.7832\n",
      "Epoch 3905: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5969 - accuracy: 0.7832 - val_loss: 1.2433 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3906/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.7936\n",
      "Epoch 3906: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5604 - accuracy: 0.7936 - val_loss: 1.2350 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3907/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.7866\n",
      "Epoch 3907: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.6064 - accuracy: 0.7866 - val_loss: 1.2207 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3908/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.8160\n",
      "Epoch 3908: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5399 - accuracy: 0.8160 - val_loss: 1.2183 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3909/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5809 - accuracy: 0.7998\n",
      "Epoch 3909: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5809 - accuracy: 0.7998 - val_loss: 1.2160 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3910/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.7877\n",
      "Epoch 3910: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5710 - accuracy: 0.7877 - val_loss: 1.2209 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3911/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7891\n",
      "Epoch 3911: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5668 - accuracy: 0.7891 - val_loss: 1.2256 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3912/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.7830\n",
      "Epoch 3912: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5710 - accuracy: 0.7830 - val_loss: 1.2292 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3913/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.8007\n",
      "Epoch 3913: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5668 - accuracy: 0.8007 - val_loss: 1.2223 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3914/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.8137\n",
      "Epoch 3914: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5502 - accuracy: 0.8137 - val_loss: 1.2094 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3915/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7842\n",
      "Epoch 3915: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.5637 - accuracy: 0.7842 - val_loss: 1.2076 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3916/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7889\n",
      "Epoch 3916: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5659 - accuracy: 0.7889 - val_loss: 1.2120 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3917/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.7842\n",
      "Epoch 3917: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6197 - accuracy: 0.7842 - val_loss: 1.2029 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3918/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7960\n",
      "Epoch 3918: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.5588 - accuracy: 0.7960 - val_loss: 1.1925 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 3919/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.7960\n",
      "Epoch 3919: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5600 - accuracy: 0.7960 - val_loss: 1.1963 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 3920/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.8042\n",
      "Epoch 3920: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5695 - accuracy: 0.8042 - val_loss: 1.1986 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3921/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5983 - accuracy: 0.7818\n",
      "Epoch 3921: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.5983 - accuracy: 0.7818 - val_loss: 1.2146 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3922/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.8172\n",
      "Epoch 3922: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5620 - accuracy: 0.8172 - val_loss: 1.2220 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3923/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.7936\n",
      "Epoch 3923: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5501 - accuracy: 0.7936 - val_loss: 1.2386 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 3924/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.7995\n",
      "Epoch 3924: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.5762 - accuracy: 0.7995 - val_loss: 1.2554 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3925/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5580 - accuracy: 0.8007\n",
      "Epoch 3925: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5580 - accuracy: 0.8007 - val_loss: 1.2731 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3926/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.8054\n",
      "Epoch 3926: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5529 - accuracy: 0.8054 - val_loss: 1.2739 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3927/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5899 - accuracy: 0.7807\n",
      "Epoch 3927: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5899 - accuracy: 0.7807 - val_loss: 1.2778 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3928/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5720 - accuracy: 0.7983\n",
      "Epoch 3928: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5720 - accuracy: 0.7983 - val_loss: 1.2760 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3929/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.8101\n",
      "Epoch 3929: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5385 - accuracy: 0.8101 - val_loss: 1.2713 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3930/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.8078\n",
      "Epoch 3930: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5373 - accuracy: 0.8078 - val_loss: 1.2677 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3931/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.7771\n",
      "Epoch 3931: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6090 - accuracy: 0.7771 - val_loss: 1.2528 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3932/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.7925\n",
      "Epoch 3932: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5706 - accuracy: 0.7925 - val_loss: 1.2435 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3933/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5625 - accuracy: 0.7936\n",
      "Epoch 3933: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5625 - accuracy: 0.7936 - val_loss: 1.2346 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3934/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.7925\n",
      "Epoch 3934: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5636 - accuracy: 0.7925 - val_loss: 1.2192 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3935/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.7969\n",
      "Epoch 3935: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5503 - accuracy: 0.7969 - val_loss: 1.2136 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3936/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.7969\n",
      "Epoch 3936: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5700 - accuracy: 0.7969 - val_loss: 1.2173 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3937/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6009 - accuracy: 0.7854\n",
      "Epoch 3937: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6009 - accuracy: 0.7854 - val_loss: 1.2249 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3938/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.7969\n",
      "Epoch 3938: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5745 - accuracy: 0.7969 - val_loss: 1.2341 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3939/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.7983\n",
      "Epoch 3939: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5722 - accuracy: 0.7983 - val_loss: 1.2493 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3940/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5982 - accuracy: 0.7889\n",
      "Epoch 3940: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5982 - accuracy: 0.7889 - val_loss: 1.2524 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3941/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.7866\n",
      "Epoch 3941: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6035 - accuracy: 0.7866 - val_loss: 1.2613 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3942/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.7936\n",
      "Epoch 3942: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5709 - accuracy: 0.7936 - val_loss: 1.2754 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3943/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5535 - accuracy: 0.7948\n",
      "Epoch 3943: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5535 - accuracy: 0.7948 - val_loss: 1.2953 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3944/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.7920\n",
      "Epoch 3944: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5654 - accuracy: 0.7920 - val_loss: 1.3067 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3945/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.7812\n",
      "Epoch 3945: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5937 - accuracy: 0.7812 - val_loss: 1.3095 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3946/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5910 - accuracy: 0.7901\n",
      "Epoch 3946: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5910 - accuracy: 0.7901 - val_loss: 1.3148 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3947/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.7913\n",
      "Epoch 3947: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5915 - accuracy: 0.7913 - val_loss: 1.3044 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3948/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.8066\n",
      "Epoch 3948: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5470 - accuracy: 0.8066 - val_loss: 1.3099 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3949/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.8160\n",
      "Epoch 3949: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5379 - accuracy: 0.8160 - val_loss: 1.3260 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3950/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.8031\n",
      "Epoch 3950: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5745 - accuracy: 0.8031 - val_loss: 1.3273 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3951/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.8137\n",
      "Epoch 3951: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5406 - accuracy: 0.8137 - val_loss: 1.3329 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3952/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5814 - accuracy: 0.8113\n",
      "Epoch 3952: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.5814 - accuracy: 0.8113 - val_loss: 1.3461 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3953/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8047\n",
      "Epoch 3953: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5425 - accuracy: 0.8047 - val_loss: 1.3622 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3954/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.8076\n",
      "Epoch 3954: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5565 - accuracy: 0.8076 - val_loss: 1.3733 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3955/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.8113\n",
      "Epoch 3955: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5556 - accuracy: 0.8113 - val_loss: 1.3784 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3956/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.8125\n",
      "Epoch 3956: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5611 - accuracy: 0.8125 - val_loss: 1.3738 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 3957/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.7948\n",
      "Epoch 3957: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5796 - accuracy: 0.7948 - val_loss: 1.3521 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3958/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.7936\n",
      "Epoch 3958: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5852 - accuracy: 0.7936 - val_loss: 1.3481 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3959/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.7939\n",
      "Epoch 3959: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.5587 - accuracy: 0.7939 - val_loss: 1.3537 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3960/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.7842\n",
      "Epoch 3960: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5878 - accuracy: 0.7842 - val_loss: 1.3634 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3961/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.7700\n",
      "Epoch 3961: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6047 - accuracy: 0.7700 - val_loss: 1.3619 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3962/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.8054\n",
      "Epoch 3962: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5261 - accuracy: 0.8054 - val_loss: 1.3611 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3963/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.7936\n",
      "Epoch 3963: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5836 - accuracy: 0.7936 - val_loss: 1.3629 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 3964/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.7822\n",
      "Epoch 3964: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5841 - accuracy: 0.7822 - val_loss: 1.3503 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3965/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7900\n",
      "Epoch 3965: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5675 - accuracy: 0.7900 - val_loss: 1.3468 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 3966/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.7939\n",
      "Epoch 3966: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5798 - accuracy: 0.7939 - val_loss: 1.3392 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3967/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.7972\n",
      "Epoch 3967: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5743 - accuracy: 0.7972 - val_loss: 1.3402 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 3968/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.8290\n",
      "Epoch 3968: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5377 - accuracy: 0.8290 - val_loss: 1.3238 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3969/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.7842\n",
      "Epoch 3969: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6038 - accuracy: 0.7842 - val_loss: 1.3080 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3970/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.8101\n",
      "Epoch 3970: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5586 - accuracy: 0.8101 - val_loss: 1.2876 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3971/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5701 - accuracy: 0.7995\n",
      "Epoch 3971: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5701 - accuracy: 0.7995 - val_loss: 1.2782 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3972/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.7983\n",
      "Epoch 3972: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5670 - accuracy: 0.7983 - val_loss: 1.2706 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3973/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.7925\n",
      "Epoch 3973: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5678 - accuracy: 0.7925 - val_loss: 1.2515 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3974/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.7972\n",
      "Epoch 3974: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5492 - accuracy: 0.7972 - val_loss: 1.2399 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3975/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5699 - accuracy: 0.7925\n",
      "Epoch 3975: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.5699 - accuracy: 0.7925 - val_loss: 1.2356 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3976/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.7972\n",
      "Epoch 3976: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.5481 - accuracy: 0.7972 - val_loss: 1.2450 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3977/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.7948\n",
      "Epoch 3977: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5937 - accuracy: 0.7948 - val_loss: 1.2594 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3978/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.7606\n",
      "Epoch 3978: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6241 - accuracy: 0.7606 - val_loss: 1.2811 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 3979/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.8019\n",
      "Epoch 3979: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5487 - accuracy: 0.8019 - val_loss: 1.2902 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3980/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5701 - accuracy: 0.7925\n",
      "Epoch 3980: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5701 - accuracy: 0.7925 - val_loss: 1.2999 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3981/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5705 - accuracy: 0.7854\n",
      "Epoch 3981: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5705 - accuracy: 0.7854 - val_loss: 1.3052 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3982/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.7783\n",
      "Epoch 3982: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5617 - accuracy: 0.7783 - val_loss: 1.3048 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3983/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5651 - accuracy: 0.8066\n",
      "Epoch 3983: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5651 - accuracy: 0.8066 - val_loss: 1.2881 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3984/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.7920\n",
      "Epoch 3984: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5518 - accuracy: 0.7920 - val_loss: 1.2801 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 3985/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.8090\n",
      "Epoch 3985: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5419 - accuracy: 0.8090 - val_loss: 1.2668 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3986/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5568 - accuracy: 0.7939\n",
      "Epoch 3986: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5568 - accuracy: 0.7939 - val_loss: 1.2549 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3987/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5523 - accuracy: 0.8027\n",
      "Epoch 3987: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.5523 - accuracy: 0.8027 - val_loss: 1.2562 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 3988/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.8090\n",
      "Epoch 3988: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5169 - accuracy: 0.8090 - val_loss: 1.2601 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 3989/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5829 - accuracy: 0.8007\n",
      "Epoch 3989: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5829 - accuracy: 0.8007 - val_loss: 1.2670 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 3990/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.8042\n",
      "Epoch 3990: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5475 - accuracy: 0.8042 - val_loss: 1.2802 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 3991/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.8113\n",
      "Epoch 3991: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5494 - accuracy: 0.8113 - val_loss: 1.2951 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3992/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.7913\n",
      "Epoch 3992: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5674 - accuracy: 0.7913 - val_loss: 1.3079 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3993/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7960\n",
      "Epoch 3993: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5637 - accuracy: 0.7960 - val_loss: 1.3012 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3994/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.8019\n",
      "Epoch 3994: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5433 - accuracy: 0.8019 - val_loss: 1.2998 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 3995/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.7854\n",
      "Epoch 3995: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5850 - accuracy: 0.7854 - val_loss: 1.2965 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3996/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.8019\n",
      "Epoch 3996: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5473 - accuracy: 0.8019 - val_loss: 1.2904 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3997/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.8018\n",
      "Epoch 3997: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5617 - accuracy: 0.8018 - val_loss: 1.2942 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3998/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.7972\n",
      "Epoch 3998: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5686 - accuracy: 0.7972 - val_loss: 1.2935 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 3999/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.7960\n",
      "Epoch 3999: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5584 - accuracy: 0.7960 - val_loss: 1.2971 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4000/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5714 - accuracy: 0.8042\n",
      "Epoch 4000: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5714 - accuracy: 0.8042 - val_loss: 1.3076 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4001/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7877\n",
      "Epoch 4001: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5765 - accuracy: 0.7877 - val_loss: 1.3167 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4002/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5821 - accuracy: 0.7832\n",
      "Epoch 4002: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5821 - accuracy: 0.7832 - val_loss: 1.3091 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4003/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.7748\n",
      "Epoch 4003: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.5853 - accuracy: 0.7748 - val_loss: 1.3001 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4004/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.7960\n",
      "Epoch 4004: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5768 - accuracy: 0.7960 - val_loss: 1.2906 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4005/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.7960\n",
      "Epoch 4005: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5577 - accuracy: 0.7960 - val_loss: 1.2736 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4006/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.8007\n",
      "Epoch 4006: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5345 - accuracy: 0.8007 - val_loss: 1.2600 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4007/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.8090\n",
      "Epoch 4007: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5448 - accuracy: 0.8090 - val_loss: 1.2445 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4008/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.7771\n",
      "Epoch 4008: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5797 - accuracy: 0.7771 - val_loss: 1.2347 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4009/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7960\n",
      "Epoch 4009: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5986 - accuracy: 0.7960 - val_loss: 1.2294 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4010/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5949 - accuracy: 0.7877\n",
      "Epoch 4010: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5949 - accuracy: 0.7877 - val_loss: 1.2262 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4011/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.7948\n",
      "Epoch 4011: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5666 - accuracy: 0.7948 - val_loss: 1.2267 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4012/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5630 - accuracy: 0.7949\n",
      "Epoch 4012: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5630 - accuracy: 0.7949 - val_loss: 1.2175 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4013/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.8066\n",
      "Epoch 4013: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5480 - accuracy: 0.8066 - val_loss: 1.2084 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4014/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.8007\n",
      "Epoch 4014: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5447 - accuracy: 0.8007 - val_loss: 1.2172 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4015/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.7759\n",
      "Epoch 4015: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.6107 - accuracy: 0.7759 - val_loss: 1.2189 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4016/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.8042\n",
      "Epoch 4016: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5458 - accuracy: 0.8042 - val_loss: 1.2217 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4017/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.7983\n",
      "Epoch 4017: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5640 - accuracy: 0.7983 - val_loss: 1.2238 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4018/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.7959\n",
      "Epoch 4018: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.5589 - accuracy: 0.7959 - val_loss: 1.2357 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4019/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.8066\n",
      "Epoch 4019: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5327 - accuracy: 0.8066 - val_loss: 1.2458 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4020/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.7995\n",
      "Epoch 4020: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5494 - accuracy: 0.7995 - val_loss: 1.2676 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4021/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.8007\n",
      "Epoch 4021: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5817 - accuracy: 0.8007 - val_loss: 1.2720 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4022/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5375 - accuracy: 0.8184\n",
      "Epoch 4022: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5375 - accuracy: 0.8184 - val_loss: 1.2788 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4023/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.7891\n",
      "Epoch 4023: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.5672 - accuracy: 0.7891 - val_loss: 1.2803 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4024/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.8172\n",
      "Epoch 4024: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5325 - accuracy: 0.8172 - val_loss: 1.2809 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4025/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.7949\n",
      "Epoch 4025: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5736 - accuracy: 0.7949 - val_loss: 1.2674 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4026/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.7877\n",
      "Epoch 4026: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6007 - accuracy: 0.7877 - val_loss: 1.2576 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4027/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.7972\n",
      "Epoch 4027: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.5593 - accuracy: 0.7972 - val_loss: 1.2482 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4028/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5571 - accuracy: 0.7995\n",
      "Epoch 4028: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5571 - accuracy: 0.7995 - val_loss: 1.2493 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4029/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.8007\n",
      "Epoch 4029: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5519 - accuracy: 0.8007 - val_loss: 1.2642 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4030/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.7969\n",
      "Epoch 4030: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5516 - accuracy: 0.7969 - val_loss: 1.2821 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4031/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.8054\n",
      "Epoch 4031: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5446 - accuracy: 0.8054 - val_loss: 1.3135 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4032/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.8096\n",
      "Epoch 4032: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5636 - accuracy: 0.8096 - val_loss: 1.3342 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4033/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.7736\n",
      "Epoch 4033: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6234 - accuracy: 0.7736 - val_loss: 1.3477 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4034/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5811 - accuracy: 0.7889\n",
      "Epoch 4034: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5811 - accuracy: 0.7889 - val_loss: 1.3450 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4035/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.7889\n",
      "Epoch 4035: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5742 - accuracy: 0.7889 - val_loss: 1.3480 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4036/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.7795\n",
      "Epoch 4036: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.5785 - accuracy: 0.7795 - val_loss: 1.3388 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4037/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.8018\n",
      "Epoch 4037: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5662 - accuracy: 0.8018 - val_loss: 1.3278 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4038/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.8031\n",
      "Epoch 4038: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5589 - accuracy: 0.8031 - val_loss: 1.3224 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4039/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.7901\n",
      "Epoch 4039: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5776 - accuracy: 0.7901 - val_loss: 1.3195 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4040/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.7913\n",
      "Epoch 4040: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5570 - accuracy: 0.7913 - val_loss: 1.3212 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4041/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.7972\n",
      "Epoch 4041: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5756 - accuracy: 0.7972 - val_loss: 1.3166 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4042/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.8125\n",
      "Epoch 4042: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5419 - accuracy: 0.8125 - val_loss: 1.3125 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4043/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.8007\n",
      "Epoch 4043: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5257 - accuracy: 0.8007 - val_loss: 1.3089 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4044/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5592 - accuracy: 0.8160\n",
      "Epoch 4044: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.5592 - accuracy: 0.8160 - val_loss: 1.3131 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4045/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.7901\n",
      "Epoch 4045: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5663 - accuracy: 0.7901 - val_loss: 1.3171 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4046/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.7783\n",
      "Epoch 4046: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.5951 - accuracy: 0.7783 - val_loss: 1.3129 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4047/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7972\n",
      "Epoch 4047: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.5677 - accuracy: 0.7972 - val_loss: 1.3072 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4048/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.8018\n",
      "Epoch 4048: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.5539 - accuracy: 0.8018 - val_loss: 1.3014 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4049/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8042\n",
      "Epoch 4049: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.5245 - accuracy: 0.8042 - val_loss: 1.2992 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4050/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7948\n",
      "Epoch 4050: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5746 - accuracy: 0.7948 - val_loss: 1.2896 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4051/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7910\n",
      "Epoch 4051: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5649 - accuracy: 0.7910 - val_loss: 1.2823 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4052/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.7995\n",
      "Epoch 4052: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5778 - accuracy: 0.7995 - val_loss: 1.2848 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4053/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7972\n",
      "Epoch 4053: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5653 - accuracy: 0.7972 - val_loss: 1.2765 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4054/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.7889\n",
      "Epoch 4054: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.5962 - accuracy: 0.7889 - val_loss: 1.2586 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4055/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.8042\n",
      "Epoch 4055: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5623 - accuracy: 0.8042 - val_loss: 1.2394 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4056/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.7854\n",
      "Epoch 4056: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5830 - accuracy: 0.7854 - val_loss: 1.2311 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4057/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.7901\n",
      "Epoch 4057: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5534 - accuracy: 0.7901 - val_loss: 1.2222 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4058/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.7936\n",
      "Epoch 4058: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5364 - accuracy: 0.7936 - val_loss: 1.2174 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4059/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7925\n",
      "Epoch 4059: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5673 - accuracy: 0.7925 - val_loss: 1.2137 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4060/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.7948\n",
      "Epoch 4060: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5698 - accuracy: 0.7948 - val_loss: 1.2214 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4061/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.8047\n",
      "Epoch 4061: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5399 - accuracy: 0.8047 - val_loss: 1.2341 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4062/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7959\n",
      "Epoch 4062: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5746 - accuracy: 0.7959 - val_loss: 1.2511 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4063/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5490 - accuracy: 0.7925\n",
      "Epoch 4063: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.5490 - accuracy: 0.7925 - val_loss: 1.2702 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4064/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.8125\n",
      "Epoch 4064: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5437 - accuracy: 0.8125 - val_loss: 1.2820 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4065/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.8101\n",
      "Epoch 4065: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5481 - accuracy: 0.8101 - val_loss: 1.2870 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4066/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.8078\n",
      "Epoch 4066: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5501 - accuracy: 0.8078 - val_loss: 1.2926 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4067/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.7960\n",
      "Epoch 4067: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5543 - accuracy: 0.7960 - val_loss: 1.3025 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4068/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.8090\n",
      "Epoch 4068: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5328 - accuracy: 0.8090 - val_loss: 1.3222 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4069/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5816 - accuracy: 0.8019\n",
      "Epoch 4069: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5816 - accuracy: 0.8019 - val_loss: 1.3447 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4070/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5362 - accuracy: 0.8149\n",
      "Epoch 4070: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5362 - accuracy: 0.8149 - val_loss: 1.3825 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4071/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.8113\n",
      "Epoch 4071: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5377 - accuracy: 0.8113 - val_loss: 1.3992 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4072/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5930 - accuracy: 0.7842\n",
      "Epoch 4072: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5930 - accuracy: 0.7842 - val_loss: 1.4036 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 4073/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5553 - accuracy: 0.7913\n",
      "Epoch 4073: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5553 - accuracy: 0.7913 - val_loss: 1.3819 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 4074/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.8042\n",
      "Epoch 4074: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.5314 - accuracy: 0.8042 - val_loss: 1.3624 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4075/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.7830\n",
      "Epoch 4075: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5615 - accuracy: 0.7830 - val_loss: 1.3356 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 4076/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.8008\n",
      "Epoch 4076: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5621 - accuracy: 0.8008 - val_loss: 1.3080 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4077/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.8019\n",
      "Epoch 4077: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5665 - accuracy: 0.8019 - val_loss: 1.2860 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4078/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5322 - accuracy: 0.8105\n",
      "Epoch 4078: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5322 - accuracy: 0.8105 - val_loss: 1.2628 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4079/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5732 - accuracy: 0.7877\n",
      "Epoch 4079: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5732 - accuracy: 0.7877 - val_loss: 1.2471 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4080/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5571 - accuracy: 0.8066\n",
      "Epoch 4080: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5571 - accuracy: 0.8066 - val_loss: 1.2277 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4081/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5191 - accuracy: 0.8113\n",
      "Epoch 4081: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5191 - accuracy: 0.8113 - val_loss: 1.2077 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4082/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.7949\n",
      "Epoch 4082: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5794 - accuracy: 0.7949 - val_loss: 1.2026 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4083/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7925\n",
      "Epoch 4083: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5641 - accuracy: 0.7925 - val_loss: 1.2008 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4084/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7901\n",
      "Epoch 4084: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5665 - accuracy: 0.7901 - val_loss: 1.2074 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4085/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0.8019\n",
      "Epoch 4085: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5753 - accuracy: 0.8019 - val_loss: 1.2145 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4086/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.7925\n",
      "Epoch 4086: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5587 - accuracy: 0.7925 - val_loss: 1.2147 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4087/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7983\n",
      "Epoch 4087: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.5673 - accuracy: 0.7983 - val_loss: 1.2065 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4088/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.7925\n",
      "Epoch 4088: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5747 - accuracy: 0.7925 - val_loss: 1.2082 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4089/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.7913\n",
      "Epoch 4089: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 367ms/step - loss: 0.5589 - accuracy: 0.7913 - val_loss: 1.2162 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4090/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5484 - accuracy: 0.8066\n",
      "Epoch 4090: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.5484 - accuracy: 0.8066 - val_loss: 1.2257 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4091/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.7988\n",
      "Epoch 4091: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 0.5706 - accuracy: 0.7988 - val_loss: 1.2423 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4092/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.7960\n",
      "Epoch 4092: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5801 - accuracy: 0.7960 - val_loss: 1.2645 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4093/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.8042\n",
      "Epoch 4093: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.5518 - accuracy: 0.8042 - val_loss: 1.2828 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4094/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.8101\n",
      "Epoch 4094: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 329ms/step - loss: 0.5674 - accuracy: 0.8101 - val_loss: 1.3147 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4095/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.8066\n",
      "Epoch 4095: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5637 - accuracy: 0.8066 - val_loss: 1.3536 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4096/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5770 - accuracy: 0.7842\n",
      "Epoch 4096: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5770 - accuracy: 0.7842 - val_loss: 1.3856 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4097/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.7983\n",
      "Epoch 4097: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5529 - accuracy: 0.7983 - val_loss: 1.4185 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 4098/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.7866\n",
      "Epoch 4098: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.6028 - accuracy: 0.7866 - val_loss: 1.4182 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 4099/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7925\n",
      "Epoch 4099: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.5667 - accuracy: 0.7925 - val_loss: 1.4178 - val_accuracy: 0.5523 - lr: 1.0000e-05\n",
      "Epoch 4100/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7948\n",
      "Epoch 4100: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5746 - accuracy: 0.7948 - val_loss: 1.3985 - val_accuracy: 0.5560 - lr: 1.0000e-05\n",
      "Epoch 4101/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.8019\n",
      "Epoch 4101: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.5643 - accuracy: 0.8019 - val_loss: 1.3827 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4102/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.8113\n",
      "Epoch 4102: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 335ms/step - loss: 0.5431 - accuracy: 0.8113 - val_loss: 1.3575 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4103/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.8101\n",
      "Epoch 4103: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.5347 - accuracy: 0.8101 - val_loss: 1.3324 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4104/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.7995\n",
      "Epoch 4104: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5715 - accuracy: 0.7995 - val_loss: 1.3134 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4105/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.8007\n",
      "Epoch 4105: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.5615 - accuracy: 0.8007 - val_loss: 1.3012 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4106/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.8172\n",
      "Epoch 4106: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.5412 - accuracy: 0.8172 - val_loss: 1.2924 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4107/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.7830\n",
      "Epoch 4107: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.5466 - accuracy: 0.7830 - val_loss: 1.2905 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4108/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.7861\n",
      "Epoch 4108: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5836 - accuracy: 0.7861 - val_loss: 1.2854 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4109/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.7995\n",
      "Epoch 4109: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5432 - accuracy: 0.7995 - val_loss: 1.2698 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4110/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.8078\n",
      "Epoch 4110: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.5470 - accuracy: 0.8078 - val_loss: 1.2449 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4111/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.8125\n",
      "Epoch 4111: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5377 - accuracy: 0.8125 - val_loss: 1.2156 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4112/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.8125\n",
      "Epoch 4112: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5316 - accuracy: 0.8125 - val_loss: 1.1984 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4113/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5809 - accuracy: 0.7866\n",
      "Epoch 4113: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5809 - accuracy: 0.7866 - val_loss: 1.1912 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4114/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.7960\n",
      "Epoch 4114: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.6023 - accuracy: 0.7960 - val_loss: 1.1977 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4115/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.8219\n",
      "Epoch 4115: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5074 - accuracy: 0.8219 - val_loss: 1.2046 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4116/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.8007\n",
      "Epoch 4116: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5586 - accuracy: 0.8007 - val_loss: 1.2082 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4117/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.7995\n",
      "Epoch 4117: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.5769 - accuracy: 0.7995 - val_loss: 1.2271 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4118/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.7925\n",
      "Epoch 4118: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.5427 - accuracy: 0.7925 - val_loss: 1.2356 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4119/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.7930\n",
      "Epoch 4119: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.5540 - accuracy: 0.7930 - val_loss: 1.2412 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4120/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.8090\n",
      "Epoch 4120: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.5394 - accuracy: 0.8090 - val_loss: 1.2409 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4121/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5704 - accuracy: 0.7959\n",
      "Epoch 4121: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.5704 - accuracy: 0.7959 - val_loss: 1.2448 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4122/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.7972\n",
      "Epoch 4122: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.5576 - accuracy: 0.7972 - val_loss: 1.2571 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4123/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.8078\n",
      "Epoch 4123: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5591 - accuracy: 0.8078 - val_loss: 1.2740 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4124/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7866\n",
      "Epoch 4124: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5682 - accuracy: 0.7866 - val_loss: 1.2943 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4125/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.7959\n",
      "Epoch 4125: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5473 - accuracy: 0.7959 - val_loss: 1.3132 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4126/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8125\n",
      "Epoch 4126: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.5424 - accuracy: 0.8125 - val_loss: 1.3205 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4127/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.8076\n",
      "Epoch 4127: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5326 - accuracy: 0.8076 - val_loss: 1.3214 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4128/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.8137\n",
      "Epoch 4128: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5509 - accuracy: 0.8137 - val_loss: 1.3136 - val_accuracy: 0.5596 - lr: 1.0000e-05\n",
      "Epoch 4129/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5532 - accuracy: 0.7972\n",
      "Epoch 4129: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5532 - accuracy: 0.7972 - val_loss: 1.3032 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4130/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.8160\n",
      "Epoch 4130: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5334 - accuracy: 0.8160 - val_loss: 1.3041 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 4131/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.8078\n",
      "Epoch 4131: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5369 - accuracy: 0.8078 - val_loss: 1.3022 - val_accuracy: 0.5632 - lr: 1.0000e-05\n",
      "Epoch 4132/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.7783\n",
      "Epoch 4132: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.5772 - accuracy: 0.7783 - val_loss: 1.2947 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4133/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8031\n",
      "Epoch 4133: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5424 - accuracy: 0.8031 - val_loss: 1.2805 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4134/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5553 - accuracy: 0.8031\n",
      "Epoch 4134: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5553 - accuracy: 0.8031 - val_loss: 1.2689 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4135/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8125\n",
      "Epoch 4135: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5232 - accuracy: 0.8125 - val_loss: 1.2539 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4136/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.8007\n",
      "Epoch 4136: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5541 - accuracy: 0.8007 - val_loss: 1.2453 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4137/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.7995\n",
      "Epoch 4137: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5244 - accuracy: 0.7995 - val_loss: 1.2465 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4138/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.8037\n",
      "Epoch 4138: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5355 - accuracy: 0.8037 - val_loss: 1.2429 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4139/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.7930\n",
      "Epoch 4139: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5552 - accuracy: 0.7930 - val_loss: 1.2491 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4140/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.7818\n",
      "Epoch 4140: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.5750 - accuracy: 0.7818 - val_loss: 1.2547 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4141/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5545 - accuracy: 0.8066\n",
      "Epoch 4141: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5545 - accuracy: 0.8066 - val_loss: 1.2591 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4142/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.8078\n",
      "Epoch 4142: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5426 - accuracy: 0.8078 - val_loss: 1.2594 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4143/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.7972\n",
      "Epoch 4143: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5744 - accuracy: 0.7972 - val_loss: 1.2558 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4144/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.8019\n",
      "Epoch 4144: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5676 - accuracy: 0.8019 - val_loss: 1.2496 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4145/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.7983\n",
      "Epoch 4145: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5548 - accuracy: 0.7983 - val_loss: 1.2523 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4146/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.7983\n",
      "Epoch 4146: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5692 - accuracy: 0.7983 - val_loss: 1.2560 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4147/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5060 - accuracy: 0.8314\n",
      "Epoch 4147: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5060 - accuracy: 0.8314 - val_loss: 1.2644 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4148/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7901\n",
      "Epoch 4148: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5682 - accuracy: 0.7901 - val_loss: 1.2818 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4149/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.7972\n",
      "Epoch 4149: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.5438 - accuracy: 0.7972 - val_loss: 1.2891 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4150/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.8031\n",
      "Epoch 4150: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5663 - accuracy: 0.8031 - val_loss: 1.2863 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4151/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.7773\n",
      "Epoch 4151: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5797 - accuracy: 0.7773 - val_loss: 1.2780 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4152/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.7936\n",
      "Epoch 4152: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5339 - accuracy: 0.7936 - val_loss: 1.2583 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4153/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5571 - accuracy: 0.8007\n",
      "Epoch 4153: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5571 - accuracy: 0.8007 - val_loss: 1.2447 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4154/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.8066\n",
      "Epoch 4154: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5237 - accuracy: 0.8066 - val_loss: 1.2341 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4155/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5389 - accuracy: 0.8008\n",
      "Epoch 4155: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 0.5389 - accuracy: 0.8008 - val_loss: 1.2250 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4156/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5545 - accuracy: 0.7889\n",
      "Epoch 4156: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5545 - accuracy: 0.7889 - val_loss: 1.2286 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4157/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.8172\n",
      "Epoch 4157: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5229 - accuracy: 0.8172 - val_loss: 1.2281 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4158/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.8054\n",
      "Epoch 4158: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5329 - accuracy: 0.8054 - val_loss: 1.2256 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4159/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.7960\n",
      "Epoch 4159: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5733 - accuracy: 0.7960 - val_loss: 1.2351 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4160/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.7877\n",
      "Epoch 4160: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.5623 - accuracy: 0.7877 - val_loss: 1.2514 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4161/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.8219\n",
      "Epoch 4161: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5224 - accuracy: 0.8219 - val_loss: 1.2612 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4162/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.8066\n",
      "Epoch 4162: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5524 - accuracy: 0.8066 - val_loss: 1.2599 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4163/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.8125\n",
      "Epoch 4163: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.5273 - accuracy: 0.8125 - val_loss: 1.2594 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4164/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7913\n",
      "Epoch 4164: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5687 - accuracy: 0.7913 - val_loss: 1.2490 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4165/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.8137\n",
      "Epoch 4165: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5188 - accuracy: 0.8137 - val_loss: 1.2392 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4166/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5443 - accuracy: 0.7877\n",
      "Epoch 4166: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5443 - accuracy: 0.7877 - val_loss: 1.2280 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4167/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.8290\n",
      "Epoch 4167: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.4908 - accuracy: 0.8290 - val_loss: 1.2318 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4168/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5880 - accuracy: 0.7983\n",
      "Epoch 4168: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5880 - accuracy: 0.7983 - val_loss: 1.2202 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4169/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.8145\n",
      "Epoch 4169: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5351 - accuracy: 0.8145 - val_loss: 1.2045 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4170/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.8172\n",
      "Epoch 4170: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5408 - accuracy: 0.8172 - val_loss: 1.1994 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4171/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.8137\n",
      "Epoch 4171: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5528 - accuracy: 0.8137 - val_loss: 1.1975 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4172/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.8008\n",
      "Epoch 4172: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5421 - accuracy: 0.8008 - val_loss: 1.2077 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4173/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.8007\n",
      "Epoch 4173: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5618 - accuracy: 0.8007 - val_loss: 1.2208 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4174/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.7901\n",
      "Epoch 4174: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5537 - accuracy: 0.7901 - val_loss: 1.2299 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4175/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.8054\n",
      "Epoch 4175: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5486 - accuracy: 0.8054 - val_loss: 1.2598 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4176/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8172\n",
      "Epoch 4176: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5289 - accuracy: 0.8172 - val_loss: 1.2824 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4177/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.7900\n",
      "Epoch 4177: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5487 - accuracy: 0.7900 - val_loss: 1.3121 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4178/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.8054\n",
      "Epoch 4178: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5393 - accuracy: 0.8054 - val_loss: 1.3164 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4179/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5642 - accuracy: 0.8042\n",
      "Epoch 4179: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5642 - accuracy: 0.8042 - val_loss: 1.2891 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4180/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.7818\n",
      "Epoch 4180: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5451 - accuracy: 0.7818 - val_loss: 1.2769 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4181/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.8086\n",
      "Epoch 4181: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5224 - accuracy: 0.8086 - val_loss: 1.2797 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4182/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.8066\n",
      "Epoch 4182: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5593 - accuracy: 0.8066 - val_loss: 1.2856 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4183/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.7842\n",
      "Epoch 4183: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5722 - accuracy: 0.7842 - val_loss: 1.2770 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4184/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.7949\n",
      "Epoch 4184: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5636 - accuracy: 0.7949 - val_loss: 1.2673 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4185/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.7854\n",
      "Epoch 4185: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5991 - accuracy: 0.7854 - val_loss: 1.2437 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4186/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.8054\n",
      "Epoch 4186: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5529 - accuracy: 0.8054 - val_loss: 1.2162 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4187/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8007\n",
      "Epoch 4187: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5415 - accuracy: 0.8007 - val_loss: 1.2015 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4188/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.7995\n",
      "Epoch 4188: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5437 - accuracy: 0.7995 - val_loss: 1.1947 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4189/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.8125\n",
      "Epoch 4189: val_loss did not improve from 1.17986\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5467 - accuracy: 0.8125 - val_loss: 1.1863 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4190/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5691 - accuracy: 0.8019\n",
      "Epoch 4190: val_loss improved from 1.17986 to 1.17018, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5691 - accuracy: 0.8019 - val_loss: 1.1702 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4191/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.7866\n",
      "Epoch 4191: val_loss improved from 1.17018 to 1.16358, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5891 - accuracy: 0.7866 - val_loss: 1.1636 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4192/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.8137\n",
      "Epoch 4192: val_loss improved from 1.16358 to 1.15974, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5527 - accuracy: 0.8137 - val_loss: 1.1597 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4193/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.7913\n",
      "Epoch 4193: val_loss improved from 1.15974 to 1.15846, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5768 - accuracy: 0.7913 - val_loss: 1.1585 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4194/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.8125\n",
      "Epoch 4194: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5359 - accuracy: 0.8125 - val_loss: 1.1620 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4195/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.8066\n",
      "Epoch 4195: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5412 - accuracy: 0.8066 - val_loss: 1.1788 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4196/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.7936\n",
      "Epoch 4196: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5875 - accuracy: 0.7936 - val_loss: 1.1911 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4197/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.8007\n",
      "Epoch 4197: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5656 - accuracy: 0.8007 - val_loss: 1.1966 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4198/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.8008\n",
      "Epoch 4198: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5444 - accuracy: 0.8008 - val_loss: 1.2039 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4199/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.7925\n",
      "Epoch 4199: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5697 - accuracy: 0.7925 - val_loss: 1.2147 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4200/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.7972\n",
      "Epoch 4200: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5636 - accuracy: 0.7972 - val_loss: 1.2322 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4201/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.8042\n",
      "Epoch 4201: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5556 - accuracy: 0.8042 - val_loss: 1.2430 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4202/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.8101\n",
      "Epoch 4202: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5567 - accuracy: 0.8101 - val_loss: 1.2404 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4203/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.7889\n",
      "Epoch 4203: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5548 - accuracy: 0.7889 - val_loss: 1.2360 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4204/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.8042\n",
      "Epoch 4204: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5319 - accuracy: 0.8042 - val_loss: 1.2281 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4205/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7771\n",
      "Epoch 4205: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5665 - accuracy: 0.7771 - val_loss: 1.2204 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4206/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5760 - accuracy: 0.7889\n",
      "Epoch 4206: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5760 - accuracy: 0.7889 - val_loss: 1.2251 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4207/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.8101\n",
      "Epoch 4207: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5329 - accuracy: 0.8101 - val_loss: 1.2261 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4208/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.7948\n",
      "Epoch 4208: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5514 - accuracy: 0.7948 - val_loss: 1.2323 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4209/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.8101\n",
      "Epoch 4209: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5604 - accuracy: 0.8101 - val_loss: 1.2423 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4210/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8164\n",
      "Epoch 4210: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5232 - accuracy: 0.8164 - val_loss: 1.2556 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4211/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5497 - accuracy: 0.8115\n",
      "Epoch 4211: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5497 - accuracy: 0.8115 - val_loss: 1.2664 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4212/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.8007\n",
      "Epoch 4212: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5768 - accuracy: 0.8007 - val_loss: 1.2782 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4213/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5306 - accuracy: 0.8105\n",
      "Epoch 4213: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5306 - accuracy: 0.8105 - val_loss: 1.2980 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4214/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.8164\n",
      "Epoch 4214: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5211 - accuracy: 0.8164 - val_loss: 1.3074 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4215/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.7995\n",
      "Epoch 4215: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5387 - accuracy: 0.7995 - val_loss: 1.3165 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4216/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.7877\n",
      "Epoch 4216: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5747 - accuracy: 0.7877 - val_loss: 1.3073 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4217/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.7948\n",
      "Epoch 4217: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.5423 - accuracy: 0.7948 - val_loss: 1.2959 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4218/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.7972\n",
      "Epoch 4218: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5507 - accuracy: 0.7972 - val_loss: 1.2788 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4219/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5496 - accuracy: 0.7983\n",
      "Epoch 4219: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5496 - accuracy: 0.7983 - val_loss: 1.2724 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4220/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.7960\n",
      "Epoch 4220: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5661 - accuracy: 0.7960 - val_loss: 1.2722 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4221/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.8149\n",
      "Epoch 4221: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5458 - accuracy: 0.8149 - val_loss: 1.2736 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4222/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8031\n",
      "Epoch 4222: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5414 - accuracy: 0.8031 - val_loss: 1.2842 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4223/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.8090\n",
      "Epoch 4223: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5428 - accuracy: 0.8090 - val_loss: 1.2988 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4224/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5313 - accuracy: 0.8145\n",
      "Epoch 4224: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5313 - accuracy: 0.8145 - val_loss: 1.2994 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4225/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5445 - accuracy: 0.8090\n",
      "Epoch 4225: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5445 - accuracy: 0.8090 - val_loss: 1.3057 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4226/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.8047\n",
      "Epoch 4226: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5632 - accuracy: 0.8047 - val_loss: 1.3103 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4227/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7988\n",
      "Epoch 4227: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5259 - accuracy: 0.7988 - val_loss: 1.3010 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4228/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.7983\n",
      "Epoch 4228: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5455 - accuracy: 0.7983 - val_loss: 1.2887 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4229/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.7818\n",
      "Epoch 4229: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5479 - accuracy: 0.7818 - val_loss: 1.2774 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4230/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.8137\n",
      "Epoch 4230: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5309 - accuracy: 0.8137 - val_loss: 1.2634 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4231/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5371 - accuracy: 0.8042\n",
      "Epoch 4231: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5371 - accuracy: 0.8042 - val_loss: 1.2544 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4232/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.7939\n",
      "Epoch 4232: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5433 - accuracy: 0.7939 - val_loss: 1.2615 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4233/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.8066\n",
      "Epoch 4233: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5527 - accuracy: 0.8066 - val_loss: 1.2685 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4234/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.7889\n",
      "Epoch 4234: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.5723 - accuracy: 0.7889 - val_loss: 1.2873 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4235/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.7939\n",
      "Epoch 4235: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.5345 - accuracy: 0.7939 - val_loss: 1.3036 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4236/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.8267\n",
      "Epoch 4236: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5042 - accuracy: 0.8267 - val_loss: 1.3134 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4237/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.7960\n",
      "Epoch 4237: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 0.5487 - accuracy: 0.7960 - val_loss: 1.2944 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4238/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.7995\n",
      "Epoch 4238: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5536 - accuracy: 0.7995 - val_loss: 1.2807 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4239/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.8076\n",
      "Epoch 4239: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5395 - accuracy: 0.8076 - val_loss: 1.2670 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4240/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.8090\n",
      "Epoch 4240: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5562 - accuracy: 0.8090 - val_loss: 1.2622 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4241/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.8008\n",
      "Epoch 4241: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5562 - accuracy: 0.8008 - val_loss: 1.2542 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4242/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.8007\n",
      "Epoch 4242: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5501 - accuracy: 0.8007 - val_loss: 1.2381 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4243/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.7979\n",
      "Epoch 4243: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5495 - accuracy: 0.7979 - val_loss: 1.2285 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4244/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.7972\n",
      "Epoch 4244: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5475 - accuracy: 0.7972 - val_loss: 1.2343 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4245/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.8184\n",
      "Epoch 4245: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5145 - accuracy: 0.8184 - val_loss: 1.2452 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4246/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5619 - accuracy: 0.8008\n",
      "Epoch 4246: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5619 - accuracy: 0.8008 - val_loss: 1.2703 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4247/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.7854\n",
      "Epoch 4247: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5607 - accuracy: 0.7854 - val_loss: 1.2918 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4248/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5315 - accuracy: 0.8113\n",
      "Epoch 4248: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5315 - accuracy: 0.8113 - val_loss: 1.3116 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4249/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.8031\n",
      "Epoch 4249: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5681 - accuracy: 0.8031 - val_loss: 1.3184 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4250/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.8019\n",
      "Epoch 4250: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5541 - accuracy: 0.8019 - val_loss: 1.3039 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4251/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.8115\n",
      "Epoch 4251: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5257 - accuracy: 0.8115 - val_loss: 1.3037 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4252/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.7983\n",
      "Epoch 4252: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5631 - accuracy: 0.7983 - val_loss: 1.3142 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4253/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.7995\n",
      "Epoch 4253: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5712 - accuracy: 0.7995 - val_loss: 1.3240 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4254/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.8125\n",
      "Epoch 4254: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5062 - accuracy: 0.8125 - val_loss: 1.3359 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4255/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.8078\n",
      "Epoch 4255: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5566 - accuracy: 0.8078 - val_loss: 1.3408 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4256/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8037\n",
      "Epoch 4256: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5425 - accuracy: 0.8037 - val_loss: 1.3354 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4257/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.7925\n",
      "Epoch 4257: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5548 - accuracy: 0.7925 - val_loss: 1.3303 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4258/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5315 - accuracy: 0.8066\n",
      "Epoch 4258: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5315 - accuracy: 0.8066 - val_loss: 1.3144 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4259/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.7960\n",
      "Epoch 4259: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5555 - accuracy: 0.7960 - val_loss: 1.2939 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4260/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.8361\n",
      "Epoch 4260: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.4889 - accuracy: 0.8361 - val_loss: 1.2768 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4261/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.7913\n",
      "Epoch 4261: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.5584 - accuracy: 0.7913 - val_loss: 1.2624 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4262/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.7983\n",
      "Epoch 4262: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5540 - accuracy: 0.7983 - val_loss: 1.2536 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4263/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.7995\n",
      "Epoch 4263: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5679 - accuracy: 0.7995 - val_loss: 1.2363 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4264/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7830\n",
      "Epoch 4264: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5662 - accuracy: 0.7830 - val_loss: 1.2214 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4265/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.8057\n",
      "Epoch 4265: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.5419 - accuracy: 0.8057 - val_loss: 1.2179 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4266/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.8090\n",
      "Epoch 4266: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5458 - accuracy: 0.8090 - val_loss: 1.2266 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4267/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.8066\n",
      "Epoch 4267: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5400 - accuracy: 0.8066 - val_loss: 1.2243 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4268/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5721 - accuracy: 0.7936\n",
      "Epoch 4268: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5721 - accuracy: 0.7936 - val_loss: 1.2242 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4269/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.8019\n",
      "Epoch 4269: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5411 - accuracy: 0.8019 - val_loss: 1.2184 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4270/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.8066\n",
      "Epoch 4270: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5249 - accuracy: 0.8066 - val_loss: 1.2183 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4271/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.8018\n",
      "Epoch 4271: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5673 - accuracy: 0.8018 - val_loss: 1.2132 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4272/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5402 - accuracy: 0.7995\n",
      "Epoch 4272: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5402 - accuracy: 0.7995 - val_loss: 1.2049 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4273/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.8007\n",
      "Epoch 4273: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5390 - accuracy: 0.8007 - val_loss: 1.1985 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4274/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5511 - accuracy: 0.8042\n",
      "Epoch 4274: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.5511 - accuracy: 0.8042 - val_loss: 1.2133 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4275/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7983\n",
      "Epoch 4275: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5657 - accuracy: 0.7983 - val_loss: 1.2356 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4276/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7969\n",
      "Epoch 4276: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5734 - accuracy: 0.7969 - val_loss: 1.2430 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4277/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.7983\n",
      "Epoch 4277: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5690 - accuracy: 0.7983 - val_loss: 1.2590 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4278/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.8066\n",
      "Epoch 4278: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5547 - accuracy: 0.8066 - val_loss: 1.2638 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4279/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.8267\n",
      "Epoch 4279: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5228 - accuracy: 0.8267 - val_loss: 1.2705 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4280/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.8007\n",
      "Epoch 4280: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5467 - accuracy: 0.8007 - val_loss: 1.2774 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4281/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.8031\n",
      "Epoch 4281: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5667 - accuracy: 0.8031 - val_loss: 1.2874 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4282/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.8325\n",
      "Epoch 4282: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5243 - accuracy: 0.8325 - val_loss: 1.2944 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4283/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.8066\n",
      "Epoch 4283: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5174 - accuracy: 0.8066 - val_loss: 1.3099 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4284/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5900 - accuracy: 0.7807\n",
      "Epoch 4284: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5900 - accuracy: 0.7807 - val_loss: 1.3148 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4285/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.8096\n",
      "Epoch 4285: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5278 - accuracy: 0.8096 - val_loss: 1.3185 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4286/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.7979\n",
      "Epoch 4286: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5471 - accuracy: 0.7979 - val_loss: 1.3090 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4287/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.8096\n",
      "Epoch 4287: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5357 - accuracy: 0.8096 - val_loss: 1.3054 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4288/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.8007\n",
      "Epoch 4288: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5513 - accuracy: 0.8007 - val_loss: 1.2975 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4289/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.8243\n",
      "Epoch 4289: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5300 - accuracy: 0.8243 - val_loss: 1.2827 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4290/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.8125\n",
      "Epoch 4290: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5339 - accuracy: 0.8125 - val_loss: 1.2674 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4291/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.8113\n",
      "Epoch 4291: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5482 - accuracy: 0.8113 - val_loss: 1.2528 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4292/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.7983\n",
      "Epoch 4292: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5461 - accuracy: 0.7983 - val_loss: 1.2388 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4293/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5837 - accuracy: 0.7995\n",
      "Epoch 4293: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5837 - accuracy: 0.7995 - val_loss: 1.2287 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4294/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.8203\n",
      "Epoch 4294: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5311 - accuracy: 0.8203 - val_loss: 1.2242 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4295/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5208 - accuracy: 0.8054\n",
      "Epoch 4295: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5208 - accuracy: 0.8054 - val_loss: 1.2219 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4296/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5354 - accuracy: 0.8078\n",
      "Epoch 4296: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5354 - accuracy: 0.8078 - val_loss: 1.2240 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4297/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.7913\n",
      "Epoch 4297: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5502 - accuracy: 0.7913 - val_loss: 1.2314 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4298/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.8113\n",
      "Epoch 4298: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5218 - accuracy: 0.8113 - val_loss: 1.2450 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4299/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.7969\n",
      "Epoch 4299: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5342 - accuracy: 0.7969 - val_loss: 1.2648 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4300/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.7972\n",
      "Epoch 4300: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5309 - accuracy: 0.7972 - val_loss: 1.2779 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4301/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.8105\n",
      "Epoch 4301: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5180 - accuracy: 0.8105 - val_loss: 1.2729 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4302/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.8007\n",
      "Epoch 4302: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5378 - accuracy: 0.8007 - val_loss: 1.2664 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4303/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.8066\n",
      "Epoch 4303: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5498 - accuracy: 0.8066 - val_loss: 1.2609 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4304/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5603 - accuracy: 0.7925\n",
      "Epoch 4304: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5603 - accuracy: 0.7925 - val_loss: 1.2517 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4305/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.7983\n",
      "Epoch 4305: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5471 - accuracy: 0.7983 - val_loss: 1.2373 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4306/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.7936\n",
      "Epoch 4306: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5591 - accuracy: 0.7936 - val_loss: 1.2267 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4307/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.8219\n",
      "Epoch 4307: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.4978 - accuracy: 0.8219 - val_loss: 1.2053 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4308/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.7948\n",
      "Epoch 4308: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5488 - accuracy: 0.7948 - val_loss: 1.1946 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4309/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.8101\n",
      "Epoch 4309: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5431 - accuracy: 0.8101 - val_loss: 1.1862 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4310/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5510 - accuracy: 0.7913\n",
      "Epoch 4310: val_loss did not improve from 1.15846\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5510 - accuracy: 0.7913 - val_loss: 1.1687 - val_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 4311/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.8042\n",
      "Epoch 4311: val_loss improved from 1.15846 to 1.15765, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5329 - accuracy: 0.8042 - val_loss: 1.1577 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4312/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.8101\n",
      "Epoch 4312: val_loss improved from 1.15765 to 1.14972, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5427 - accuracy: 0.8101 - val_loss: 1.1497 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4313/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.8019\n",
      "Epoch 4313: val_loss improved from 1.14972 to 1.14708, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5369 - accuracy: 0.8019 - val_loss: 1.1471 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4314/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.7913\n",
      "Epoch 4314: val_loss improved from 1.14708 to 1.13383, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5399 - accuracy: 0.7913 - val_loss: 1.1338 - val_accuracy: 0.6462 - lr: 1.0000e-05\n",
      "Epoch 4315/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.8042\n",
      "Epoch 4315: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5506 - accuracy: 0.8042 - val_loss: 1.1375 - val_accuracy: 0.6426 - lr: 1.0000e-05\n",
      "Epoch 4316/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.8172\n",
      "Epoch 4316: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5332 - accuracy: 0.8172 - val_loss: 1.1597 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4317/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.8113\n",
      "Epoch 4317: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.5417 - accuracy: 0.8113 - val_loss: 1.1766 - val_accuracy: 0.6318 - lr: 1.0000e-05\n",
      "Epoch 4318/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.8031\n",
      "Epoch 4318: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5455 - accuracy: 0.8031 - val_loss: 1.1930 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4319/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.7959\n",
      "Epoch 4319: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5589 - accuracy: 0.7959 - val_loss: 1.2046 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4320/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7983\n",
      "Epoch 4320: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5574 - accuracy: 0.7983 - val_loss: 1.2148 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4321/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.8042\n",
      "Epoch 4321: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5444 - accuracy: 0.8042 - val_loss: 1.2194 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4322/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5403 - accuracy: 0.8066\n",
      "Epoch 4322: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5403 - accuracy: 0.8066 - val_loss: 1.2281 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4323/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5198 - accuracy: 0.8125\n",
      "Epoch 4323: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5198 - accuracy: 0.8125 - val_loss: 1.2374 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4324/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.8037\n",
      "Epoch 4324: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5488 - accuracy: 0.8037 - val_loss: 1.2427 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4325/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5612 - accuracy: 0.7807\n",
      "Epoch 4325: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5612 - accuracy: 0.7807 - val_loss: 1.2497 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4326/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.8172\n",
      "Epoch 4326: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5073 - accuracy: 0.8172 - val_loss: 1.2535 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4327/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.8066\n",
      "Epoch 4327: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5251 - accuracy: 0.8066 - val_loss: 1.2561 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4328/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.7995\n",
      "Epoch 4328: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5591 - accuracy: 0.7995 - val_loss: 1.2600 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4329/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.8145\n",
      "Epoch 4329: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5166 - accuracy: 0.8145 - val_loss: 1.2727 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4330/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.8008\n",
      "Epoch 4330: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5542 - accuracy: 0.8008 - val_loss: 1.2861 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4331/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.7830\n",
      "Epoch 4331: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5570 - accuracy: 0.7830 - val_loss: 1.2899 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4332/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5267 - accuracy: 0.7972\n",
      "Epoch 4332: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5267 - accuracy: 0.7972 - val_loss: 1.2968 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4333/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.8008\n",
      "Epoch 4333: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5610 - accuracy: 0.8008 - val_loss: 1.3066 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4334/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.8184\n",
      "Epoch 4334: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5257 - accuracy: 0.8184 - val_loss: 1.3073 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4335/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.8243\n",
      "Epoch 4335: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5113 - accuracy: 0.8243 - val_loss: 1.3065 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4336/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.8078\n",
      "Epoch 4336: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5216 - accuracy: 0.8078 - val_loss: 1.3094 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4337/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.8054\n",
      "Epoch 4337: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5404 - accuracy: 0.8054 - val_loss: 1.2924 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4338/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.7998\n",
      "Epoch 4338: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5468 - accuracy: 0.7998 - val_loss: 1.2786 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4339/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.8213\n",
      "Epoch 4339: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5014 - accuracy: 0.8213 - val_loss: 1.2685 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4340/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.8160\n",
      "Epoch 4340: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5195 - accuracy: 0.8160 - val_loss: 1.2610 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4341/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.8255\n",
      "Epoch 4341: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5197 - accuracy: 0.8255 - val_loss: 1.2658 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4342/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5811 - accuracy: 0.7913\n",
      "Epoch 4342: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5811 - accuracy: 0.7913 - val_loss: 1.2712 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4343/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.8078\n",
      "Epoch 4343: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5278 - accuracy: 0.8078 - val_loss: 1.2703 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4344/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8007\n",
      "Epoch 4344: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5245 - accuracy: 0.8007 - val_loss: 1.2679 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4345/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7972\n",
      "Epoch 4345: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5734 - accuracy: 0.7972 - val_loss: 1.2762 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4346/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.8172\n",
      "Epoch 4346: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5174 - accuracy: 0.8172 - val_loss: 1.2817 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4347/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.8047\n",
      "Epoch 4347: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5216 - accuracy: 0.8047 - val_loss: 1.2782 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4348/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.8031\n",
      "Epoch 4348: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5405 - accuracy: 0.8031 - val_loss: 1.2852 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4349/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.8137\n",
      "Epoch 4349: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5216 - accuracy: 0.8137 - val_loss: 1.2731 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4350/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.8219\n",
      "Epoch 4350: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5169 - accuracy: 0.8219 - val_loss: 1.2512 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4351/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.8007\n",
      "Epoch 4351: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5430 - accuracy: 0.8007 - val_loss: 1.2453 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4352/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.8196\n",
      "Epoch 4352: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5205 - accuracy: 0.8196 - val_loss: 1.2488 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4353/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.7877\n",
      "Epoch 4353: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5621 - accuracy: 0.7877 - val_loss: 1.2566 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4354/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.8007\n",
      "Epoch 4354: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5465 - accuracy: 0.8007 - val_loss: 1.2683 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4355/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.7925\n",
      "Epoch 4355: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5585 - accuracy: 0.7925 - val_loss: 1.2765 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4356/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.8019\n",
      "Epoch 4356: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5589 - accuracy: 0.8019 - val_loss: 1.2870 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4357/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.8208\n",
      "Epoch 4357: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.4958 - accuracy: 0.8208 - val_loss: 1.2990 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4358/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.8219\n",
      "Epoch 4358: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5346 - accuracy: 0.8219 - val_loss: 1.3012 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4359/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.8137\n",
      "Epoch 4359: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5340 - accuracy: 0.8137 - val_loss: 1.2905 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4360/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.8325\n",
      "Epoch 4360: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5012 - accuracy: 0.8325 - val_loss: 1.2800 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4361/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.8208\n",
      "Epoch 4361: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5395 - accuracy: 0.8208 - val_loss: 1.2557 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4362/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.8113\n",
      "Epoch 4362: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5528 - accuracy: 0.8113 - val_loss: 1.2263 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4363/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.8145\n",
      "Epoch 4363: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5178 - accuracy: 0.8145 - val_loss: 1.2133 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4364/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.8007\n",
      "Epoch 4364: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5459 - accuracy: 0.8007 - val_loss: 1.2033 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4365/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.8090\n",
      "Epoch 4365: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5483 - accuracy: 0.8090 - val_loss: 1.1915 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4366/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.8042\n",
      "Epoch 4366: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5311 - accuracy: 0.8042 - val_loss: 1.1851 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4367/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.8096\n",
      "Epoch 4367: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5311 - accuracy: 0.8096 - val_loss: 1.1820 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4368/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.8037\n",
      "Epoch 4368: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5350 - accuracy: 0.8037 - val_loss: 1.1882 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4369/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.8208\n",
      "Epoch 4369: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5121 - accuracy: 0.8208 - val_loss: 1.2059 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4370/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.7972\n",
      "Epoch 4370: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5507 - accuracy: 0.7972 - val_loss: 1.2174 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4371/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5987 - accuracy: 0.7724\n",
      "Epoch 4371: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5987 - accuracy: 0.7724 - val_loss: 1.2262 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4372/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5324 - accuracy: 0.8196\n",
      "Epoch 4372: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5324 - accuracy: 0.8196 - val_loss: 1.2375 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4373/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.8047\n",
      "Epoch 4373: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5361 - accuracy: 0.8047 - val_loss: 1.2534 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4374/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.8172\n",
      "Epoch 4374: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5321 - accuracy: 0.8172 - val_loss: 1.2750 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4375/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.8019\n",
      "Epoch 4375: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5548 - accuracy: 0.8019 - val_loss: 1.2998 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4376/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.8007\n",
      "Epoch 4376: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5658 - accuracy: 0.8007 - val_loss: 1.3111 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4377/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5268 - accuracy: 0.8019\n",
      "Epoch 4377: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.5268 - accuracy: 0.8019 - val_loss: 1.3174 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4378/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.8054\n",
      "Epoch 4378: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5460 - accuracy: 0.8054 - val_loss: 1.3182 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4379/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.8078\n",
      "Epoch 4379: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5345 - accuracy: 0.8078 - val_loss: 1.3177 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4380/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.7830\n",
      "Epoch 4380: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5418 - accuracy: 0.7830 - val_loss: 1.3122 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4381/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.8208\n",
      "Epoch 4381: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.4941 - accuracy: 0.8208 - val_loss: 1.3185 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4382/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.8160\n",
      "Epoch 4382: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5048 - accuracy: 0.8160 - val_loss: 1.3295 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4383/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8232\n",
      "Epoch 4383: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.4977 - accuracy: 0.8232 - val_loss: 1.3428 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4384/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.7995\n",
      "Epoch 4384: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.5601 - accuracy: 0.7995 - val_loss: 1.3325 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4385/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5260 - accuracy: 0.8031\n",
      "Epoch 4385: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5260 - accuracy: 0.8031 - val_loss: 1.3300 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4386/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5353 - accuracy: 0.8078\n",
      "Epoch 4386: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5353 - accuracy: 0.8078 - val_loss: 1.3380 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4387/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8149\n",
      "Epoch 4387: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5415 - accuracy: 0.8149 - val_loss: 1.3405 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4388/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.8018\n",
      "Epoch 4388: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5380 - accuracy: 0.8018 - val_loss: 1.3499 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4389/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.8054\n",
      "Epoch 4389: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5335 - accuracy: 0.8054 - val_loss: 1.3438 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4390/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.8184\n",
      "Epoch 4390: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5133 - accuracy: 0.8184 - val_loss: 1.3295 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4391/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.8019\n",
      "Epoch 4391: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5383 - accuracy: 0.8019 - val_loss: 1.3153 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4392/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.8057\n",
      "Epoch 4392: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5303 - accuracy: 0.8057 - val_loss: 1.2952 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4393/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5484 - accuracy: 0.7949\n",
      "Epoch 4393: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5484 - accuracy: 0.7949 - val_loss: 1.2821 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4394/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.8213\n",
      "Epoch 4394: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5035 - accuracy: 0.8213 - val_loss: 1.2643 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4395/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8267\n",
      "Epoch 4395: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.4848 - accuracy: 0.8267 - val_loss: 1.2558 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4396/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.8042\n",
      "Epoch 4396: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5385 - accuracy: 0.8042 - val_loss: 1.2441 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4397/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5445 - accuracy: 0.8160\n",
      "Epoch 4397: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5445 - accuracy: 0.8160 - val_loss: 1.2270 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4398/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5267 - accuracy: 0.8057\n",
      "Epoch 4398: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5267 - accuracy: 0.8057 - val_loss: 1.2117 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4399/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.8160\n",
      "Epoch 4399: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5211 - accuracy: 0.8160 - val_loss: 1.2191 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4400/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.8066\n",
      "Epoch 4400: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5515 - accuracy: 0.8066 - val_loss: 1.2355 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4401/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.7936\n",
      "Epoch 4401: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5359 - accuracy: 0.7936 - val_loss: 1.2443 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4402/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7818\n",
      "Epoch 4402: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5658 - accuracy: 0.7818 - val_loss: 1.2542 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4403/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5267 - accuracy: 0.8101\n",
      "Epoch 4403: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5267 - accuracy: 0.8101 - val_loss: 1.2593 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4404/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5288 - accuracy: 0.8115\n",
      "Epoch 4404: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5288 - accuracy: 0.8115 - val_loss: 1.2753 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4405/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5067 - accuracy: 0.8255\n",
      "Epoch 4405: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5067 - accuracy: 0.8255 - val_loss: 1.2835 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4406/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.8054\n",
      "Epoch 4406: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.5346 - accuracy: 0.8054 - val_loss: 1.2763 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4407/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.8196\n",
      "Epoch 4407: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.4957 - accuracy: 0.8196 - val_loss: 1.2663 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4408/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.7936\n",
      "Epoch 4408: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5471 - accuracy: 0.7936 - val_loss: 1.2598 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4409/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8149\n",
      "Epoch 4409: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5182 - accuracy: 0.8149 - val_loss: 1.2659 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4410/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.8078\n",
      "Epoch 4410: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5622 - accuracy: 0.8078 - val_loss: 1.2611 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4411/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7830\n",
      "Epoch 4411: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5675 - accuracy: 0.7830 - val_loss: 1.2561 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4412/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.8101\n",
      "Epoch 4412: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.5269 - accuracy: 0.8101 - val_loss: 1.2563 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4413/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.8090\n",
      "Epoch 4413: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5369 - accuracy: 0.8090 - val_loss: 1.2571 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4414/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5260 - accuracy: 0.8078\n",
      "Epoch 4414: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5260 - accuracy: 0.8078 - val_loss: 1.2459 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4415/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7983\n",
      "Epoch 4415: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5574 - accuracy: 0.7983 - val_loss: 1.2366 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4416/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.7983\n",
      "Epoch 4416: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5460 - accuracy: 0.7983 - val_loss: 1.2211 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4417/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.7866\n",
      "Epoch 4417: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5544 - accuracy: 0.7866 - val_loss: 1.2041 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4418/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.8314\n",
      "Epoch 4418: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5050 - accuracy: 0.8314 - val_loss: 1.1908 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4419/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5462 - accuracy: 0.7960\n",
      "Epoch 4419: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5462 - accuracy: 0.7960 - val_loss: 1.1894 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4420/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.8076\n",
      "Epoch 4420: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5308 - accuracy: 0.8076 - val_loss: 1.1914 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4421/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.8278\n",
      "Epoch 4421: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5114 - accuracy: 0.8278 - val_loss: 1.1897 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4422/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.7948\n",
      "Epoch 4422: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5441 - accuracy: 0.7948 - val_loss: 1.1818 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4423/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.8054\n",
      "Epoch 4423: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5125 - accuracy: 0.8054 - val_loss: 1.1800 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4424/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.8042\n",
      "Epoch 4424: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.5563 - accuracy: 0.8042 - val_loss: 1.2033 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4425/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.8019\n",
      "Epoch 4425: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5396 - accuracy: 0.8019 - val_loss: 1.2174 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4426/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.8101\n",
      "Epoch 4426: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5250 - accuracy: 0.8101 - val_loss: 1.2402 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4427/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.8208\n",
      "Epoch 4427: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5393 - accuracy: 0.8208 - val_loss: 1.2461 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4428/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8008\n",
      "Epoch 4428: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5495 - accuracy: 0.8008 - val_loss: 1.2310 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4429/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.8076\n",
      "Epoch 4429: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5406 - accuracy: 0.8076 - val_loss: 1.2075 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4430/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.8027\n",
      "Epoch 4430: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.5472 - accuracy: 0.8027 - val_loss: 1.1945 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4431/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5443 - accuracy: 0.8078\n",
      "Epoch 4431: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5443 - accuracy: 0.8078 - val_loss: 1.1842 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4432/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.8101\n",
      "Epoch 4432: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5295 - accuracy: 0.8101 - val_loss: 1.1758 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4433/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.8384\n",
      "Epoch 4433: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.4843 - accuracy: 0.8384 - val_loss: 1.1757 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4434/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.8096\n",
      "Epoch 4434: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5270 - accuracy: 0.8096 - val_loss: 1.1814 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4435/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5546 - accuracy: 0.7960\n",
      "Epoch 4435: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5546 - accuracy: 0.7960 - val_loss: 1.1901 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4436/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8037\n",
      "Epoch 4436: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5414 - accuracy: 0.8037 - val_loss: 1.1948 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4437/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.8042\n",
      "Epoch 4437: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5339 - accuracy: 0.8042 - val_loss: 1.1983 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4438/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.8027\n",
      "Epoch 4438: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5130 - accuracy: 0.8027 - val_loss: 1.2061 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4439/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.8172\n",
      "Epoch 4439: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5087 - accuracy: 0.8172 - val_loss: 1.2100 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4440/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.8019\n",
      "Epoch 4440: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5284 - accuracy: 0.8019 - val_loss: 1.2006 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4441/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.8066\n",
      "Epoch 4441: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5400 - accuracy: 0.8066 - val_loss: 1.1843 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4442/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.8090\n",
      "Epoch 4442: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5108 - accuracy: 0.8090 - val_loss: 1.1691 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4443/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.8219\n",
      "Epoch 4443: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.4817 - accuracy: 0.8219 - val_loss: 1.1733 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4444/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8145\n",
      "Epoch 4444: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5247 - accuracy: 0.8145 - val_loss: 1.1741 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4445/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.8184\n",
      "Epoch 4445: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5312 - accuracy: 0.8184 - val_loss: 1.1862 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4446/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8007\n",
      "Epoch 4446: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5425 - accuracy: 0.8007 - val_loss: 1.2008 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4447/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.8184\n",
      "Epoch 4447: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5233 - accuracy: 0.8184 - val_loss: 1.2112 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4448/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.8149\n",
      "Epoch 4448: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5051 - accuracy: 0.8149 - val_loss: 1.2168 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4449/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.7948\n",
      "Epoch 4449: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5628 - accuracy: 0.7948 - val_loss: 1.2052 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4450/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.8066\n",
      "Epoch 4450: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.5503 - accuracy: 0.8066 - val_loss: 1.2033 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4451/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.8037\n",
      "Epoch 4451: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5143 - accuracy: 0.8037 - val_loss: 1.2067 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4452/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8137\n",
      "Epoch 4452: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5247 - accuracy: 0.8137 - val_loss: 1.2188 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4453/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.8031\n",
      "Epoch 4453: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5271 - accuracy: 0.8031 - val_loss: 1.2275 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4454/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.7920\n",
      "Epoch 4454: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5708 - accuracy: 0.7920 - val_loss: 1.2311 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4455/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.7936\n",
      "Epoch 4455: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.5633 - accuracy: 0.7936 - val_loss: 1.2278 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4456/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.8019\n",
      "Epoch 4456: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5506 - accuracy: 0.8019 - val_loss: 1.2373 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4457/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5267 - accuracy: 0.8154\n",
      "Epoch 4457: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5267 - accuracy: 0.8154 - val_loss: 1.2495 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4458/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.8231\n",
      "Epoch 4458: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5155 - accuracy: 0.8231 - val_loss: 1.2612 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4459/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.8243\n",
      "Epoch 4459: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5180 - accuracy: 0.8243 - val_loss: 1.2786 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4460/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.8066\n",
      "Epoch 4460: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5473 - accuracy: 0.8066 - val_loss: 1.2928 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4461/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8219\n",
      "Epoch 4461: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5182 - accuracy: 0.8219 - val_loss: 1.3021 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4462/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5497 - accuracy: 0.7936\n",
      "Epoch 4462: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5497 - accuracy: 0.7936 - val_loss: 1.3088 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4463/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.8096\n",
      "Epoch 4463: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5253 - accuracy: 0.8096 - val_loss: 1.3099 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4464/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8302\n",
      "Epoch 4464: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.4980 - accuracy: 0.8302 - val_loss: 1.3083 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4465/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5142 - accuracy: 0.8101\n",
      "Epoch 4465: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5142 - accuracy: 0.8101 - val_loss: 1.3114 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4466/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.7995\n",
      "Epoch 4466: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5337 - accuracy: 0.7995 - val_loss: 1.2958 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4467/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.8090\n",
      "Epoch 4467: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5089 - accuracy: 0.8090 - val_loss: 1.2622 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4468/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.8196\n",
      "Epoch 4468: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5011 - accuracy: 0.8196 - val_loss: 1.2385 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4469/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8325\n",
      "Epoch 4469: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5057 - accuracy: 0.8325 - val_loss: 1.2340 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4470/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5489 - accuracy: 0.7901\n",
      "Epoch 4470: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.5489 - accuracy: 0.7901 - val_loss: 1.2262 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4471/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.8125\n",
      "Epoch 4471: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.4955 - accuracy: 0.8125 - val_loss: 1.2221 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4472/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.8361\n",
      "Epoch 4472: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.4871 - accuracy: 0.8361 - val_loss: 1.2218 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4473/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.8113\n",
      "Epoch 4473: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5300 - accuracy: 0.8113 - val_loss: 1.2223 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4474/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.8145\n",
      "Epoch 4474: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.5303 - accuracy: 0.8145 - val_loss: 1.2244 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4475/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8137\n",
      "Epoch 4475: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5289 - accuracy: 0.8137 - val_loss: 1.2341 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4476/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.8231\n",
      "Epoch 4476: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5229 - accuracy: 0.8231 - val_loss: 1.2436 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4477/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.8290\n",
      "Epoch 4477: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.4891 - accuracy: 0.8290 - val_loss: 1.2527 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4478/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.8090\n",
      "Epoch 4478: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5259 - accuracy: 0.8090 - val_loss: 1.2602 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4479/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.8149\n",
      "Epoch 4479: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.5160 - accuracy: 0.8149 - val_loss: 1.2677 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4480/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5462 - accuracy: 0.7960\n",
      "Epoch 4480: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5462 - accuracy: 0.7960 - val_loss: 1.2705 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4481/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.8149\n",
      "Epoch 4481: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5391 - accuracy: 0.8149 - val_loss: 1.2686 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4482/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.8090\n",
      "Epoch 4482: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5374 - accuracy: 0.8090 - val_loss: 1.2537 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4483/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.8008\n",
      "Epoch 4483: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5584 - accuracy: 0.8008 - val_loss: 1.2474 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4484/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.8019\n",
      "Epoch 4484: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5500 - accuracy: 0.8019 - val_loss: 1.2413 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4485/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.8149\n",
      "Epoch 4485: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5192 - accuracy: 0.8149 - val_loss: 1.2345 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4486/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.8007\n",
      "Epoch 4486: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5549 - accuracy: 0.8007 - val_loss: 1.2254 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4487/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.8172\n",
      "Epoch 4487: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5275 - accuracy: 0.8172 - val_loss: 1.2309 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4488/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.8149\n",
      "Epoch 4488: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5136 - accuracy: 0.8149 - val_loss: 1.2437 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4489/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.7936\n",
      "Epoch 4489: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5611 - accuracy: 0.7936 - val_loss: 1.2572 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4490/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.8007\n",
      "Epoch 4490: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5498 - accuracy: 0.8007 - val_loss: 1.2563 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4491/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.7925\n",
      "Epoch 4491: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5435 - accuracy: 0.7925 - val_loss: 1.2441 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4492/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.8125\n",
      "Epoch 4492: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5196 - accuracy: 0.8125 - val_loss: 1.2243 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4493/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.8137\n",
      "Epoch 4493: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5292 - accuracy: 0.8137 - val_loss: 1.2031 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4494/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.7995\n",
      "Epoch 4494: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5569 - accuracy: 0.7995 - val_loss: 1.1901 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4495/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5533 - accuracy: 0.8042\n",
      "Epoch 4495: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5533 - accuracy: 0.8042 - val_loss: 1.1741 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4496/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5452 - accuracy: 0.8078\n",
      "Epoch 4496: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5452 - accuracy: 0.8078 - val_loss: 1.1659 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4497/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.7972\n",
      "Epoch 4497: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5463 - accuracy: 0.7972 - val_loss: 1.1650 - val_accuracy: 0.6318 - lr: 1.0000e-05\n",
      "Epoch 4498/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5338 - accuracy: 0.8042\n",
      "Epoch 4498: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5338 - accuracy: 0.8042 - val_loss: 1.1659 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4499/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.8066\n",
      "Epoch 4499: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5209 - accuracy: 0.8066 - val_loss: 1.1686 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4500/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.8149\n",
      "Epoch 4500: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5073 - accuracy: 0.8149 - val_loss: 1.1733 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4501/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.7995\n",
      "Epoch 4501: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5301 - accuracy: 0.7995 - val_loss: 1.1767 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4502/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.8149\n",
      "Epoch 4502: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5444 - accuracy: 0.8149 - val_loss: 1.1847 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4503/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.8125\n",
      "Epoch 4503: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5284 - accuracy: 0.8125 - val_loss: 1.2044 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4504/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.7972\n",
      "Epoch 4504: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5309 - accuracy: 0.7972 - val_loss: 1.2193 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4505/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.8090\n",
      "Epoch 4505: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5265 - accuracy: 0.8090 - val_loss: 1.2405 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4506/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8125\n",
      "Epoch 4506: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5247 - accuracy: 0.8125 - val_loss: 1.2534 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4507/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5022 - accuracy: 0.8278\n",
      "Epoch 4507: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5022 - accuracy: 0.8278 - val_loss: 1.2507 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4508/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5367 - accuracy: 0.8113\n",
      "Epoch 4508: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5367 - accuracy: 0.8113 - val_loss: 1.2373 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4509/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.8184\n",
      "Epoch 4509: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5100 - accuracy: 0.8184 - val_loss: 1.2339 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4510/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.8145\n",
      "Epoch 4510: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5199 - accuracy: 0.8145 - val_loss: 1.2318 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4511/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.7889\n",
      "Epoch 4511: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.5453 - accuracy: 0.7889 - val_loss: 1.2153 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4512/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.8101\n",
      "Epoch 4512: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5331 - accuracy: 0.8101 - val_loss: 1.1936 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4513/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5489 - accuracy: 0.8031\n",
      "Epoch 4513: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5489 - accuracy: 0.8031 - val_loss: 1.1867 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4514/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.7889\n",
      "Epoch 4514: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5507 - accuracy: 0.7889 - val_loss: 1.1869 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4515/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4830 - accuracy: 0.8255\n",
      "Epoch 4515: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.4830 - accuracy: 0.8255 - val_loss: 1.1770 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4516/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.8101\n",
      "Epoch 4516: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5335 - accuracy: 0.8101 - val_loss: 1.1854 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4517/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.8101\n",
      "Epoch 4517: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5647 - accuracy: 0.8101 - val_loss: 1.1999 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4518/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.8031\n",
      "Epoch 4518: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5276 - accuracy: 0.8031 - val_loss: 1.2086 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4519/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.8174\n",
      "Epoch 4519: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5134 - accuracy: 0.8174 - val_loss: 1.2243 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4520/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.8007\n",
      "Epoch 4520: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5482 - accuracy: 0.8007 - val_loss: 1.2491 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4521/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8184\n",
      "Epoch 4521: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.4923 - accuracy: 0.8184 - val_loss: 1.2620 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4522/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.8090\n",
      "Epoch 4522: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5359 - accuracy: 0.8090 - val_loss: 1.2713 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4523/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.8290\n",
      "Epoch 4523: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.4892 - accuracy: 0.8290 - val_loss: 1.2670 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4524/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5489 - accuracy: 0.7995\n",
      "Epoch 4524: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5489 - accuracy: 0.7995 - val_loss: 1.2637 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4525/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.8137\n",
      "Epoch 4525: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5180 - accuracy: 0.8137 - val_loss: 1.2607 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4526/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.8054\n",
      "Epoch 4526: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5397 - accuracy: 0.8054 - val_loss: 1.2575 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4527/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.8125\n",
      "Epoch 4527: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.5011 - accuracy: 0.8125 - val_loss: 1.2557 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4528/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.8101\n",
      "Epoch 4528: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 0.5298 - accuracy: 0.8101 - val_loss: 1.2582 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4529/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.8267\n",
      "Epoch 4529: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 0.5042 - accuracy: 0.8267 - val_loss: 1.2481 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4530/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5200 - accuracy: 0.7995\n",
      "Epoch 4530: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5200 - accuracy: 0.7995 - val_loss: 1.2453 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4531/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.8042\n",
      "Epoch 4531: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5505 - accuracy: 0.8042 - val_loss: 1.2396 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4532/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.8078\n",
      "Epoch 4532: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5276 - accuracy: 0.8078 - val_loss: 1.2431 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4533/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.8154\n",
      "Epoch 4533: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.5125 - accuracy: 0.8154 - val_loss: 1.2439 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4534/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8066\n",
      "Epoch 4534: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5247 - accuracy: 0.8066 - val_loss: 1.2384 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4535/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.7998\n",
      "Epoch 4535: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.5339 - accuracy: 0.7998 - val_loss: 1.2296 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4536/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4969 - accuracy: 0.8172\n",
      "Epoch 4536: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.4969 - accuracy: 0.8172 - val_loss: 1.2241 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4537/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8019\n",
      "Epoch 4537: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5182 - accuracy: 0.8019 - val_loss: 1.2268 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4538/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.8031\n",
      "Epoch 4538: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.5431 - accuracy: 0.8031 - val_loss: 1.2218 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4539/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7983\n",
      "Epoch 4539: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5259 - accuracy: 0.7983 - val_loss: 1.2225 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4540/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.8090\n",
      "Epoch 4540: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5256 - accuracy: 0.8090 - val_loss: 1.2262 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4541/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.8193\n",
      "Epoch 4541: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5065 - accuracy: 0.8193 - val_loss: 1.2402 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4542/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.8149\n",
      "Epoch 4542: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.5276 - accuracy: 0.8149 - val_loss: 1.2480 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4543/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4763 - accuracy: 0.8290\n",
      "Epoch 4543: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.4763 - accuracy: 0.8290 - val_loss: 1.2572 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4544/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.8184\n",
      "Epoch 4544: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5021 - accuracy: 0.8184 - val_loss: 1.2662 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4545/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.8172\n",
      "Epoch 4545: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5139 - accuracy: 0.8172 - val_loss: 1.2819 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4546/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.8125\n",
      "Epoch 4546: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5125 - accuracy: 0.8125 - val_loss: 1.2906 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4547/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5127 - accuracy: 0.8208\n",
      "Epoch 4547: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5127 - accuracy: 0.8208 - val_loss: 1.2863 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4548/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.7972\n",
      "Epoch 4548: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.5397 - accuracy: 0.7972 - val_loss: 1.2715 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4549/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.8172\n",
      "Epoch 4549: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 332ms/step - loss: 0.5224 - accuracy: 0.8172 - val_loss: 1.2664 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4550/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.8255\n",
      "Epoch 4550: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.5025 - accuracy: 0.8255 - val_loss: 1.2626 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4551/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8160\n",
      "Epoch 4551: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5182 - accuracy: 0.8160 - val_loss: 1.2440 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4552/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.8243\n",
      "Epoch 4552: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5137 - accuracy: 0.8243 - val_loss: 1.2166 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4553/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.8066\n",
      "Epoch 4553: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5432 - accuracy: 0.8066 - val_loss: 1.1924 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4554/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.8196\n",
      "Epoch 4554: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.5156 - accuracy: 0.8196 - val_loss: 1.1761 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4555/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.8096\n",
      "Epoch 4555: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5122 - accuracy: 0.8096 - val_loss: 1.1605 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4556/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.8101\n",
      "Epoch 4556: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5333 - accuracy: 0.8101 - val_loss: 1.1543 - val_accuracy: 0.6318 - lr: 1.0000e-05\n",
      "Epoch 4557/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.8137\n",
      "Epoch 4557: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5184 - accuracy: 0.8137 - val_loss: 1.1612 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4558/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.8054\n",
      "Epoch 4558: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5347 - accuracy: 0.8054 - val_loss: 1.1752 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4559/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.8125\n",
      "Epoch 4559: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5223 - accuracy: 0.8125 - val_loss: 1.1967 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4560/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.8184\n",
      "Epoch 4560: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5003 - accuracy: 0.8184 - val_loss: 1.2104 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4561/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.8090\n",
      "Epoch 4561: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5149 - accuracy: 0.8090 - val_loss: 1.2153 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4562/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.8066\n",
      "Epoch 4562: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5435 - accuracy: 0.8066 - val_loss: 1.2075 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4563/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8314\n",
      "Epoch 4563: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.4923 - accuracy: 0.8314 - val_loss: 1.1778 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4564/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.8125\n",
      "Epoch 4564: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5345 - accuracy: 0.8125 - val_loss: 1.1588 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4565/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.8160\n",
      "Epoch 4565: val_loss did not improve from 1.13383\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5219 - accuracy: 0.8160 - val_loss: 1.1416 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4566/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.8115\n",
      "Epoch 4566: val_loss improved from 1.13383 to 1.12158, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5195 - accuracy: 0.8115 - val_loss: 1.1216 - val_accuracy: 0.6462 - lr: 1.0000e-05\n",
      "Epoch 4567/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.8208\n",
      "Epoch 4567: val_loss improved from 1.12158 to 1.11515, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.5113 - accuracy: 0.8208 - val_loss: 1.1152 - val_accuracy: 0.6498 - lr: 1.0000e-05\n",
      "Epoch 4568/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.8019\n",
      "Epoch 4568: val_loss improved from 1.11515 to 1.11145, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.5330 - accuracy: 0.8019 - val_loss: 1.1114 - val_accuracy: 0.6498 - lr: 1.0000e-05\n",
      "Epoch 4569/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.8054\n",
      "Epoch 4569: val_loss improved from 1.11145 to 1.11046, saving model to weights_best_lr_1_e-5.h5\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5177 - accuracy: 0.8054 - val_loss: 1.1105 - val_accuracy: 0.6498 - lr: 1.0000e-05\n",
      "Epoch 4570/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5496 - accuracy: 0.8113\n",
      "Epoch 4570: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5496 - accuracy: 0.8113 - val_loss: 1.1135 - val_accuracy: 0.6498 - lr: 1.0000e-05\n",
      "Epoch 4571/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.8101\n",
      "Epoch 4571: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5181 - accuracy: 0.8101 - val_loss: 1.1131 - val_accuracy: 0.6498 - lr: 1.0000e-05\n",
      "Epoch 4572/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4982 - accuracy: 0.8054\n",
      "Epoch 4572: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.4982 - accuracy: 0.8054 - val_loss: 1.1146 - val_accuracy: 0.6534 - lr: 1.0000e-05\n",
      "Epoch 4573/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.8208\n",
      "Epoch 4573: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5221 - accuracy: 0.8208 - val_loss: 1.1218 - val_accuracy: 0.6498 - lr: 1.0000e-05\n",
      "Epoch 4574/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.7995\n",
      "Epoch 4574: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5177 - accuracy: 0.7995 - val_loss: 1.1433 - val_accuracy: 0.6318 - lr: 1.0000e-05\n",
      "Epoch 4575/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.8267\n",
      "Epoch 4575: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.4932 - accuracy: 0.8267 - val_loss: 1.1711 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4576/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.8184\n",
      "Epoch 4576: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5144 - accuracy: 0.8184 - val_loss: 1.1979 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4577/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.8373\n",
      "Epoch 4577: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.4725 - accuracy: 0.8373 - val_loss: 1.2117 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4578/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.8137\n",
      "Epoch 4578: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5271 - accuracy: 0.8137 - val_loss: 1.2223 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4579/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.8125\n",
      "Epoch 4579: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5149 - accuracy: 0.8125 - val_loss: 1.2480 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4580/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.8125\n",
      "Epoch 4580: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.5270 - accuracy: 0.8125 - val_loss: 1.2726 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4581/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.7866\n",
      "Epoch 4581: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5421 - accuracy: 0.7866 - val_loss: 1.3028 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4582/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.8037\n",
      "Epoch 4582: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5419 - accuracy: 0.8037 - val_loss: 1.3275 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4583/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5613 - accuracy: 0.7959\n",
      "Epoch 4583: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.5613 - accuracy: 0.7959 - val_loss: 1.3449 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4584/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.8096\n",
      "Epoch 4584: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5358 - accuracy: 0.8096 - val_loss: 1.3502 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4585/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.8019\n",
      "Epoch 4585: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5387 - accuracy: 0.8019 - val_loss: 1.3553 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4586/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.8302\n",
      "Epoch 4586: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5021 - accuracy: 0.8302 - val_loss: 1.3490 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4587/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.8160\n",
      "Epoch 4587: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5014 - accuracy: 0.8160 - val_loss: 1.3394 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4588/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5009 - accuracy: 0.8231\n",
      "Epoch 4588: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.5009 - accuracy: 0.8231 - val_loss: 1.3430 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4589/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5152 - accuracy: 0.8096\n",
      "Epoch 4589: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5152 - accuracy: 0.8096 - val_loss: 1.3343 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4590/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8019\n",
      "Epoch 4590: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5415 - accuracy: 0.8019 - val_loss: 1.3150 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4591/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.8172\n",
      "Epoch 4591: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5072 - accuracy: 0.8172 - val_loss: 1.2989 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4592/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.7983\n",
      "Epoch 4592: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5448 - accuracy: 0.7983 - val_loss: 1.2819 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4593/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.8278\n",
      "Epoch 4593: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.4946 - accuracy: 0.8278 - val_loss: 1.2592 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4594/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.8090\n",
      "Epoch 4594: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5388 - accuracy: 0.8090 - val_loss: 1.2409 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4595/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.8019\n",
      "Epoch 4595: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5293 - accuracy: 0.8019 - val_loss: 1.2258 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4596/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.8078\n",
      "Epoch 4596: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.5166 - accuracy: 0.8078 - val_loss: 1.2113 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4597/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.8031\n",
      "Epoch 4597: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5269 - accuracy: 0.8031 - val_loss: 1.2010 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4598/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.8203\n",
      "Epoch 4598: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.5017 - accuracy: 0.8203 - val_loss: 1.1975 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4599/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.8196\n",
      "Epoch 4599: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.5085 - accuracy: 0.8196 - val_loss: 1.1887 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4600/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.8078\n",
      "Epoch 4600: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5266 - accuracy: 0.8078 - val_loss: 1.1815 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4601/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4796 - accuracy: 0.8243\n",
      "Epoch 4601: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.4796 - accuracy: 0.8243 - val_loss: 1.1742 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4602/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.8054\n",
      "Epoch 4602: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5336 - accuracy: 0.8054 - val_loss: 1.1810 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4603/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.8196\n",
      "Epoch 4603: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5242 - accuracy: 0.8196 - val_loss: 1.1877 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4604/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.8078\n",
      "Epoch 4604: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5231 - accuracy: 0.8078 - val_loss: 1.2043 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4605/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.8231\n",
      "Epoch 4605: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5012 - accuracy: 0.8231 - val_loss: 1.2295 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4606/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.8278\n",
      "Epoch 4606: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.4798 - accuracy: 0.8278 - val_loss: 1.2556 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4607/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.8007\n",
      "Epoch 4607: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5430 - accuracy: 0.8007 - val_loss: 1.2705 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4608/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.8066\n",
      "Epoch 4608: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5112 - accuracy: 0.8066 - val_loss: 1.2801 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4609/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.8019\n",
      "Epoch 4609: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5230 - accuracy: 0.8019 - val_loss: 1.2903 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4610/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.8172\n",
      "Epoch 4610: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5438 - accuracy: 0.8172 - val_loss: 1.2949 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4611/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.7936\n",
      "Epoch 4611: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5555 - accuracy: 0.7936 - val_loss: 1.3051 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4612/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.8066\n",
      "Epoch 4612: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5618 - accuracy: 0.8066 - val_loss: 1.3117 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4613/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.8090\n",
      "Epoch 4613: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5131 - accuracy: 0.8090 - val_loss: 1.3216 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4614/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.8113\n",
      "Epoch 4614: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5211 - accuracy: 0.8113 - val_loss: 1.3233 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4615/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5294 - accuracy: 0.8115\n",
      "Epoch 4615: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.5294 - accuracy: 0.8115 - val_loss: 1.3141 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4616/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.8278\n",
      "Epoch 4616: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.4792 - accuracy: 0.8278 - val_loss: 1.3072 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4617/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.8090\n",
      "Epoch 4617: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5390 - accuracy: 0.8090 - val_loss: 1.3108 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4618/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.8096\n",
      "Epoch 4618: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.5358 - accuracy: 0.8096 - val_loss: 1.3106 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4619/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.8090\n",
      "Epoch 4619: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5230 - accuracy: 0.8090 - val_loss: 1.2862 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4620/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.8184\n",
      "Epoch 4620: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.4903 - accuracy: 0.8184 - val_loss: 1.2606 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4621/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.7995\n",
      "Epoch 4621: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5357 - accuracy: 0.7995 - val_loss: 1.2361 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4622/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.8219\n",
      "Epoch 4622: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.5048 - accuracy: 0.8219 - val_loss: 1.2123 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4623/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.8196\n",
      "Epoch 4623: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.4957 - accuracy: 0.8196 - val_loss: 1.1878 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4624/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.8090\n",
      "Epoch 4624: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5237 - accuracy: 0.8090 - val_loss: 1.1823 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4625/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.8105\n",
      "Epoch 4625: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5231 - accuracy: 0.8105 - val_loss: 1.1741 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4626/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.8255\n",
      "Epoch 4626: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5025 - accuracy: 0.8255 - val_loss: 1.1764 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4627/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5117 - accuracy: 0.8184\n",
      "Epoch 4627: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5117 - accuracy: 0.8184 - val_loss: 1.1696 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4628/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.8231\n",
      "Epoch 4628: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 0.5054 - accuracy: 0.8231 - val_loss: 1.1625 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4629/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.8196\n",
      "Epoch 4629: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5214 - accuracy: 0.8196 - val_loss: 1.1604 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4630/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.8172\n",
      "Epoch 4630: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5300 - accuracy: 0.8172 - val_loss: 1.1633 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4631/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.8019\n",
      "Epoch 4631: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5093 - accuracy: 0.8019 - val_loss: 1.1653 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4632/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5173 - accuracy: 0.8145\n",
      "Epoch 4632: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5173 - accuracy: 0.8145 - val_loss: 1.1741 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4633/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.8219\n",
      "Epoch 4633: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5210 - accuracy: 0.8219 - val_loss: 1.1714 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4634/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.8172\n",
      "Epoch 4634: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.5066 - accuracy: 0.8172 - val_loss: 1.1746 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4635/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.8101\n",
      "Epoch 4635: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.4826 - accuracy: 0.8101 - val_loss: 1.1712 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4636/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.8054\n",
      "Epoch 4636: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5355 - accuracy: 0.8054 - val_loss: 1.1663 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4637/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.8125\n",
      "Epoch 4637: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5114 - accuracy: 0.8125 - val_loss: 1.1698 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4638/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.8101\n",
      "Epoch 4638: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5325 - accuracy: 0.8101 - val_loss: 1.1777 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4639/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.8078\n",
      "Epoch 4639: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5230 - accuracy: 0.8078 - val_loss: 1.1796 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4640/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.7960\n",
      "Epoch 4640: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5355 - accuracy: 0.7960 - val_loss: 1.1917 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4641/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.8219\n",
      "Epoch 4641: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.4731 - accuracy: 0.8219 - val_loss: 1.2105 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4642/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5239 - accuracy: 0.7995\n",
      "Epoch 4642: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5239 - accuracy: 0.7995 - val_loss: 1.2215 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4643/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.8105\n",
      "Epoch 4643: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5266 - accuracy: 0.8105 - val_loss: 1.2247 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4644/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.8267\n",
      "Epoch 4644: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 0.5164 - accuracy: 0.8267 - val_loss: 1.2265 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4645/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.7960\n",
      "Epoch 4645: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5201 - accuracy: 0.7960 - val_loss: 1.2180 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4646/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5189 - accuracy: 0.8078\n",
      "Epoch 4646: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5189 - accuracy: 0.8078 - val_loss: 1.2094 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4647/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.8262\n",
      "Epoch 4647: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5171 - accuracy: 0.8262 - val_loss: 1.2053 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4648/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.8149\n",
      "Epoch 4648: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5065 - accuracy: 0.8149 - val_loss: 1.2064 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4649/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.8267\n",
      "Epoch 4649: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 0.5259 - accuracy: 0.8267 - val_loss: 1.2185 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4650/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.8291\n",
      "Epoch 4650: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5033 - accuracy: 0.8291 - val_loss: 1.2305 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4651/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.8101\n",
      "Epoch 4651: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5221 - accuracy: 0.8101 - val_loss: 1.2442 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4652/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.8101\n",
      "Epoch 4652: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5249 - accuracy: 0.8101 - val_loss: 1.2575 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4653/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.8213\n",
      "Epoch 4653: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5243 - accuracy: 0.8213 - val_loss: 1.2678 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4654/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.8196\n",
      "Epoch 4654: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.4985 - accuracy: 0.8196 - val_loss: 1.2827 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4655/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.8301\n",
      "Epoch 4655: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.4887 - accuracy: 0.8301 - val_loss: 1.2910 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4656/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4986 - accuracy: 0.8291\n",
      "Epoch 4656: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.4986 - accuracy: 0.8291 - val_loss: 1.2892 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4657/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8101\n",
      "Epoch 4657: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5232 - accuracy: 0.8101 - val_loss: 1.2762 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4658/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.8213\n",
      "Epoch 4658: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5062 - accuracy: 0.8213 - val_loss: 1.2609 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4659/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.8231\n",
      "Epoch 4659: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5332 - accuracy: 0.8231 - val_loss: 1.2552 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4660/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.8054\n",
      "Epoch 4660: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5122 - accuracy: 0.8054 - val_loss: 1.2506 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4661/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.7995\n",
      "Epoch 4661: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5323 - accuracy: 0.7995 - val_loss: 1.2381 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4662/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5107 - accuracy: 0.8184\n",
      "Epoch 4662: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5107 - accuracy: 0.8184 - val_loss: 1.2114 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4663/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.8076\n",
      "Epoch 4663: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.5237 - accuracy: 0.8076 - val_loss: 1.1891 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4664/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.8007\n",
      "Epoch 4664: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5394 - accuracy: 0.8007 - val_loss: 1.1685 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4665/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.8231\n",
      "Epoch 4665: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.4974 - accuracy: 0.8231 - val_loss: 1.1445 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4666/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.7854\n",
      "Epoch 4666: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5300 - accuracy: 0.7854 - val_loss: 1.1359 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4667/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.8125\n",
      "Epoch 4667: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5251 - accuracy: 0.8125 - val_loss: 1.1331 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4668/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5403 - accuracy: 0.7983\n",
      "Epoch 4668: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5403 - accuracy: 0.7983 - val_loss: 1.1326 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4669/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.8042\n",
      "Epoch 4669: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5422 - accuracy: 0.8042 - val_loss: 1.1480 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4670/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.8057\n",
      "Epoch 4670: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5238 - accuracy: 0.8057 - val_loss: 1.1589 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4671/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.8172\n",
      "Epoch 4671: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5162 - accuracy: 0.8172 - val_loss: 1.1708 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4672/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.8314\n",
      "Epoch 4672: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.4998 - accuracy: 0.8314 - val_loss: 1.1856 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4673/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.8408\n",
      "Epoch 4673: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.4726 - accuracy: 0.8408 - val_loss: 1.2055 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4674/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5028 - accuracy: 0.8154\n",
      "Epoch 4674: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.5028 - accuracy: 0.8154 - val_loss: 1.2273 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4675/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.8208\n",
      "Epoch 4675: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5123 - accuracy: 0.8208 - val_loss: 1.2347 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4676/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.8184\n",
      "Epoch 4676: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.4978 - accuracy: 0.8184 - val_loss: 1.2335 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4677/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.8149\n",
      "Epoch 4677: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5280 - accuracy: 0.8149 - val_loss: 1.2251 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4678/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.8078\n",
      "Epoch 4678: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5194 - accuracy: 0.8078 - val_loss: 1.2220 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4679/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.8160\n",
      "Epoch 4679: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5166 - accuracy: 0.8160 - val_loss: 1.2185 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4680/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.8105\n",
      "Epoch 4680: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5286 - accuracy: 0.8105 - val_loss: 1.2142 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4681/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.8031\n",
      "Epoch 4681: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 331ms/step - loss: 0.5125 - accuracy: 0.8031 - val_loss: 1.2085 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4682/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.8219\n",
      "Epoch 4682: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.4988 - accuracy: 0.8219 - val_loss: 1.1932 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4683/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.8078\n",
      "Epoch 4683: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5074 - accuracy: 0.8078 - val_loss: 1.1858 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4684/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.7983\n",
      "Epoch 4684: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.5582 - accuracy: 0.7983 - val_loss: 1.1866 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4685/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.8125\n",
      "Epoch 4685: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 0.5323 - accuracy: 0.8125 - val_loss: 1.1810 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4686/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.8125\n",
      "Epoch 4686: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5124 - accuracy: 0.8125 - val_loss: 1.1816 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4687/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5568 - accuracy: 0.8019\n",
      "Epoch 4687: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5568 - accuracy: 0.8019 - val_loss: 1.1626 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4688/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.8278\n",
      "Epoch 4688: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5023 - accuracy: 0.8278 - val_loss: 1.1577 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4689/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5296 - accuracy: 0.8125\n",
      "Epoch 4689: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5296 - accuracy: 0.8125 - val_loss: 1.1514 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4690/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.8184\n",
      "Epoch 4690: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5275 - accuracy: 0.8184 - val_loss: 1.1514 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4691/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5053 - accuracy: 0.8164\n",
      "Epoch 4691: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5053 - accuracy: 0.8164 - val_loss: 1.1498 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4692/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.7913\n",
      "Epoch 4692: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.5380 - accuracy: 0.7913 - val_loss: 1.1355 - val_accuracy: 0.6318 - lr: 1.0000e-05\n",
      "Epoch 4693/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.8078\n",
      "Epoch 4693: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5203 - accuracy: 0.8078 - val_loss: 1.1315 - val_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 4694/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.8031\n",
      "Epoch 4694: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5455 - accuracy: 0.8031 - val_loss: 1.1323 - val_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 4695/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5154 - accuracy: 0.8219\n",
      "Epoch 4695: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5154 - accuracy: 0.8219 - val_loss: 1.1390 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4696/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.8174\n",
      "Epoch 4696: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5304 - accuracy: 0.8174 - val_loss: 1.1447 - val_accuracy: 0.6282 - lr: 1.0000e-05\n",
      "Epoch 4697/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.8090\n",
      "Epoch 4697: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5287 - accuracy: 0.8090 - val_loss: 1.1530 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4698/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.8090\n",
      "Epoch 4698: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.5086 - accuracy: 0.8090 - val_loss: 1.1734 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4699/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5401 - accuracy: 0.8086\n",
      "Epoch 4699: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.5401 - accuracy: 0.8086 - val_loss: 1.1915 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4700/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7983\n",
      "Epoch 4700: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5328 - accuracy: 0.7983 - val_loss: 1.2131 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4701/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.8267\n",
      "Epoch 4701: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.4943 - accuracy: 0.8267 - val_loss: 1.2370 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4702/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.8019\n",
      "Epoch 4702: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5308 - accuracy: 0.8019 - val_loss: 1.2664 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4703/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5354 - accuracy: 0.8047\n",
      "Epoch 4703: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5354 - accuracy: 0.8047 - val_loss: 1.2783 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4704/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.8090\n",
      "Epoch 4704: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5536 - accuracy: 0.8090 - val_loss: 1.2730 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4705/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.7995\n",
      "Epoch 4705: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5582 - accuracy: 0.7995 - val_loss: 1.2689 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4706/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.8019\n",
      "Epoch 4706: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5321 - accuracy: 0.8019 - val_loss: 1.2568 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4707/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.8086\n",
      "Epoch 4707: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.5206 - accuracy: 0.8086 - val_loss: 1.2543 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4708/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.8057\n",
      "Epoch 4708: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5325 - accuracy: 0.8057 - val_loss: 1.2498 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4709/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5389 - accuracy: 0.8042\n",
      "Epoch 4709: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5389 - accuracy: 0.8042 - val_loss: 1.2511 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4710/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.8267\n",
      "Epoch 4710: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 0.4773 - accuracy: 0.8267 - val_loss: 1.2465 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4711/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5285 - accuracy: 0.8149\n",
      "Epoch 4711: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5285 - accuracy: 0.8149 - val_loss: 1.2397 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4712/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.8031\n",
      "Epoch 4712: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5172 - accuracy: 0.8031 - val_loss: 1.2357 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4713/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.8172\n",
      "Epoch 4713: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5081 - accuracy: 0.8172 - val_loss: 1.2344 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4714/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.8149\n",
      "Epoch 4714: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 0.5138 - accuracy: 0.8149 - val_loss: 1.2323 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4715/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.8172\n",
      "Epoch 4715: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.4957 - accuracy: 0.8172 - val_loss: 1.2382 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4716/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.8125\n",
      "Epoch 4716: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.5177 - accuracy: 0.8125 - val_loss: 1.2409 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4717/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8113\n",
      "Epoch 4717: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5015 - accuracy: 0.8113 - val_loss: 1.2464 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4718/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.7936\n",
      "Epoch 4718: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.5438 - accuracy: 0.7936 - val_loss: 1.2633 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4719/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.8384\n",
      "Epoch 4719: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.4861 - accuracy: 0.8384 - val_loss: 1.2745 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4720/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.8113\n",
      "Epoch 4720: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5405 - accuracy: 0.8113 - val_loss: 1.2926 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4721/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.8184\n",
      "Epoch 4721: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.5223 - accuracy: 0.8184 - val_loss: 1.2973 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4722/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5398 - accuracy: 0.7925\n",
      "Epoch 4722: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5398 - accuracy: 0.7925 - val_loss: 1.3084 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4723/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5352 - accuracy: 0.8037\n",
      "Epoch 4723: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.5352 - accuracy: 0.8037 - val_loss: 1.3200 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4724/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5103 - accuracy: 0.8113\n",
      "Epoch 4724: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.5103 - accuracy: 0.8113 - val_loss: 1.3402 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4725/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.8054\n",
      "Epoch 4725: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.5223 - accuracy: 0.8054 - val_loss: 1.3371 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4726/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.8160\n",
      "Epoch 4726: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5001 - accuracy: 0.8160 - val_loss: 1.3135 - val_accuracy: 0.5740 - lr: 1.0000e-05\n",
      "Epoch 4727/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.7972\n",
      "Epoch 4727: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5408 - accuracy: 0.7972 - val_loss: 1.2825 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4728/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8113\n",
      "Epoch 4728: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.5182 - accuracy: 0.8113 - val_loss: 1.2661 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4729/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8054\n",
      "Epoch 4729: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5170 - accuracy: 0.8054 - val_loss: 1.2556 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4730/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.8042\n",
      "Epoch 4730: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.4922 - accuracy: 0.8042 - val_loss: 1.2419 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4731/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.8172\n",
      "Epoch 4731: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5176 - accuracy: 0.8172 - val_loss: 1.2295 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4732/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.8208\n",
      "Epoch 4732: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.4962 - accuracy: 0.8208 - val_loss: 1.2169 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4733/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.8042\n",
      "Epoch 4733: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5228 - accuracy: 0.8042 - val_loss: 1.1992 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4734/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8231\n",
      "Epoch 4734: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5047 - accuracy: 0.8231 - val_loss: 1.1771 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4735/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.8349\n",
      "Epoch 4735: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.4876 - accuracy: 0.8349 - val_loss: 1.1695 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4736/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8160\n",
      "Epoch 4736: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5289 - accuracy: 0.8160 - val_loss: 1.1737 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4737/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.8137\n",
      "Epoch 4737: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 0.5040 - accuracy: 0.8137 - val_loss: 1.1891 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4738/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.8290\n",
      "Epoch 4738: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4879 - accuracy: 0.8290 - val_loss: 1.2022 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4739/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.8231\n",
      "Epoch 4739: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5092 - accuracy: 0.8231 - val_loss: 1.2138 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4740/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5049 - accuracy: 0.8149\n",
      "Epoch 4740: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.5049 - accuracy: 0.8149 - val_loss: 1.2050 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4741/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.8184\n",
      "Epoch 4741: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5104 - accuracy: 0.8184 - val_loss: 1.1957 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4742/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.8019\n",
      "Epoch 4742: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5377 - accuracy: 0.8019 - val_loss: 1.1971 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4743/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.8208\n",
      "Epoch 4743: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5012 - accuracy: 0.8208 - val_loss: 1.1939 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4744/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.8149\n",
      "Epoch 4744: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5042 - accuracy: 0.8149 - val_loss: 1.1919 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4745/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.8231\n",
      "Epoch 4745: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5037 - accuracy: 0.8231 - val_loss: 1.1828 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4746/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.8271\n",
      "Epoch 4746: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 0.4953 - accuracy: 0.8271 - val_loss: 1.1801 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4747/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4830 - accuracy: 0.8314\n",
      "Epoch 4747: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 332ms/step - loss: 0.4830 - accuracy: 0.8314 - val_loss: 1.2001 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4748/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.8278\n",
      "Epoch 4748: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 0.5018 - accuracy: 0.8278 - val_loss: 1.2182 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4749/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.8160\n",
      "Epoch 4749: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5024 - accuracy: 0.8160 - val_loss: 1.2256 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4750/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.8231\n",
      "Epoch 4750: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4942 - accuracy: 0.8231 - val_loss: 1.2337 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4751/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.8196\n",
      "Epoch 4751: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.4994 - accuracy: 0.8196 - val_loss: 1.2398 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4752/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.8361\n",
      "Epoch 4752: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.4554 - accuracy: 0.8361 - val_loss: 1.2467 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4753/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4969 - accuracy: 0.8208\n",
      "Epoch 4753: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.4969 - accuracy: 0.8208 - val_loss: 1.2569 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4754/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8137\n",
      "Epoch 4754: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.5015 - accuracy: 0.8137 - val_loss: 1.2695 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4755/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.8278\n",
      "Epoch 4755: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.4991 - accuracy: 0.8278 - val_loss: 1.2699 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4756/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.8219\n",
      "Epoch 4756: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4924 - accuracy: 0.8219 - val_loss: 1.2665 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4757/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5101 - accuracy: 0.8101\n",
      "Epoch 4757: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5101 - accuracy: 0.8101 - val_loss: 1.2585 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4758/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.8149\n",
      "Epoch 4758: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5280 - accuracy: 0.8149 - val_loss: 1.2537 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4759/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8149\n",
      "Epoch 4759: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5015 - accuracy: 0.8149 - val_loss: 1.2557 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4760/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.8101\n",
      "Epoch 4760: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5339 - accuracy: 0.8101 - val_loss: 1.2652 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4761/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.8172\n",
      "Epoch 4761: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.4958 - accuracy: 0.8172 - val_loss: 1.2697 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4762/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.8337\n",
      "Epoch 4762: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.4757 - accuracy: 0.8337 - val_loss: 1.2908 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4763/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.8125\n",
      "Epoch 4763: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5331 - accuracy: 0.8125 - val_loss: 1.3061 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4764/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.8160\n",
      "Epoch 4764: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.5138 - accuracy: 0.8160 - val_loss: 1.3043 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4765/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.8066\n",
      "Epoch 4765: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.5233 - accuracy: 0.8066 - val_loss: 1.3054 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4766/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4956 - accuracy: 0.8290\n",
      "Epoch 4766: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.4956 - accuracy: 0.8290 - val_loss: 1.2829 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4767/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.8278\n",
      "Epoch 4767: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5284 - accuracy: 0.8278 - val_loss: 1.2592 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4768/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.8255\n",
      "Epoch 4768: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.5021 - accuracy: 0.8255 - val_loss: 1.2442 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4769/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.8149\n",
      "Epoch 4769: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5228 - accuracy: 0.8149 - val_loss: 1.2302 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4770/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.8174\n",
      "Epoch 4770: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.4899 - accuracy: 0.8174 - val_loss: 1.2204 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4771/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.8007\n",
      "Epoch 4771: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5278 - accuracy: 0.8007 - val_loss: 1.2147 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4772/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.8113\n",
      "Epoch 4772: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.5243 - accuracy: 0.8113 - val_loss: 1.2297 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4773/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.8160\n",
      "Epoch 4773: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.5136 - accuracy: 0.8160 - val_loss: 1.2500 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4774/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.8113\n",
      "Epoch 4774: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5116 - accuracy: 0.8113 - val_loss: 1.2639 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4775/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.8208\n",
      "Epoch 4775: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.5084 - accuracy: 0.8208 - val_loss: 1.2759 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4776/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.8252\n",
      "Epoch 4776: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 0.5078 - accuracy: 0.8252 - val_loss: 1.2816 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4777/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5039 - accuracy: 0.8160\n",
      "Epoch 4777: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5039 - accuracy: 0.8160 - val_loss: 1.2701 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4778/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.8349\n",
      "Epoch 4778: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.4832 - accuracy: 0.8349 - val_loss: 1.2609 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4779/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.8042\n",
      "Epoch 4779: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5145 - accuracy: 0.8042 - val_loss: 1.2581 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4780/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.8203\n",
      "Epoch 4780: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.4906 - accuracy: 0.8203 - val_loss: 1.2532 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4781/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.8090\n",
      "Epoch 4781: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4957 - accuracy: 0.8090 - val_loss: 1.2618 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4782/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.8149\n",
      "Epoch 4782: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 0.5265 - accuracy: 0.8149 - val_loss: 1.2496 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4783/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.8281\n",
      "Epoch 4783: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.4894 - accuracy: 0.8281 - val_loss: 1.2465 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4784/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.8302\n",
      "Epoch 4784: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4873 - accuracy: 0.8302 - val_loss: 1.2472 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4785/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8135\n",
      "Epoch 4785: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.5057 - accuracy: 0.8135 - val_loss: 1.2418 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4786/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8193\n",
      "Epoch 4786: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5061 - accuracy: 0.8193 - val_loss: 1.2449 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4787/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5159 - accuracy: 0.8196\n",
      "Epoch 4787: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.5159 - accuracy: 0.8196 - val_loss: 1.2514 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4788/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.8213\n",
      "Epoch 4788: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5021 - accuracy: 0.8213 - val_loss: 1.2474 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4789/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.8018\n",
      "Epoch 4789: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5448 - accuracy: 0.8018 - val_loss: 1.2443 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4790/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.8066\n",
      "Epoch 4790: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.5072 - accuracy: 0.8066 - val_loss: 1.2419 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4791/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.8172\n",
      "Epoch 4791: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 0.5018 - accuracy: 0.8172 - val_loss: 1.2497 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4792/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.8243\n",
      "Epoch 4792: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4701 - accuracy: 0.8243 - val_loss: 1.2549 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4793/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.8196\n",
      "Epoch 4793: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5215 - accuracy: 0.8196 - val_loss: 1.2597 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4794/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.8101\n",
      "Epoch 4794: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 0.5220 - accuracy: 0.8101 - val_loss: 1.2536 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4795/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.8101\n",
      "Epoch 4795: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5227 - accuracy: 0.8101 - val_loss: 1.2419 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4796/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.8054\n",
      "Epoch 4796: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 0.5334 - accuracy: 0.8054 - val_loss: 1.2290 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4797/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8278\n",
      "Epoch 4797: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.4977 - accuracy: 0.8278 - val_loss: 1.2075 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4798/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.8290\n",
      "Epoch 4798: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.4860 - accuracy: 0.8290 - val_loss: 1.1938 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4799/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.8149\n",
      "Epoch 4799: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.5210 - accuracy: 0.8149 - val_loss: 1.1969 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4800/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8137\n",
      "Epoch 4800: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.5061 - accuracy: 0.8137 - val_loss: 1.2028 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4801/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.8302\n",
      "Epoch 4801: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.4976 - accuracy: 0.8302 - val_loss: 1.2088 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4802/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.8196\n",
      "Epoch 4802: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.5376 - accuracy: 0.8196 - val_loss: 1.2136 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4803/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8066\n",
      "Epoch 4803: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 2s 713ms/step - loss: 0.5170 - accuracy: 0.8066 - val_loss: 1.2260 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4804/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.8174\n",
      "Epoch 4804: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 0.5133 - accuracy: 0.8174 - val_loss: 1.2339 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4805/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.8349\n",
      "Epoch 4805: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.4742 - accuracy: 0.8349 - val_loss: 1.2461 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4806/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.8231\n",
      "Epoch 4806: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.4860 - accuracy: 0.8231 - val_loss: 1.2561 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4807/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8054\n",
      "Epoch 4807: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.5414 - accuracy: 0.8054 - val_loss: 1.2512 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4808/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.8314\n",
      "Epoch 4808: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.5055 - accuracy: 0.8314 - val_loss: 1.2448 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4809/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.8007\n",
      "Epoch 4809: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.5327 - accuracy: 0.8007 - val_loss: 1.2492 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4810/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.8184\n",
      "Epoch 4810: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.5146 - accuracy: 0.8184 - val_loss: 1.2526 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4811/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.8350\n",
      "Epoch 4811: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 3s 832ms/step - loss: 0.4733 - accuracy: 0.8350 - val_loss: 1.2535 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4812/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8172\n",
      "Epoch 4812: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.4977 - accuracy: 0.8172 - val_loss: 1.2479 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4813/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.8101\n",
      "Epoch 4813: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.5277 - accuracy: 0.8101 - val_loss: 1.2451 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4814/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.8125\n",
      "Epoch 4814: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.5201 - accuracy: 0.8125 - val_loss: 1.2381 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4815/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.8432\n",
      "Epoch 4815: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.4718 - accuracy: 0.8432 - val_loss: 1.2309 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4816/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.8243\n",
      "Epoch 4816: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.4853 - accuracy: 0.8243 - val_loss: 1.2229 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4817/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5118 - accuracy: 0.8125\n",
      "Epoch 4817: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.5118 - accuracy: 0.8125 - val_loss: 1.2231 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4818/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.8384\n",
      "Epoch 4818: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.4896 - accuracy: 0.8384 - val_loss: 1.2254 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4819/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.8054\n",
      "Epoch 4819: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.5174 - accuracy: 0.8054 - val_loss: 1.2282 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4820/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.8302\n",
      "Epoch 4820: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.4925 - accuracy: 0.8302 - val_loss: 1.2269 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4821/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.8054\n",
      "Epoch 4821: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.5183 - accuracy: 0.8054 - val_loss: 1.2340 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4822/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.8369\n",
      "Epoch 4822: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.4720 - accuracy: 0.8369 - val_loss: 1.2351 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4823/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.8373\n",
      "Epoch 4823: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.4696 - accuracy: 0.8373 - val_loss: 1.2371 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4824/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.8271\n",
      "Epoch 4824: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.4970 - accuracy: 0.8271 - val_loss: 1.2279 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4825/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5091 - accuracy: 0.8137\n",
      "Epoch 4825: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5091 - accuracy: 0.8137 - val_loss: 1.2178 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4826/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4999 - accuracy: 0.8174\n",
      "Epoch 4826: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.4999 - accuracy: 0.8174 - val_loss: 1.2072 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4827/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8278\n",
      "Epoch 4827: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.4813 - accuracy: 0.8278 - val_loss: 1.1892 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4828/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4967 - accuracy: 0.8208\n",
      "Epoch 4828: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.4967 - accuracy: 0.8208 - val_loss: 1.1734 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4829/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.8078\n",
      "Epoch 4829: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.5256 - accuracy: 0.8078 - val_loss: 1.1687 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4830/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.8231\n",
      "Epoch 4830: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.4946 - accuracy: 0.8231 - val_loss: 1.1613 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4831/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5152 - accuracy: 0.8231\n",
      "Epoch 4831: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5152 - accuracy: 0.8231 - val_loss: 1.1706 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4832/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.8184\n",
      "Epoch 4832: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4946 - accuracy: 0.8184 - val_loss: 1.1784 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4833/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.8078\n",
      "Epoch 4833: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4927 - accuracy: 0.8078 - val_loss: 1.1810 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4834/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.8113\n",
      "Epoch 4834: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.5157 - accuracy: 0.8113 - val_loss: 1.1825 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4835/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.8066\n",
      "Epoch 4835: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.5287 - accuracy: 0.8066 - val_loss: 1.1933 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4836/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.8172\n",
      "Epoch 4836: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.5160 - accuracy: 0.8172 - val_loss: 1.2036 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4837/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.8193\n",
      "Epoch 4837: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.4891 - accuracy: 0.8193 - val_loss: 1.2040 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4838/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.8196\n",
      "Epoch 4838: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.5130 - accuracy: 0.8196 - val_loss: 1.2001 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4839/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5161 - accuracy: 0.8160\n",
      "Epoch 4839: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.5161 - accuracy: 0.8160 - val_loss: 1.1856 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4840/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4917 - accuracy: 0.8243\n",
      "Epoch 4840: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.4917 - accuracy: 0.8243 - val_loss: 1.1907 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4841/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.8105\n",
      "Epoch 4841: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.4930 - accuracy: 0.8105 - val_loss: 1.1932 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4842/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.8090\n",
      "Epoch 4842: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.5215 - accuracy: 0.8090 - val_loss: 1.2009 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4843/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8090\n",
      "Epoch 4843: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.5299 - accuracy: 0.8090 - val_loss: 1.2007 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4844/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4909 - accuracy: 0.8219\n",
      "Epoch 4844: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.4909 - accuracy: 0.8219 - val_loss: 1.1893 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4845/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.8125\n",
      "Epoch 4845: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.4984 - accuracy: 0.8125 - val_loss: 1.1794 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4846/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.8184\n",
      "Epoch 4846: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.5217 - accuracy: 0.8184 - val_loss: 1.1897 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4847/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5101 - accuracy: 0.8137\n",
      "Epoch 4847: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5101 - accuracy: 0.8137 - val_loss: 1.2046 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4848/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.8255\n",
      "Epoch 4848: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.5141 - accuracy: 0.8255 - val_loss: 1.2339 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4849/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.8384\n",
      "Epoch 4849: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.4764 - accuracy: 0.8384 - val_loss: 1.2703 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4850/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.8255\n",
      "Epoch 4850: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4770 - accuracy: 0.8255 - val_loss: 1.2973 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4851/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.8160\n",
      "Epoch 4851: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.5210 - accuracy: 0.8160 - val_loss: 1.3122 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4852/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8208 \n",
      "Epoch 4852: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 25s 8s/step - loss: 0.4911 - accuracy: 0.8208 - val_loss: 1.3414 - val_accuracy: 0.5704 - lr: 1.0000e-05\n",
      "Epoch 4853/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.8208\n",
      "Epoch 4853: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.5085 - accuracy: 0.8208 - val_loss: 1.3520 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4854/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.8137\n",
      "Epoch 4854: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.5256 - accuracy: 0.8137 - val_loss: 1.3472 - val_accuracy: 0.5668 - lr: 1.0000e-05\n",
      "Epoch 4855/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4809 - accuracy: 0.8314\n",
      "Epoch 4855: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.4809 - accuracy: 0.8314 - val_loss: 1.3234 - val_accuracy: 0.5776 - lr: 1.0000e-05\n",
      "Epoch 4856/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.8125\n",
      "Epoch 4856: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.5055 - accuracy: 0.8125 - val_loss: 1.2995 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 4857/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.8243\n",
      "Epoch 4857: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.4913 - accuracy: 0.8243 - val_loss: 1.2790 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4858/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.8278\n",
      "Epoch 4858: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.4962 - accuracy: 0.8278 - val_loss: 1.2678 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4859/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.8057\n",
      "Epoch 4859: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.5213 - accuracy: 0.8057 - val_loss: 1.2448 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4860/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.8379\n",
      "Epoch 4860: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 2s 444ms/step - loss: 0.4832 - accuracy: 0.8379 - val_loss: 1.2220 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4861/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.8325\n",
      "Epoch 4861: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 2s 476ms/step - loss: 0.4970 - accuracy: 0.8325 - val_loss: 1.2133 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4862/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.8172\n",
      "Epoch 4862: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.5291 - accuracy: 0.8172 - val_loss: 1.2100 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4863/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.8184\n",
      "Epoch 4863: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.4937 - accuracy: 0.8184 - val_loss: 1.2076 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4864/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.8019\n",
      "Epoch 4864: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5158 - accuracy: 0.8019 - val_loss: 1.2140 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4865/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.8219\n",
      "Epoch 4865: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.5210 - accuracy: 0.8219 - val_loss: 1.2094 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4866/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.8231\n",
      "Epoch 4866: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.4818 - accuracy: 0.8231 - val_loss: 1.1979 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4867/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.8219\n",
      "Epoch 4867: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.5109 - accuracy: 0.8219 - val_loss: 1.1918 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4868/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.8267\n",
      "Epoch 4868: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.4756 - accuracy: 0.8267 - val_loss: 1.1913 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4869/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8078\n",
      "Epoch 4869: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5094 - accuracy: 0.8078 - val_loss: 1.2025 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4870/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.8255\n",
      "Epoch 4870: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.5147 - accuracy: 0.8255 - val_loss: 1.2141 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4871/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.8325\n",
      "Epoch 4871: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.4881 - accuracy: 0.8325 - val_loss: 1.2431 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4872/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8037\n",
      "Epoch 4872: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.5245 - accuracy: 0.8037 - val_loss: 1.2673 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4873/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.8172\n",
      "Epoch 4873: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.4983 - accuracy: 0.8172 - val_loss: 1.2825 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4874/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.8149\n",
      "Epoch 4874: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.5175 - accuracy: 0.8149 - val_loss: 1.2777 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4875/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8160\n",
      "Epoch 4875: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.5061 - accuracy: 0.8160 - val_loss: 1.2783 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4876/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.8174\n",
      "Epoch 4876: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.4987 - accuracy: 0.8174 - val_loss: 1.2730 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4877/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.8231\n",
      "Epoch 4877: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.5188 - accuracy: 0.8231 - val_loss: 1.2721 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4878/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.8349\n",
      "Epoch 4878: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.4686 - accuracy: 0.8349 - val_loss: 1.2647 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 4879/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.8349\n",
      "Epoch 4879: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.4988 - accuracy: 0.8349 - val_loss: 1.2543 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4880/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.8105\n",
      "Epoch 4880: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.5012 - accuracy: 0.8105 - val_loss: 1.2393 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4881/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.8243\n",
      "Epoch 4881: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4987 - accuracy: 0.8243 - val_loss: 1.2247 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4882/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.8291\n",
      "Epoch 4882: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.4838 - accuracy: 0.8291 - val_loss: 1.2193 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4883/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.8337\n",
      "Epoch 4883: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.4701 - accuracy: 0.8337 - val_loss: 1.2119 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4884/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.8514\n",
      "Epoch 4884: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.4682 - accuracy: 0.8514 - val_loss: 1.1915 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4885/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.8340\n",
      "Epoch 4885: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.4677 - accuracy: 0.8340 - val_loss: 1.1796 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4886/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.7995\n",
      "Epoch 4886: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.5320 - accuracy: 0.7995 - val_loss: 1.1748 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4887/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.8054\n",
      "Epoch 4887: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.5204 - accuracy: 0.8054 - val_loss: 1.1772 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4888/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.8291\n",
      "Epoch 4888: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.5001 - accuracy: 0.8291 - val_loss: 1.1843 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4889/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.8361\n",
      "Epoch 4889: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.4587 - accuracy: 0.8361 - val_loss: 1.1804 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4890/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.8174\n",
      "Epoch 4890: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.5073 - accuracy: 0.8174 - val_loss: 1.1796 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4891/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4931 - accuracy: 0.8314\n",
      "Epoch 4891: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.4931 - accuracy: 0.8314 - val_loss: 1.1815 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4892/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4938 - accuracy: 0.8219\n",
      "Epoch 4892: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.4938 - accuracy: 0.8219 - val_loss: 1.1767 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4893/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4933 - accuracy: 0.8278\n",
      "Epoch 4893: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.4933 - accuracy: 0.8278 - val_loss: 1.1637 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4894/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.8196\n",
      "Epoch 4894: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.5045 - accuracy: 0.8196 - val_loss: 1.1588 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4895/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.8078\n",
      "Epoch 4895: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5137 - accuracy: 0.8078 - val_loss: 1.1591 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4896/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.8149\n",
      "Epoch 4896: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.5177 - accuracy: 0.8149 - val_loss: 1.1604 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4897/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.8196\n",
      "Epoch 4897: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.4780 - accuracy: 0.8196 - val_loss: 1.1725 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4898/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8337\n",
      "Epoch 4898: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.4980 - accuracy: 0.8337 - val_loss: 1.1934 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4899/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.8361\n",
      "Epoch 4899: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.4789 - accuracy: 0.8361 - val_loss: 1.2178 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4900/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.8320\n",
      "Epoch 4900: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.4829 - accuracy: 0.8320 - val_loss: 1.2388 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4901/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.8243\n",
      "Epoch 4901: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.4762 - accuracy: 0.8243 - val_loss: 1.2452 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4902/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.8042\n",
      "Epoch 4902: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.5055 - accuracy: 0.8042 - val_loss: 1.2397 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4903/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8219\n",
      "Epoch 4903: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4923 - accuracy: 0.8219 - val_loss: 1.2460 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4904/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4775 - accuracy: 0.8196\n",
      "Epoch 4904: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.4775 - accuracy: 0.8196 - val_loss: 1.2504 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4905/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.8255\n",
      "Epoch 4905: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.5171 - accuracy: 0.8255 - val_loss: 1.2471 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 4906/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.8135\n",
      "Epoch 4906: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.5076 - accuracy: 0.8135 - val_loss: 1.2390 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4907/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.8302\n",
      "Epoch 4907: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4976 - accuracy: 0.8302 - val_loss: 1.2288 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4908/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.8408\n",
      "Epoch 4908: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.4601 - accuracy: 0.8408 - val_loss: 1.2200 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4909/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.8302\n",
      "Epoch 4909: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4853 - accuracy: 0.8302 - val_loss: 1.2084 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4910/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.8164\n",
      "Epoch 4910: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5181 - accuracy: 0.8164 - val_loss: 1.2121 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4911/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4939 - accuracy: 0.8291\n",
      "Epoch 4911: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.4939 - accuracy: 0.8291 - val_loss: 1.2165 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4912/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.8184\n",
      "Epoch 4912: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.4852 - accuracy: 0.8184 - val_loss: 1.2210 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4913/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.8149\n",
      "Epoch 4913: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.4991 - accuracy: 0.8149 - val_loss: 1.2208 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4914/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.8231\n",
      "Epoch 4914: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.4859 - accuracy: 0.8231 - val_loss: 1.2200 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4915/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.8231\n",
      "Epoch 4915: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.5108 - accuracy: 0.8231 - val_loss: 1.2195 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4916/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.8243\n",
      "Epoch 4916: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4805 - accuracy: 0.8243 - val_loss: 1.2212 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4917/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.8208\n",
      "Epoch 4917: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.4951 - accuracy: 0.8208 - val_loss: 1.2116 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4918/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8281\n",
      "Epoch 4918: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4923 - accuracy: 0.8281 - val_loss: 1.1814 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4919/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5097 - accuracy: 0.8101\n",
      "Epoch 4919: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5097 - accuracy: 0.8101 - val_loss: 1.1576 - val_accuracy: 0.6318 - lr: 1.0000e-05\n",
      "Epoch 4920/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4933 - accuracy: 0.8196\n",
      "Epoch 4920: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.4933 - accuracy: 0.8196 - val_loss: 1.1482 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4921/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.8184\n",
      "Epoch 4921: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.5093 - accuracy: 0.8184 - val_loss: 1.1416 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4922/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.8113\n",
      "Epoch 4922: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.5168 - accuracy: 0.8113 - val_loss: 1.1416 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4923/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.8113\n",
      "Epoch 4923: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5193 - accuracy: 0.8113 - val_loss: 1.1518 - val_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 4924/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4777 - accuracy: 0.8311\n",
      "Epoch 4924: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.4777 - accuracy: 0.8311 - val_loss: 1.1616 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4925/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.8125\n",
      "Epoch 4925: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.4892 - accuracy: 0.8125 - val_loss: 1.1688 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4926/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4900 - accuracy: 0.8243\n",
      "Epoch 4926: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.4900 - accuracy: 0.8243 - val_loss: 1.1701 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4927/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.8160\n",
      "Epoch 4927: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.5052 - accuracy: 0.8160 - val_loss: 1.1741 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4928/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.8255\n",
      "Epoch 4928: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.4725 - accuracy: 0.8255 - val_loss: 1.1911 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4929/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.8278\n",
      "Epoch 4929: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.4998 - accuracy: 0.8278 - val_loss: 1.2018 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4930/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8302\n",
      "Epoch 4930: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.5047 - accuracy: 0.8302 - val_loss: 1.2090 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4931/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8137\n",
      "Epoch 4931: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.4980 - accuracy: 0.8137 - val_loss: 1.2090 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4932/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.8396\n",
      "Epoch 4932: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.4797 - accuracy: 0.8396 - val_loss: 1.2148 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4933/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.8361\n",
      "Epoch 4933: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.4770 - accuracy: 0.8361 - val_loss: 1.2206 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4934/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.8278\n",
      "Epoch 4934: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.4879 - accuracy: 0.8278 - val_loss: 1.2296 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4935/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.8219\n",
      "Epoch 4935: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.4861 - accuracy: 0.8219 - val_loss: 1.2285 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4936/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.8361\n",
      "Epoch 4936: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.4828 - accuracy: 0.8361 - val_loss: 1.2370 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4937/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.8172\n",
      "Epoch 4937: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.4991 - accuracy: 0.8172 - val_loss: 1.2563 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4938/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.8314\n",
      "Epoch 4938: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.5051 - accuracy: 0.8314 - val_loss: 1.2508 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4939/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.8193\n",
      "Epoch 4939: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.4846 - accuracy: 0.8193 - val_loss: 1.2320 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4940/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.8314\n",
      "Epoch 4940: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.4700 - accuracy: 0.8314 - val_loss: 1.2224 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4941/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.8213\n",
      "Epoch 4941: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.4954 - accuracy: 0.8213 - val_loss: 1.2207 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4942/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.8379\n",
      "Epoch 4942: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.4782 - accuracy: 0.8379 - val_loss: 1.2138 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4943/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.8373\n",
      "Epoch 4943: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.4729 - accuracy: 0.8373 - val_loss: 1.2094 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4944/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.8290\n",
      "Epoch 4944: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.4817 - accuracy: 0.8290 - val_loss: 1.2125 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4945/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.8231\n",
      "Epoch 4945: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.5106 - accuracy: 0.8231 - val_loss: 1.2279 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4946/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.8054\n",
      "Epoch 4946: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.5166 - accuracy: 0.8054 - val_loss: 1.2569 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4947/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8137\n",
      "Epoch 4947: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4977 - accuracy: 0.8137 - val_loss: 1.2542 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4948/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.8054\n",
      "Epoch 4948: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.5033 - accuracy: 0.8054 - val_loss: 1.2513 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4949/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.8252\n",
      "Epoch 4949: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.4954 - accuracy: 0.8252 - val_loss: 1.2442 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4950/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.8203\n",
      "Epoch 4950: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.4934 - accuracy: 0.8203 - val_loss: 1.2487 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4951/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.8196\n",
      "Epoch 4951: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5032 - accuracy: 0.8196 - val_loss: 1.2442 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4952/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.8302\n",
      "Epoch 4952: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.4872 - accuracy: 0.8302 - val_loss: 1.2426 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4953/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8172\n",
      "Epoch 4953: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.5059 - accuracy: 0.8172 - val_loss: 1.2394 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4954/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.8232\n",
      "Epoch 4954: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 385s 128s/step - loss: 0.4783 - accuracy: 0.8232 - val_loss: 1.2448 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4955/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.8066\n",
      "Epoch 4955: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5137 - accuracy: 0.8066 - val_loss: 1.2465 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4956/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.8164\n",
      "Epoch 4956: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5018 - accuracy: 0.8164 - val_loss: 1.2481 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4957/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.8066\n",
      "Epoch 4957: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5115 - accuracy: 0.8066 - val_loss: 1.2508 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4958/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8349\n",
      "Epoch 4958: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4744 - accuracy: 0.8349 - val_loss: 1.2552 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4959/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.8090\n",
      "Epoch 4959: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.5119 - accuracy: 0.8090 - val_loss: 1.2623 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4960/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.8219\n",
      "Epoch 4960: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.4831 - accuracy: 0.8219 - val_loss: 1.2616 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4961/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.8267\n",
      "Epoch 4961: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.5050 - accuracy: 0.8267 - val_loss: 1.2473 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4962/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.8066\n",
      "Epoch 4962: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.5321 - accuracy: 0.8066 - val_loss: 1.2339 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4963/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.8252\n",
      "Epoch 4963: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.4741 - accuracy: 0.8252 - val_loss: 1.2296 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4964/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.8232\n",
      "Epoch 4964: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.4902 - accuracy: 0.8232 - val_loss: 1.2309 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4965/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.8042\n",
      "Epoch 4965: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.5017 - accuracy: 0.8042 - val_loss: 1.2288 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4966/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.8172\n",
      "Epoch 4966: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.4854 - accuracy: 0.8172 - val_loss: 1.2363 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4967/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.8349\n",
      "Epoch 4967: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.4655 - accuracy: 0.8349 - val_loss: 1.2405 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 4968/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.8231\n",
      "Epoch 4968: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.4889 - accuracy: 0.8231 - val_loss: 1.2306 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 4969/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.8196\n",
      "Epoch 4969: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.5244 - accuracy: 0.8196 - val_loss: 1.2155 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4970/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.8203\n",
      "Epoch 4970: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4768 - accuracy: 0.8203 - val_loss: 1.2127 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4971/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.8196\n",
      "Epoch 4971: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.4884 - accuracy: 0.8196 - val_loss: 1.2212 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4972/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.8337\n",
      "Epoch 4972: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.4743 - accuracy: 0.8337 - val_loss: 1.2309 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4973/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.8278\n",
      "Epoch 4973: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.5052 - accuracy: 0.8278 - val_loss: 1.2370 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4974/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.8219\n",
      "Epoch 4974: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.4823 - accuracy: 0.8219 - val_loss: 1.2171 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4975/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5159 - accuracy: 0.8125\n",
      "Epoch 4975: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.5159 - accuracy: 0.8125 - val_loss: 1.1850 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 4976/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.7995\n",
      "Epoch 4976: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.5404 - accuracy: 0.7995 - val_loss: 1.1657 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 4977/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.8078\n",
      "Epoch 4977: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.5001 - accuracy: 0.8078 - val_loss: 1.1521 - val_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 4978/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.8149\n",
      "Epoch 4978: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.4994 - accuracy: 0.8149 - val_loss: 1.1442 - val_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 4979/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.8196\n",
      "Epoch 4979: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.5147 - accuracy: 0.8196 - val_loss: 1.1414 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4980/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5082 - accuracy: 0.8290\n",
      "Epoch 4980: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.5082 - accuracy: 0.8290 - val_loss: 1.1399 - val_accuracy: 0.6426 - lr: 1.0000e-05\n",
      "Epoch 4981/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.8242\n",
      "Epoch 4981: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.4920 - accuracy: 0.8242 - val_loss: 1.1366 - val_accuracy: 0.6426 - lr: 1.0000e-05\n",
      "Epoch 4982/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.8291\n",
      "Epoch 4982: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.4779 - accuracy: 0.8291 - val_loss: 1.1330 - val_accuracy: 0.6534 - lr: 1.0000e-05\n",
      "Epoch 4983/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4856 - accuracy: 0.8184\n",
      "Epoch 4983: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.4856 - accuracy: 0.8184 - val_loss: 1.1436 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4984/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4981 - accuracy: 0.8196\n",
      "Epoch 4984: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.4981 - accuracy: 0.8196 - val_loss: 1.1442 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4985/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.8193\n",
      "Epoch 4985: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.5065 - accuracy: 0.8193 - val_loss: 1.1395 - val_accuracy: 0.6426 - lr: 1.0000e-05\n",
      "Epoch 4986/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.8420\n",
      "Epoch 4986: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.4380 - accuracy: 0.8420 - val_loss: 1.1370 - val_accuracy: 0.6426 - lr: 1.0000e-05\n",
      "Epoch 4987/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.8196\n",
      "Epoch 4987: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4921 - accuracy: 0.8196 - val_loss: 1.1455 - val_accuracy: 0.6390 - lr: 1.0000e-05\n",
      "Epoch 4988/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.8137\n",
      "Epoch 4988: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.5168 - accuracy: 0.8137 - val_loss: 1.1588 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 4989/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5007 - accuracy: 0.8255\n",
      "Epoch 4989: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.5007 - accuracy: 0.8255 - val_loss: 1.1788 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 4990/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8113\n",
      "Epoch 4990: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4936 - accuracy: 0.8113 - val_loss: 1.2003 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 4991/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.8467\n",
      "Epoch 4991: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.4798 - accuracy: 0.8467 - val_loss: 1.2232 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4992/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5107 - accuracy: 0.8184\n",
      "Epoch 4992: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.5107 - accuracy: 0.8184 - val_loss: 1.2449 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4993/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.8231\n",
      "Epoch 4993: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.4991 - accuracy: 0.8231 - val_loss: 1.2538 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 4994/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.8078\n",
      "Epoch 4994: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.5248 - accuracy: 0.8078 - val_loss: 1.2453 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4995/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.8137\n",
      "Epoch 4995: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.4854 - accuracy: 0.8137 - val_loss: 1.2392 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4996/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.8262\n",
      "Epoch 4996: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.4803 - accuracy: 0.8262 - val_loss: 1.2289 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4997/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.8271\n",
      "Epoch 4997: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.4926 - accuracy: 0.8271 - val_loss: 1.2302 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 4998/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.8149\n",
      "Epoch 4998: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.4925 - accuracy: 0.8149 - val_loss: 1.2469 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 4999/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.8135\n",
      "Epoch 4999: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.5010 - accuracy: 0.8135 - val_loss: 1.2642 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5000/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.8101\n",
      "Epoch 5000: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5031 - accuracy: 0.8101 - val_loss: 1.2780 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5001/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8172\n",
      "Epoch 5001: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.4977 - accuracy: 0.8172 - val_loss: 1.2739 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5002/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.8184\n",
      "Epoch 5002: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.4753 - accuracy: 0.8184 - val_loss: 1.2619 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5003/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.8384\n",
      "Epoch 5003: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.4862 - accuracy: 0.8384 - val_loss: 1.2369 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5004/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.8101\n",
      "Epoch 5004: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.4984 - accuracy: 0.8101 - val_loss: 1.2118 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5005/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.8242\n",
      "Epoch 5005: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.4850 - accuracy: 0.8242 - val_loss: 1.2065 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5006/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8066\n",
      "Epoch 5006: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.5094 - accuracy: 0.8066 - val_loss: 1.1984 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 5007/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.8262\n",
      "Epoch 5007: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.4880 - accuracy: 0.8262 - val_loss: 1.2024 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5008/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.8196\n",
      "Epoch 5008: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.4921 - accuracy: 0.8196 - val_loss: 1.2055 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5009/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.8432\n",
      "Epoch 5009: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.4718 - accuracy: 0.8432 - val_loss: 1.2046 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5010/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.8105\n",
      "Epoch 5010: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.5157 - accuracy: 0.8105 - val_loss: 1.2058 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5011/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.8291\n",
      "Epoch 5011: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.4921 - accuracy: 0.8291 - val_loss: 1.2070 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5012/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4999 - accuracy: 0.8373\n",
      "Epoch 5012: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.4999 - accuracy: 0.8373 - val_loss: 1.2181 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5013/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.8101\n",
      "Epoch 5013: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.4935 - accuracy: 0.8101 - val_loss: 1.2282 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5014/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.8314\n",
      "Epoch 5014: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4850 - accuracy: 0.8314 - val_loss: 1.2334 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5015/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.8231\n",
      "Epoch 5015: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.4983 - accuracy: 0.8231 - val_loss: 1.2325 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5016/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.8373\n",
      "Epoch 5016: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.4632 - accuracy: 0.8373 - val_loss: 1.2166 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5017/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.8203\n",
      "Epoch 5017: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.5172 - accuracy: 0.8203 - val_loss: 1.2071 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5018/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.8184\n",
      "Epoch 5018: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.4851 - accuracy: 0.8184 - val_loss: 1.2041 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5019/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.8243\n",
      "Epoch 5019: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.4857 - accuracy: 0.8243 - val_loss: 1.2234 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 5020/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.8031\n",
      "Epoch 5020: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.5087 - accuracy: 0.8031 - val_loss: 1.2246 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5021/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4670 - accuracy: 0.8208\n",
      "Epoch 5021: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.4670 - accuracy: 0.8208 - val_loss: 1.2320 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5022/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.8314\n",
      "Epoch 5022: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.4875 - accuracy: 0.8314 - val_loss: 1.2266 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5023/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4840 - accuracy: 0.8154\n",
      "Epoch 5023: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.4840 - accuracy: 0.8154 - val_loss: 1.2287 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5024/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.8125\n",
      "Epoch 5024: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.4928 - accuracy: 0.8125 - val_loss: 1.2311 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 5025/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5036 - accuracy: 0.8278\n",
      "Epoch 5025: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5036 - accuracy: 0.8278 - val_loss: 1.2303 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 5026/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.8213\n",
      "Epoch 5026: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.4731 - accuracy: 0.8213 - val_loss: 1.2327 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5027/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5132 - accuracy: 0.8054\n",
      "Epoch 5027: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.5132 - accuracy: 0.8054 - val_loss: 1.2354 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5028/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5036 - accuracy: 0.8172\n",
      "Epoch 5028: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.5036 - accuracy: 0.8172 - val_loss: 1.2387 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5029/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.7877\n",
      "Epoch 5029: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5201 - accuracy: 0.7877 - val_loss: 1.2289 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5030/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.8361\n",
      "Epoch 5030: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.4632 - accuracy: 0.8361 - val_loss: 1.2298 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5031/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.8302\n",
      "Epoch 5031: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.4746 - accuracy: 0.8302 - val_loss: 1.2374 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5032/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.8302\n",
      "Epoch 5032: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.4734 - accuracy: 0.8302 - val_loss: 1.2400 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5033/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.8213\n",
      "Epoch 5033: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.4937 - accuracy: 0.8213 - val_loss: 1.2390 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5034/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.8255\n",
      "Epoch 5034: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.4695 - accuracy: 0.8255 - val_loss: 1.2373 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5035/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4652 - accuracy: 0.8325\n",
      "Epoch 5035: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.4652 - accuracy: 0.8325 - val_loss: 1.2443 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5036/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.8398\n",
      "Epoch 5036: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4640 - accuracy: 0.8398 - val_loss: 1.2430 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5037/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.8302\n",
      "Epoch 5037: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.4580 - accuracy: 0.8302 - val_loss: 1.2259 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5038/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.8267\n",
      "Epoch 5038: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.4785 - accuracy: 0.8267 - val_loss: 1.2299 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 5039/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8078\n",
      "Epoch 5039: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.4911 - accuracy: 0.8078 - val_loss: 1.2442 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5040/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.8231\n",
      "Epoch 5040: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.5292 - accuracy: 0.8231 - val_loss: 1.2548 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5041/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4809 - accuracy: 0.8255\n",
      "Epoch 5041: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4809 - accuracy: 0.8255 - val_loss: 1.2638 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 5042/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5097 - accuracy: 0.8149\n",
      "Epoch 5042: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5097 - accuracy: 0.8149 - val_loss: 1.2680 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 5043/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.8219\n",
      "Epoch 5043: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.4916 - accuracy: 0.8219 - val_loss: 1.2594 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5044/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.8184\n",
      "Epoch 5044: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5115 - accuracy: 0.8184 - val_loss: 1.2485 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5045/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.8349\n",
      "Epoch 5045: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.4851 - accuracy: 0.8349 - val_loss: 1.2420 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 5046/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.8172\n",
      "Epoch 5046: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.5046 - accuracy: 0.8172 - val_loss: 1.2299 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5047/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4898 - accuracy: 0.8267\n",
      "Epoch 5047: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.4898 - accuracy: 0.8267 - val_loss: 1.2142 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5048/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.8137\n",
      "Epoch 5048: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.4943 - accuracy: 0.8137 - val_loss: 1.2027 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5049/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.7995\n",
      "Epoch 5049: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.5163 - accuracy: 0.7995 - val_loss: 1.2051 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5050/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5064 - accuracy: 0.8113\n",
      "Epoch 5050: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5064 - accuracy: 0.8113 - val_loss: 1.2091 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5051/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.8090\n",
      "Epoch 5051: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.5201 - accuracy: 0.8090 - val_loss: 1.2179 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5052/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.8047\n",
      "Epoch 5052: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.5003 - accuracy: 0.8047 - val_loss: 1.2275 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 5053/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.8231\n",
      "Epoch 5053: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.4818 - accuracy: 0.8231 - val_loss: 1.2479 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 5054/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.8242\n",
      "Epoch 5054: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.5055 - accuracy: 0.8242 - val_loss: 1.2742 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 5055/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.8267\n",
      "Epoch 5055: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.4919 - accuracy: 0.8267 - val_loss: 1.2864 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 5056/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.8137\n",
      "Epoch 5056: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.5052 - accuracy: 0.8137 - val_loss: 1.3024 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 5057/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.8271\n",
      "Epoch 5057: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.4949 - accuracy: 0.8271 - val_loss: 1.2969 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 5058/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.8311\n",
      "Epoch 5058: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.4814 - accuracy: 0.8311 - val_loss: 1.2837 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 5059/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.8101\n",
      "Epoch 5059: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.5110 - accuracy: 0.8101 - val_loss: 1.2549 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5060/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.8278\n",
      "Epoch 5060: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.4624 - accuracy: 0.8278 - val_loss: 1.2186 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5061/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4868 - accuracy: 0.8184\n",
      "Epoch 5061: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.4868 - accuracy: 0.8184 - val_loss: 1.2042 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5062/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8290\n",
      "Epoch 5062: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.4674 - accuracy: 0.8290 - val_loss: 1.1813 - val_accuracy: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 5063/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.8349\n",
      "Epoch 5063: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.4688 - accuracy: 0.8349 - val_loss: 1.1782 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 5064/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.8302\n",
      "Epoch 5064: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.4698 - accuracy: 0.8302 - val_loss: 1.1871 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 5065/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5039 - accuracy: 0.8090\n",
      "Epoch 5065: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.5039 - accuracy: 0.8090 - val_loss: 1.2115 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 5066/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.8349\n",
      "Epoch 5066: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.4565 - accuracy: 0.8349 - val_loss: 1.2313 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5067/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.8054\n",
      "Epoch 5067: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.4863 - accuracy: 0.8054 - val_loss: 1.2668 - val_accuracy: 0.5957 - lr: 1.0000e-05\n",
      "Epoch 5068/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.8538\n",
      "Epoch 5068: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4363 - accuracy: 0.8538 - val_loss: 1.2969 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Epoch 5069/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.8349\n",
      "Epoch 5069: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.4671 - accuracy: 0.8349 - val_loss: 1.3052 - val_accuracy: 0.5812 - lr: 1.0000e-05\n",
      "Epoch 5070/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5322 - accuracy: 0.8066\n",
      "Epoch 5070: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.5322 - accuracy: 0.8066 - val_loss: 1.3133 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 5071/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.8219\n",
      "Epoch 5071: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.5034 - accuracy: 0.8219 - val_loss: 1.3130 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 5072/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.8172\n",
      "Epoch 5072: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.4871 - accuracy: 0.8172 - val_loss: 1.3091 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 5073/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.8432\n",
      "Epoch 5073: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.4659 - accuracy: 0.8432 - val_loss: 1.3038 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 5074/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8302\n",
      "Epoch 5074: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.4609 - accuracy: 0.8302 - val_loss: 1.2989 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 5075/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.8255\n",
      "Epoch 5075: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.4887 - accuracy: 0.8255 - val_loss: 1.2982 - val_accuracy: 0.5884 - lr: 1.0000e-05\n",
      "Epoch 5076/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.8057\n",
      "Epoch 5076: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.5014 - accuracy: 0.8057 - val_loss: 1.2823 - val_accuracy: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 5077/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4864 - accuracy: 0.8172\n",
      "Epoch 5077: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.4864 - accuracy: 0.8172 - val_loss: 1.2634 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5078/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.8314\n",
      "Epoch 5078: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.4675 - accuracy: 0.8314 - val_loss: 1.2571 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5079/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.8291\n",
      "Epoch 5079: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.4698 - accuracy: 0.8291 - val_loss: 1.2565 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5080/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.8160\n",
      "Epoch 5080: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5222 - accuracy: 0.8160 - val_loss: 1.2548 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5081/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.8267\n",
      "Epoch 5081: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.5077 - accuracy: 0.8267 - val_loss: 1.2472 - val_accuracy: 0.6101 - lr: 1.0000e-05\n",
      "Epoch 5082/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8361\n",
      "Epoch 5082: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4579 - accuracy: 0.8361 - val_loss: 1.2356 - val_accuracy: 0.6065 - lr: 1.0000e-05\n",
      "Epoch 5083/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.8184\n",
      "Epoch 5083: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.5081 - accuracy: 0.8184 - val_loss: 1.2149 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 5084/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.8231\n",
      "Epoch 5084: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.5109 - accuracy: 0.8231 - val_loss: 1.2112 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 5085/10000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.8443\n",
      "Epoch 5085: val_loss did not improve from 1.11046\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4612 - accuracy: 0.8443 - val_loss: 1.2045 - val_accuracy: 0.6173 - lr: 1.0000e-05\n",
      "Epoch 5086/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m NO_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNO_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NO_EPOCHS = 10000\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "                              shuffle=True,\n",
    "                              epochs=NO_EPOCHS, validation_data = (x_val, y_val),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // BATCH_SIZE,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "Green"
         },
         "mode": "markers+lines",
         "name": "Training accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200",
          "201",
          "202",
          "203",
          "204",
          "205",
          "206",
          "207",
          "208",
          "209",
          "210",
          "211",
          "212",
          "213",
          "214",
          "215",
          "216",
          "217",
          "218",
          "219",
          "220",
          "221",
          "222",
          "223",
          "224",
          "225",
          "226",
          "227",
          "228",
          "229",
          "230",
          "231",
          "232",
          "233",
          "234",
          "235",
          "236",
          "237",
          "238",
          "239",
          "240",
          "241",
          "242",
          "243",
          "244",
          "245",
          "246",
          "247",
          "248",
          "249",
          "250",
          "251",
          "252",
          "253",
          "254",
          "255",
          "256",
          "257",
          "258",
          "259",
          "260",
          "261",
          "262",
          "263",
          "264",
          "265",
          "266",
          "267",
          "268",
          "269",
          "270",
          "271",
          "272",
          "273",
          "274",
          "275",
          "276",
          "277",
          "278",
          "279",
          "280",
          "281",
          "282",
          "283",
          "284",
          "285",
          "286",
          "287",
          "288",
          "289",
          "290",
          "291",
          "292",
          "293",
          "294",
          "295",
          "296",
          "297",
          "298",
          "299",
          "300",
          "301",
          "302",
          "303",
          "304",
          "305",
          "306",
          "307",
          "308",
          "309",
          "310",
          "311",
          "312",
          "313",
          "314",
          "315",
          "316",
          "317",
          "318",
          "319",
          "320",
          "321",
          "322",
          "323",
          "324",
          "325",
          "326",
          "327",
          "328",
          "329",
          "330",
          "331",
          "332",
          "333",
          "334",
          "335",
          "336",
          "337",
          "338",
          "339",
          "340",
          "341",
          "342",
          "343",
          "344",
          "345",
          "346",
          "347",
          "348",
          "349",
          "350",
          "351",
          "352",
          "353",
          "354",
          "355",
          "356",
          "357",
          "358",
          "359",
          "360",
          "361",
          "362",
          "363",
          "364",
          "365",
          "366",
          "367",
          "368",
          "369",
          "370",
          "371",
          "372",
          "373",
          "374",
          "375",
          "376",
          "377",
          "378",
          "379",
          "380",
          "381",
          "382",
          "383",
          "384",
          "385",
          "386",
          "387",
          "388",
          "389",
          "390",
          "391",
          "392",
          "393",
          "394",
          "395",
          "396",
          "397",
          "398",
          "399",
          "400",
          "401",
          "402",
          "403",
          "404",
          "405",
          "406",
          "407",
          "408",
          "409",
          "410",
          "411",
          "412",
          "413",
          "414",
          "415",
          "416",
          "417",
          "418",
          "419",
          "420",
          "421",
          "422",
          "423",
          "424",
          "425",
          "426",
          "427",
          "428",
          "429",
          "430",
          "431",
          "432",
          "433",
          "434",
          "435",
          "436",
          "437",
          "438",
          "439",
          "440",
          "441",
          "442",
          "443",
          "444",
          "445",
          "446",
          "447",
          "448",
          "449",
          "450",
          "451",
          "452",
          "453",
          "454",
          "455",
          "456",
          "457",
          "458",
          "459",
          "460",
          "461",
          "462",
          "463",
          "464",
          "465",
          "466",
          "467",
          "468",
          "469",
          "470",
          "471",
          "472",
          "473",
          "474",
          "475",
          "476",
          "477",
          "478",
          "479",
          "480",
          "481",
          "482",
          "483",
          "484",
          "485",
          "486",
          "487",
          "488",
          "489",
          "490",
          "491",
          "492",
          "493",
          "494",
          "495",
          "496",
          "497",
          "498",
          "499",
          "500",
          "501",
          "502",
          "503",
          "504",
          "505",
          "506",
          "507",
          "508",
          "509",
          "510",
          "511",
          "512",
          "513",
          "514",
          "515",
          "516",
          "517",
          "518",
          "519",
          "520",
          "521",
          "522",
          "523",
          "524",
          "525",
          "526",
          "527",
          "528",
          "529",
          "530",
          "531",
          "532",
          "533",
          "534",
          "535",
          "536",
          "537",
          "538",
          "539",
          "540",
          "541",
          "542",
          "543",
          "544",
          "545",
          "546",
          "547",
          "548",
          "549",
          "550",
          "551",
          "552",
          "553",
          "554",
          "555",
          "556",
          "557",
          "558",
          "559",
          "560",
          "561",
          "562",
          "563",
          "564",
          "565",
          "566",
          "567",
          "568",
          "569",
          "570",
          "571",
          "572",
          "573",
          "574",
          "575",
          "576",
          "577",
          "578",
          "579",
          "580",
          "581",
          "582",
          "583",
          "584",
          "585",
          "586",
          "587",
          "588",
          "589",
          "590",
          "591",
          "592",
          "593",
          "594",
          "595",
          "596",
          "597",
          "598",
          "599",
          "600",
          "601",
          "602",
          "603",
          "604",
          "605",
          "606",
          "607",
          "608",
          "609",
          "610",
          "611",
          "612",
          "613",
          "614",
          "615",
          "616",
          "617",
          "618",
          "619",
          "620",
          "621",
          "622",
          "623",
          "624",
          "625",
          "626",
          "627",
          "628",
          "629",
          "630",
          "631",
          "632",
          "633",
          "634",
          "635",
          "636",
          "637",
          "638",
          "639",
          "640",
          "641",
          "642",
          "643",
          "644",
          "645",
          "646",
          "647",
          "648",
          "649",
          "650",
          "651",
          "652",
          "653",
          "654",
          "655",
          "656",
          "657",
          "658",
          "659",
          "660",
          "661",
          "662",
          "663",
          "664",
          "665",
          "666",
          "667",
          "668",
          "669",
          "670",
          "671",
          "672",
          "673",
          "674",
          "675",
          "676",
          "677",
          "678",
          "679",
          "680",
          "681",
          "682",
          "683",
          "684",
          "685",
          "686",
          "687",
          "688",
          "689",
          "690",
          "691",
          "692",
          "693",
          "694",
          "695",
          "696",
          "697",
          "698",
          "699",
          "700",
          "701",
          "702",
          "703",
          "704",
          "705",
          "706",
          "707",
          "708",
          "709",
          "710",
          "711",
          "712",
          "713",
          "714",
          "715",
          "716",
          "717",
          "718",
          "719",
          "720",
          "721",
          "722",
          "723",
          "724",
          "725",
          "726",
          "727",
          "728",
          "729",
          "730",
          "731",
          "732",
          "733",
          "734",
          "735",
          "736",
          "737",
          "738",
          "739",
          "740",
          "741",
          "742",
          "743",
          "744",
          "745",
          "746",
          "747",
          "748",
          "749",
          "750",
          "751",
          "752",
          "753",
          "754",
          "755",
          "756",
          "757",
          "758",
          "759",
          "760",
          "761",
          "762",
          "763",
          "764",
          "765",
          "766",
          "767",
          "768",
          "769",
          "770",
          "771",
          "772",
          "773",
          "774",
          "775",
          "776",
          "777",
          "778",
          "779",
          "780",
          "781",
          "782",
          "783",
          "784",
          "785",
          "786",
          "787",
          "788",
          "789",
          "790",
          "791",
          "792",
          "793",
          "794",
          "795",
          "796",
          "797",
          "798",
          "799",
          "800",
          "801",
          "802",
          "803",
          "804",
          "805",
          "806",
          "807",
          "808",
          "809",
          "810",
          "811",
          "812",
          "813",
          "814",
          "815",
          "816",
          "817",
          "818",
          "819",
          "820",
          "821",
          "822",
          "823",
          "824",
          "825",
          "826",
          "827",
          "828",
          "829",
          "830",
          "831",
          "832",
          "833",
          "834",
          "835",
          "836",
          "837",
          "838",
          "839",
          "840",
          "841",
          "842",
          "843",
          "844",
          "845",
          "846",
          "847",
          "848",
          "849",
          "850",
          "851",
          "852",
          "853",
          "854",
          "855",
          "856",
          "857",
          "858",
          "859",
          "860",
          "861",
          "862",
          "863",
          "864",
          "865",
          "866",
          "867",
          "868",
          "869",
          "870",
          "871",
          "872",
          "873",
          "874",
          "875",
          "876",
          "877",
          "878",
          "879",
          "880",
          "881",
          "882",
          "883",
          "884",
          "885",
          "886",
          "887",
          "888",
          "889",
          "890",
          "891",
          "892",
          "893",
          "894",
          "895",
          "896",
          "897",
          "898",
          "899",
          "900",
          "901",
          "902",
          "903",
          "904",
          "905",
          "906",
          "907",
          "908",
          "909",
          "910",
          "911",
          "912",
          "913",
          "914",
          "915",
          "916",
          "917",
          "918",
          "919",
          "920",
          "921",
          "922",
          "923",
          "924",
          "925",
          "926",
          "927",
          "928",
          "929",
          "930",
          "931",
          "932",
          "933",
          "934",
          "935",
          "936",
          "937",
          "938",
          "939",
          "940",
          "941",
          "942",
          "943",
          "944",
          "945",
          "946",
          "947",
          "948",
          "949",
          "950",
          "951",
          "952",
          "953",
          "954",
          "955",
          "956",
          "957",
          "958",
          "959",
          "960",
          "961",
          "962",
          "963",
          "964",
          "965",
          "966",
          "967",
          "968",
          "969",
          "970",
          "971",
          "972",
          "973",
          "974",
          "975",
          "976",
          "977",
          "978",
          "979",
          "980",
          "981",
          "982",
          "983",
          "984",
          "985",
          "986",
          "987",
          "988",
          "989",
          "990",
          "991",
          "992",
          "993",
          "994",
          "995",
          "996",
          "997",
          "998",
          "999",
          "1000"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "xaxis": "x",
         "y": [
          0.21344339847564697,
          0.3950471580028534,
          0.4541015625,
          0.5129716992378235,
          0.4988207519054413,
          0.4873046875,
          0.48828125,
          0.4658018946647644,
          0.4705188572406769,
          0.5117924809455872,
          0.4941037595272064,
          0.5247641801834106,
          0.5078125,
          0.50390625,
          0.5,
          0.5107421875,
          0.5224609375,
          0.5294811129570007,
          0.5318396091461182,
          0.5271226167678833,
          0.5176886916160583,
          0.515625,
          0.537109375,
          0.5153301954269409,
          0.5294811129570007,
          0.5117924809455872,
          0.5212264060974121,
          0.5212264060974121,
          0.5412735939025879,
          0.5400943160057068,
          0.5459905862808228,
          0.5318396091461182,
          0.5322265625,
          0.5412735939025879,
          0.5306603908538818,
          0.5498046875,
          0.5318396091461182,
          0.5707547068595886,
          0.5400943160057068,
          0.5595703125,
          0.552734375,
          0.5636792182922363,
          0.5576171875,
          0.5673828125,
          0.5790094137191772,
          0.5498046875,
          0.5589622855186462,
          0.5683962106704712,
          0.5483490824699402,
          0.5754716992378235,
          0.5791015625,
          0.573113203048706,
          0.5648584961891174,
          0.5683962106704712,
          0.5742924809455872,
          0.5837264060974121,
          0.5707547068595886,
          0.578125,
          0.603515625,
          0.5825471878051758,
          0.5507075190544128,
          0.58203125,
          0.56640625,
          0.5766509175300598,
          0.5648584961891174,
          0.5660377144813538,
          0.5672169923782349,
          0.5766509175300598,
          0.5766509175300598,
          0.5790094137191772,
          0.58984375,
          0.5849056839942932,
          0.6132075190544128,
          0.5947265625,
          0.5978773832321167,
          0.5919811129570007,
          0.5849056839942932,
          0.5908018946647644,
          0.5872641801834106,
          0.5837264060974121,
          0.5872641801834106,
          0.5943396091461182,
          0.6167452931404114,
          0.6044921875,
          0.5849056839942932,
          0.599056601524353,
          0.6049528121948242,
          0.614386796951294,
          0.5766509175300598,
          0.5872641801834106,
          0.6108490824699402,
          0.6002358198165894,
          0.603515625,
          0.6037735939025879,
          0.6108490824699402,
          0.614386796951294,
          0.6037735939025879,
          0.6332547068595886,
          0.6155660152435303,
          0.62109375,
          0.6155660152435303,
          0.6379716992378235,
          0.6261792182922363,
          0.6084905862808228,
          0.6049528121948242,
          0.6096698045730591,
          0.5860849022865295,
          0.6096698045730591,
          0.6061320900917053,
          0.6171875,
          0.62890625,
          0.5986328125,
          0.6108490824699402,
          0.6367924809455872,
          0.5978773832321167,
          0.6120283007621765,
          0.6202830076217651,
          0.6391509175300598,
          0.6279296875,
          0.6320754885673523,
          0.638671875,
          0.6450471878051758,
          0.6462264060974121,
          0.6497641801834106,
          0.6108490824699402,
          0.6285377144813538,
          0.6396484375,
          0.6167452931404114,
          0.630859375,
          0.6568396091461182,
          0.6462264060974121,
          0.635613203048706,
          0.635613203048706,
          0.6298828125,
          0.6497641801834106,
          0.625,
          0.6367924809455872,
          0.6485849022865295,
          0.6521226167678833,
          0.63671875,
          0.650943398475647,
          0.63671875,
          0.662109375,
          0.6474056839942932,
          0.635613203048706,
          0.6662735939025879,
          0.6415094137191772,
          0.6662735939025879,
          0.6485849022865295,
          0.66015625,
          0.661556601524353,
          0.666015625,
          0.6521226167678833,
          0.6591981053352356,
          0.6698113083839417,
          0.666015625,
          0.6796875,
          0.6662735939025879,
          0.6816037893295288,
          0.6591796875,
          0.6757075190544128,
          0.6851415038108826,
          0.6886792182922363,
          0.6933962106704712,
          0.6572265625,
          0.6686320900917053,
          0.658203125,
          0.6450471878051758,
          0.6922169923782349,
          0.7063679099082947,
          0.6591981053352356,
          0.6686320900917053,
          0.676886796951294,
          0.6544811129570007,
          0.6709905862808228,
          0.6709905862808228,
          0.676886796951294,
          0.6533018946647644,
          0.669921875,
          0.6780660152435303,
          0.6630859375,
          0.6806640625,
          0.6708984375,
          0.693359375,
          0.676886796951294,
          0.6957547068595886,
          0.6572265625,
          0.6804245114326477,
          0.6839622855186462,
          0.6674528121948242,
          0.6922169923782349,
          0.6922169923782349,
          0.6910377144813538,
          0.6748046875,
          0.6957547068595886,
          0.6721698045730591,
          0.698113203048706,
          0.676886796951294,
          0.6796875,
          0.6650943160057068,
          0.6886792182922363,
          0.6910377144813538,
          0.7075471878051758,
          0.7040094137191772,
          0.7110849022865295,
          0.6757075190544128,
          0.6922169923782349,
          0.6898584961891174,
          0.713443398475647,
          0.6780660152435303,
          0.693359375,
          0.6982421875,
          0.6957547068595886,
          0.705078125,
          0.6816037893295288,
          0.6957547068595886,
          0.6962890625,
          0.6898584961891174,
          0.7122641801834106,
          0.713443398475647,
          0.6933962106704712,
          0.7028301954269409,
          0.6792452931404114,
          0.7040094137191772,
          0.7099609375,
          0.7177734375,
          0.6863207817077637,
          0.7075471878051758,
          0.7110849022865295,
          0.7216981053352356,
          0.6969339847564697,
          0.7146226167678833,
          0.697265625,
          0.713443398475647,
          0.7169811129570007,
          0.7080078125,
          0.7087264060974121,
          0.7122641801834106,
          0.7004716992378235,
          0.724056601524353,
          0.7041015625,
          0.7004716992378235,
          0.712890625,
          0.7109375,
          0.7075471878051758,
          0.713443398475647,
          0.7299528121948242,
          0.6886792182922363,
          0.7016509175300598,
          0.7236328125,
          0.7169811129570007,
          0.7299528121948242,
          0.7099056839942932,
          0.7146226167678833,
          0.7110849022865295,
          0.7110849022865295,
          0.7122641801834106,
          0.6945754885673523,
          0.7382075190544128,
          0.7016509175300598,
          0.7264150977134705,
          0.7353515625,
          0.71875,
          0.7040094137191772,
          0.7264150977134705,
          0.7264150977134705,
          0.7216981053352356,
          0.7181603908538818,
          0.7146226167678833,
          0.7040094137191772,
          0.7122641801834106,
          0.7216981053352356,
          0.7287735939025879,
          0.728515625,
          0.7358490824699402,
          0.7122641801834106,
          0.7476415038108826,
          0.713443398475647,
          0.7205188870429993,
          0.7323113083839417,
          0.7299528121948242,
          0.732421875,
          0.7216796875,
          0.7392578125,
          0.7358490824699402,
          0.739386796951294,
          0.7429245114326477,
          0.7334905862808228,
          0.7252358198165894,
          0.7452830076217651,
          0.7252358198165894,
          0.7314453125,
          0.7417452931404114,
          0.7146226167678833,
          0.7169811129570007,
          0.7382075190544128,
          0.7476415038108826,
          0.7582547068595886,
          0.7441037893295288,
          0.7370283007621765,
          0.7275390625,
          0.7358490824699402,
          0.75,
          0.7429245114326477,
          0.7451171875,
          0.7228773832321167,
          0.7323113083839417,
          0.7431640625,
          0.7370283007621765,
          0.7311320900917053,
          0.7358490824699402,
          0.7358490824699402,
          0.724056601524353,
          0.7452830076217651,
          0.7346698045730591,
          0.760613203048706,
          0.7429245114326477,
          0.7452830076217651,
          0.7370283007621765,
          0.740234375,
          0.7333984375,
          0.7578125,
          0.7535377144813538,
          0.7488207817077637,
          0.7323113083839417,
          0.7582547068595886,
          0.7547169923782349,
          0.7346698045730591,
          0.7417452931404114,
          0.751953125,
          0.7405660152435303,
          0.7511792182922363,
          0.7523584961891174,
          0.7488207817077637,
          0.7488207817077637,
          0.75,
          0.760613203048706,
          0.744140625,
          0.7511792182922363,
          0.7464622855186462,
          0.7311320900917053,
          0.7700471878051758,
          0.751953125,
          0.7641509175300598,
          0.74609375,
          0.7594339847564697,
          0.7346698045730591,
          0.75390625,
          0.7529296875,
          0.7431640625,
          0.7653301954269409,
          0.7476415038108826,
          0.7653301954269409,
          0.7629716992378235,
          0.759765625,
          0.7523584961891174,
          0.7205188870429993,
          0.7405660152435303,
          0.7264150977134705,
          0.767578125,
          0.7594339847564697,
          0.7641509175300598,
          0.7617924809455872,
          0.7405660152435303,
          0.7629716992378235,
          0.7629716992378235,
          0.7547169923782349,
          0.7558962106704712,
          0.7311320900917053,
          0.75,
          0.7594339847564697,
          0.7558962106704712,
          0.75,
          0.7617924809455872,
          0.75,
          0.7570754885673523,
          0.7665094137191772,
          0.7794811129570007,
          0.7688679099082947,
          0.7629716992378235,
          0.7558962106704712,
          0.7582547068595886,
          0.7700471878051758,
          0.7712264060974121,
          0.7676886916160583,
          0.7712264060974121,
          0.7523584961891174,
          0.7724056839942932,
          0.7617924809455872,
          0.7417452931404114,
          0.7570754885673523,
          0.7523584961891174,
          0.7641509175300598,
          0.7783018946647644,
          0.7441037893295288,
          0.7558962106704712,
          0.76171875,
          0.7653301954269409,
          0.7853773832321167,
          0.7558962106704712,
          0.7712264060974121,
          0.7712264060974121,
          0.7509765625,
          0.7783203125,
          0.7653301954269409,
          0.763671875,
          0.7617924809455872,
          0.7744140625,
          0.7724056839942932,
          0.7665094137191772,
          0.760613203048706,
          0.7653301954269409,
          0.7700471878051758,
          0.7558962106704712,
          0.76171875,
          0.7783203125,
          0.7802734375,
          0.7735849022865295,
          0.7771226167678833,
          0.7594339847564697,
          0.7794811129570007,
          0.7783018946647644,
          0.7747641801834106,
          0.7783018946647644,
          0.7688679099082947,
          0.7802734375,
          0.786556601524353,
          0.7806603908538818,
          0.7629716992378235,
          0.7959905862808228,
          0.7724056839942932,
          0.763671875,
          0.7688679099082947,
          0.7724056839942932,
          0.7818396091461182,
          0.78125,
          0.7830188870429993,
          0.7830188870429993,
          0.7806603908538818,
          0.775943398475647,
          0.7688679099082947,
          0.7802734375,
          0.7783203125,
          0.7568359375,
          0.783203125,
          0.7724056839942932,
          0.7700471878051758,
          0.7582547068595886,
          0.763671875,
          0.7877358198165894,
          0.7841981053352356,
          0.7889150977134705,
          0.7948113083839417,
          0.775943398475647,
          0.7806603908538818,
          0.7948113083839417,
          0.7617924809455872,
          0.7794811129570007,
          0.7735849022865295,
          0.7771226167678833,
          0.7900943160057068,
          0.775943398475647,
          0.7641509175300598,
          0.7889150977134705,
          0.7877358198165894,
          0.7735849022865295,
          0.7653301954269409,
          0.7626953125,
          0.7877358198165894,
          0.7889150977134705,
          0.7853773832321167,
          0.7724056839942932,
          0.7783018946647644,
          0.7924528121948242,
          0.7646484375,
          0.7665094137191772,
          0.7924528121948242,
          0.78125,
          0.7747641801834106,
          0.7877358198165894,
          0.7971698045730591,
          0.7889150977134705,
          0.801886796951294,
          0.7889150977134705,
          0.779296875,
          0.794921875,
          0.8007075190544128,
          0.7853773832321167,
          0.8030660152435303,
          0.7724609375,
          0.7806603908538818,
          0.7818396091461182,
          0.7841981053352356,
          0.7676886916160583,
          0.7877358198165894,
          0.7806603908538818,
          0.8030660152435303,
          0.8101415038108826,
          0.7700471878051758,
          0.7998046875,
          0.7900943160057068,
          0.8089622855186462,
          0.7771226167678833,
          0.8042452931404114,
          0.7818396091461182,
          0.7890625,
          0.786556601524353,
          0.7924528121948242,
          0.7841981053352356,
          0.7747641801834106,
          0.7771226167678833,
          0.8066037893295288,
          0.7995283007621765,
          0.7822265625,
          0.8125,
          0.78125,
          0.7939453125,
          0.8077830076217651,
          0.8113207817077637,
          0.7971698045730591,
          0.78125,
          0.7948113083839417,
          0.7983490824699402,
          0.8030660152435303,
          0.7971698045730591,
          0.7794811129570007,
          0.7853773832321167,
          0.7948113083839417,
          0.8054245114326477,
          0.7924528121948242,
          0.7771226167678833,
          0.7841981053352356,
          0.7936320900917053,
          0.8125,
          0.7900943160057068,
          0.801886796951294,
          0.7948113083839417,
          0.7912735939025879,
          0.7818396091461182,
          0.8154296875,
          0.7877358198165894,
          0.8089622855186462,
          0.7919921875,
          0.8101415038108826,
          0.7802734375,
          0.8095703125,
          0.7841981053352356,
          0.7841796875,
          0.8160377144813538,
          0.7948113083839417,
          0.801886796951294,
          0.8054245114326477,
          0.8101415038108826,
          0.8042452931404114,
          0.7948113083839417,
          0.806640625,
          0.8125,
          0.8136792182922363,
          0.8077830076217651,
          0.8042452931404114,
          0.8077830076217651,
          0.8089622855186462,
          0.7959905862808228,
          0.7959905862808228,
          0.7958984375,
          0.8042452931404114,
          0.7948113083839417,
          0.8089622855186462,
          0.7983490824699402,
          0.8113207817077637,
          0.8046875,
          0.7877358198165894,
          0.8195754885673523,
          0.796875,
          0.7958984375,
          0.8136792182922363,
          0.8042452931404114,
          0.7936320900917053,
          0.8056640625,
          0.8030660152435303,
          0.8125,
          0.7889150977134705,
          0.802734375,
          0.7900943160057068,
          0.786556601524353,
          0.8007075190544128,
          0.794921875,
          0.8172169923782349,
          0.8101415038108826,
          0.8101415038108826,
          0.8148584961891174,
          0.794921875,
          0.8101415038108826,
          0.8030660152435303,
          0.8183962106704712,
          0.8278301954269409,
          0.8160377144813538,
          0.8183962106704712,
          0.8183962106704712,
          0.8089622855186462,
          0.7783018946647644,
          0.8066037893295288,
          0.7936320900917053,
          0.7889150977134705,
          0.7983490824699402,
          0.8254716992378235,
          0.8219339847564697,
          0.8136792182922363,
          0.8030660152435303,
          0.7841981053352356,
          0.8172169923782349,
          0.8113207817077637,
          0.823113203048706,
          0.8030660152435303,
          0.806640625,
          0.8101415038108826,
          0.826171875,
          0.8125,
          0.8160377144813538,
          0.8207547068595886,
          0.8251953125,
          0.8183962106704712,
          0.8242924809455872,
          0.7936320900917053,
          0.8254716992378235,
          0.801886796951294,
          0.82421875,
          0.8113207817077637,
          0.8077830076217651,
          0.8007075190544128,
          0.8113207817077637,
          0.8232421875,
          0.8254716992378235,
          0.8290094137191772,
          0.8301886916160583,
          0.8089622855186462,
          0.818359375,
          0.8325471878051758,
          0.8101415038108826,
          0.8007075190544128,
          0.810546875,
          0.8101415038108826,
          0.8278301954269409,
          0.8172169923782349,
          0.8054245114326477,
          0.7995283007621765,
          0.814453125,
          0.8172169923782349,
          0.8291015625,
          0.8125,
          0.8219339847564697,
          0.8136792182922363,
          0.8183962106704712,
          0.822265625,
          0.8007075190544128,
          0.8313679099082947,
          0.8337264060974121,
          0.8136792182922363,
          0.7948113083839417,
          0.810546875,
          0.830078125,
          0.8349056839942932,
          0.8125,
          0.8136792182922363,
          0.8242924809455872,
          0.8325471878051758,
          0.8349056839942932,
          0.814453125,
          0.801886796951294,
          0.8101415038108826,
          0.8301886916160583,
          0.8443396091461182,
          0.8172169923782349,
          0.8066037893295288,
          0.801886796951294,
          0.8172169923782349,
          0.8160377144813538,
          0.8160377144813538,
          0.8160377144813538,
          0.8290094137191772,
          0.8301886916160583,
          0.837890625,
          0.8325471878051758,
          0.8337264060974121,
          0.7983490824699402,
          0.8266509175300598,
          0.8148584961891174,
          0.8337264060974121,
          0.849056601524353,
          0.8278301954269409,
          0.8349609375,
          0.8360849022865295,
          0.8396226167678833,
          0.8313679099082947,
          0.8219339847564697,
          0.8125,
          0.8325471878051758,
          0.8301886916160583,
          0.8136792182922363,
          0.8160377144813538,
          0.823113203048706,
          0.8242924809455872,
          0.8408018946647644,
          0.8136792182922363,
          0.8290094137191772,
          0.8030660152435303,
          0.8325471878051758,
          0.8219339847564697,
          0.838443398475647,
          0.8478773832321167,
          0.8310546875,
          0.8172169923782349,
          0.8254716992378235,
          0.8359375,
          0.8455188870429993,
          0.8447265625,
          0.8369140625,
          0.8054245114326477,
          0.8278301954269409,
          0.82421875,
          0.8301886916160583,
          0.8369140625,
          0.8266509175300598,
          0.8125,
          0.823113203048706,
          0.8372641801834106,
          0.8160377144813538,
          0.8242924809455872,
          0.8278301954269409,
          0.8301886916160583,
          0.8266509175300598,
          0.8183962106704712,
          0.8251953125,
          0.8113207817077637,
          0.8408018946647644,
          0.8242924809455872,
          0.8242924809455872,
          0.8266509175300598,
          0.822265625,
          0.8330078125,
          0.8290094137191772,
          0.8278301954269409,
          0.8207547068595886,
          0.837890625,
          0.8148584961891174,
          0.8266509175300598,
          0.8349056839942932,
          0.8254716992378235,
          0.8443396091461182,
          0.8242924809455872,
          0.8172169923782349,
          0.8431603908538818,
          0.8310546875,
          0.8254716992378235,
          0.8212890625,
          0.8232421875,
          0.8172169923782349,
          0.8396226167678833,
          0.8408203125,
          0.849609375,
          0.8325471878051758,
          0.83984375,
          0.8290094137191772,
          0.8369140625,
          0.8313679099082947,
          0.8349609375,
          0.8466981053352356,
          0.8172169923782349,
          0.8219339847564697,
          0.8290094137191772,
          0.8372641801834106,
          0.8372641801834106,
          0.8349609375,
          0.838443398475647,
          0.8337264060974121,
          0.8349056839942932,
          0.838443398475647,
          0.8313679099082947,
          0.823113203048706,
          0.8549528121948242,
          0.8337264060974121,
          0.8360849022865295,
          0.8443396091461182,
          0.8466796875,
          0.8360849022865295,
          0.8360849022865295,
          0.8549528121948242,
          0.8584905862808228,
          0.83203125,
          0.8596698045730591,
          0.838443398475647,
          0.8254716992378235,
          0.8478773832321167,
          0.8408018946647644,
          0.841796875,
          0.83984375,
          0.8388671875,
          0.8408018946647644,
          0.8372641801834106,
          0.84375,
          0.8419811129570007,
          0.849056601524353,
          0.8515625,
          0.83984375,
          0.8514150977134705,
          0.8408203125,
          0.8232421875,
          0.8372641801834106,
          0.8372641801834106,
          0.8278301954269409,
          0.8431603908538818,
          0.8514150977134705,
          0.8549528121948242,
          0.8608490824699402,
          0.8313679099082947,
          0.8408018946647644,
          0.8313679099082947,
          0.8396226167678833,
          0.841796875,
          0.8455188870429993,
          0.8325471878051758,
          0.8525943160057068,
          0.8443396091461182,
          0.8502358198165894,
          0.83984375,
          0.8561320900917053,
          0.8360849022865295,
          0.8466981053352356,
          0.8301886916160583,
          0.8325471878051758,
          0.8313679099082947,
          0.8360849022865295,
          0.8502358198165894,
          0.8325471878051758,
          0.8525390625,
          0.8431603908538818,
          0.8372641801834106,
          0.8502358198165894,
          0.8278301954269409,
          0.8369140625,
          0.8419811129570007,
          0.84765625,
          0.8455188870429993,
          0.8537735939025879,
          0.8549528121948242,
          0.8544921875,
          0.8502358198165894,
          0.8514150977134705,
          0.8620283007621765,
          0.8702830076217651,
          0.8372641801834106,
          0.8502358198165894,
          0.8301886916160583,
          0.8388671875,
          0.8431603908538818,
          0.8396226167678833,
          0.8537735939025879,
          0.8573113083839417,
          0.8502358198165894,
          0.8349056839942932,
          0.849056601524353,
          0.8466981053352356,
          0.8337264060974121,
          0.8514150977134705,
          0.8431603908538818,
          0.845703125,
          0.8466796875,
          0.8603515625,
          0.838443398475647,
          0.8325471878051758,
          0.8478773832321167,
          0.8691037893295288,
          0.853515625,
          0.8502358198165894,
          0.8537735939025879,
          0.8537735939025879,
          0.849609375,
          0.8408018946647644,
          0.8325471878051758,
          0.853515625,
          0.849056601524353,
          0.8396226167678833,
          0.8549528121948242,
          0.8360849022865295,
          0.8608490824699402,
          0.8455188870429993,
          0.84765625,
          0.8408018946647644,
          0.8544921875,
          0.8573113083839417,
          0.8549528121948242,
          0.8573113083839417,
          0.837890625,
          0.8431603908538818,
          0.8549528121948242,
          0.8679245114326477,
          0.8537735939025879,
          0.8408018946647644,
          0.859375,
          0.8596698045730591,
          0.8573113083839417,
          0.8537735939025879,
          0.8525943160057068,
          0.8620283007621765,
          0.8549528121948242,
          0.8620283007621765,
          0.849056601524353,
          0.8620283007621765,
          0.8359375,
          0.8561320900917053,
          0.8537735939025879,
          0.8525390625,
          0.8632075190544128,
          0.8478773832321167,
          0.8505859375,
          0.8561320900917053,
          0.8655660152435303,
          0.8584905862808228,
          0.859375,
          0.8667452931404114,
          0.8584905862808228,
          0.8720703125,
          0.8502358198165894,
          0.8408018946647644,
          0.8761792182922363,
          0.869140625,
          0.8573113083839417,
          0.8419811129570007,
          0.8642578125,
          0.8667452931404114,
          0.8714622855186462,
          0.8632075190544128,
          0.8596698045730591,
          0.8549528121948242,
          0.8620283007621765,
          0.8408018946647644,
          0.8561320900917053,
          0.838443398475647,
          0.8502358198165894,
          0.8478773832321167,
          0.8525943160057068,
          0.864386796951294,
          0.8584905862808228,
          0.8596698045730591,
          0.8573113083839417,
          0.8691037893295288,
          0.8478773832321167,
          0.8608490824699402,
          0.8655660152435303,
          0.8584905862808228,
          0.857421875,
          0.8478773832321167,
          0.87109375,
          0.8514150977134705,
          0.8726415038108826,
          0.8573113083839417,
          0.8608490824699402,
          0.885613203048706,
          0.864386796951294,
          0.84375,
          0.8671875,
          0.8903301954269409,
          0.875,
          0.8667452931404114,
          0.8632075190544128,
          0.8773584961891174,
          0.8623046875,
          0.8797169923782349,
          0.8726415038108826,
          0.8679245114326477,
          0.849056601524353,
          0.864386796951294,
          0.865234375,
          0.8655660152435303,
          0.8396226167678833,
          0.8738207817077637,
          0.864386796951294,
          0.8691037893295288,
          0.8655660152435303,
          0.8738207817077637,
          0.86328125,
          0.8514150977134705,
          0.875,
          0.869140625,
          0.8620283007621765,
          0.8679245114326477,
          0.8596698045730591,
          0.8525943160057068,
          0.859375,
          0.8726415038108826,
          0.865234375,
          0.885613203048706,
          0.865234375,
          0.8537735939025879,
          0.8583984375,
          0.8564453125,
          0.8691037893295288,
          0.8537735939025879,
          0.8761792182922363,
          0.8478773832321167
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Red"
         },
         "mode": "markers+lines",
         "name": "Validation accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200",
          "201",
          "202",
          "203",
          "204",
          "205",
          "206",
          "207",
          "208",
          "209",
          "210",
          "211",
          "212",
          "213",
          "214",
          "215",
          "216",
          "217",
          "218",
          "219",
          "220",
          "221",
          "222",
          "223",
          "224",
          "225",
          "226",
          "227",
          "228",
          "229",
          "230",
          "231",
          "232",
          "233",
          "234",
          "235",
          "236",
          "237",
          "238",
          "239",
          "240",
          "241",
          "242",
          "243",
          "244",
          "245",
          "246",
          "247",
          "248",
          "249",
          "250",
          "251",
          "252",
          "253",
          "254",
          "255",
          "256",
          "257",
          "258",
          "259",
          "260",
          "261",
          "262",
          "263",
          "264",
          "265",
          "266",
          "267",
          "268",
          "269",
          "270",
          "271",
          "272",
          "273",
          "274",
          "275",
          "276",
          "277",
          "278",
          "279",
          "280",
          "281",
          "282",
          "283",
          "284",
          "285",
          "286",
          "287",
          "288",
          "289",
          "290",
          "291",
          "292",
          "293",
          "294",
          "295",
          "296",
          "297",
          "298",
          "299",
          "300",
          "301",
          "302",
          "303",
          "304",
          "305",
          "306",
          "307",
          "308",
          "309",
          "310",
          "311",
          "312",
          "313",
          "314",
          "315",
          "316",
          "317",
          "318",
          "319",
          "320",
          "321",
          "322",
          "323",
          "324",
          "325",
          "326",
          "327",
          "328",
          "329",
          "330",
          "331",
          "332",
          "333",
          "334",
          "335",
          "336",
          "337",
          "338",
          "339",
          "340",
          "341",
          "342",
          "343",
          "344",
          "345",
          "346",
          "347",
          "348",
          "349",
          "350",
          "351",
          "352",
          "353",
          "354",
          "355",
          "356",
          "357",
          "358",
          "359",
          "360",
          "361",
          "362",
          "363",
          "364",
          "365",
          "366",
          "367",
          "368",
          "369",
          "370",
          "371",
          "372",
          "373",
          "374",
          "375",
          "376",
          "377",
          "378",
          "379",
          "380",
          "381",
          "382",
          "383",
          "384",
          "385",
          "386",
          "387",
          "388",
          "389",
          "390",
          "391",
          "392",
          "393",
          "394",
          "395",
          "396",
          "397",
          "398",
          "399",
          "400",
          "401",
          "402",
          "403",
          "404",
          "405",
          "406",
          "407",
          "408",
          "409",
          "410",
          "411",
          "412",
          "413",
          "414",
          "415",
          "416",
          "417",
          "418",
          "419",
          "420",
          "421",
          "422",
          "423",
          "424",
          "425",
          "426",
          "427",
          "428",
          "429",
          "430",
          "431",
          "432",
          "433",
          "434",
          "435",
          "436",
          "437",
          "438",
          "439",
          "440",
          "441",
          "442",
          "443",
          "444",
          "445",
          "446",
          "447",
          "448",
          "449",
          "450",
          "451",
          "452",
          "453",
          "454",
          "455",
          "456",
          "457",
          "458",
          "459",
          "460",
          "461",
          "462",
          "463",
          "464",
          "465",
          "466",
          "467",
          "468",
          "469",
          "470",
          "471",
          "472",
          "473",
          "474",
          "475",
          "476",
          "477",
          "478",
          "479",
          "480",
          "481",
          "482",
          "483",
          "484",
          "485",
          "486",
          "487",
          "488",
          "489",
          "490",
          "491",
          "492",
          "493",
          "494",
          "495",
          "496",
          "497",
          "498",
          "499",
          "500",
          "501",
          "502",
          "503",
          "504",
          "505",
          "506",
          "507",
          "508",
          "509",
          "510",
          "511",
          "512",
          "513",
          "514",
          "515",
          "516",
          "517",
          "518",
          "519",
          "520",
          "521",
          "522",
          "523",
          "524",
          "525",
          "526",
          "527",
          "528",
          "529",
          "530",
          "531",
          "532",
          "533",
          "534",
          "535",
          "536",
          "537",
          "538",
          "539",
          "540",
          "541",
          "542",
          "543",
          "544",
          "545",
          "546",
          "547",
          "548",
          "549",
          "550",
          "551",
          "552",
          "553",
          "554",
          "555",
          "556",
          "557",
          "558",
          "559",
          "560",
          "561",
          "562",
          "563",
          "564",
          "565",
          "566",
          "567",
          "568",
          "569",
          "570",
          "571",
          "572",
          "573",
          "574",
          "575",
          "576",
          "577",
          "578",
          "579",
          "580",
          "581",
          "582",
          "583",
          "584",
          "585",
          "586",
          "587",
          "588",
          "589",
          "590",
          "591",
          "592",
          "593",
          "594",
          "595",
          "596",
          "597",
          "598",
          "599",
          "600",
          "601",
          "602",
          "603",
          "604",
          "605",
          "606",
          "607",
          "608",
          "609",
          "610",
          "611",
          "612",
          "613",
          "614",
          "615",
          "616",
          "617",
          "618",
          "619",
          "620",
          "621",
          "622",
          "623",
          "624",
          "625",
          "626",
          "627",
          "628",
          "629",
          "630",
          "631",
          "632",
          "633",
          "634",
          "635",
          "636",
          "637",
          "638",
          "639",
          "640",
          "641",
          "642",
          "643",
          "644",
          "645",
          "646",
          "647",
          "648",
          "649",
          "650",
          "651",
          "652",
          "653",
          "654",
          "655",
          "656",
          "657",
          "658",
          "659",
          "660",
          "661",
          "662",
          "663",
          "664",
          "665",
          "666",
          "667",
          "668",
          "669",
          "670",
          "671",
          "672",
          "673",
          "674",
          "675",
          "676",
          "677",
          "678",
          "679",
          "680",
          "681",
          "682",
          "683",
          "684",
          "685",
          "686",
          "687",
          "688",
          "689",
          "690",
          "691",
          "692",
          "693",
          "694",
          "695",
          "696",
          "697",
          "698",
          "699",
          "700",
          "701",
          "702",
          "703",
          "704",
          "705",
          "706",
          "707",
          "708",
          "709",
          "710",
          "711",
          "712",
          "713",
          "714",
          "715",
          "716",
          "717",
          "718",
          "719",
          "720",
          "721",
          "722",
          "723",
          "724",
          "725",
          "726",
          "727",
          "728",
          "729",
          "730",
          "731",
          "732",
          "733",
          "734",
          "735",
          "736",
          "737",
          "738",
          "739",
          "740",
          "741",
          "742",
          "743",
          "744",
          "745",
          "746",
          "747",
          "748",
          "749",
          "750",
          "751",
          "752",
          "753",
          "754",
          "755",
          "756",
          "757",
          "758",
          "759",
          "760",
          "761",
          "762",
          "763",
          "764",
          "765",
          "766",
          "767",
          "768",
          "769",
          "770",
          "771",
          "772",
          "773",
          "774",
          "775",
          "776",
          "777",
          "778",
          "779",
          "780",
          "781",
          "782",
          "783",
          "784",
          "785",
          "786",
          "787",
          "788",
          "789",
          "790",
          "791",
          "792",
          "793",
          "794",
          "795",
          "796",
          "797",
          "798",
          "799",
          "800",
          "801",
          "802",
          "803",
          "804",
          "805",
          "806",
          "807",
          "808",
          "809",
          "810",
          "811",
          "812",
          "813",
          "814",
          "815",
          "816",
          "817",
          "818",
          "819",
          "820",
          "821",
          "822",
          "823",
          "824",
          "825",
          "826",
          "827",
          "828",
          "829",
          "830",
          "831",
          "832",
          "833",
          "834",
          "835",
          "836",
          "837",
          "838",
          "839",
          "840",
          "841",
          "842",
          "843",
          "844",
          "845",
          "846",
          "847",
          "848",
          "849",
          "850",
          "851",
          "852",
          "853",
          "854",
          "855",
          "856",
          "857",
          "858",
          "859",
          "860",
          "861",
          "862",
          "863",
          "864",
          "865",
          "866",
          "867",
          "868",
          "869",
          "870",
          "871",
          "872",
          "873",
          "874",
          "875",
          "876",
          "877",
          "878",
          "879",
          "880",
          "881",
          "882",
          "883",
          "884",
          "885",
          "886",
          "887",
          "888",
          "889",
          "890",
          "891",
          "892",
          "893",
          "894",
          "895",
          "896",
          "897",
          "898",
          "899",
          "900",
          "901",
          "902",
          "903",
          "904",
          "905",
          "906",
          "907",
          "908",
          "909",
          "910",
          "911",
          "912",
          "913",
          "914",
          "915",
          "916",
          "917",
          "918",
          "919",
          "920",
          "921",
          "922",
          "923",
          "924",
          "925",
          "926",
          "927",
          "928",
          "929",
          "930",
          "931",
          "932",
          "933",
          "934",
          "935",
          "936",
          "937",
          "938",
          "939",
          "940",
          "941",
          "942",
          "943",
          "944",
          "945",
          "946",
          "947",
          "948",
          "949",
          "950",
          "951",
          "952",
          "953",
          "954",
          "955",
          "956",
          "957",
          "958",
          "959",
          "960",
          "961",
          "962",
          "963",
          "964",
          "965",
          "966",
          "967",
          "968",
          "969",
          "970",
          "971",
          "972",
          "973",
          "974",
          "975",
          "976",
          "977",
          "978",
          "979",
          "980",
          "981",
          "982",
          "983",
          "984",
          "985",
          "986",
          "987",
          "988",
          "989",
          "990",
          "991",
          "992",
          "993",
          "994",
          "995",
          "996",
          "997",
          "998",
          "999",
          "1000"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "xaxis": "x",
         "y": [
          0.2671480178833008,
          0.3465704023838043,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.31768953800201416,
          0.31768953800201416,
          0.31768953800201416,
          0.32129964232444763,
          0.3249097466468811,
          0.3285198509693146,
          0.3285198509693146,
          0.3285198509693146,
          0.3285198509693146,
          0.3285198509693146,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3357400596141815,
          0.3393501937389374,
          0.3393501937389374,
          0.35740071535110474,
          0.36823105812072754,
          0.371841162443161,
          0.3754512667655945,
          0.37906137108802795,
          0.37906137108802795,
          0.37906137108802795,
          0.3826714754104614,
          0.38989168405532837,
          0.39350181818008423,
          0.3826714754104614,
          0.3826714754104614,
          0.3862815797328949,
          0.3971119225025177,
          0.39350181818008423,
          0.4079422354698181,
          0.4223826825618744,
          0.42599278688430786,
          0.454873651266098,
          0.47653430700302124,
          0.47653430700302124,
          0.46570396423339844,
          0.44043320417404175,
          0.4332129955291748,
          0.4368230998516083,
          0.454873651266098,
          0.4837545156478882,
          0.4837545156478882,
          0.5090252757072449,
          0.5270758271217346,
          0.5162454843521118,
          0.4909747242927551,
          0.4729241728782654,
          0.44043320417404175,
          0.44043320417404175,
          0.47653430700302124,
          0.49819493293762207,
          0.5018050670623779,
          0.5090252757072449,
          0.5090252757072449,
          0.4909747242927551,
          0.48736461997032166,
          0.4837545156478882,
          0.4837545156478882,
          0.5090252757072449,
          0.5198556184768677,
          0.5451263785362244,
          0.5451263785362244,
          0.5487364530563354,
          0.5523465871810913,
          0.5487364530563354,
          0.5595667958259583,
          0.5667870044708252,
          0.5740072131156921,
          0.577617347240448,
          0.577617347240448,
          0.588447630405426,
          0.6064981818199158,
          0.5812274217605591,
          0.570397138595581,
          0.5667870044708252,
          0.5487364530563354,
          0.5451263785362244,
          0.5342960357666016,
          0.5451263785362244,
          0.5595667958259583,
          0.5667870044708252,
          0.570397138595581,
          0.570397138595581,
          0.6064981818199158,
          0.6137183904647827,
          0.6137183904647827,
          0.6281588673591614,
          0.6281588673591614,
          0.6281588673591614,
          0.6389891505241394,
          0.6317689418792725,
          0.6281588673591614,
          0.6209385991096497,
          0.6064981818199158,
          0.6028881072998047,
          0.5992779731750488,
          0.5992779731750488,
          0.588447630405426,
          0.5992779731750488,
          0.5992779731750488,
          0.6028881072998047,
          0.6209385991096497,
          0.6317689418792725,
          0.6281588673591614,
          0.6281588673591614,
          0.6245487332344055,
          0.6245487332344055,
          0.6281588673591614,
          0.6245487332344055,
          0.6245487332344055,
          0.6245487332344055,
          0.6245487332344055,
          0.6245487332344055,
          0.6353790760040283,
          0.6389891505241394,
          0.6353790760040283,
          0.6173285245895386,
          0.5920577645301819,
          0.6209385991096497,
          0.6353790760040283,
          0.6425992846488953,
          0.6570397019386292,
          0.660649836063385,
          0.667870044708252,
          0.667870044708252,
          0.6750902533531189,
          0.6750902533531189,
          0.6570397019386292,
          0.6570397019386292,
          0.667870044708252,
          0.6895306706428528,
          0.6425992846488953,
          0.6137183904647827,
          0.6137183904647827,
          0.6425992846488953,
          0.6498194932937622,
          0.6498194932937622,
          0.6353790760040283,
          0.6353790760040283,
          0.671480119228363,
          0.6750902533531189,
          0.6570397019386292,
          0.6353790760040283,
          0.6389891505241394,
          0.6353790760040283,
          0.6425992846488953,
          0.6462093591690063,
          0.6425992846488953,
          0.660649836063385,
          0.671480119228363,
          0.6823104619979858,
          0.667870044708252,
          0.6389891505241394,
          0.6281588673591614,
          0.6317689418792725,
          0.6498194932937622,
          0.6389891505241394,
          0.6570397019386292,
          0.6353790760040283,
          0.6534296274185181,
          0.6642599105834961,
          0.667870044708252,
          0.671480119228363,
          0.671480119228363,
          0.6642599105834961,
          0.660649836063385,
          0.6389891505241394,
          0.6389891505241394,
          0.6462093591690063,
          0.660649836063385,
          0.6823104619979858,
          0.6750902533531189,
          0.6642599105834961,
          0.6534296274185181,
          0.6570397019386292,
          0.667870044708252,
          0.6823104619979858,
          0.671480119228363,
          0.660649836063385,
          0.660649836063385,
          0.6642599105834961,
          0.6823104619979858,
          0.6931408047676086,
          0.6931408047676086,
          0.6787003874778748,
          0.671480119228363,
          0.660649836063385,
          0.667870044708252,
          0.667870044708252,
          0.6823104619979858,
          0.6895306706428528,
          0.6931408047676086,
          0.7039711475372314,
          0.6859205961227417,
          0.6823104619979858,
          0.6642599105834961,
          0.667870044708252,
          0.6787003874778748,
          0.6931408047676086,
          0.6895306706428528,
          0.6931408047676086,
          0.6895306706428528,
          0.6823104619979858,
          0.6823104619979858,
          0.6931408047676086,
          0.6859205961227417,
          0.6859205961227417,
          0.7039711475372314,
          0.7039711475372314,
          0.7003610134124756,
          0.7003610134124756,
          0.6859205961227417,
          0.6967508792877197,
          0.7039711475372314,
          0.7111913561820984,
          0.7111913561820984,
          0.7075812220573425,
          0.7075812220573425,
          0.7111913561820984,
          0.7003610134124756,
          0.6931408047676086,
          0.6931408047676086,
          0.667870044708252,
          0.667870044708252,
          0.7003610134124756,
          0.7075812220573425,
          0.7039711475372314,
          0.7039711475372314,
          0.7111913561820984,
          0.7039711475372314,
          0.7148014307022095,
          0.7075812220573425,
          0.7075812220573425,
          0.7111913561820984,
          0.7039711475372314,
          0.7039711475372314,
          0.7075812220573425,
          0.7075812220573425,
          0.6967508792877197,
          0.6859205961227417,
          0.6787003874778748,
          0.667870044708252,
          0.671480119228363,
          0.6859205961227417,
          0.6823104619979858,
          0.667870044708252,
          0.6823104619979858,
          0.6750902533531189,
          0.6787003874778748,
          0.6895306706428528,
          0.6931408047676086,
          0.6895306706428528,
          0.6931408047676086,
          0.7039711475372314,
          0.7039711475372314,
          0.7039711475372314,
          0.7111913561820984,
          0.6895306706428528,
          0.6931408047676086,
          0.7148014307022095,
          0.7148014307022095,
          0.7148014307022095,
          0.7075812220573425,
          0.7039711475372314,
          0.6895306706428528,
          0.6859205961227417,
          0.6931408047676086,
          0.6823104619979858,
          0.6787003874778748,
          0.6895306706428528,
          0.7039711475372314,
          0.7075812220573425,
          0.6859205961227417,
          0.6823104619979858,
          0.6859205961227417,
          0.660649836063385,
          0.667870044708252,
          0.6750902533531189,
          0.6823104619979858,
          0.6895306706428528,
          0.7003610134124756,
          0.7039711475372314,
          0.7003610134124756,
          0.6931408047676086,
          0.6895306706428528,
          0.667870044708252,
          0.660649836063385,
          0.6642599105834961,
          0.6895306706428528,
          0.7039711475372314,
          0.7075812220573425,
          0.7003610134124756,
          0.7039711475372314,
          0.6895306706428528,
          0.671480119228363,
          0.667870044708252,
          0.6642599105834961,
          0.6931408047676086,
          0.7039711475372314,
          0.7111913561820984,
          0.7220216393470764,
          0.7075812220573425,
          0.7111913561820984,
          0.6823104619979858,
          0.6787003874778748,
          0.6750902533531189,
          0.6750902533531189,
          0.6895306706428528,
          0.6895306706428528,
          0.6859205961227417,
          0.6931408047676086,
          0.6895306706428528,
          0.667870044708252,
          0.6823104619979858,
          0.6895306706428528,
          0.6895306706428528,
          0.6895306706428528,
          0.6967508792877197,
          0.6859205961227417,
          0.6859205961227417,
          0.6859205961227417,
          0.6750902533531189,
          0.6859205961227417,
          0.7075812220573425,
          0.7111913561820984,
          0.7148014307022095,
          0.7111913561820984,
          0.7220216393470764,
          0.7220216393470764,
          0.7256317734718323,
          0.7184115648269653,
          0.7111913561820984,
          0.7220216393470764,
          0.7220216393470764,
          0.7148014307022095,
          0.7039711475372314,
          0.7003610134124756,
          0.7111913561820984,
          0.6967508792877197,
          0.7184115648269653,
          0.7220216393470764,
          0.7256317734718323,
          0.7328519821166992,
          0.7220216393470764,
          0.6931408047676086,
          0.6967508792877197,
          0.6967508792877197,
          0.7075812220573425,
          0.6823104619979858,
          0.660649836063385,
          0.6534296274185181,
          0.7075812220573425,
          0.7256317734718323,
          0.7292418479919434,
          0.7148014307022095,
          0.7111913561820984,
          0.7220216393470764,
          0.7075812220573425,
          0.6895306706428528,
          0.6967508792877197,
          0.7111913561820984,
          0.7220216393470764,
          0.7292418479919434,
          0.7220216393470764,
          0.7220216393470764,
          0.7148014307022095,
          0.6787003874778748,
          0.7039711475372314,
          0.7184115648269653,
          0.7039711475372314,
          0.7003610134124756,
          0.7039711475372314,
          0.6931408047676086,
          0.6895306706428528,
          0.7003610134124756,
          0.7075812220573425,
          0.7039711475372314,
          0.7111913561820984,
          0.7075812220573425,
          0.6967508792877197,
          0.7039711475372314,
          0.6967508792877197,
          0.7003610134124756,
          0.7111913561820984,
          0.7328519821166992,
          0.7184115648269653,
          0.6787003874778748,
          0.6498194932937622,
          0.6859205961227417,
          0.6967508792877197,
          0.6787003874778748,
          0.6787003874778748,
          0.6823104619979858,
          0.7184115648269653,
          0.7292418479919434,
          0.7364621162414551,
          0.743682324886322,
          0.7400721907615662,
          0.7328519821166992,
          0.7256317734718323,
          0.7328519821166992,
          0.7328519821166992,
          0.743682324886322,
          0.7328519821166992,
          0.7400721907615662,
          0.7292418479919434,
          0.7039711475372314,
          0.6750902533531189,
          0.6895306706428528,
          0.7003610134124756,
          0.6967508792877197,
          0.6967508792877197,
          0.7039711475372314,
          0.7075812220573425,
          0.6859205961227417,
          0.6823104619979858,
          0.6823104619979858,
          0.7003610134124756,
          0.6967508792877197,
          0.6967508792877197,
          0.7039711475372314,
          0.7039711475372314,
          0.7039711475372314,
          0.6967508792877197,
          0.6498194932937622,
          0.6750902533531189,
          0.6967508792877197,
          0.6967508792877197,
          0.7184115648269653,
          0.7220216393470764,
          0.7256317734718323,
          0.7220216393470764,
          0.7075812220573425,
          0.6931408047676086,
          0.6787003874778748,
          0.6823104619979858,
          0.6895306706428528,
          0.7039711475372314,
          0.7148014307022095,
          0.7148014307022095,
          0.7220216393470764,
          0.7184115648269653,
          0.7256317734718323,
          0.7111913561820984,
          0.6967508792877197,
          0.6859205961227417,
          0.6895306706428528,
          0.6823104619979858,
          0.6750902533531189,
          0.7003610134124756,
          0.7003610134124756,
          0.7039711475372314,
          0.7220216393470764,
          0.7256317734718323,
          0.6895306706428528,
          0.7003610134124756,
          0.7075812220573425,
          0.7039711475372314,
          0.7039711475372314,
          0.7039711475372314,
          0.7075812220573425,
          0.7039711475372314,
          0.7039711475372314,
          0.6931408047676086,
          0.6931408047676086,
          0.7256317734718323,
          0.7400721907615662,
          0.743682324886322,
          0.7400721907615662,
          0.7075812220573425,
          0.6823104619979858,
          0.6787003874778748,
          0.7075812220573425,
          0.7075812220573425,
          0.7003610134124756,
          0.7075812220573425,
          0.6895306706428528,
          0.6895306706428528,
          0.7003610134124756,
          0.7039711475372314,
          0.7039711475372314,
          0.7003610134124756,
          0.7184115648269653,
          0.7184115648269653,
          0.7292418479919434,
          0.7148014307022095,
          0.7111913561820984,
          0.7256317734718323,
          0.7148014307022095,
          0.7075812220573425,
          0.7003610134124756,
          0.6823104619979858,
          0.7075812220573425,
          0.7220216393470764,
          0.7220216393470764,
          0.7184115648269653,
          0.7184115648269653,
          0.7111913561820984,
          0.7220216393470764,
          0.7292418479919434,
          0.7256317734718323,
          0.7039711475372314,
          0.7003610134124756,
          0.7184115648269653,
          0.7039711475372314,
          0.7039711475372314,
          0.7111913561820984,
          0.7039711475372314,
          0.7039711475372314,
          0.7292418479919434,
          0.7292418479919434,
          0.7184115648269653,
          0.7148014307022095,
          0.7184115648269653,
          0.7075812220573425,
          0.6895306706428528,
          0.6967508792877197,
          0.6895306706428528,
          0.6967508792877197,
          0.7003610134124756,
          0.7184115648269653,
          0.7220216393470764,
          0.7400721907615662,
          0.7220216393470764,
          0.7111913561820984,
          0.7003610134124756,
          0.7075812220573425,
          0.7220216393470764,
          0.7364621162414551,
          0.7328519821166992,
          0.7364621162414551,
          0.743682324886322,
          0.7328519821166992,
          0.7292418479919434,
          0.7364621162414551,
          0.7328519821166992,
          0.7400721907615662,
          0.7111913561820984,
          0.6967508792877197,
          0.7003610134124756,
          0.7003610134124756,
          0.7111913561820984,
          0.7111913561820984,
          0.7148014307022095,
          0.7148014307022095,
          0.7220216393470764,
          0.7256317734718323,
          0.7220216393470764,
          0.7039711475372314,
          0.7039711475372314,
          0.7111913561820984,
          0.7148014307022095,
          0.7220216393470764,
          0.7256317734718323,
          0.7111913561820984,
          0.7148014307022095,
          0.7364621162414551,
          0.7364621162414551,
          0.7292418479919434,
          0.7184115648269653,
          0.7111913561820984,
          0.7039711475372314,
          0.7039711475372314,
          0.7148014307022095,
          0.7220216393470764,
          0.7184115648269653,
          0.7184115648269653,
          0.7256317734718323,
          0.7075812220573425,
          0.7039711475372314,
          0.7075812220573425,
          0.7256317734718323,
          0.7292418479919434,
          0.7292418479919434,
          0.7220216393470764,
          0.7364621162414551,
          0.750902533531189,
          0.7328519821166992,
          0.7292418479919434,
          0.7400721907615662,
          0.7220216393470764,
          0.6931408047676086,
          0.7111913561820984,
          0.7292418479919434,
          0.7256317734718323,
          0.7364621162414551,
          0.7472923994064331,
          0.7400721907615662,
          0.7400721907615662,
          0.7328519821166992,
          0.7184115648269653,
          0.7184115648269653,
          0.7111913561820984,
          0.7148014307022095,
          0.7039711475372314,
          0.6895306706428528,
          0.6967508792877197,
          0.7039711475372314,
          0.7256317734718323,
          0.743682324886322,
          0.7364621162414551,
          0.7400721907615662,
          0.7220216393470764,
          0.7003610134124756,
          0.7111913561820984,
          0.7292418479919434,
          0.7400721907615662,
          0.7256317734718323,
          0.7039711475372314,
          0.7148014307022095,
          0.7184115648269653,
          0.7328519821166992,
          0.7292418479919434,
          0.7292418479919434,
          0.7292418479919434,
          0.7292418479919434,
          0.6931408047676086,
          0.7111913561820984,
          0.7184115648269653,
          0.7328519821166992,
          0.7220216393470764,
          0.7256317734718323,
          0.7148014307022095,
          0.7148014307022095,
          0.7364621162414551,
          0.7400721907615662,
          0.7364621162414551,
          0.750902533531189,
          0.7364621162414551,
          0.7256317734718323,
          0.7256317734718323,
          0.7256317734718323,
          0.750902533531189,
          0.743682324886322,
          0.7328519821166992,
          0.7075812220573425,
          0.7003610134124756,
          0.6967508792877197,
          0.7039711475372314,
          0.7039711475372314,
          0.7184115648269653,
          0.7328519821166992,
          0.7328519821166992,
          0.743682324886322,
          0.7400721907615662,
          0.7364621162414551,
          0.7256317734718323,
          0.7220216393470764,
          0.7328519821166992,
          0.7220216393470764,
          0.6967508792877197,
          0.7256317734718323,
          0.7256317734718323,
          0.7111913561820984,
          0.7148014307022095,
          0.7148014307022095,
          0.7148014307022095,
          0.7184115648269653,
          0.7220216393470764,
          0.7292418479919434,
          0.7256317734718323,
          0.7328519821166992,
          0.7292418479919434,
          0.7148014307022095,
          0.7003610134124756,
          0.6967508792877197,
          0.7039711475372314,
          0.7184115648269653,
          0.6967508792877197,
          0.7003610134124756,
          0.7220216393470764,
          0.7472923994064331,
          0.7545126080513,
          0.7545126080513,
          0.7364621162414551,
          0.7400721907615662,
          0.7292418479919434,
          0.7220216393470764,
          0.7148014307022095,
          0.7220216393470764,
          0.7184115648269653,
          0.7111913561820984,
          0.7256317734718323,
          0.743682324886322,
          0.743682324886322,
          0.7472923994064331,
          0.743682324886322,
          0.7328519821166992,
          0.7328519821166992,
          0.743682324886322,
          0.7364621162414551,
          0.7148014307022095,
          0.7256317734718323,
          0.7256317734718323,
          0.7148014307022095,
          0.7184115648269653,
          0.7256317734718323,
          0.7184115648269653,
          0.7075812220573425,
          0.6931408047676086,
          0.7220216393470764,
          0.7328519821166992,
          0.7364621162414551,
          0.7256317734718323,
          0.7220216393470764,
          0.7184115648269653,
          0.7220216393470764,
          0.7148014307022095,
          0.7184115648269653,
          0.7184115648269653,
          0.7256317734718323,
          0.7256317734718323,
          0.7075812220573425,
          0.7075812220573425,
          0.7075812220573425,
          0.6895306706428528,
          0.6967508792877197,
          0.7003610134124756,
          0.7075812220573425,
          0.7184115648269653,
          0.7256317734718323,
          0.7256317734718323,
          0.7256317734718323,
          0.7220216393470764,
          0.7292418479919434,
          0.7220216393470764,
          0.7111913561820984,
          0.7111913561820984,
          0.7148014307022095,
          0.7075812220573425,
          0.7039711475372314,
          0.7148014307022095,
          0.7111913561820984,
          0.7111913561820984,
          0.7039711475372314,
          0.7003610134124756,
          0.6931408047676086,
          0.6931408047676086,
          0.6895306706428528,
          0.6931408047676086,
          0.6895306706428528,
          0.6931408047676086,
          0.6967508792877197,
          0.6967508792877197,
          0.6859205961227417,
          0.7148014307022095,
          0.7184115648269653,
          0.7039711475372314,
          0.7075812220573425,
          0.7148014307022095,
          0.7292418479919434,
          0.7400721907615662,
          0.7400721907615662,
          0.7400721907615662,
          0.7472923994064331,
          0.7292418479919434,
          0.7220216393470764,
          0.7111913561820984,
          0.7039711475372314,
          0.7039711475372314,
          0.7256317734718323,
          0.7400721907615662,
          0.7472923994064331,
          0.7472923994064331,
          0.7328519821166992,
          0.7220216393470764,
          0.7075812220573425,
          0.7148014307022095,
          0.7075812220573425,
          0.7075812220573425,
          0.7220216393470764,
          0.7364621162414551,
          0.7400721907615662,
          0.7581227421760559,
          0.7545126080513,
          0.743682324886322,
          0.7364621162414551,
          0.7472923994064331,
          0.7292418479919434,
          0.7328519821166992,
          0.7364621162414551,
          0.7328519821166992,
          0.7328519821166992,
          0.7256317734718323,
          0.7364621162414551,
          0.7400721907615662,
          0.7184115648269653,
          0.6967508792877197,
          0.6859205961227417,
          0.7039711475372314,
          0.7111913561820984,
          0.7328519821166992,
          0.7292418479919434,
          0.7400721907615662,
          0.7292418479919434,
          0.7039711475372314,
          0.6967508792877197,
          0.7184115648269653,
          0.7075812220573425,
          0.7184115648269653,
          0.7364621162414551,
          0.7111913561820984,
          0.7075812220573425,
          0.6967508792877197,
          0.6931408047676086,
          0.6967508792877197,
          0.7184115648269653,
          0.7256317734718323,
          0.7328519821166992,
          0.7292418479919434,
          0.7292418479919434,
          0.7220216393470764,
          0.7003610134124756,
          0.6859205961227417,
          0.6895306706428528,
          0.6895306706428528,
          0.7039711475372314,
          0.7111913561820984,
          0.7111913561820984,
          0.7220216393470764,
          0.7364621162414551,
          0.7292418479919434,
          0.7400721907615662,
          0.7292418479919434,
          0.7400721907615662,
          0.7545126080513,
          0.7617328763008118,
          0.7400721907615662,
          0.7545126080513,
          0.743682324886322,
          0.7256317734718323,
          0.7220216393470764,
          0.7148014307022095,
          0.7148014307022095,
          0.7075812220573425,
          0.7256317734718323,
          0.7220216393470764,
          0.750902533531189,
          0.7472923994064331,
          0.7400721907615662,
          0.7364621162414551,
          0.7328519821166992,
          0.7220216393470764,
          0.7184115648269653,
          0.7364621162414551,
          0.7400721907615662,
          0.743682324886322,
          0.7292418479919434,
          0.7184115648269653,
          0.7111913561820984,
          0.7220216393470764
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Blue"
         },
         "mode": "markers+lines",
         "name": "Training loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200",
          "201",
          "202",
          "203",
          "204",
          "205",
          "206",
          "207",
          "208",
          "209",
          "210",
          "211",
          "212",
          "213",
          "214",
          "215",
          "216",
          "217",
          "218",
          "219",
          "220",
          "221",
          "222",
          "223",
          "224",
          "225",
          "226",
          "227",
          "228",
          "229",
          "230",
          "231",
          "232",
          "233",
          "234",
          "235",
          "236",
          "237",
          "238",
          "239",
          "240",
          "241",
          "242",
          "243",
          "244",
          "245",
          "246",
          "247",
          "248",
          "249",
          "250",
          "251",
          "252",
          "253",
          "254",
          "255",
          "256",
          "257",
          "258",
          "259",
          "260",
          "261",
          "262",
          "263",
          "264",
          "265",
          "266",
          "267",
          "268",
          "269",
          "270",
          "271",
          "272",
          "273",
          "274",
          "275",
          "276",
          "277",
          "278",
          "279",
          "280",
          "281",
          "282",
          "283",
          "284",
          "285",
          "286",
          "287",
          "288",
          "289",
          "290",
          "291",
          "292",
          "293",
          "294",
          "295",
          "296",
          "297",
          "298",
          "299",
          "300",
          "301",
          "302",
          "303",
          "304",
          "305",
          "306",
          "307",
          "308",
          "309",
          "310",
          "311",
          "312",
          "313",
          "314",
          "315",
          "316",
          "317",
          "318",
          "319",
          "320",
          "321",
          "322",
          "323",
          "324",
          "325",
          "326",
          "327",
          "328",
          "329",
          "330",
          "331",
          "332",
          "333",
          "334",
          "335",
          "336",
          "337",
          "338",
          "339",
          "340",
          "341",
          "342",
          "343",
          "344",
          "345",
          "346",
          "347",
          "348",
          "349",
          "350",
          "351",
          "352",
          "353",
          "354",
          "355",
          "356",
          "357",
          "358",
          "359",
          "360",
          "361",
          "362",
          "363",
          "364",
          "365",
          "366",
          "367",
          "368",
          "369",
          "370",
          "371",
          "372",
          "373",
          "374",
          "375",
          "376",
          "377",
          "378",
          "379",
          "380",
          "381",
          "382",
          "383",
          "384",
          "385",
          "386",
          "387",
          "388",
          "389",
          "390",
          "391",
          "392",
          "393",
          "394",
          "395",
          "396",
          "397",
          "398",
          "399",
          "400",
          "401",
          "402",
          "403",
          "404",
          "405",
          "406",
          "407",
          "408",
          "409",
          "410",
          "411",
          "412",
          "413",
          "414",
          "415",
          "416",
          "417",
          "418",
          "419",
          "420",
          "421",
          "422",
          "423",
          "424",
          "425",
          "426",
          "427",
          "428",
          "429",
          "430",
          "431",
          "432",
          "433",
          "434",
          "435",
          "436",
          "437",
          "438",
          "439",
          "440",
          "441",
          "442",
          "443",
          "444",
          "445",
          "446",
          "447",
          "448",
          "449",
          "450",
          "451",
          "452",
          "453",
          "454",
          "455",
          "456",
          "457",
          "458",
          "459",
          "460",
          "461",
          "462",
          "463",
          "464",
          "465",
          "466",
          "467",
          "468",
          "469",
          "470",
          "471",
          "472",
          "473",
          "474",
          "475",
          "476",
          "477",
          "478",
          "479",
          "480",
          "481",
          "482",
          "483",
          "484",
          "485",
          "486",
          "487",
          "488",
          "489",
          "490",
          "491",
          "492",
          "493",
          "494",
          "495",
          "496",
          "497",
          "498",
          "499",
          "500",
          "501",
          "502",
          "503",
          "504",
          "505",
          "506",
          "507",
          "508",
          "509",
          "510",
          "511",
          "512",
          "513",
          "514",
          "515",
          "516",
          "517",
          "518",
          "519",
          "520",
          "521",
          "522",
          "523",
          "524",
          "525",
          "526",
          "527",
          "528",
          "529",
          "530",
          "531",
          "532",
          "533",
          "534",
          "535",
          "536",
          "537",
          "538",
          "539",
          "540",
          "541",
          "542",
          "543",
          "544",
          "545",
          "546",
          "547",
          "548",
          "549",
          "550",
          "551",
          "552",
          "553",
          "554",
          "555",
          "556",
          "557",
          "558",
          "559",
          "560",
          "561",
          "562",
          "563",
          "564",
          "565",
          "566",
          "567",
          "568",
          "569",
          "570",
          "571",
          "572",
          "573",
          "574",
          "575",
          "576",
          "577",
          "578",
          "579",
          "580",
          "581",
          "582",
          "583",
          "584",
          "585",
          "586",
          "587",
          "588",
          "589",
          "590",
          "591",
          "592",
          "593",
          "594",
          "595",
          "596",
          "597",
          "598",
          "599",
          "600",
          "601",
          "602",
          "603",
          "604",
          "605",
          "606",
          "607",
          "608",
          "609",
          "610",
          "611",
          "612",
          "613",
          "614",
          "615",
          "616",
          "617",
          "618",
          "619",
          "620",
          "621",
          "622",
          "623",
          "624",
          "625",
          "626",
          "627",
          "628",
          "629",
          "630",
          "631",
          "632",
          "633",
          "634",
          "635",
          "636",
          "637",
          "638",
          "639",
          "640",
          "641",
          "642",
          "643",
          "644",
          "645",
          "646",
          "647",
          "648",
          "649",
          "650",
          "651",
          "652",
          "653",
          "654",
          "655",
          "656",
          "657",
          "658",
          "659",
          "660",
          "661",
          "662",
          "663",
          "664",
          "665",
          "666",
          "667",
          "668",
          "669",
          "670",
          "671",
          "672",
          "673",
          "674",
          "675",
          "676",
          "677",
          "678",
          "679",
          "680",
          "681",
          "682",
          "683",
          "684",
          "685",
          "686",
          "687",
          "688",
          "689",
          "690",
          "691",
          "692",
          "693",
          "694",
          "695",
          "696",
          "697",
          "698",
          "699",
          "700",
          "701",
          "702",
          "703",
          "704",
          "705",
          "706",
          "707",
          "708",
          "709",
          "710",
          "711",
          "712",
          "713",
          "714",
          "715",
          "716",
          "717",
          "718",
          "719",
          "720",
          "721",
          "722",
          "723",
          "724",
          "725",
          "726",
          "727",
          "728",
          "729",
          "730",
          "731",
          "732",
          "733",
          "734",
          "735",
          "736",
          "737",
          "738",
          "739",
          "740",
          "741",
          "742",
          "743",
          "744",
          "745",
          "746",
          "747",
          "748",
          "749",
          "750",
          "751",
          "752",
          "753",
          "754",
          "755",
          "756",
          "757",
          "758",
          "759",
          "760",
          "761",
          "762",
          "763",
          "764",
          "765",
          "766",
          "767",
          "768",
          "769",
          "770",
          "771",
          "772",
          "773",
          "774",
          "775",
          "776",
          "777",
          "778",
          "779",
          "780",
          "781",
          "782",
          "783",
          "784",
          "785",
          "786",
          "787",
          "788",
          "789",
          "790",
          "791",
          "792",
          "793",
          "794",
          "795",
          "796",
          "797",
          "798",
          "799",
          "800",
          "801",
          "802",
          "803",
          "804",
          "805",
          "806",
          "807",
          "808",
          "809",
          "810",
          "811",
          "812",
          "813",
          "814",
          "815",
          "816",
          "817",
          "818",
          "819",
          "820",
          "821",
          "822",
          "823",
          "824",
          "825",
          "826",
          "827",
          "828",
          "829",
          "830",
          "831",
          "832",
          "833",
          "834",
          "835",
          "836",
          "837",
          "838",
          "839",
          "840",
          "841",
          "842",
          "843",
          "844",
          "845",
          "846",
          "847",
          "848",
          "849",
          "850",
          "851",
          "852",
          "853",
          "854",
          "855",
          "856",
          "857",
          "858",
          "859",
          "860",
          "861",
          "862",
          "863",
          "864",
          "865",
          "866",
          "867",
          "868",
          "869",
          "870",
          "871",
          "872",
          "873",
          "874",
          "875",
          "876",
          "877",
          "878",
          "879",
          "880",
          "881",
          "882",
          "883",
          "884",
          "885",
          "886",
          "887",
          "888",
          "889",
          "890",
          "891",
          "892",
          "893",
          "894",
          "895",
          "896",
          "897",
          "898",
          "899",
          "900",
          "901",
          "902",
          "903",
          "904",
          "905",
          "906",
          "907",
          "908",
          "909",
          "910",
          "911",
          "912",
          "913",
          "914",
          "915",
          "916",
          "917",
          "918",
          "919",
          "920",
          "921",
          "922",
          "923",
          "924",
          "925",
          "926",
          "927",
          "928",
          "929",
          "930",
          "931",
          "932",
          "933",
          "934",
          "935",
          "936",
          "937",
          "938",
          "939",
          "940",
          "941",
          "942",
          "943",
          "944",
          "945",
          "946",
          "947",
          "948",
          "949",
          "950",
          "951",
          "952",
          "953",
          "954",
          "955",
          "956",
          "957",
          "958",
          "959",
          "960",
          "961",
          "962",
          "963",
          "964",
          "965",
          "966",
          "967",
          "968",
          "969",
          "970",
          "971",
          "972",
          "973",
          "974",
          "975",
          "976",
          "977",
          "978",
          "979",
          "980",
          "981",
          "982",
          "983",
          "984",
          "985",
          "986",
          "987",
          "988",
          "989",
          "990",
          "991",
          "992",
          "993",
          "994",
          "995",
          "996",
          "997",
          "998",
          "999",
          "1000"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "xaxis": "x2",
         "y": [
          2.3976614475250244,
          1.8733036518096924,
          1.7380521297454834,
          1.574101448059082,
          1.532613754272461,
          1.5371837615966797,
          1.5309953689575195,
          1.4796836376190186,
          1.472392201423645,
          1.388698935508728,
          1.4268320798873901,
          1.4351285696029663,
          1.439465880393982,
          1.467207670211792,
          1.469916820526123,
          1.418340802192688,
          1.3959360122680664,
          1.3338114023208618,
          1.3765228986740112,
          1.356245517730713,
          1.4334628582000732,
          1.421950340270996,
          1.3611390590667725,
          1.380205512046814,
          1.4256231784820557,
          1.3792400360107422,
          1.3734781742095947,
          1.3697608709335327,
          1.3489267826080322,
          1.364051103591919,
          1.3470085859298706,
          1.3242990970611572,
          1.3139634132385254,
          1.352676510810852,
          1.3256781101226807,
          1.3163905143737793,
          1.3109586238861084,
          1.2644498348236084,
          1.2974512577056885,
          1.2669312953948975,
          1.2842974662780762,
          1.2757476568222046,
          1.242868185043335,
          1.2710057497024536,
          1.2610129117965698,
          1.2858082056045532,
          1.2564092874526978,
          1.1730577945709229,
          1.2906087636947632,
          1.2099725008010864,
          1.2012269496917725,
          1.212558627128601,
          1.2312973737716675,
          1.2145460844039917,
          1.2464218139648438,
          1.220622181892395,
          1.2553024291992188,
          1.212443470954895,
          1.177351474761963,
          1.1997714042663574,
          1.2807459831237793,
          1.2218661308288574,
          1.2308207750320435,
          1.2223899364471436,
          1.18351149559021,
          1.228057622909546,
          1.1885766983032227,
          1.1999657154083252,
          1.1751949787139893,
          1.1809178590774536,
          1.1969678401947021,
          1.1569926738739014,
          1.1265119314193726,
          1.1632888317108154,
          1.162956953048706,
          1.1279798746109009,
          1.1834787130355835,
          1.180091142654419,
          1.1784473657608032,
          1.1798944473266602,
          1.1282848119735718,
          1.1434143781661987,
          1.1052078008651733,
          1.1475515365600586,
          1.1653432846069336,
          1.1542479991912842,
          1.1238600015640259,
          1.1059151887893677,
          1.1906434297561646,
          1.1416410207748413,
          1.1286810636520386,
          1.1230615377426147,
          1.1049362421035767,
          1.1307499408721924,
          1.1116807460784912,
          1.110259771347046,
          1.076442837715149,
          1.1014894247055054,
          1.0600916147232056,
          1.0945696830749512,
          1.0904829502105713,
          1.0729962587356567,
          1.0945404767990112,
          1.0679478645324707,
          1.1141669750213623,
          1.0909929275512695,
          1.145726203918457,
          1.1048710346221924,
          1.1144689321517944,
          1.094584584236145,
          1.0605648756027222,
          1.0854921340942383,
          1.088788628578186,
          1.0332913398742676,
          1.0961289405822754,
          1.0550827980041504,
          1.0590437650680542,
          1.0558353662490845,
          1.0682766437530518,
          1.06087064743042,
          1.0147391557693481,
          1.0493086576461792,
          1.0531588792800903,
          1.0254125595092773,
          1.0425606966018677,
          1.038246750831604,
          1.0429364442825317,
          1.05257248878479,
          1.0065386295318604,
          1.0097265243530273,
          1.0331727266311646,
          1.0175390243530273,
          1.0119789838790894,
          1.0110442638397217,
          1.0127416849136353,
          1.0068049430847168,
          1.0712283849716187,
          1.0077084302902222,
          0.9802001118659973,
          0.9862845540046692,
          0.9898602962493896,
          1.022798776626587,
          0.9948185086250305,
          0.980507493019104,
          1.0069501399993896,
          0.9572702646255493,
          0.9997649192810059,
          0.9963254332542419,
          0.9737738370895386,
          0.9556495547294617,
          0.9768375158309937,
          0.9650142192840576,
          0.980827271938324,
          0.9724737405776978,
          0.9482898116111755,
          0.9405496120452881,
          0.9447922706604004,
          0.955247700214386,
          0.9123664498329163,
          0.978165864944458,
          0.9193708300590515,
          0.920744001865387,
          0.9442139863967896,
          0.8949581384658813,
          0.9511404037475586,
          0.9566304683685303,
          0.9725301861763,
          0.9600804448127747,
          0.9097293019294739,
          0.8933643698692322,
          0.944267213344574,
          0.9239487648010254,
          0.9433295130729675,
          0.9297455549240112,
          0.9631271958351135,
          0.920142412185669,
          0.9260665774345398,
          0.9610062837600708,
          0.9189009666442871,
          0.9164495468139648,
          0.957183837890625,
          0.9233056902885437,
          0.9154678583145142,
          0.9092355966567993,
          0.8890905380249023,
          0.9027217626571655,
          0.9116321206092834,
          0.9198158979415894,
          0.8996062874794006,
          0.9345126152038574,
          0.8946967720985413,
          0.8749393224716187,
          0.8824978470802307,
          0.9114303588867188,
          0.8652516007423401,
          0.9233577847480774,
          0.8696722388267517,
          0.903497040271759,
          0.8969079256057739,
          0.9208060503005981,
          0.8593698143959045,
          0.8994342088699341,
          0.8381572961807251,
          0.859211266040802,
          0.874313235282898,
          0.892573893070221,
          0.8778074979782104,
          0.8702149391174316,
          0.8670956492424011,
          0.8942078351974487,
          0.8502492904663086,
          0.8512420654296875,
          0.8740363121032715,
          0.8333505392074585,
          0.8631013631820679,
          0.8496907949447632,
          0.8560832738876343,
          0.8570543527603149,
          0.8168851733207703,
          0.8024600148200989,
          0.8353455662727356,
          0.8428356051445007,
          0.8896892666816711,
          0.8377287983894348,
          0.8180849552154541,
          0.804263710975647,
          0.8733537793159485,
          0.82579505443573,
          0.8058222532272339,
          0.813352644443512,
          0.8477291464805603,
          0.8302767276763916,
          0.840739905834198,
          0.8098026514053345,
          0.816300094127655,
          0.8112040758132935,
          0.8262375593185425,
          0.7877016663551331,
          0.8219794631004333,
          0.8006348013877869,
          0.8228541016578674,
          0.8091890811920166,
          0.8222246170043945,
          0.8159430027008057,
          0.8450657725334167,
          0.8186219334602356,
          0.7913210988044739,
          0.8424800634384155,
          0.845294177532196,
          0.8096701502799988,
          0.8037348389625549,
          0.7897883057594299,
          0.8133462071418762,
          0.7514262795448303,
          0.7958292961120605,
          0.7861688137054443,
          0.8277554512023926,
          0.8361655473709106,
          0.7927451133728027,
          0.8004733324050903,
          0.7599851489067078,
          0.7741949558258057,
          0.7718321681022644,
          0.7858726978302002,
          0.7774154543876648,
          0.7809112071990967,
          0.7977865934371948,
          0.8110279440879822,
          0.791741669178009,
          0.8146525621414185,
          0.7672752737998962,
          0.7638923525810242,
          0.7702167630195618,
          0.7480590343475342,
          0.7609135508537292,
          0.8004847764968872,
          0.7579622864723206,
          0.7785922288894653,
          0.7579057812690735,
          0.7647749185562134,
          0.7238940000534058,
          0.7762652635574341,
          0.7917525768280029,
          0.7618864178657532,
          0.7561593651771545,
          0.7469440698623657,
          0.7273272275924683,
          0.7528670430183411,
          0.7645765542984009,
          0.753930926322937,
          0.7683335542678833,
          0.7522215843200684,
          0.7527021765708923,
          0.7728695869445801,
          0.7719060778617859,
          0.7242327928543091,
          0.7836439609527588,
          0.7252218723297119,
          0.7399652004241943,
          0.7512609362602234,
          0.7487928867340088,
          0.7559428811073303,
          0.741336464881897,
          0.7082033157348633,
          0.7396377921104431,
          0.7615165114402771,
          0.749828040599823,
          0.7491456866264343,
          0.7443999648094177,
          0.7555419206619263,
          0.7226133346557617,
          0.7138664126396179,
          0.7279320359230042,
          0.7272464036941528,
          0.7322350740432739,
          0.6980394124984741,
          0.7194585800170898,
          0.7048991918563843,
          0.7504280805587769,
          0.7353602647781372,
          0.7385978698730469,
          0.7031658887863159,
          0.7071167826652527,
          0.7214324474334717,
          0.7293515205383301,
          0.7002018094062805,
          0.7014032006263733,
          0.7288252115249634,
          0.7072688341140747,
          0.6828817129135132,
          0.7135133743286133,
          0.7112051248550415,
          0.7105764746665955,
          0.7146537899971008,
          0.7087644338607788,
          0.7191380858421326,
          0.7146804332733154,
          0.7118600606918335,
          0.686565101146698,
          0.7031968832015991,
          0.7174662947654724,
          0.670171320438385,
          0.7043777108192444,
          0.7051284313201904,
          0.7071340680122375,
          0.6866580247879028,
          0.7584471702575684,
          0.7109342813491821,
          0.6625863909721375,
          0.702601969242096,
          0.676950991153717,
          0.7010570168495178,
          0.6693354845046997,
          0.6860459446907043,
          0.6868443489074707,
          0.6878085732460022,
          0.7256795167922974,
          0.7183488607406616,
          0.7355179786682129,
          0.6715752482414246,
          0.6778351664543152,
          0.6781659126281738,
          0.6874532699584961,
          0.6901317238807678,
          0.6553753018379211,
          0.6910820603370667,
          0.6726508736610413,
          0.6593422293663025,
          0.7343053221702576,
          0.7078967094421387,
          0.6857571601867676,
          0.7022135257720947,
          0.6795930862426758,
          0.6599234342575073,
          0.6744793057441711,
          0.689950168132782,
          0.6537100076675415,
          0.6360414624214172,
          0.6962200403213501,
          0.6689127087593079,
          0.689697265625,
          0.6683470606803894,
          0.649232804775238,
          0.6551984548568726,
          0.6503576040267944,
          0.64711993932724,
          0.6665863990783691,
          0.6328257918357849,
          0.644135594367981,
          0.7083263993263245,
          0.6821938753128052,
          0.6930625438690186,
          0.6409026980400085,
          0.6424242258071899,
          0.6973744630813599,
          0.6622058749198914,
          0.668641209602356,
          0.6525481343269348,
          0.6353815793991089,
          0.6787890195846558,
          0.6602965593338013,
          0.6256349682807922,
          0.6574510931968689,
          0.6270108819007874,
          0.660453200340271,
          0.6297639012336731,
          0.6868899464607239,
          0.6477470397949219,
          0.6475726962089539,
          0.6461381912231445,
          0.664817750453949,
          0.6402504444122314,
          0.6395424604415894,
          0.6582030057907104,
          0.6206365823745728,
          0.6270010471343994,
          0.6210098266601562,
          0.6540088057518005,
          0.6293755173683167,
          0.6767897605895996,
          0.635560929775238,
          0.6309800148010254,
          0.6017441153526306,
          0.6305772066116333,
          0.6414337158203125,
          0.6337717771530151,
          0.6425167918205261,
          0.6461796164512634,
          0.6515393257141113,
          0.6090964078903198,
          0.6129321455955505,
          0.6600936651229858,
          0.6437218189239502,
          0.6353766322135925,
          0.6047779321670532,
          0.6476927995681763,
          0.6146425008773804,
          0.6080557703971863,
          0.5977875590324402,
          0.6354488134384155,
          0.6038187742233276,
          0.616020917892456,
          0.6117866635322571,
          0.614138126373291,
          0.6052144765853882,
          0.6219687461853027,
          0.6285316944122314,
          0.648402750492096,
          0.6346033811569214,
          0.5942863821983337,
          0.613795280456543,
          0.610219419002533,
          0.5838795304298401,
          0.626566469669342,
          0.6051309108734131,
          0.6028752326965332,
          0.6487084627151489,
          0.5931726694107056,
          0.6224058866500854,
          0.6174505949020386,
          0.5712926387786865,
          0.6097266674041748,
          0.6400426626205444,
          0.5739460587501526,
          0.6003127098083496,
          0.6198520064353943,
          0.6548404097557068,
          0.6171540021896362,
          0.5748752951622009,
          0.5953313708305359,
          0.5986269116401672,
          0.590341329574585,
          0.5991831421852112,
          0.5968930721282959,
          0.6088403463363647,
          0.6251304745674133,
          0.5918910503387451,
          0.6174895763397217,
          0.5819558501243591,
          0.5924389362335205,
          0.585643470287323,
          0.5807150602340698,
          0.5852124094963074,
          0.6125430464744568,
          0.6434195041656494,
          0.5638054609298706,
          0.5831055641174316,
          0.6049399375915527,
          0.5690984129905701,
          0.601447582244873,
          0.5893664360046387,
          0.574918270111084,
          0.5732508301734924,
          0.6208950877189636,
          0.5863375663757324,
          0.5959200859069824,
          0.5535058379173279,
          0.558700442314148,
          0.624910295009613,
          0.5609288215637207,
          0.5823180675506592,
          0.5528111457824707,
          0.584471583366394,
          0.5952696204185486,
          0.59200519323349,
          0.5779651403427124,
          0.6018367409706116,
          0.5912057757377625,
          0.6058447360992432,
          0.6009318232536316,
          0.5971583724021912,
          0.584997832775116,
          0.5660988688468933,
          0.593104362487793,
          0.578740656375885,
          0.5652838945388794,
          0.5590602159500122,
          0.5428410172462463,
          0.540306806564331,
          0.5746195316314697,
          0.5754538178443909,
          0.5712249875068665,
          0.5813648104667664,
          0.5769698619842529,
          0.5682691335678101,
          0.5813857913017273,
          0.5721311569213867,
          0.5819184184074402,
          0.5443434119224548,
          0.5547500252723694,
          0.5910404324531555,
          0.6097114086151123,
          0.5775365233421326,
          0.5345576405525208,
          0.5756000280380249,
          0.5536729097366333,
          0.5743290185928345,
          0.5947691202163696,
          0.559898853302002,
          0.5569040179252625,
          0.5491481423377991,
          0.554858922958374,
          0.557199239730835,
          0.5279008150100708,
          0.5597059726715088,
          0.5427473783493042,
          0.5772126317024231,
          0.5625837445259094,
          0.5134879946708679,
          0.5450757145881653,
          0.5718837976455688,
          0.5384857058525085,
          0.5182520747184753,
          0.5513491630554199,
          0.5861033201217651,
          0.5455058813095093,
          0.534839928150177,
          0.544108510017395,
          0.5302754640579224,
          0.5713833570480347,
          0.5605802536010742,
          0.5300003886222839,
          0.5413516759872437,
          0.5469542145729065,
          0.5473014116287231,
          0.5414129495620728,
          0.5219715237617493,
          0.551805317401886,
          0.5583926439285278,
          0.535923957824707,
          0.5581908226013184,
          0.560005247592926,
          0.5002942085266113,
          0.5533145070075989,
          0.5447289943695068,
          0.5338903665542603,
          0.5312693119049072,
          0.5512157082557678,
          0.5448575615882874,
          0.5486726760864258,
          0.5142303109169006,
          0.5506609678268433,
          0.5389014482498169,
          0.5699321627616882,
          0.5427259206771851,
          0.532966136932373,
          0.5698330402374268,
          0.5269721150398254,
          0.5511816143989563,
          0.5354838371276855,
          0.5115543007850647,
          0.5358103513717651,
          0.5358277559280396,
          0.5426607728004456,
          0.553064227104187,
          0.5147417187690735,
          0.502312183380127,
          0.5294268131256104,
          0.5359282493591309,
          0.5173918008804321,
          0.5629950761795044,
          0.5332897901535034,
          0.5383851528167725,
          0.5812802314758301,
          0.5552821755409241,
          0.4847179651260376,
          0.5145502090454102,
          0.5213701725006104,
          0.5272661447525024,
          0.5946012735366821,
          0.5130698084831238,
          0.5417580604553223,
          0.49025216698646545,
          0.5370973348617554,
          0.5228922367095947,
          0.5198063850402832,
          0.5065029263496399,
          0.5093651413917542,
          0.5201184153556824,
          0.49780434370040894,
          0.50618577003479,
          0.505407452583313,
          0.5266983509063721,
          0.538202166557312,
          0.49175015091896057,
          0.5343325734138489,
          0.5075132846832275,
          0.5123357176780701,
          0.5253554582595825,
          0.5446563959121704,
          0.519283652305603,
          0.5145172476768494,
          0.4958944022655487,
          0.5170403122901917,
          0.5053524374961853,
          0.5082545280456543,
          0.5097463130950928,
          0.4967702329158783,
          0.5171900987625122,
          0.5248647928237915,
          0.5090223550796509,
          0.5124955177307129,
          0.49131327867507935,
          0.509824812412262,
          0.5303217768669128,
          0.531787097454071,
          0.5027742385864258,
          0.5026081800460815,
          0.4735633134841919,
          0.5044196248054504,
          0.4877983629703522,
          0.5270358324050903,
          0.5124403834342957,
          0.49594059586524963,
          0.5282628536224365,
          0.4641307294368744,
          0.4830292761325836,
          0.48313939571380615,
          0.5375601053237915,
          0.5033523440361023,
          0.48309850692749023,
          0.47487348318099976,
          0.5261553525924683,
          0.5011643171310425,
          0.486228883266449,
          0.4824272096157074,
          0.4564794600009918,
          0.5007237195968628,
          0.5252337455749512,
          0.4986029267311096,
          0.5005450248718262,
          0.4631599187850952,
          0.49053680896759033,
          0.5116792917251587,
          0.5301508903503418,
          0.48859649896621704,
          0.4790547788143158,
          0.5216191411018372,
          0.5217989087104797,
          0.4742523431777954,
          0.48120588064193726,
          0.48653078079223633,
          0.4873911440372467,
          0.4490894079208374,
          0.516932487487793,
          0.4890022277832031,
          0.4752887785434723,
          0.45423832535743713,
          0.4463530480861664,
          0.4818451404571533,
          0.48017096519470215,
          0.44603869318962097,
          0.4708655774593353,
          0.4711061120033264,
          0.4669780433177948,
          0.4940187633037567,
          0.4821503758430481,
          0.4876524806022644,
          0.49828141927719116,
          0.5012555122375488,
          0.46802595257759094,
          0.49029362201690674,
          0.4668377637863159,
          0.4843396842479706,
          0.4673132598400116,
          0.5196945667266846,
          0.4533606469631195,
          0.48848599195480347,
          0.44774118065834045,
          0.44587111473083496,
          0.4707886576652527,
          0.49578210711479187,
          0.47867682576179504,
          0.47607409954071045,
          0.4586292505264282,
          0.4648163914680481,
          0.44992518424987793,
          0.4889506995677948,
          0.47954416275024414,
          0.49115800857543945,
          0.4712611436843872,
          0.46328026056289673,
          0.44665834307670593,
          0.504881739616394,
          0.483050674200058,
          0.4777359962463379,
          0.4886362552642822,
          0.4756016135215759,
          0.47606420516967773,
          0.4821324646472931,
          0.47741615772247314,
          0.5043511390686035,
          0.4540121257305145,
          0.501517653465271,
          0.46135076880455017,
          0.4590546190738678,
          0.4591792821884155,
          0.4734041392803192,
          0.47988253831863403,
          0.47951817512512207,
          0.4688724875450134,
          0.48043984174728394,
          0.47779780626296997,
          0.4424630403518677,
          0.4904293417930603,
          0.4719737470149994,
          0.4409703016281128,
          0.4550522267818451,
          0.4599163234233856,
          0.4746879041194916,
          0.4852612316608429,
          0.4542384743690491,
          0.4619266092777252,
          0.4743254780769348,
          0.4719575047492981,
          0.4731057584285736,
          0.48403987288475037,
          0.43060341477394104,
          0.4526832699775696,
          0.4378316402435303,
          0.47642338275909424,
          0.4541594684123993,
          0.49110645055770874,
          0.44447392225265503,
          0.48120251297950745,
          0.44348567724227905,
          0.4384475648403168,
          0.46429821848869324,
          0.48028743267059326,
          0.46700412034988403,
          0.457383394241333,
          0.44325584173202515,
          0.4425663948059082,
          0.44974061846733093,
          0.44039565324783325,
          0.46636566519737244,
          0.4498586356639862,
          0.449235200881958,
          0.4552272856235504,
          0.4106384813785553,
          0.4593987762928009,
          0.44518789649009705,
          0.4330368638038635,
          0.43012648820877075,
          0.4418835937976837,
          0.4543873071670532,
          0.41945546865463257,
          0.4004053771495819,
          0.45112180709838867,
          0.41924360394477844,
          0.42863667011260986,
          0.463032603263855,
          0.41756460070610046,
          0.44671928882598877,
          0.4268985092639923,
          0.43913304805755615,
          0.45130881667137146,
          0.4339587092399597,
          0.4496593773365021,
          0.4289608597755432,
          0.4234292805194855,
          0.45232924818992615,
          0.4266025722026825,
          0.4326445460319519,
          0.4296189546585083,
          0.44041967391967773,
          0.4542222321033478,
          0.43182435631752014,
          0.4390217065811157,
          0.4436480700969696,
          0.43251585960388184,
          0.4251619279384613,
          0.4176366329193115,
          0.4098913073539734,
          0.44057145714759827,
          0.43591582775115967,
          0.45361170172691345,
          0.44174423813819885,
          0.4381522536277771,
          0.45512014627456665,
          0.44483286142349243,
          0.4334433078765869,
          0.41981613636016846,
          0.4063642919063568,
          0.43543609976768494,
          0.41092774271965027,
          0.4361237585544586,
          0.4470289945602417,
          0.4323456585407257,
          0.45261937379837036,
          0.44628822803497314,
          0.4085931181907654,
          0.41796648502349854,
          0.4500347077846527,
          0.41361552476882935,
          0.4049789607524872,
          0.4223441779613495,
          0.4170350134372711,
          0.4518459737300873,
          0.4347277283668518,
          0.42634254693984985,
          0.42631715536117554,
          0.4160129725933075,
          0.4054419994354248,
          0.4263443350791931,
          0.39948639273643494,
          0.3958846628665924,
          0.42646324634552,
          0.4095238447189331,
          0.38036105036735535,
          0.40941810607910156,
          0.4012121558189392,
          0.4484720826148987,
          0.42355236411094666,
          0.4412711262702942,
          0.4219648540019989,
          0.39813724160194397,
          0.4146082103252411,
          0.3899020850658417,
          0.4604603052139282,
          0.4160766005516052,
          0.4198877513408661,
          0.43105316162109375,
          0.39795875549316406,
          0.4157126545906067,
          0.41182634234428406,
          0.4106481969356537,
          0.39168214797973633,
          0.415235310792923,
          0.42348378896713257,
          0.3977775275707245,
          0.38183867931365967,
          0.393842875957489,
          0.4026409089565277,
          0.4001357853412628,
          0.39441901445388794,
          0.390026330947876,
          0.4334867596626282,
          0.44529372453689575,
          0.40682968497276306,
          0.4059332609176636,
          0.4184156358242035,
          0.40484440326690674,
          0.4403952956199646,
          0.3991023302078247,
          0.41946902871131897,
          0.40985026955604553,
          0.4134305417537689,
          0.4040840268135071,
          0.40289008617401123,
          0.39069101214408875,
          0.39052388072013855,
          0.4157298803329468,
          0.4310229420661926,
          0.394694447517395,
          0.37749233841896057,
          0.40516361594200134,
          0.39269718527793884,
          0.39138221740722656,
          0.3952175974845886,
          0.39212682843208313,
          0.39780303835868835,
          0.3904508948326111,
          0.401482492685318,
          0.39098015427589417,
          0.38785141706466675,
          0.4021011292934418,
          0.3923705220222473,
          0.419857382774353,
          0.39738303422927856,
          0.3902572691440582,
          0.40077632665634155,
          0.37764304876327515,
          0.3956647217273712,
          0.40517547726631165,
          0.3942005932331085,
          0.3826959729194641,
          0.3819434940814972,
          0.41164708137512207,
          0.3739243149757385,
          0.40209218859672546,
          0.36894017457962036,
          0.41317218542099,
          0.39318498969078064,
          0.3868061304092407,
          0.3719642162322998,
          0.3763482868671417,
          0.4236758351325989,
          0.38083213567733765,
          0.3927634358406067,
          0.36719265580177307,
          0.38507014513015747,
          0.39240121841430664,
          0.40596315264701843,
          0.37512335181236267,
          0.42843085527420044,
          0.39574551582336426,
          0.4164532721042633,
          0.3969394862651825,
          0.4032319188117981,
          0.3990163505077362,
          0.38250070810317993,
          0.3844256103038788,
          0.39515551924705505,
          0.3979894518852234,
          0.38669735193252563,
          0.3966198265552521,
          0.3691357374191284,
          0.3786173462867737,
          0.39850229024887085,
          0.40669500827789307,
          0.39240097999572754,
          0.3806246519088745,
          0.41435351967811584,
          0.3458694815635681,
          0.40370941162109375,
          0.36136943101882935,
          0.34443721175193787,
          0.36685246229171753,
          0.41085851192474365,
          0.3658965826034546,
          0.35367515683174133,
          0.3516800105571747,
          0.3729952573776245,
          0.3579440712928772,
          0.3527440130710602,
          0.36258411407470703,
          0.3776606023311615,
          0.3763042688369751,
          0.36912018060684204,
          0.39088332653045654,
          0.3762025535106659,
          0.3612808883190155,
          0.3830505907535553,
          0.4212718605995178,
          0.384788453578949,
          0.36782756447792053,
          0.35759061574935913,
          0.3637777268886566,
          0.36686158180236816,
          0.3671249747276306,
          0.40284693241119385,
          0.3752216696739197,
          0.3595210015773773,
          0.3701379597187042,
          0.3655560314655304,
          0.40226706862449646,
          0.3662002980709076,
          0.37820351123809814,
          0.36261287331581116,
          0.3599274754524231,
          0.33818575739860535,
          0.3787229657173157,
          0.3721908926963806,
          0.37032532691955566,
          0.36663001775741577,
          0.36304453015327454,
          0.3849655091762543,
          0.3433159291744232,
          0.38723522424697876
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "Magenta"
         },
         "mode": "markers+lines",
         "name": "Validation loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200",
          "201",
          "202",
          "203",
          "204",
          "205",
          "206",
          "207",
          "208",
          "209",
          "210",
          "211",
          "212",
          "213",
          "214",
          "215",
          "216",
          "217",
          "218",
          "219",
          "220",
          "221",
          "222",
          "223",
          "224",
          "225",
          "226",
          "227",
          "228",
          "229",
          "230",
          "231",
          "232",
          "233",
          "234",
          "235",
          "236",
          "237",
          "238",
          "239",
          "240",
          "241",
          "242",
          "243",
          "244",
          "245",
          "246",
          "247",
          "248",
          "249",
          "250",
          "251",
          "252",
          "253",
          "254",
          "255",
          "256",
          "257",
          "258",
          "259",
          "260",
          "261",
          "262",
          "263",
          "264",
          "265",
          "266",
          "267",
          "268",
          "269",
          "270",
          "271",
          "272",
          "273",
          "274",
          "275",
          "276",
          "277",
          "278",
          "279",
          "280",
          "281",
          "282",
          "283",
          "284",
          "285",
          "286",
          "287",
          "288",
          "289",
          "290",
          "291",
          "292",
          "293",
          "294",
          "295",
          "296",
          "297",
          "298",
          "299",
          "300",
          "301",
          "302",
          "303",
          "304",
          "305",
          "306",
          "307",
          "308",
          "309",
          "310",
          "311",
          "312",
          "313",
          "314",
          "315",
          "316",
          "317",
          "318",
          "319",
          "320",
          "321",
          "322",
          "323",
          "324",
          "325",
          "326",
          "327",
          "328",
          "329",
          "330",
          "331",
          "332",
          "333",
          "334",
          "335",
          "336",
          "337",
          "338",
          "339",
          "340",
          "341",
          "342",
          "343",
          "344",
          "345",
          "346",
          "347",
          "348",
          "349",
          "350",
          "351",
          "352",
          "353",
          "354",
          "355",
          "356",
          "357",
          "358",
          "359",
          "360",
          "361",
          "362",
          "363",
          "364",
          "365",
          "366",
          "367",
          "368",
          "369",
          "370",
          "371",
          "372",
          "373",
          "374",
          "375",
          "376",
          "377",
          "378",
          "379",
          "380",
          "381",
          "382",
          "383",
          "384",
          "385",
          "386",
          "387",
          "388",
          "389",
          "390",
          "391",
          "392",
          "393",
          "394",
          "395",
          "396",
          "397",
          "398",
          "399",
          "400",
          "401",
          "402",
          "403",
          "404",
          "405",
          "406",
          "407",
          "408",
          "409",
          "410",
          "411",
          "412",
          "413",
          "414",
          "415",
          "416",
          "417",
          "418",
          "419",
          "420",
          "421",
          "422",
          "423",
          "424",
          "425",
          "426",
          "427",
          "428",
          "429",
          "430",
          "431",
          "432",
          "433",
          "434",
          "435",
          "436",
          "437",
          "438",
          "439",
          "440",
          "441",
          "442",
          "443",
          "444",
          "445",
          "446",
          "447",
          "448",
          "449",
          "450",
          "451",
          "452",
          "453",
          "454",
          "455",
          "456",
          "457",
          "458",
          "459",
          "460",
          "461",
          "462",
          "463",
          "464",
          "465",
          "466",
          "467",
          "468",
          "469",
          "470",
          "471",
          "472",
          "473",
          "474",
          "475",
          "476",
          "477",
          "478",
          "479",
          "480",
          "481",
          "482",
          "483",
          "484",
          "485",
          "486",
          "487",
          "488",
          "489",
          "490",
          "491",
          "492",
          "493",
          "494",
          "495",
          "496",
          "497",
          "498",
          "499",
          "500",
          "501",
          "502",
          "503",
          "504",
          "505",
          "506",
          "507",
          "508",
          "509",
          "510",
          "511",
          "512",
          "513",
          "514",
          "515",
          "516",
          "517",
          "518",
          "519",
          "520",
          "521",
          "522",
          "523",
          "524",
          "525",
          "526",
          "527",
          "528",
          "529",
          "530",
          "531",
          "532",
          "533",
          "534",
          "535",
          "536",
          "537",
          "538",
          "539",
          "540",
          "541",
          "542",
          "543",
          "544",
          "545",
          "546",
          "547",
          "548",
          "549",
          "550",
          "551",
          "552",
          "553",
          "554",
          "555",
          "556",
          "557",
          "558",
          "559",
          "560",
          "561",
          "562",
          "563",
          "564",
          "565",
          "566",
          "567",
          "568",
          "569",
          "570",
          "571",
          "572",
          "573",
          "574",
          "575",
          "576",
          "577",
          "578",
          "579",
          "580",
          "581",
          "582",
          "583",
          "584",
          "585",
          "586",
          "587",
          "588",
          "589",
          "590",
          "591",
          "592",
          "593",
          "594",
          "595",
          "596",
          "597",
          "598",
          "599",
          "600",
          "601",
          "602",
          "603",
          "604",
          "605",
          "606",
          "607",
          "608",
          "609",
          "610",
          "611",
          "612",
          "613",
          "614",
          "615",
          "616",
          "617",
          "618",
          "619",
          "620",
          "621",
          "622",
          "623",
          "624",
          "625",
          "626",
          "627",
          "628",
          "629",
          "630",
          "631",
          "632",
          "633",
          "634",
          "635",
          "636",
          "637",
          "638",
          "639",
          "640",
          "641",
          "642",
          "643",
          "644",
          "645",
          "646",
          "647",
          "648",
          "649",
          "650",
          "651",
          "652",
          "653",
          "654",
          "655",
          "656",
          "657",
          "658",
          "659",
          "660",
          "661",
          "662",
          "663",
          "664",
          "665",
          "666",
          "667",
          "668",
          "669",
          "670",
          "671",
          "672",
          "673",
          "674",
          "675",
          "676",
          "677",
          "678",
          "679",
          "680",
          "681",
          "682",
          "683",
          "684",
          "685",
          "686",
          "687",
          "688",
          "689",
          "690",
          "691",
          "692",
          "693",
          "694",
          "695",
          "696",
          "697",
          "698",
          "699",
          "700",
          "701",
          "702",
          "703",
          "704",
          "705",
          "706",
          "707",
          "708",
          "709",
          "710",
          "711",
          "712",
          "713",
          "714",
          "715",
          "716",
          "717",
          "718",
          "719",
          "720",
          "721",
          "722",
          "723",
          "724",
          "725",
          "726",
          "727",
          "728",
          "729",
          "730",
          "731",
          "732",
          "733",
          "734",
          "735",
          "736",
          "737",
          "738",
          "739",
          "740",
          "741",
          "742",
          "743",
          "744",
          "745",
          "746",
          "747",
          "748",
          "749",
          "750",
          "751",
          "752",
          "753",
          "754",
          "755",
          "756",
          "757",
          "758",
          "759",
          "760",
          "761",
          "762",
          "763",
          "764",
          "765",
          "766",
          "767",
          "768",
          "769",
          "770",
          "771",
          "772",
          "773",
          "774",
          "775",
          "776",
          "777",
          "778",
          "779",
          "780",
          "781",
          "782",
          "783",
          "784",
          "785",
          "786",
          "787",
          "788",
          "789",
          "790",
          "791",
          "792",
          "793",
          "794",
          "795",
          "796",
          "797",
          "798",
          "799",
          "800",
          "801",
          "802",
          "803",
          "804",
          "805",
          "806",
          "807",
          "808",
          "809",
          "810",
          "811",
          "812",
          "813",
          "814",
          "815",
          "816",
          "817",
          "818",
          "819",
          "820",
          "821",
          "822",
          "823",
          "824",
          "825",
          "826",
          "827",
          "828",
          "829",
          "830",
          "831",
          "832",
          "833",
          "834",
          "835",
          "836",
          "837",
          "838",
          "839",
          "840",
          "841",
          "842",
          "843",
          "844",
          "845",
          "846",
          "847",
          "848",
          "849",
          "850",
          "851",
          "852",
          "853",
          "854",
          "855",
          "856",
          "857",
          "858",
          "859",
          "860",
          "861",
          "862",
          "863",
          "864",
          "865",
          "866",
          "867",
          "868",
          "869",
          "870",
          "871",
          "872",
          "873",
          "874",
          "875",
          "876",
          "877",
          "878",
          "879",
          "880",
          "881",
          "882",
          "883",
          "884",
          "885",
          "886",
          "887",
          "888",
          "889",
          "890",
          "891",
          "892",
          "893",
          "894",
          "895",
          "896",
          "897",
          "898",
          "899",
          "900",
          "901",
          "902",
          "903",
          "904",
          "905",
          "906",
          "907",
          "908",
          "909",
          "910",
          "911",
          "912",
          "913",
          "914",
          "915",
          "916",
          "917",
          "918",
          "919",
          "920",
          "921",
          "922",
          "923",
          "924",
          "925",
          "926",
          "927",
          "928",
          "929",
          "930",
          "931",
          "932",
          "933",
          "934",
          "935",
          "936",
          "937",
          "938",
          "939",
          "940",
          "941",
          "942",
          "943",
          "944",
          "945",
          "946",
          "947",
          "948",
          "949",
          "950",
          "951",
          "952",
          "953",
          "954",
          "955",
          "956",
          "957",
          "958",
          "959",
          "960",
          "961",
          "962",
          "963",
          "964",
          "965",
          "966",
          "967",
          "968",
          "969",
          "970",
          "971",
          "972",
          "973",
          "974",
          "975",
          "976",
          "977",
          "978",
          "979",
          "980",
          "981",
          "982",
          "983",
          "984",
          "985",
          "986",
          "987",
          "988",
          "989",
          "990",
          "991",
          "992",
          "993",
          "994",
          "995",
          "996",
          "997",
          "998",
          "999",
          "1000"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "xaxis": "x2",
         "y": [
          2.0909876823425293,
          1.9868621826171875,
          1.8735263347625732,
          1.9639339447021484,
          2.3641538619995117,
          2.9018819332122803,
          3.2878496646881104,
          3.6313982009887695,
          3.95869517326355,
          4.236389636993408,
          4.482275009155273,
          4.737209320068359,
          4.970511436462402,
          5.178940773010254,
          5.377942085266113,
          5.5637383460998535,
          5.75303840637207,
          5.94485330581665,
          6.124678134918213,
          6.29374885559082,
          6.445132255554199,
          6.576912879943848,
          6.691708087921143,
          6.815639495849609,
          6.939561367034912,
          7.055246353149414,
          7.158263206481934,
          7.229493618011475,
          7.304708003997803,
          7.379887580871582,
          7.459587097167969,
          7.5694355964660645,
          7.652073860168457,
          7.732916355133057,
          7.806596755981445,
          7.887373447418213,
          7.949302673339844,
          8.011911392211914,
          8.070266723632812,
          8.124813079833984,
          8.169074058532715,
          8.230817794799805,
          8.266596794128418,
          8.279428482055664,
          8.286055564880371,
          8.30152416229248,
          8.324185371398926,
          8.34112548828125,
          8.375116348266602,
          8.388043403625488,
          8.3992919921875,
          8.380419731140137,
          8.350172996520996,
          8.308269500732422,
          8.26058292388916,
          8.201509475708008,
          8.150672912597656,
          8.09650993347168,
          8.05904483795166,
          8.023581504821777,
          7.987608909606934,
          7.951848030090332,
          7.908378601074219,
          7.857544422149658,
          7.822685241699219,
          7.797982215881348,
          7.751028537750244,
          7.724579334259033,
          7.687167644500732,
          7.665714263916016,
          7.620138168334961,
          7.576151371002197,
          7.5264763832092285,
          7.486211776733398,
          7.440010070800781,
          7.4178242683410645,
          7.36527156829834,
          7.319587707519531,
          7.269487380981445,
          7.207221984863281,
          7.1480631828308105,
          7.102282524108887,
          7.035595417022705,
          6.979118824005127,
          6.900022506713867,
          6.810378551483154,
          6.727283000946045,
          6.658317565917969,
          6.578729629516602,
          6.503628730773926,
          6.447163105010986,
          6.425139904022217,
          6.421227931976318,
          6.398203372955322,
          6.343837261199951,
          6.277589797973633,
          6.207949638366699,
          6.134565830230713,
          6.045848846435547,
          5.9660515785217285,
          5.922032833099365,
          5.929983615875244,
          5.875477313995361,
          5.783780574798584,
          5.710598468780518,
          5.646530628204346,
          5.570286750793457,
          5.52374267578125,
          5.496713638305664,
          5.421473503112793,
          5.349325656890869,
          5.285084247589111,
          5.246016979217529,
          5.207888126373291,
          5.144594669342041,
          5.015122890472412,
          4.879064083099365,
          4.809691905975342,
          4.734593391418457,
          4.710977554321289,
          4.711657524108887,
          4.70161771774292,
          4.7178425788879395,
          4.677196502685547,
          4.641098976135254,
          4.590791702270508,
          4.577855587005615,
          4.54021692276001,
          4.478268623352051,
          4.444234371185303,
          4.427219390869141,
          4.3938984870910645,
          4.312210559844971,
          4.254970073699951,
          4.160028457641602,
          4.061495304107666,
          4.009274005889893,
          3.917539596557617,
          3.9113197326660156,
          3.923185110092163,
          3.908970832824707,
          3.9149720668792725,
          3.8323538303375244,
          3.7312655448913574,
          3.5698089599609375,
          3.3657071590423584,
          3.2629809379577637,
          3.23166561126709,
          3.1712632179260254,
          3.1390774250030518,
          3.153578996658325,
          3.1740615367889404,
          3.125267267227173,
          3.1038687229156494,
          3.141646385192871,
          3.067218065261841,
          3.048358678817749,
          3.0789942741394043,
          3.0742368698120117,
          3.053658962249756,
          2.9466769695281982,
          2.880042314529419,
          2.8364367485046387,
          2.68567156791687,
          2.562485933303833,
          2.4577674865722656,
          2.3787381649017334,
          2.29313588142395,
          2.279340982437134,
          2.2269554138183594,
          2.183441400527954,
          2.0950520038604736,
          2.074101209640503,
          2.1963870525360107,
          2.1598961353302,
          2.127392053604126,
          2.0864369869232178,
          2.053029775619507,
          1.9858579635620117,
          1.9087632894515991,
          1.8085492849349976,
          1.7276723384857178,
          1.6799956560134888,
          1.6354138851165771,
          1.6451016664505005,
          1.6777547597885132,
          1.7245228290557861,
          1.7067283391952515,
          1.6477012634277344,
          1.5776793956756592,
          1.533799409866333,
          1.4614585638046265,
          1.4377555847167969,
          1.4588308334350586,
          1.5125356912612915,
          1.5676679611206055,
          1.6372770071029663,
          1.6416171789169312,
          1.559423565864563,
          1.4680614471435547,
          1.4439018964767456,
          1.438031792640686,
          1.4552078247070312,
          1.4820752143859863,
          1.512932538986206,
          1.571399211883545,
          1.539496660232544,
          1.4481180906295776,
          1.3921616077423096,
          1.343994140625,
          1.3227746486663818,
          1.3042383193969727,
          1.2998569011688232,
          1.3034031391143799,
          1.2773228883743286,
          1.2515627145767212,
          1.2383742332458496,
          1.235527515411377,
          1.238397240638733,
          1.2011843919754028,
          1.1849271059036255,
          1.2042999267578125,
          1.2208629846572876,
          1.2319450378417969,
          1.2655996084213257,
          1.3145942687988281,
          1.3102282285690308,
          1.3021334409713745,
          1.2721381187438965,
          1.2378076314926147,
          1.2237792015075684,
          1.1953787803649902,
          1.1502882242202759,
          1.1326595544815063,
          1.1197818517684937,
          1.0886547565460205,
          1.0833145380020142,
          1.0848435163497925,
          1.0862619876861572,
          1.0835869312286377,
          1.099222183227539,
          1.1211549043655396,
          1.1416399478912354,
          1.1565088033676147,
          1.167367935180664,
          1.1538907289505005,
          1.1622849702835083,
          1.1553081274032593,
          1.1566553115844727,
          1.1502748727798462,
          1.1201890707015991,
          1.084306240081787,
          1.0745773315429688,
          1.0799040794372559,
          1.0747439861297607,
          1.0595487356185913,
          1.0791279077529907,
          1.0885967016220093,
          1.090877652168274,
          1.0859636068344116,
          1.0865519046783447,
          1.0730853080749512,
          1.0413377285003662,
          1.029280662536621,
          1.0525590181350708,
          1.0991230010986328,
          1.1192162036895752,
          1.085929036140442,
          1.0471690893173218,
          1.0363177061080933,
          1.0009664297103882,
          1.00475013256073,
          1.0305962562561035,
          1.0165103673934937,
          1.0004948377609253,
          0.9877133369445801,
          1.0018680095672607,
          1.0185816287994385,
          0.9875210523605347,
          0.9758263230323792,
          1.112351417541504,
          1.187449336051941,
          1.1745316982269287,
          1.0947439670562744,
          1.0434536933898926,
          1.0419771671295166,
          1.050775170326233,
          1.0265401601791382,
          0.9948768019676208,
          0.9806053638458252,
          1.0035762786865234,
          1.050567865371704,
          1.061189889907837,
          1.0534343719482422,
          1.0436699390411377,
          1.0237877368927002,
          1.0042606592178345,
          0.9837180376052856,
          0.9872676730155945,
          0.977898120880127,
          0.9937365055084229,
          1.045447826385498,
          1.0752367973327637,
          1.0514628887176514,
          1.0470296144485474,
          1.0548133850097656,
          1.0692861080169678,
          1.132240653038025,
          1.0831551551818848,
          1.0256608724594116,
          1.0024583339691162,
          1.008246898651123,
          1.0095611810684204,
          1.002577304840088,
          0.9890097975730896,
          1.0008714199066162,
          1.0043519735336304,
          0.9836047887802124,
          0.9725520014762878,
          0.981201708316803,
          1.0073047876358032,
          1.0083603858947754,
          0.9965131878852844,
          0.9859740138053894,
          0.9827835559844971,
          0.9739452600479126,
          0.9826130270957947,
          0.9889376759529114,
          0.9968868494033813,
          0.9974102973937988,
          0.9769122004508972,
          0.9636857509613037,
          0.9570522904396057,
          0.9614363312721252,
          0.9721392393112183,
          0.9858312606811523,
          0.9752441644668579,
          0.9734030961990356,
          0.9498958587646484,
          0.9345716238021851,
          0.9474818706512451,
          0.9523919224739075,
          0.9375198483467102,
          0.9438401460647583,
          0.9783169627189636,
          0.9778457880020142,
          0.974556028842926,
          0.9671229720115662,
          0.9764730334281921,
          0.979621410369873,
          0.9757686257362366,
          0.9686558246612549,
          0.9664790034294128,
          0.9542519450187683,
          0.9560975432395935,
          0.946074366569519,
          0.9401099681854248,
          0.9546796083450317,
          0.9415429830551147,
          0.9367656111717224,
          0.9445483684539795,
          0.9402781128883362,
          0.9332736730575562,
          0.9259443283081055,
          0.9246697425842285,
          0.9328641891479492,
          0.9351186156272888,
          0.9308153390884399,
          0.9263287782669067,
          0.9473733901977539,
          0.9644240140914917,
          0.9955967664718628,
          0.9940125942230225,
          0.9318497180938721,
          0.9320377111434937,
          0.9411991238594055,
          0.9211497902870178,
          0.9184994101524353,
          0.9257264137268066,
          0.929137110710144,
          0.9316331148147583,
          0.9372543096542358,
          0.9405651092529297,
          0.9581527709960938,
          0.9674039483070374,
          0.9494432806968689,
          0.9310486912727356,
          0.9210543036460876,
          0.9328653812408447,
          0.9946152567863464,
          1.0429229736328125,
          1.0128940343856812,
          0.9852129817008972,
          0.9529986381530762,
          0.958530604839325,
          0.9590340852737427,
          0.9669128656387329,
          0.9526327252388,
          0.9480625987052917,
          0.952428936958313,
          0.9567195773124695,
          0.9483415484428406,
          0.9469099640846252,
          0.9498893618583679,
          0.9520332217216492,
          0.950262188911438,
          0.9740031957626343,
          0.9597384929656982,
          0.9481112957000732,
          0.9492473006248474,
          0.9521162509918213,
          0.9554430246353149,
          0.9582715630531311,
          0.9576488733291626,
          0.9488177299499512,
          0.9497657418251038,
          0.9544492363929749,
          0.961938738822937,
          0.9646945595741272,
          0.9687042832374573,
          0.9744665026664734,
          0.9889060258865356,
          0.9728893637657166,
          0.95316082239151,
          0.9734116792678833,
          1.00078547000885,
          0.9871596097946167,
          0.9676313996315002,
          0.9485812783241272,
          0.9353066086769104,
          0.9306799173355103,
          0.9389097690582275,
          0.9433999061584473,
          0.9625977873802185,
          1.0083101987838745,
          1.0478259325027466,
          1.0231465101242065,
          0.9506183862686157,
          0.9244356155395508,
          0.9233726263046265,
          0.9332396388053894,
          0.9393259882926941,
          0.9553244709968567,
          0.9850632548332214,
          1.0044368505477905,
          1.0171890258789062,
          0.9593691229820251,
          0.9365378618240356,
          0.9271897077560425,
          0.9297569990158081,
          0.9532281160354614,
          0.9311040639877319,
          0.926856517791748,
          0.9957210421562195,
          1.0344158411026,
          1.0228464603424072,
          1.015138864517212,
          1.007431149482727,
          0.9747298955917358,
          0.9799277782440186,
          0.9879738688468933,
          1.02466881275177,
          0.9872264862060547,
          0.974433958530426,
          0.9578526020050049,
          0.9546700716018677,
          0.9474941492080688,
          0.9730746746063232,
          0.9998624920845032,
          1.0191543102264404,
          0.9861377477645874,
          0.9684657454490662,
          0.9461564421653748,
          0.9283309578895569,
          0.9312059879302979,
          0.9126805663108826,
          0.8998245596885681,
          0.9000055193901062,
          0.9045575857162476,
          0.9003925919532776,
          0.9094851016998291,
          0.9222776889801025,
          0.9319887757301331,
          0.9294467568397522,
          0.928125262260437,
          0.9294543862342834,
          0.9288367629051208,
          0.9335950613021851,
          0.9263625144958496,
          0.9169838428497314,
          0.9179070591926575,
          0.9206589460372925,
          0.9227738976478577,
          0.9463189244270325,
          0.9538845419883728,
          0.9629251956939697,
          0.9651874899864197,
          0.970819890499115,
          1.0433472394943237,
          1.0562012195587158,
          0.9601836800575256,
          0.9175227880477905,
          0.9068468809127808,
          0.9096712470054626,
          0.9163169264793396,
          0.9207651019096375,
          0.9346705675125122,
          0.9523042440414429,
          0.9543622136116028,
          0.9391995072364807,
          0.9158223867416382,
          0.9061997532844543,
          0.9055389165878296,
          0.9133918881416321,
          0.9581274390220642,
          1.0213170051574707,
          0.9759818911552429,
          0.9387848377227783,
          0.9425931572914124,
          0.9308630228042603,
          0.9183477759361267,
          0.9147253632545471,
          0.8994703888893127,
          0.8874624967575073,
          0.891174852848053,
          0.8969836831092834,
          0.9135412573814392,
          0.9346810579299927,
          0.9316006302833557,
          0.929362952709198,
          0.9362691640853882,
          0.9212315082550049,
          0.8986192345619202,
          0.8914636969566345,
          0.9121442437171936,
          0.9838385581970215,
          1.0241694450378418,
          0.9817758202552795,
          0.9391592741012573,
          0.9560271501541138,
          0.9521746635437012,
          0.9294798374176025,
          0.8951669931411743,
          0.8878380060195923,
          0.8790242075920105,
          0.8549497127532959,
          0.8511333465576172,
          0.855364203453064,
          0.8639482855796814,
          0.8758679628372192,
          0.8853386044502258,
          0.8860467076301575,
          0.8962497711181641,
          0.8770669102668762,
          0.9084820747375488,
          0.9896796345710754,
          1.043947458267212,
          0.9967800378799438,
          0.9581462144851685,
          0.9358612895011902,
          0.915677547454834,
          0.9161351323127747,
          0.9235466718673706,
          0.9516817331314087,
          0.9653922915458679,
          1.0017082691192627,
          0.9626312851905823,
          0.913176953792572,
          0.8964149355888367,
          0.8895663022994995,
          0.904057502746582,
          0.9283487796783447,
          1.004115104675293,
          1.0994513034820557,
          1.0328370332717896,
          0.9462987780570984,
          0.9180954098701477,
          0.9082648754119873,
          0.9153475165367126,
          0.899648129940033,
          0.8937934041023254,
          0.9186321496963501,
          0.9850423336029053,
          1.0351392030715942,
          1.009669542312622,
          0.9412909150123596,
          0.9333934783935547,
          0.9237795472145081,
          0.9192526340484619,
          0.904218852519989,
          0.8961248993873596,
          0.906764805316925,
          0.9376554489135742,
          0.987425684928894,
          1.035810112953186,
          1.0491456985473633,
          1.0365599393844604,
          1.032446265220642,
          0.9617849588394165,
          0.9449909925460815,
          0.9099858403205872,
          0.8897321224212646,
          0.8885831832885742,
          0.9310004115104675,
          0.936418354511261,
          0.9138014912605286,
          0.9098442196846008,
          0.9246892333030701,
          0.9617917537689209,
          0.9796360731124878,
          0.9725860953330994,
          0.9561305046081543,
          1.0141103267669678,
          0.9722211956977844,
          0.9344674944877625,
          0.8887860178947449,
          0.8736299276351929,
          0.8876808881759644,
          0.9465724229812622,
          1.0183095932006836,
          1.0340425968170166,
          0.9356540441513062,
          0.9032992720603943,
          0.9203796982765198,
          0.9243770241737366,
          0.9473543167114258,
          0.9745137691497803,
          0.9330019950866699,
          0.9027798771858215,
          0.9272206425666809,
          0.9169193506240845,
          0.923582136631012,
          0.9117363691329956,
          0.891708254814148,
          0.8912625908851624,
          0.8950163722038269,
          0.8878124952316284,
          0.8816899657249451,
          0.9380276203155518,
          0.9673036932945251,
          0.9987325668334961,
          0.9465726613998413,
          0.8894031643867493,
          0.8916850090026855,
          0.9107713103294373,
          0.9382411241531372,
          0.937694787979126,
          0.9029853940010071,
          0.8802783489227295,
          0.8927233815193176,
          0.9532673358917236,
          0.9354804158210754,
          0.9230769872665405,
          0.9453893899917603,
          0.9656186103820801,
          0.9778724312782288,
          0.9689174890518188,
          0.9644911885261536,
          0.9495123624801636,
          0.9497767686843872,
          0.9372970461845398,
          0.9381913542747498,
          0.9338870048522949,
          0.9460157155990601,
          0.9835940003395081,
          1.0118677616119385,
          1.0016545057296753,
          1.0006921291351318,
          0.9486486315727234,
          0.9163362979888916,
          0.8935668468475342,
          0.8889470100402832,
          0.8900750875473022,
          0.9021209478378296,
          0.9333688020706177,
          0.9070215821266174,
          0.896457850933075,
          0.9000160098075867,
          0.8748247027397156,
          0.8603437542915344,
          0.8539101481437683,
          0.8701607584953308,
          0.8626547455787659,
          0.8354488015174866,
          0.835119366645813,
          0.8599067330360413,
          0.9164718985557556,
          0.9414176940917969,
          0.9506873488426208,
          0.9445874691009521,
          0.9454505443572998,
          0.9439778923988342,
          0.9412645697593689,
          0.9305812120437622,
          0.9155363440513611,
          0.9033271670341492,
          0.9096677899360657,
          0.9219232201576233,
          0.9173833727836609,
          0.89373379945755,
          0.8770423531532288,
          0.8679011464118958,
          0.8705865740776062,
          0.8715810179710388,
          0.8617120385169983,
          0.8601241111755371,
          0.867327868938446,
          0.8705339431762695,
          0.8756927847862244,
          0.8902733325958252,
          0.889471173286438,
          0.9079316258430481,
          0.9172732830047607,
          0.9170843362808228,
          0.9183556437492371,
          0.9161620140075684,
          0.9112319946289062,
          0.961034893989563,
          0.9583907723426819,
          0.9266495108604431,
          0.8908802270889282,
          0.8841688632965088,
          0.8938100934028625,
          0.8957635760307312,
          0.8825548887252808,
          0.8750436902046204,
          0.8800007104873657,
          0.8807163834571838,
          0.878004252910614,
          0.8985435366630554,
          0.9438703656196594,
          0.9196651577949524,
          0.8742117881774902,
          0.8719717264175415,
          0.8722116351127625,
          0.867293655872345,
          0.8554472923278809,
          0.8573590517044067,
          0.8677748441696167,
          0.8888927698135376,
          0.9049564599990845,
          0.8949142098426819,
          0.9005212187767029,
          0.9561378955841064,
          0.9818377494812012,
          0.9532536864280701,
          0.9305404424667358,
          0.8910167217254639,
          0.8560648560523987,
          0.8658071160316467,
          0.8574384450912476,
          0.8921586871147156,
          0.9180733561515808,
          0.8897891044616699,
          0.8745858073234558,
          0.8819063305854797,
          0.9167433381080627,
          0.9605489373207092,
          0.9386295080184937,
          0.9262634515762329,
          0.889234721660614,
          0.8807511925697327,
          0.8701412677764893,
          0.8756126761436462,
          0.874057948589325,
          0.9128798246383667,
          0.8937225341796875,
          0.8834179043769836,
          0.8787032961845398,
          0.8879220485687256,
          0.8884848952293396,
          0.8955870270729065,
          0.8851724863052368,
          0.859195351600647,
          0.8563588857650757,
          0.8539605140686035,
          0.8525307774543762,
          0.8630952835083008,
          0.9054824709892273,
          0.8901360034942627,
          0.865431010723114,
          0.8572601675987244,
          0.8755374550819397,
          0.9034692049026489,
          0.9332471489906311,
          0.960852324962616,
          0.9708376526832581,
          0.9524511694908142,
          0.9522590637207031,
          0.9464486837387085,
          0.9624845385551453,
          0.9524371027946472,
          0.9090915322303772,
          0.8982900977134705,
          0.8958464860916138,
          0.9035412073135376,
          0.9085583686828613,
          0.9140291810035706,
          0.944984495639801,
          0.9792567491531372,
          0.9255939722061157,
          0.9180982112884521,
          0.9379140138626099,
          0.952582061290741,
          0.9503616690635681,
          0.9431051015853882,
          0.9360827207565308,
          0.9237595796585083,
          0.898810088634491,
          0.8845484852790833,
          0.8803288340568542,
          0.8908411860466003,
          0.9443919062614441,
          0.9770551919937134,
          0.9802756309509277,
          0.9464999437332153,
          0.9478722214698792,
          0.9910845756530762,
          0.9975121021270752,
          0.9338425993919373,
          0.8861774802207947,
          0.8644435405731201,
          0.8619685769081116,
          0.869499683380127,
          0.8916159272193909,
          0.9052292704582214,
          0.9091215133666992,
          0.9193196892738342,
          0.9052818417549133,
          0.8932192921638489,
          0.8990862965583801,
          0.8931015729904175,
          0.8715937733650208,
          0.8543241024017334,
          0.8536079525947571,
          0.8499329686164856,
          0.8596143126487732,
          0.8636503219604492,
          0.860821545124054,
          0.9002385139465332,
          0.943096935749054,
          0.9318694472312927,
          0.9133272171020508,
          0.9169621467590332,
          0.9236862659454346,
          0.9019649624824524,
          0.9058452844619751,
          0.9287404417991638,
          0.9671077728271484,
          0.920417845249176,
          0.8868668675422668,
          0.8901550769805908,
          0.9025357365608215,
          0.9156537055969238,
          0.91731196641922,
          0.9153969287872314,
          0.9098981022834778,
          0.9129265546798706,
          0.9098342657089233,
          0.8982781171798706,
          0.8990459442138672,
          0.9493346214294434,
          0.9429179430007935,
          0.9322333335876465,
          0.946723997592926,
          0.9580318331718445,
          0.9493261575698853,
          0.9251412749290466,
          0.9220218062400818,
          0.9211267232894897,
          0.9091489911079407,
          0.9335107803344727,
          0.9503324627876282,
          0.9268331527709961,
          0.91051185131073,
          0.953906774520874,
          0.9490556120872498,
          0.9354062080383301,
          0.946203351020813,
          0.9498358368873596,
          0.9284176826477051,
          0.9386034607887268,
          0.9483693242073059,
          0.9237706661224365,
          0.9454451203346252,
          0.9712038636207581,
          0.9767735600471497,
          1.0030508041381836,
          1.0251014232635498,
          1.038304328918457,
          1.019508719444275,
          1.0163300037384033,
          1.0469995737075806,
          1.067751407623291,
          0.9781268239021301,
          0.9609991908073425,
          0.9822759032249451,
          0.9602245688438416,
          0.9257379770278931,
          0.9066476821899414,
          0.9069585800170898,
          0.9001445174217224,
          0.8947114944458008,
          0.915192186832428,
          0.9555639624595642,
          0.9504531025886536,
          0.9672094583511353,
          0.9656749963760376,
          0.9631550312042236,
          0.9294984340667725,
          0.8896082639694214,
          0.877189576625824,
          0.8927659392356873,
          0.9163878560066223,
          0.9472783207893372,
          1.003902554512024,
          0.9864410758018494,
          0.9750595092773438,
          0.9406859278678894,
          0.916278064250946,
          0.882174015045166,
          0.8656457662582397,
          0.861627995967865,
          0.8651411533355713,
          0.862226665019989,
          0.8650946617126465,
          0.8750766515731812,
          0.9206990003585815,
          0.9490314722061157,
          0.8939467072486877,
          0.8888665437698364,
          0.8917632699012756,
          0.9031042456626892,
          0.918768584728241,
          0.9347909688949585,
          0.9533470869064331,
          1.034529685974121,
          1.045596718788147,
          0.9706875681877136,
          0.9387140870094299,
          0.9308320879936218,
          0.9250624775886536,
          0.9041907787322998,
          0.9486961960792542,
          1.040574550628662,
          1.0333712100982666,
          0.9939767718315125,
          0.9719079732894897,
          0.9337524175643921,
          0.9108085632324219,
          0.9399903416633606,
          0.9561084508895874,
          0.9743295311927795,
          0.9810393452644348,
          0.966163694858551,
          0.9361525774002075,
          0.9103564023971558,
          0.9013333916664124,
          0.902110755443573,
          0.9178770780563354,
          0.940936803817749,
          0.9919800758361816,
          0.9971773028373718,
          0.9655677080154419,
          0.9611101150512695,
          0.9516509175300598,
          0.9261311292648315,
          0.9050978422164917,
          0.8834801316261292,
          0.8770231604576111,
          0.8806753158569336,
          0.8911676406860352,
          0.8848248720169067,
          0.8727040886878967,
          0.8592433929443359,
          0.8735512495040894,
          0.8872409462928772,
          0.8709836602210999,
          0.8670007586479187,
          0.8918097615242004,
          0.9141109585762024,
          0.9099282026290894,
          0.9198117852210999,
          0.9434532523155212,
          0.912922203540802,
          0.9173631072044373,
          0.8706115484237671,
          0.8636277318000793,
          0.8710557222366333,
          0.8818694353103638,
          0.898908257484436,
          0.9235799908638,
          0.9234922528266907,
          0.921520471572876,
          0.9103590250015259,
          0.8999805450439453,
          0.919617772102356,
          0.952278196811676,
          0.9472737908363342,
          0.9184767603874207
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation accuracy",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.876590371131897\n",
      "Test Accuracy: 0.4857954680919647\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,verbose=0)\n",
    "print(\"Test Loss:\",score[0])\n",
    "print(\"Test Accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "modelLoad = keras.models.load_model(\"weights_best_lr_1_e-5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.6939151287078857\n",
      "Test Accuracy: 0.49147728085517883\n"
     ]
    }
   ],
   "source": [
    "score = modelLoad.evaluate(x_test, y_test,verbose=0)\n",
    "print(\"Test Loss:\",score[0])\n",
    "print(\"Test Accuracy:\",score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
