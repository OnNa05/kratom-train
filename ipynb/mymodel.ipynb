{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "Adam = tf.keras.optimizers.Adam\n",
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten , Conv2D, MaxPool2D\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly import subplots\n",
    "import plotly\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 28\n",
    "num_classes = 8\n",
    "trainpath = '/Users/onna/Documents/krotom-train/img-eng/train'\n",
    "testpath = '/Users/onna/Documents/krotom-train/img-eng/test'\n",
    "trainImg = [trainpath + \"/\"+ f for f in listdir(trainpath)]\n",
    "testImg = [testpath + \"/\"+ f for f in listdir(testpath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2data(path):\n",
    "    rawImgs = []\n",
    "    labels = []\n",
    "\n",
    "    for imagePath in (path):\n",
    "        for item in tqdm(listdir(imagePath)):\n",
    "            file = join(imagePath, item)\n",
    "            \n",
    "            if file[-1] =='g':\n",
    "                img = cv2.imread(file , cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img ,(width,width))\n",
    "                rawImgs.append(img)\n",
    "\n",
    "                name =  imagePath.split('/')\n",
    "                l = name[len(name) - 1]\n",
    "            #['Boiled_leaves', 'Green_stalk_GradeA', 'Green_stalk_GradeB', 'Green_stalk_GradeC', 'JUMBO', 'Red_stalk_GradeA', 'Red_stalk_GradeB', 'Red_stalk_GradeC']\n",
    "            if l == 'Boiled_leaves':\n",
    "                labels.append([1,0,0,0,0,0,0,0])         \n",
    "            elif l == 'Green_stalk_GradeA':\n",
    "                labels.append([0,1,0,0,0,0,0,0])  \n",
    "            elif l == 'Green_stalk_GradeB':\n",
    "                labels.append([0,0,1,0,0,0,0,0])\n",
    "            elif l == 'Green_stalk_GradeC':\n",
    "                labels.append([0,0,0,1,0,0,0,0])\n",
    "            elif l == 'JUMBO':\n",
    "                labels.append([0,0,0,0,1,0,0,0])\n",
    "            elif l == 'Red_stalk_GradeA':\n",
    "                labels.append([0,0,0,0,0,1,0,0])\n",
    "            elif l == 'Red_stalk_GradeB':\n",
    "                labels.append([0,0,0,0,0,0,1,0])\n",
    "            elif l == 'Red_stalk_GradeC':\n",
    "                labels.append([0,0,0,0,0,0,0,1])\n",
    "    return rawImgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 225.73it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 229.13it/s]\n",
      "100%|██████████| 394/394 [00:01<00:00, 249.19it/s]\n",
      "100%|██████████| 429/429 [00:01<00:00, 224.72it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 235.93it/s]\n",
      "100%|██████████| 176/176 [00:00<00:00, 195.89it/s]\n",
      "100%|██████████| 146/146 [00:00<00:00, 237.70it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 228.78it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = img2data(trainImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 186.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 228.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 191.33it/s]\n",
      "100%|██████████| 104/104 [00:00<00:00, 288.99it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 268.34it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 189.28it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 229.38it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 187.35it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = img2data(testImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1381, 28, 28), (1381, 8), (352, 28, 28), (352, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "test_data = x_test.reshape((x_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 28, 28, 1) (352, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8\n",
    "VAL_SIZE = 0.2\n",
    "RANDOM_STATE = 99\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1104, 28, 28, 1), (277, 28, 28, 1), (1104, 8), (277, 8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train_data, y_train, test_size=VAL_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trace(x,y,ylabel,color):\n",
    "        trace = go.Scatter(\n",
    "            x = x,y = y,\n",
    "            name=ylabel,\n",
    "            marker=dict(color=color),\n",
    "            mode = \"markers+lines\",\n",
    "            text=x\n",
    "        )\n",
    "        return trace\n",
    "    \n",
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['accuracy']\n",
    "    val_acc = hist['val_accuracy']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = list(range(1,len(acc)+1))\n",
    "    \n",
    "    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n",
    "    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n",
    "    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n",
    "    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n",
    "   \n",
    "    fig = subplots.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n",
    "                                                             'Training and validation loss'))\n",
    "    fig.append_trace(trace_ta,1,1)\n",
    "    fig.append_trace(trace_va,1,1)\n",
    "    fig.append_trace(trace_tl,1,2)\n",
    "    fig.append_trace(trace_vl,1,2)\n",
    "    fig['layout']['xaxis'].update(title = 'Epoch')\n",
    "    fig['layout']['xaxis2'].update(title = 'Epoch')\n",
    "    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n",
    "    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n",
    "\n",
    "    plotly.offline.iplot(fig, filename='accuracy-loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=0.05,    #Randomly rotate images in the range\n",
    "        zoom_range=0.2,         #Randomly zoom image\n",
    "        width_shift_range=0.1,  #Randomly shift images horizontally\n",
    "        height_shift_range=0.1, #Randomly shift images vertically\n",
    "        shear_range=0.05        #Randomly shear images\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#1. CNN LAYER\n",
    "model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#2. CNN LAYER\n",
    "model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#3. CNN LAYER\n",
    "model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#4. CNN LAYER\n",
    "model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "#FULLY CONNECTED LAYER\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.30))\n",
    "\n",
    "#OUTPUT LAYER\n",
    "model.add(tf.keras.layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               803072    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 871,912\n",
      "Trainable params: 871,016\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 17:26:01.106061: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 212ms/step - loss: 2.2855 - accuracy: 0.2146 - val_loss: 2.0343 - val_accuracy: 0.2527\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 1.7937 - accuracy: 0.4057 - val_loss: 1.9318 - val_accuracy: 0.3141\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 1.6848 - accuracy: 0.4611 - val_loss: 1.8865 - val_accuracy: 0.3141\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 1.5888 - accuracy: 0.4873 - val_loss: 1.9908 - val_accuracy: 0.3141\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 1.5982 - accuracy: 0.4811 - val_loss: 2.2655 - val_accuracy: 0.3141\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.5854 - accuracy: 0.4953 - val_loss: 2.6465 - val_accuracy: 0.3141\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.5438 - accuracy: 0.4917 - val_loss: 3.0291 - val_accuracy: 0.3141\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.4844 - accuracy: 0.4988 - val_loss: 3.4139 - val_accuracy: 0.3141\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 1.4289 - accuracy: 0.5130 - val_loss: 3.7293 - val_accuracy: 0.3141\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.3657 - accuracy: 0.5071 - val_loss: 4.1308 - val_accuracy: 0.3141\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.3435 - accuracy: 0.5483 - val_loss: 4.5938 - val_accuracy: 0.3141\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 1.3163 - accuracy: 0.5472 - val_loss: 5.0026 - val_accuracy: 0.3141\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 1.2850 - accuracy: 0.5448 - val_loss: 5.3073 - val_accuracy: 0.3141\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 1.1817 - accuracy: 0.5649 - val_loss: 5.5883 - val_accuracy: 0.3141\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 1.2316 - accuracy: 0.5684 - val_loss: 5.8235 - val_accuracy: 0.3141\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 1.2290 - accuracy: 0.5840 - val_loss: 6.0151 - val_accuracy: 0.3141\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 1.2597 - accuracy: 0.5703 - val_loss: 6.2270 - val_accuracy: 0.3141\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 1.1941 - accuracy: 0.5790 - val_loss: 6.4583 - val_accuracy: 0.3141\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.2141 - accuracy: 0.5389 - val_loss: 6.7530 - val_accuracy: 0.3141\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 1.1416 - accuracy: 0.5790 - val_loss: 7.1511 - val_accuracy: 0.3141\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 1.2130 - accuracy: 0.5731 - val_loss: 7.5032 - val_accuracy: 0.3141\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.1408 - accuracy: 0.5955 - val_loss: 7.8312 - val_accuracy: 0.3141\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.1067 - accuracy: 0.5979 - val_loss: 8.1682 - val_accuracy: 0.3141\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.1562 - accuracy: 0.5991 - val_loss: 8.5007 - val_accuracy: 0.3141\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.1345 - accuracy: 0.5943 - val_loss: 8.7293 - val_accuracy: 0.3141\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 1.1164 - accuracy: 0.6104 - val_loss: 8.8415 - val_accuracy: 0.3141\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.0990 - accuracy: 0.5979 - val_loss: 8.8326 - val_accuracy: 0.3141\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.0684 - accuracy: 0.6097 - val_loss: 8.9044 - val_accuracy: 0.3141\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.0520 - accuracy: 0.6014 - val_loss: 9.2257 - val_accuracy: 0.3141\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.1079 - accuracy: 0.6085 - val_loss: 9.6512 - val_accuracy: 0.3141\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 1.0411 - accuracy: 0.6073 - val_loss: 10.2090 - val_accuracy: 0.3141\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 1.0572 - accuracy: 0.6344 - val_loss: 10.4571 - val_accuracy: 0.3141\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.0259 - accuracy: 0.6427 - val_loss: 10.3904 - val_accuracy: 0.3141\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.0549 - accuracy: 0.6262 - val_loss: 10.4001 - val_accuracy: 0.3141\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 1.0587 - accuracy: 0.6297 - val_loss: 10.4911 - val_accuracy: 0.3141\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.0045 - accuracy: 0.6344 - val_loss: 10.5387 - val_accuracy: 0.3141\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.0088 - accuracy: 0.6274 - val_loss: 10.7985 - val_accuracy: 0.3141\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 1.0563 - accuracy: 0.6348 - val_loss: 11.1813 - val_accuracy: 0.3141\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.9768 - accuracy: 0.6450 - val_loss: 11.3766 - val_accuracy: 0.3141\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 1.0166 - accuracy: 0.6297 - val_loss: 11.4979 - val_accuracy: 0.3141\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 1.0079 - accuracy: 0.6299 - val_loss: 11.6947 - val_accuracy: 0.3141\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.0141 - accuracy: 0.6285 - val_loss: 11.8253 - val_accuracy: 0.3141\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.9707 - accuracy: 0.6523 - val_loss: 11.9833 - val_accuracy: 0.3141\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.9488 - accuracy: 0.6616 - val_loss: 11.8292 - val_accuracy: 0.3141\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.9631 - accuracy: 0.6557 - val_loss: 11.2641 - val_accuracy: 0.3141\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.9488 - accuracy: 0.6533 - val_loss: 10.9694 - val_accuracy: 0.3141\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.9434 - accuracy: 0.6639 - val_loss: 10.7007 - val_accuracy: 0.3141\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.9412 - accuracy: 0.6621 - val_loss: 10.7130 - val_accuracy: 0.3141\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.9590 - accuracy: 0.6722 - val_loss: 10.9355 - val_accuracy: 0.3141\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.9484 - accuracy: 0.6557 - val_loss: 11.0168 - val_accuracy: 0.3141\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.9388 - accuracy: 0.6465 - val_loss: 11.0521 - val_accuracy: 0.3141\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.9792 - accuracy: 0.6521 - val_loss: 11.1082 - val_accuracy: 0.3141\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.9159 - accuracy: 0.6781 - val_loss: 11.1722 - val_accuracy: 0.3141\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.9192 - accuracy: 0.6486 - val_loss: 11.3935 - val_accuracy: 0.3141\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.8842 - accuracy: 0.6863 - val_loss: 11.6847 - val_accuracy: 0.3141\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.9233 - accuracy: 0.6592 - val_loss: 11.9161 - val_accuracy: 0.3141\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.9022 - accuracy: 0.6627 - val_loss: 11.8737 - val_accuracy: 0.3141\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.8653 - accuracy: 0.6958 - val_loss: 11.4244 - val_accuracy: 0.3141\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.9043 - accuracy: 0.6722 - val_loss: 11.4688 - val_accuracy: 0.3141\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.8646 - accuracy: 0.6722 - val_loss: 11.6020 - val_accuracy: 0.3141\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8818 - accuracy: 0.6777 - val_loss: 11.6888 - val_accuracy: 0.3141\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.8823 - accuracy: 0.6698 - val_loss: 11.6603 - val_accuracy: 0.3141\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.9111 - accuracy: 0.6509 - val_loss: 11.7834 - val_accuracy: 0.3141\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8474 - accuracy: 0.6958 - val_loss: 11.6137 - val_accuracy: 0.3141\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8573 - accuracy: 0.6895 - val_loss: 11.5279 - val_accuracy: 0.3141\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8993 - accuracy: 0.6675 - val_loss: 11.6226 - val_accuracy: 0.3141\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8553 - accuracy: 0.6973 - val_loss: 11.6409 - val_accuracy: 0.3141\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.8610 - accuracy: 0.6757 - val_loss: 11.6688 - val_accuracy: 0.3141\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8351 - accuracy: 0.7080 - val_loss: 11.8051 - val_accuracy: 0.3141\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.8669 - accuracy: 0.6946 - val_loss: 11.7518 - val_accuracy: 0.3141\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.8576 - accuracy: 0.6887 - val_loss: 11.6060 - val_accuracy: 0.3141\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8319 - accuracy: 0.6914 - val_loss: 12.0741 - val_accuracy: 0.3141\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.8439 - accuracy: 0.6863 - val_loss: 12.3096 - val_accuracy: 0.3141\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.8615 - accuracy: 0.6875 - val_loss: 12.3446 - val_accuracy: 0.3141\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.7956 - accuracy: 0.7252 - val_loss: 11.8472 - val_accuracy: 0.3141\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.8472 - accuracy: 0.6855 - val_loss: 11.4130 - val_accuracy: 0.3141\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.8817 - accuracy: 0.6851 - val_loss: 11.0558 - val_accuracy: 0.3141\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8703 - accuracy: 0.6922 - val_loss: 11.1129 - val_accuracy: 0.3141\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.8187 - accuracy: 0.6934 - val_loss: 11.1583 - val_accuracy: 0.3141\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.8004 - accuracy: 0.7193 - val_loss: 11.0375 - val_accuracy: 0.3141\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.8286 - accuracy: 0.7241 - val_loss: 10.6962 - val_accuracy: 0.3141\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.8010 - accuracy: 0.7217 - val_loss: 10.3421 - val_accuracy: 0.3141\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.7914 - accuracy: 0.7111 - val_loss: 10.1298 - val_accuracy: 0.3141\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.8084 - accuracy: 0.7170 - val_loss: 9.9409 - val_accuracy: 0.3141\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8515 - accuracy: 0.6840 - val_loss: 10.1744 - val_accuracy: 0.3141\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.7761 - accuracy: 0.7264 - val_loss: 10.7004 - val_accuracy: 0.3141\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.7888 - accuracy: 0.7275 - val_loss: 10.7822 - val_accuracy: 0.3141\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8120 - accuracy: 0.6934 - val_loss: 10.8831 - val_accuracy: 0.3141\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8022 - accuracy: 0.7075 - val_loss: 10.9946 - val_accuracy: 0.3141\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.7888 - accuracy: 0.7129 - val_loss: 10.9019 - val_accuracy: 0.3141\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.7953 - accuracy: 0.7087 - val_loss: 10.7726 - val_accuracy: 0.3141\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.7647 - accuracy: 0.7252 - val_loss: 10.8243 - val_accuracy: 0.3141\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.7540 - accuracy: 0.7217 - val_loss: 10.7129 - val_accuracy: 0.3141\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.7800 - accuracy: 0.7123 - val_loss: 10.5309 - val_accuracy: 0.3141\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8038 - accuracy: 0.6910 - val_loss: 10.4367 - val_accuracy: 0.3141\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.7633 - accuracy: 0.7182 - val_loss: 10.0174 - val_accuracy: 0.3141\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.7744 - accuracy: 0.7229 - val_loss: 9.5335 - val_accuracy: 0.3141\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.8088 - accuracy: 0.7064 - val_loss: 9.5805 - val_accuracy: 0.3141\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7006 - accuracy: 0.7480 - val_loss: 9.8622 - val_accuracy: 0.3141\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.7789 - accuracy: 0.7264 - val_loss: 10.2750 - val_accuracy: 0.3141\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.7548 - accuracy: 0.7323 - val_loss: 10.5807 - val_accuracy: 0.3141\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7546 - accuracy: 0.7288 - val_loss: 10.9354 - val_accuracy: 0.3141\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.7354 - accuracy: 0.7347 - val_loss: 10.4464 - val_accuracy: 0.3141\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7456 - accuracy: 0.7193 - val_loss: 9.9588 - val_accuracy: 0.3141\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.7507 - accuracy: 0.7252 - val_loss: 9.9260 - val_accuracy: 0.3141\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7263 - accuracy: 0.7295 - val_loss: 9.7915 - val_accuracy: 0.3141\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.7190 - accuracy: 0.7406 - val_loss: 9.2826 - val_accuracy: 0.3141\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6944 - accuracy: 0.7529 - val_loss: 8.6190 - val_accuracy: 0.3141\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.7358 - accuracy: 0.7311 - val_loss: 8.4289 - val_accuracy: 0.3141\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.7040 - accuracy: 0.7429 - val_loss: 8.5352 - val_accuracy: 0.3141\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.7299 - accuracy: 0.7453 - val_loss: 8.4257 - val_accuracy: 0.3141\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.6836 - accuracy: 0.7512 - val_loss: 8.3134 - val_accuracy: 0.3141\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.7150 - accuracy: 0.7653 - val_loss: 8.1054 - val_accuracy: 0.3141\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.7410 - accuracy: 0.7288 - val_loss: 7.4209 - val_accuracy: 0.3141\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.7228 - accuracy: 0.7441 - val_loss: 7.5162 - val_accuracy: 0.3141\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7109 - accuracy: 0.7393 - val_loss: 7.8205 - val_accuracy: 0.3141\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.7296 - accuracy: 0.7382 - val_loss: 7.8695 - val_accuracy: 0.3177\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6999 - accuracy: 0.7471 - val_loss: 7.8088 - val_accuracy: 0.3177\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.6578 - accuracy: 0.7724 - val_loss: 8.3230 - val_accuracy: 0.3141\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7443 - accuracy: 0.7311 - val_loss: 7.6435 - val_accuracy: 0.3213\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.7031 - accuracy: 0.7465 - val_loss: 6.6858 - val_accuracy: 0.3249\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.7009 - accuracy: 0.7311 - val_loss: 6.8664 - val_accuracy: 0.3249\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6935 - accuracy: 0.7323 - val_loss: 6.1477 - val_accuracy: 0.3357\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.6734 - accuracy: 0.7606 - val_loss: 5.5869 - val_accuracy: 0.3430\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6789 - accuracy: 0.7637 - val_loss: 5.7525 - val_accuracy: 0.3394\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6838 - accuracy: 0.7630 - val_loss: 4.7919 - val_accuracy: 0.3466\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6637 - accuracy: 0.7583 - val_loss: 5.5478 - val_accuracy: 0.3357\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6884 - accuracy: 0.7588 - val_loss: 6.4268 - val_accuracy: 0.3357\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.6892 - accuracy: 0.7465 - val_loss: 6.4733 - val_accuracy: 0.3321\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.6608 - accuracy: 0.7795 - val_loss: 5.5132 - val_accuracy: 0.3466\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6665 - accuracy: 0.7568 - val_loss: 4.5342 - val_accuracy: 0.3718\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.6419 - accuracy: 0.7453 - val_loss: 4.1337 - val_accuracy: 0.3827\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6850 - accuracy: 0.7594 - val_loss: 4.4388 - val_accuracy: 0.3827\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6659 - accuracy: 0.7637 - val_loss: 4.0314 - val_accuracy: 0.3863\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.6499 - accuracy: 0.7583 - val_loss: 3.9678 - val_accuracy: 0.3791\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6426 - accuracy: 0.7618 - val_loss: 4.1666 - val_accuracy: 0.3718\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6663 - accuracy: 0.7547 - val_loss: 4.2338 - val_accuracy: 0.3718\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6352 - accuracy: 0.7748 - val_loss: 3.7723 - val_accuracy: 0.3863\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6685 - accuracy: 0.7578 - val_loss: 2.8660 - val_accuracy: 0.4477\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6491 - accuracy: 0.7642 - val_loss: 3.4223 - val_accuracy: 0.4116\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6356 - accuracy: 0.7677 - val_loss: 4.5554 - val_accuracy: 0.3574\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6187 - accuracy: 0.7771 - val_loss: 4.1306 - val_accuracy: 0.3755\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6553 - accuracy: 0.7642 - val_loss: 3.3147 - val_accuracy: 0.4188\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.5897 - accuracy: 0.7830 - val_loss: 3.5860 - val_accuracy: 0.4152\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6627 - accuracy: 0.7642 - val_loss: 4.0539 - val_accuracy: 0.3935\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.6227 - accuracy: 0.7736 - val_loss: 3.3179 - val_accuracy: 0.4188\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.6146 - accuracy: 0.7700 - val_loss: 2.7857 - val_accuracy: 0.4440\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6495 - accuracy: 0.7705 - val_loss: 3.0381 - val_accuracy: 0.4332\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.5889 - accuracy: 0.7913 - val_loss: 2.8575 - val_accuracy: 0.4404\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.5709 - accuracy: 0.8031 - val_loss: 2.8038 - val_accuracy: 0.4404\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.6275 - accuracy: 0.7712 - val_loss: 2.9618 - val_accuracy: 0.4368\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6128 - accuracy: 0.7744 - val_loss: 2.8400 - val_accuracy: 0.4621\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6090 - accuracy: 0.7795 - val_loss: 2.6649 - val_accuracy: 0.4621\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6161 - accuracy: 0.7818 - val_loss: 2.8607 - val_accuracy: 0.4657\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6400 - accuracy: 0.7618 - val_loss: 1.8152 - val_accuracy: 0.5704\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6093 - accuracy: 0.7712 - val_loss: 2.2861 - val_accuracy: 0.5054\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.6313 - accuracy: 0.7653 - val_loss: 2.8502 - val_accuracy: 0.4404\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.5719 - accuracy: 0.8090 - val_loss: 2.5748 - val_accuracy: 0.4585\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.6147 - accuracy: 0.7724 - val_loss: 2.2449 - val_accuracy: 0.4982\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.6391 - accuracy: 0.7712 - val_loss: 2.9158 - val_accuracy: 0.4477\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.6410 - accuracy: 0.7712 - val_loss: 3.1331 - val_accuracy: 0.4368\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.6312 - accuracy: 0.7795 - val_loss: 1.8739 - val_accuracy: 0.5379\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.5895 - accuracy: 0.7948 - val_loss: 1.4869 - val_accuracy: 0.5921\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.5856 - accuracy: 0.7889 - val_loss: 4.0447 - val_accuracy: 0.3935\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.6392 - accuracy: 0.7665 - val_loss: 3.1319 - val_accuracy: 0.4404\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.6045 - accuracy: 0.7759 - val_loss: 1.5511 - val_accuracy: 0.5921\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.6202 - accuracy: 0.7818 - val_loss: 2.0114 - val_accuracy: 0.4982\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5948 - accuracy: 0.7901 - val_loss: 2.5266 - val_accuracy: 0.4657\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.5903 - accuracy: 0.7949 - val_loss: 2.4241 - val_accuracy: 0.4874\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.5740 - accuracy: 0.7948 - val_loss: 2.3932 - val_accuracy: 0.4982\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.6134 - accuracy: 0.7736 - val_loss: 2.4214 - val_accuracy: 0.4729\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.5784 - accuracy: 0.7842 - val_loss: 2.7868 - val_accuracy: 0.4440\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.6215 - accuracy: 0.7642 - val_loss: 2.1900 - val_accuracy: 0.4765\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.5790 - accuracy: 0.7959 - val_loss: 1.5588 - val_accuracy: 0.5560\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.6507 - accuracy: 0.7653 - val_loss: 1.5151 - val_accuracy: 0.6029\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.6061 - accuracy: 0.7877 - val_loss: 1.9421 - val_accuracy: 0.5415\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.5545 - accuracy: 0.7901 - val_loss: 1.3366 - val_accuracy: 0.6245\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.5384 - accuracy: 0.8054 - val_loss: 0.9448 - val_accuracy: 0.7329\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.6171 - accuracy: 0.7712 - val_loss: 0.9430 - val_accuracy: 0.7292\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5473 - accuracy: 0.8027 - val_loss: 0.9339 - val_accuracy: 0.7256\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.5519 - accuracy: 0.8137 - val_loss: 0.9403 - val_accuracy: 0.7220\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.5856 - accuracy: 0.7803 - val_loss: 0.9371 - val_accuracy: 0.7148\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.5594 - accuracy: 0.7983 - val_loss: 0.9258 - val_accuracy: 0.7292\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5716 - accuracy: 0.7930 - val_loss: 0.9834 - val_accuracy: 0.6968\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.5461 - accuracy: 0.8090 - val_loss: 1.0408 - val_accuracy: 0.6859\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.5823 - accuracy: 0.7939 - val_loss: 0.9027 - val_accuracy: 0.7509\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.5822 - accuracy: 0.7936 - val_loss: 0.9297 - val_accuracy: 0.7401\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.5616 - accuracy: 0.8007 - val_loss: 0.9584 - val_accuracy: 0.7184\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.5512 - accuracy: 0.8054 - val_loss: 0.9664 - val_accuracy: 0.7112\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.5415 - accuracy: 0.8054 - val_loss: 0.9784 - val_accuracy: 0.6823\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.5724 - accuracy: 0.7925 - val_loss: 1.0109 - val_accuracy: 0.6859\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.5605 - accuracy: 0.7854 - val_loss: 0.9557 - val_accuracy: 0.7220\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.5516 - accuracy: 0.8054 - val_loss: 1.1632 - val_accuracy: 0.6968\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.4999 - accuracy: 0.8219 - val_loss: 1.2295 - val_accuracy: 0.6318\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.5653 - accuracy: 0.7972 - val_loss: 0.9674 - val_accuracy: 0.7148\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.5679 - accuracy: 0.7913 - val_loss: 1.2465 - val_accuracy: 0.6101\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.5721 - accuracy: 0.8090 - val_loss: 2.4259 - val_accuracy: 0.3899\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.5461 - accuracy: 0.7960 - val_loss: 1.1118 - val_accuracy: 0.6751\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.5228 - accuracy: 0.8115 - val_loss: 0.9929 - val_accuracy: 0.7076\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.5377 - accuracy: 0.7972 - val_loss: 1.8765 - val_accuracy: 0.4838\n"
     ]
    }
   ],
   "source": [
    "NO_EPOCHS = 200\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "                              shuffle=True,\n",
    "                              epochs=NO_EPOCHS, validation_data = (x_val, y_val),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "Green"
         },
         "mode": "markers+lines",
         "name": "Training accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200
         ],
         "xaxis": "x",
         "y": [
          0.2146226465702057,
          0.40566039085388184,
          0.46108490228652954,
          0.4873046875,
          0.4811320900917053,
          0.49528300762176514,
          0.4917452931404114,
          0.4988207519054413,
          0.5129716992378235,
          0.5070754885673523,
          0.5483490824699402,
          0.5471698045730591,
          0.5448113083839417,
          0.5648584961891174,
          0.5683962106704712,
          0.583984375,
          0.5703125,
          0.5790094137191772,
          0.5389150977134705,
          0.5790094137191772,
          0.573113203048706,
          0.5955188870429993,
          0.5978773832321167,
          0.599056601524353,
          0.5943396091461182,
          0.6103515625,
          0.5978773832321167,
          0.6096698045730591,
          0.6014150977134705,
          0.6084905862808228,
          0.6073113083839417,
          0.6344339847564697,
          0.6426886916160583,
          0.6261792182922363,
          0.6297169923782349,
          0.6344339847564697,
          0.6273584961891174,
          0.634765625,
          0.6450471878051758,
          0.6297169923782349,
          0.6298828125,
          0.6285377144813538,
          0.65234375,
          0.661556601524353,
          0.6556603908538818,
          0.6533018946647644,
          0.6639150977134705,
          0.662109375,
          0.6721698045730591,
          0.6556603908538818,
          0.646484375,
          0.6521226167678833,
          0.6780660152435303,
          0.6485849022865295,
          0.6863207817077637,
          0.6591981053352356,
          0.6627358198165894,
          0.6957547068595886,
          0.6721698045730591,
          0.6721698045730591,
          0.677734375,
          0.6698113083839417,
          0.650943398475647,
          0.6957547068595886,
          0.689453125,
          0.6674528121948242,
          0.697265625,
          0.6757075190544128,
          0.7080078125,
          0.6945754885673523,
          0.6886792182922363,
          0.69140625,
          0.6863207817077637,
          0.6875,
          0.7252358198165894,
          0.685546875,
          0.6851415038108826,
          0.6922169923782349,
          0.693359375,
          0.7193396091461182,
          0.724056601524353,
          0.7216981053352356,
          0.7110849022865295,
          0.7169811129570007,
          0.6839622855186462,
          0.7264150977134705,
          0.7275390625,
          0.6933962106704712,
          0.7075471878051758,
          0.712890625,
          0.7087264060974121,
          0.7252358198165894,
          0.7216981053352356,
          0.7122641801834106,
          0.6910377144813538,
          0.7181603908538818,
          0.7228773832321167,
          0.7063679099082947,
          0.748046875,
          0.7264150977134705,
          0.7323113083839417,
          0.7287735939025879,
          0.7346698045730591,
          0.7193396091461182,
          0.7252358198165894,
          0.7294921875,
          0.7405660152435303,
          0.7529296875,
          0.7311320900917053,
          0.7429245114326477,
          0.7452830076217651,
          0.7511792182922363,
          0.7653301954269409,
          0.7287735939025879,
          0.7441037893295288,
          0.7392578125,
          0.7382075190544128,
          0.7470703125,
          0.7724056839942932,
          0.7311320900917053,
          0.7464622855186462,
          0.7311320900917053,
          0.7323113083839417,
          0.760613203048706,
          0.763671875,
          0.7629716992378235,
          0.7582547068595886,
          0.7587890625,
          0.7464622855186462,
          0.7794811129570007,
          0.7568359375,
          0.7452830076217651,
          0.7594339847564697,
          0.763671875,
          0.7582547068595886,
          0.7617924809455872,
          0.7547169923782349,
          0.7747641801834106,
          0.7578125,
          0.7641509175300598,
          0.7676886916160583,
          0.7771226167678833,
          0.7641509175300598,
          0.7830188870429993,
          0.7641509175300598,
          0.7735849022865295,
          0.7700471878051758,
          0.7705078125,
          0.7912735939025879,
          0.8030660152435303,
          0.7712264060974121,
          0.7744140625,
          0.7794811129570007,
          0.7818396091461182,
          0.7617924809455872,
          0.7712264060974121,
          0.7653301954269409,
          0.8089622855186462,
          0.7724056839942932,
          0.7712264060974121,
          0.7712264060974121,
          0.7794811129570007,
          0.7948113083839417,
          0.7889150977134705,
          0.7665094137191772,
          0.775943398475647,
          0.7818396091461182,
          0.7900943160057068,
          0.794921875,
          0.7948113083839417,
          0.7735849022865295,
          0.7841981053352356,
          0.7641509175300598,
          0.7958984375,
          0.7653301954269409,
          0.7877358198165894,
          0.7900943160057068,
          0.8054245114326477,
          0.7712264060974121,
          0.802734375,
          0.8136792182922363,
          0.7802734375,
          0.7983490824699402,
          0.79296875,
          0.8089622855186462,
          0.7939453125,
          0.7936320900917053,
          0.8007075190544128,
          0.8054245114326477,
          0.8054245114326477,
          0.7924528121948242,
          0.7853773832321167,
          0.8054245114326477,
          0.8219339847564697,
          0.7971698045730591,
          0.7912735939025879,
          0.8089622855186462,
          0.7959905862808228,
          0.8115234375,
          0.7971698045730591
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Red"
         },
         "mode": "markers+lines",
         "name": "Validation accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200
         ],
         "xaxis": "x",
         "y": [
          0.2527075707912445,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.3140794336795807,
          0.31768953800201416,
          0.31768953800201416,
          0.3140794336795807,
          0.32129964232444763,
          0.3249097466468811,
          0.3249097466468811,
          0.3357400596141815,
          0.34296029806137085,
          0.3393501937389374,
          0.3465704023838043,
          0.3357400596141815,
          0.3357400596141815,
          0.33212995529174805,
          0.3465704023838043,
          0.371841162443161,
          0.3826714754104614,
          0.3826714754104614,
          0.3862815797328949,
          0.37906137108802795,
          0.371841162443161,
          0.371841162443161,
          0.3862815797328949,
          0.4476534426212311,
          0.4115523397922516,
          0.35740071535110474,
          0.3754512667655945,
          0.41877254843711853,
          0.41516244411468506,
          0.39350181818008423,
          0.41877254843711853,
          0.4440433084964752,
          0.4332129955291748,
          0.44043320417404175,
          0.44043320417404175,
          0.4368230998516083,
          0.46209385991096497,
          0.46209385991096497,
          0.46570396423339844,
          0.570397138595581,
          0.505415141582489,
          0.44043320417404175,
          0.4584837555885315,
          0.49819493293762207,
          0.4476534426212311,
          0.4368230998516083,
          0.5379061102867126,
          0.5920577645301819,
          0.39350181818008423,
          0.44043320417404175,
          0.5920577645301819,
          0.49819493293762207,
          0.46570396423339844,
          0.48736461997032166,
          0.49819493293762207,
          0.4729241728782654,
          0.4440433084964752,
          0.47653430700302124,
          0.5559566617012024,
          0.6028881072998047,
          0.5415162444114685,
          0.6245487332344055,
          0.7328519821166992,
          0.7292418479919434,
          0.7256317734718323,
          0.7220216393470764,
          0.7148014307022095,
          0.7292418479919434,
          0.6967508792877197,
          0.6859205961227417,
          0.750902533531189,
          0.7400721907615662,
          0.7184115648269653,
          0.7111913561820984,
          0.6823104619979858,
          0.6859205961227417,
          0.7220216393470764,
          0.6967508792877197,
          0.6317689418792725,
          0.7148014307022095,
          0.6101083159446716,
          0.38989168405532837,
          0.6750902533531189,
          0.7075812220573425,
          0.4837545156478882
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Blue"
         },
         "mode": "markers+lines",
         "name": "Training loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200
         ],
         "xaxis": "x2",
         "y": [
          2.2854549884796143,
          1.7937192916870117,
          1.6847985982894897,
          1.5887980461120605,
          1.5981701612472534,
          1.5854369401931763,
          1.5437898635864258,
          1.4844334125518799,
          1.4288768768310547,
          1.3657433986663818,
          1.3435044288635254,
          1.3162972927093506,
          1.2850443124771118,
          1.1817220449447632,
          1.2316354513168335,
          1.2290005683898926,
          1.259705901145935,
          1.1941378116607666,
          1.214147925376892,
          1.1416428089141846,
          1.2129573822021484,
          1.1408488750457764,
          1.1066908836364746,
          1.1562023162841797,
          1.1345444917678833,
          1.1163536310195923,
          1.0990381240844727,
          1.0684372186660767,
          1.0520257949829102,
          1.107916235923767,
          1.0411293506622314,
          1.0571918487548828,
          1.0258865356445312,
          1.0548598766326904,
          1.0587342977523804,
          1.004457712173462,
          1.0088075399398804,
          1.0562565326690674,
          0.9768092036247253,
          1.0165501832962036,
          1.007910132408142,
          1.0140864849090576,
          0.9707387089729309,
          0.9488126635551453,
          0.963078498840332,
          0.9487919211387634,
          0.9434301853179932,
          0.9411877393722534,
          0.9590327143669128,
          0.9484187960624695,
          0.9388238191604614,
          0.9791735410690308,
          0.9159135818481445,
          0.9191521406173706,
          0.8841660022735596,
          0.9233473539352417,
          0.9022241234779358,
          0.865252673625946,
          0.9042826294898987,
          0.8646011352539062,
          0.881766676902771,
          0.8822627663612366,
          0.9110512733459473,
          0.8473799228668213,
          0.8572828769683838,
          0.8992660641670227,
          0.8552551865577698,
          0.8610265254974365,
          0.8350604772567749,
          0.8668929934501648,
          0.8576327562332153,
          0.8319472074508667,
          0.8438794612884521,
          0.8615258932113647,
          0.7956181764602661,
          0.8471550941467285,
          0.8816659450531006,
          0.8703374266624451,
          0.8186614513397217,
          0.8004406690597534,
          0.8285518288612366,
          0.8009548783302307,
          0.7914127111434937,
          0.8083772659301758,
          0.8515093326568604,
          0.7761375308036804,
          0.7887724041938782,
          0.8119992613792419,
          0.8022007346153259,
          0.7888111472129822,
          0.7952515482902527,
          0.7647223472595215,
          0.7539772391319275,
          0.7800320386886597,
          0.8037928938865662,
          0.7632745504379272,
          0.7743887305259705,
          0.8087783455848694,
          0.7005769610404968,
          0.778908371925354,
          0.7548272609710693,
          0.7545645236968994,
          0.7353817820549011,
          0.7456114888191223,
          0.7506754398345947,
          0.7262545824050903,
          0.7189722061157227,
          0.6943867802619934,
          0.7358087301254272,
          0.7039619088172913,
          0.7299184203147888,
          0.6836197972297668,
          0.7150112390518188,
          0.7409588694572449,
          0.7227897047996521,
          0.7109100222587585,
          0.729559600353241,
          0.6998799443244934,
          0.6577631831169128,
          0.7443439364433289,
          0.7031159400939941,
          0.7009116411209106,
          0.693492591381073,
          0.6734068989753723,
          0.6789147853851318,
          0.6838377714157104,
          0.6637077927589417,
          0.6883721351623535,
          0.689154326915741,
          0.6608353853225708,
          0.6664891839027405,
          0.6419327855110168,
          0.6850079894065857,
          0.6658734083175659,
          0.6499443650245667,
          0.6426302790641785,
          0.6663435697555542,
          0.6352013349533081,
          0.6684931516647339,
          0.6491189002990723,
          0.6356284022331238,
          0.6187106370925903,
          0.6553142666816711,
          0.5896512866020203,
          0.662723183631897,
          0.6226564049720764,
          0.6146059632301331,
          0.649502694606781,
          0.5889423489570618,
          0.5708566904067993,
          0.6274827718734741,
          0.6128427982330322,
          0.6089799404144287,
          0.616124153137207,
          0.6399561166763306,
          0.6093028783798218,
          0.631337583065033,
          0.5719084739685059,
          0.6146824955940247,
          0.6390971541404724,
          0.6409600377082825,
          0.6311993598937988,
          0.5895293354988098,
          0.5856454372406006,
          0.6391756534576416,
          0.6044816970825195,
          0.6202067136764526,
          0.5948060154914856,
          0.5903024673461914,
          0.5739639401435852,
          0.6133630275726318,
          0.5783641934394836,
          0.6215018630027771,
          0.5790207386016846,
          0.6506912708282471,
          0.606096088886261,
          0.5545142292976379,
          0.5383936166763306,
          0.6170504093170166,
          0.547306478023529,
          0.5518696904182434,
          0.585563063621521,
          0.5593873262405396,
          0.5716264843940735,
          0.546116828918457,
          0.5823449492454529,
          0.5821613669395447,
          0.5616283416748047,
          0.5512475967407227,
          0.5414790511131287,
          0.5724446773529053,
          0.5604860186576843,
          0.5516423583030701,
          0.49986714124679565,
          0.5653153657913208,
          0.5678589940071106,
          0.5721365809440613,
          0.5460575222969055,
          0.5227712392807007,
          0.5377352237701416
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "Magenta"
         },
         "mode": "markers+lines",
         "name": "Validation loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200
         ],
         "xaxis": "x2",
         "y": [
          2.0342824459075928,
          1.9318040609359741,
          1.8865158557891846,
          1.9907792806625366,
          2.2655410766601562,
          2.646458387374878,
          3.0291402339935303,
          3.413933038711548,
          3.7292611598968506,
          4.130774021148682,
          4.59382963180542,
          5.002572536468506,
          5.3072509765625,
          5.588347434997559,
          5.823545932769775,
          6.0151166915893555,
          6.22698450088501,
          6.458346843719482,
          6.752956390380859,
          7.151134490966797,
          7.503211498260498,
          7.831171989440918,
          8.168243408203125,
          8.500691413879395,
          8.729349136352539,
          8.841485977172852,
          8.832568168640137,
          8.904426574707031,
          9.225708961486816,
          9.651226043701172,
          10.209046363830566,
          10.457070350646973,
          10.39037036895752,
          10.400089263916016,
          10.491072654724121,
          10.538717269897461,
          10.798531532287598,
          11.181305885314941,
          11.376587867736816,
          11.497909545898438,
          11.69468879699707,
          11.825303077697754,
          11.983328819274902,
          11.829169273376465,
          11.264144897460938,
          10.969416618347168,
          10.700736045837402,
          10.712992668151855,
          10.935458183288574,
          11.016803741455078,
          11.052082061767578,
          11.108241081237793,
          11.172221183776855,
          11.393461227416992,
          11.684662818908691,
          11.9161376953125,
          11.873723983764648,
          11.424368858337402,
          11.468823432922363,
          11.60201358795166,
          11.688835144042969,
          11.6602783203125,
          11.783440589904785,
          11.613733291625977,
          11.527928352355957,
          11.622566223144531,
          11.64091682434082,
          11.66879653930664,
          11.805145263671875,
          11.751765251159668,
          11.605962753295898,
          12.074092864990234,
          12.309632301330566,
          12.344564437866211,
          11.847161293029785,
          11.41295051574707,
          11.055761337280273,
          11.112914085388184,
          11.158289909362793,
          11.037458419799805,
          10.696224212646484,
          10.342090606689453,
          10.129770278930664,
          9.94093132019043,
          10.174393653869629,
          10.700433731079102,
          10.782219886779785,
          10.883099555969238,
          10.994565963745117,
          10.901906967163086,
          10.772595405578613,
          10.824300765991211,
          10.712946891784668,
          10.530867576599121,
          10.436683654785156,
          10.017441749572754,
          9.533473014831543,
          9.580467224121094,
          9.862212181091309,
          10.274983406066895,
          10.580677032470703,
          10.9353666305542,
          10.446418762207031,
          9.958812713623047,
          9.926007270812988,
          9.791545867919922,
          9.282553672790527,
          8.61900520324707,
          8.428930282592773,
          8.53524398803711,
          8.425677299499512,
          8.313384056091309,
          8.10543155670166,
          7.420853614807129,
          7.516162872314453,
          7.820462226867676,
          7.869488716125488,
          7.808805465698242,
          8.32304859161377,
          7.643454074859619,
          6.685848236083984,
          6.866359710693359,
          6.147719860076904,
          5.586920738220215,
          5.752534866333008,
          4.791925430297852,
          5.547813415527344,
          6.426828861236572,
          6.473331451416016,
          5.513209819793701,
          4.534229278564453,
          4.133686542510986,
          4.438822269439697,
          4.031431198120117,
          3.9677977561950684,
          4.1665754318237305,
          4.233756065368652,
          3.7723493576049805,
          2.8660380840301514,
          3.4223055839538574,
          4.5553741455078125,
          4.130596160888672,
          3.3146560192108154,
          3.586049795150757,
          4.053877353668213,
          3.317932367324829,
          2.7856874465942383,
          3.038097381591797,
          2.857508659362793,
          2.8037943840026855,
          2.9617745876312256,
          2.8400282859802246,
          2.6649301052093506,
          2.860682964324951,
          1.8151769638061523,
          2.2861006259918213,
          2.8502283096313477,
          2.5747721195220947,
          2.244903802871704,
          2.915816068649292,
          3.1331186294555664,
          1.8738964796066284,
          1.4869117736816406,
          4.044704437255859,
          3.131925344467163,
          1.5511113405227661,
          2.011411428451538,
          2.5265605449676514,
          2.424118995666504,
          2.3931796550750732,
          2.4213740825653076,
          2.7868003845214844,
          2.1900367736816406,
          1.5587886571884155,
          1.5151127576828003,
          1.9420667886734009,
          1.3365657329559326,
          0.944837212562561,
          0.9429832696914673,
          0.9339364767074585,
          0.9402732253074646,
          0.9371241927146912,
          0.9257727861404419,
          0.9833909273147583,
          1.040810227394104,
          0.9027076363563538,
          0.9296540021896362,
          0.9583683013916016,
          0.9663668870925903,
          0.978425920009613,
          1.0108639001846313,
          0.9557145833969116,
          1.1632376909255981,
          1.2295328378677368,
          0.967412531375885,
          1.246450662612915,
          2.425910472869873,
          1.111849308013916,
          0.9928534626960754,
          1.8765311241149902
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation accuracy",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.8765311241149902\n",
      "Test Accuracy: 0.4837545156478882\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, y_test,verbose=0)\n",
    "print(\"Test Loss:\",score[0])\n",
    "print(\"Test Accuracy:\",score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
